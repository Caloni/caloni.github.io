<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>blog on Blogue do Caloni</title>
    <link>http://www.caloni.com.br/tags/blog/</link>
    <description>Recent content in blog on Blogue do Caloni</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <lastBuildDate>Sun, 17 Jan 2021 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://www.caloni.com.br/tags/blog/" rel="self" type="application/rss+xml" />
    
     
        <item>
  <title>Um Delduca no Pedaço</title>
  <link>http://www.caloni.com.br/um-delduca-no-pedaco/</link>
  <pubDate>2021-01-17</pubDate>
  
  <guid>http://www.caloni.com.br/um-delduca-no-pedaco/</guid>
  <description>Esta série de anime obscura iniciou há mais de três décadas. Na época na região de Mococa, interior do estado de São Paulo, nasciam os primeiros computadores pessoais e esta é a história de um jovem que aprendeu a usá-los como ninguém.
Se renovando a cada nova temporada, a série foi se adaptando com o surgimento da internet e, principalmente, dos stickers. Foi nesse momento que a gama de espectadores aumentou consideravelmente. Até otakus desavisados acabavam assistindo, mal entendendo que a série criticava justamente esse comportamento nocivo de inanição social e incapacidade profissional.
Hoje a série ainda é exibida, mas poucos a conhecem. E é assim que toda obra de arte visionária costuma se manter: com um grupo de fãs coesos que nunca deixarão de ver conteúdo inteligente para ligar a Netflix.
</description>
</item>

     
        <item>
  <title>Resoluções 2021</title>
  <link>http://www.caloni.com.br/resolucoes-2021/</link>
  <pubDate>2021-01-02</pubDate>
  
  <guid>http://www.caloni.com.br/resolucoes-2021/</guid>
  <description>Inspirado no post que vi de meu amigo DQ sobre resoluções de ano-novo, algo que ele já vem fazendo desde 2007 (impressionante), resolvi compartilhar um pouco neste post sobre minhas resoluções de 2020. Na verdade não costumo fazer isso, mas ao passar a virada de 2019 para 2020 na casa de outro amigo, ele e sua esposa vieram com um presente e uma ideia para todo o grupo na ocasião: um caderno e uma caneta. Cada um deveria preencher nas primeiras folhas do caderno o que pretendia fazer durante o ano que se inicia. Algo mais ou menos assim, eu provavelmente já estava bêbado o suficiente para não me lembrar dos detalhes.
Hoje abro nesse momento o caderno cuja primeira página havia preenchido e nunca mais olhado. Eis a minha pequena lista:
 Assistir um DVD por semana. Escrever 10 minutos por dia. Andar de bike 1 vez por semana.  Vejamos os resultados.
Assistir um DVD por semana Acredito que tenha cumprido essa meta em sua maioria. Alterei a funcionalidade de busca no blog para conseguir filtrar os filmes assistidos que não foram em cabines de imprensa e deram 110 resultados. Sabendo que há 54 semanas em um ano e que durante o ano cada vez menos assisti conteúdo via streaming por conta da péssima qualidade do cinema e TV contemporâneos, em uma conta de padaria acredito ter atingido o objetivo na média. Outro fator que contribui para meus cálculos é a quantidade de pilhas de DVDs que foram desovados da nossa coleção temporária. (A ideia é assistir os mais de 400 títulos e vendê-los.)
Escrever 10 minutos por dia. Esse foi mais complicado. Houve momentos de grande hiato em que eu lia cada vez mais posts aleatórios sobre como praticar a escrita ou qual a rotina de escritores (o que basicamente se resume em sentar a bunda na cadeira e escrever), mas também houve momentos em que li conteúdo importantíssimo para melhorar minha concentração e o incentivo interno para assumir cada vez mais uma rotina de escritor, como o livro de Mihaly Csikszentmihalyi.
Nos últimos meses comecei a revisar todos meus textos antigos em ordem cronológica e tenho obtido sucesso através de uma rotina em que realizo anotações no Kindle na leitura antes de dormir e nos momentos de sentar a bunda na frente do computador busco por essas anotações e vou checando cada post antigo como não-rascunho. Como a maior parte são textos de filmes esta é minha métrica. Usando mais uma vez a nova busca constato que há 1921 textos de filmes de antes de 2020, e no momento deixaram de conter a tag draft exatos 311, ou seja, 16% de todos os textos antigos foram revisados.
Andar de bike 1 vez por semana. Consegui este feito com louvor em 2019, mas em 2020 caí nos mesmos imprevistos que o DQ comentou em seu post: chegou a pandemia e o isolamento. Praticamente não saí de casa ano passado. Devo conseguir contar nos dedos as vezes. E esta foi a tarefa alternativa a andar de bike.
Enfim, minhas resoluções para o ano que inicia:
Resolução 2021  Assistir um DVD por semana. Revisar textos antigos todo dia. Andar de bike 1 vez por semana.  Sim, continua basicamente o mesmo, exceto o foco no item 2 para revisão em vez de escrever novos textos. Com os novos dados sobre o contágio do vírus e vendo que as pessoas estão menos paranoicas a respeito disso, exceto as malucas, mas que não devo encontrar nas minhas pedaladas, resolvi manter minha tarefa número 3, o que para mim significa reativar minha bicicleta e adicionar mais um exercício semanal além do matinal, que realizei com significativa frequência esse ano.
Não irei adicionar mais tarefas, pois estas estão em andamento e devem continuar consumindo um tempo que é possível se comprometer.
</description>
</item>

     
        <item>
  <title>Degustações esporádicas de cervejas</title>
  <link>http://www.caloni.com.br/cervejas/</link>
  <pubDate>2020-12-27</pubDate>
  
  <guid>http://www.caloni.com.br/cervejas/</guid>
  <description> 2020-11-08 A Ambev lança a versão &amp;quot;Puro Malte&amp;quot; para suas &amp;quot;cervejas&amp;quot;. Experimentei a Skol e agora a Bohemia, que já era um tanto espumenta e doce para meu paladar. Ela continua espumenta, mas menos doce. São tantas gradações de mediocridade que se torna difícil diferenciar. Logo estaremos como naquele vídeo paródia de degustação de águas. 2020-11-08 Não tenho mais minhas anotações de cervejas, mas sempre posso começar de novo. E vou aproveitar agora, que fazia uns dois meses que não ia ao mercado e tive essa oportunidade. Peguei alguns rótulos de mercadinho de bairro, mesmo. Alguns ouvi falar bem dos amigos e conhecidos, outros por pura curiosidade. E um dos mais acessíveis foi essa Skol Puro Malte, a versão plus da cerveja conhecidíssima do pessoal de boteco e fãs de derivados de milho. O site da Ambev diz que esta edição é &amp;quot;leve e democrática&amp;quot;, tentando sugerir que agrada todos os gostos. De fato ela não é amarga o suficiente para não afastar os bebedores das cervejas doces e baratas do mercado, como a própria Skol tradicional. No entanto, é possível sentir um certo amargor a mais. É bem leve, mas se eu tiver que escolher entre a tradicional e esta, esta com certeza é preferência. 2019-07-01 IPA Gorillaz, da cervejaria homônima de Poços de Caldas, tem corpo parrudo, amargor amigo com os snacks de mandioca e batata fritas cortadas fininhas e sequinhas do Justo no Terraço, um lugar bom para música ao vivo mais tranquila e papear sem pressa de ir embora. 2019-07-01 Dama Bier IPA que é aquele amargor simples que sempre é sucesso quando não se quer prestar muita atenção à cerveja e mais à pizza do 430o em Jundiaí, massa feita com fermentação de 24 horas e estilo napolitana, com pizzas individuais pra comer com a mão. 2019-05-30 Goose Midway Session IPA é amargada com lúpulos aromáticos e vem para acompanhar um queijo mais parrudo ou alguma comida picante. 2019-05-30 Faxe IPA é uma IPA mais fortinha, com amargor sólido. É interessante, mas ainda prefiro as outras cores da latinha. 2019-04-13 Degustação no Kloser revelou cerveja com gosto de sorvete da infância. 2019-02-28 Praya Wit Bier é uma cerveja do Rio de Janeiro com corpo muito leve e desnecessariamente valorizada. Ignore. 2019-02-03 PS: A Carmen Cerveja Forte Clara com Laranja e Maracujá você acha essa cerveja nas Empanadas La Guapa em Pinheiros. 2019-02-03 Carmen Cerveja Forte Clara com Laranja e Maracujá já diz tudo pelo seu nome. O consumidor não deve intepretar pois não possui senso crítico. Nada melhor que uma cerveja forte, clara, com laranja, com maracujá e sem exigir cérebro do degustador. Um brinde! 2019-01-04 Colorado ICI 02 French IPA (chope) é amargurado na medida com lúpulos aromáticos franceses, o que a torna menos amarga (porque franceses são bixas) mas mais fácil de beber sozinha, o que lhe dá um ótimo atrativo para esse verão dos infernos em terras tupiniquins. 2019-01-02 Vixnu é uma Imperial IPA, o que quer dizer um soco no estômago., mas por ser uma Colorado também quer dizer que esse soco está equilibradíssimo entre as doses de malte e lúpulo, com aromas detectáveis só de cheirar. Aprecie com comidas fortes. 2018-12-30 Minerva Viena de Guadalajara é uma cerveja artesanal mexicana que vende dentro do aeroporto da Cidade do México. E não é aguada, é bem saborosa enquanto leve. 2018-11-23 Blue Moon IPA possui corpo médio e é cítrico em vez de lupulado aromático, fácil de beber. 2018-11-21 Minerva artesanal do México é uma draft de corpo médio pra fraco com final de café por causa do malte tostado. Fica bom com nachos do lugar onde comemos no aeroporto. 2018-11-05 Tupiniquim Session IPA tem amargor, mas é constante e médio, como seu corpo; para um kebab seja demais, mas foi com ele que eu tomei. 2018-11-05 Tupiniquim Chocolate é uma cerveja escura tipo stout cujo sabor lembra mais café, apesar de não ter café em sua composição (é só a torra do malte). Bom pra tomar sem nada embora a dica é com algum doce à base de chocolate. 2018-11-05 Tupiniquim Anunciação IPA é porradinha no estômago, mas seu lúpulo parece de respeito. Sinceramente, minha memória alcoólica deteriora na velocidade da luz. 2018-11-05 Invicta Saison tem aroma de coentro e não é soco no estômago como todas as Invictas que já provei (inclusive na própria cervejaria). É leve, clara, aromática e gasosa. 2018-11-05 Faxe Royal Export é uma dinamarquesa com malte leve, mas menos leve que uma pilsen: tem presença enquanto você bebe. Foi a porta de entrada da nova casa do Incrível. 2018-11-05 Burgman Midnight Riders é surpreendentemente uma Weiss, mas não tão doce como costumam ser as Weisses, nem tão gasosa. A palavra chave é: surpreendente. 2018-11-05 Burgman Fun Weiss é menos weiss ainda que a Midnight Riders. Eu não me lembro mais que isso. 2018-10-28 Colorado Okto Session tem pouco álcool, lembra Tubaína e vem com caju. O amargor é sereno com corpo fraco pra médio; boa pedida com castanhas de caju. 2018-10-02 Exterminador de trigo American Wheat. Essa receita da Três Lobos com Capim Limão poderia ser melhor. Mal misturado, gosto ameno, tem corpo médio demais para um wheat. 2018-09-25 O chope Putz IPA têm lúpulos cheirosos e corpo leve, pouco alcoólico e bem agradável gelado. Ou seja, nem parece IPA. 2018-09-25 Coruja Pilsen é uma... pilsen? Bom, tem um salgadinho próximo de uma witbier prestes a ser esquecida. 2018-09-23 O chope da Strappa Gingerberry é um chá preto fermentado com gengibre e gradação alcoólica ridícula de 0.6%. Ele é ainda frutado (possui morango) e deixa a garganta quentinha. Ótima opção entre bebidas mais fortes. Dá uma pausa etílica e estilosa na balada. 2018-09-22 Kairós Sol Poente é uma West Coast IPA de respeito. Equilibrada de corpo leve, seu chope é aromático e um pouco salgado com amargor presente sem exageros. 2018-09-20 O Saint Golden Ale é ligeiramente melado, corpo médio com pouca espuma. Artesanal da região de Floripa, bom custo/benefício. Primeira cerveja da viagem do Native Floripa. 2018-08-26 Dogfish Head Namaste White Belgian-Style Witbier. Com esse nome longuíssimo é óbvio que não é legal. Se trata de uma Witbier esquecível, cítricazinha, levezinha, espumazinha. Tudo inha para uma cerveja que se chamacomo é o nome, mesmo? 2018-08-09 Colorado Ithaca é selada com um material plástico/borracha vermelho e uma produção limitada e inacessível nos grandes mercados. Ela é preta, densa, intomável em vários goles (tente para ver como estragar uma garrafa). O sabor de rapadura se mistura com o lúpulo agressivo, e a bebida merece o mais forte e gorduroso dos pratos com louvor. 2018-08-08 Ruddles County English Ale. Uma Cream Ale porcamente estocada pelo OMalleys, o pub que faz um tempo não sabe muito bem o que está fazendo (se continua enchendo a culpa é dos Paulistanos, imagino). É uma cerveja da promoção da semana, que contém equilíbrio no lúpulo e pouco gás. Fácil de ingerir e de esquecer. 2018-08-08 Double Hop Monster IPA. Mais uma amostra do OMalleys, mas essa nem eles conseguiram estragar. Essa Double IPA é intensa na medida certa para quem quer apenas um copo para degustar por uma hora. Um gole é uma memória. Corpo médio para forte com intensidade de sabores que vai te fazer bebericar novamente assim que puder. 2018-08-06 Tripel Karmeliet é uma blonde Belgian beer bem alcoólica, mas que você não sente, pois seu aroma cítrico é mais potente sempre. Ela desce tão fácil e vai liberando novos aromas conforme a temperatura sobe de 4 a 15. Para quem não gosta do amargor da cerveja. 2018-08-06 Mafiosa Consiglieri Double India Pale Ale é, de acordo com o rapaz da Cervejoteca, a melhor IPA do mercado. E ela possui aquele equilíbrio que gostamos quando não queremos apenas sentir lúpulo. Às vezes o negócio da cerveja lupulada não é o amargor sem fim, mas apenas a impressão de estar bebendo algo que encaixa em nossa vida. 2018-08-06 La Guapa Carmen é a cerveja do restaurante anônimo produzida pela ZalaZ, de Paraisópolis (mineira), que é leve o suficiente para ser degustada e pesada o suficiente para ser degustada com empanadas. Seu aroma de laranja e maracujá do rótulo dá um tom cítrico, mas pouco perceptível por conta de seu corpo leve. 2018-08-06 Colorado Murica é mais um dos experimentos da cervejaria do urso com frutas. Dessa vez a escolhida é a graviola, e, rapaz, o Sr. Laércio Shiya, Mestre Cervejeiro desde sempre, sabe fazer as coisas bem feitas em pequena e grande escala. 2018-08-06 Bierland Witbier. Nunca me decepciono com os resultados dessa cervejaria de Blumenau. Aqui eles te entregam uma Witbier tão equilibrada que ela arrisca agradar gregos e troianos, no sentido que há pouquíssimo amargor, mas ele é sólido, e seus tons cítricos e sua espuma conferem o corpo e maciez. 2018-07-26 1681 Schloss Eggenberg Flopfen Rönig é de uma cervejaria bem antiga da Áustria, feita em um castelo, e que nessa edição nos traz um sabor rapidamente intenso, um pouco de sal, cítrico e aromas que se esvaem rapidamente. É uma cerveja boa para tomar sozinha se quiser. 2018-07-16 A Colorado Cauim 016, que mantenho algumas garrafas em estoque, é uma Pilsen, mas não é uma Pilsen qualquer. Ela não é tão amarga, possui corpo fraco a médio, ou talvez até médio, e também frescor no aroma e um toque cítrico no sabor, com after que lembra manga, tangerina, ou algo próximo. 2018-07-15 A Brewdog Punk IPA, essa sim, vale a pena. Lupulada com aroma, amarga na medida certa e com um after completo, que cobre a boca toda, essa versão da cervejaria do Reino Unido merece palmas pela conquista em latinha. 2018-07-13 A Brewdog que o Incrível achou na lojinha da liberdade se chama Indie Pale Ale, o que parece uma brincadeira, pois no fundo se trata de um pilsen leve, que embora aromático e um tanto com certos tons condimentados, seu corpo é muito leve e amargor inexistente (ou some tão rápido que não se constrói um after sensível). 2018-07-07 O chope da Colorado Demoiselle na degustação ao final visita da Toca do Urso, demonstrando o sistema de auto tap (My Tap, acho que é o nome), revela uma cerveja surpreendentemente aromática, algo difícil de sentir nas engarrafadas. O colarinho é delicioso e o sabor misto da cerveja e da espuma sugerem fortemente o café. Amargor um pouco enjoativo, mas saboroso. 2018-07-07 Este foi o grande achado na visita da Toca do Urso. A pilsen com Dry Hopping Cauim 016, parte da degustação, é uma pilsen aromática e equilibrada. Chega a ter o corpo quase médio, mas peca um pouco pelo after. De qualquer forma, o chope vale muito à pena. 2018-07-07 Colorado Eugênia fez parte da degustação da visita da Toca do Urso e me ganhou pelo frescor que ela oferece em detrimento às mais potências. O corpo é médio para forte, mas o tom cítrico compensa. 2018-07-07 Assim como o Colorado Murica, que tem um creme aromático e um sabor igualmente cítrico, mas mais frutado, pois vem da graviola. 2018-06-20 Grolsch Premium Lager. Cerveja de corpo leve para média, acompanha bem comida árabe desse restaurante inusitado de Tucumán na Argentina. 2018-05-26 Ashby Pale Ale. Essa cerveja de Amparo é bem melada para uma Pale Ale e tem um final de amargo adoçante que não me agrada. Mas é consistente e pode combinar bem com pratos semi doces, como o ensopado de curry que a mulher fez para harmonizar. Consumir em ritmo médio porque tem corpo médio e é cerveja para assistir standup na Netflix. 2018-05-20 Old Specked Hen é uma Ale meio sem graça para temperaturas frias (pela falta de gás) e sem graça em temperaturas quentes (pela falta de gosto). Pode estar choca, mas mesmo choca teria que ter potência. Seu corpo é uma pilsen glorificada com uma coloração bonita. Não serve para acompanhar séries fortes como Happy é muito menos para gastar em conversas animadas com amigos. Deixe na prateleira (exceto se for sensível). 2018-04-19 Eisenbahn Pale Ale. Tem no mercado da frente de casa, é um bom custo/benefício; então sempre tem na geladeira; seu amargor é desequilibrado demais, e um tanto aguada, mas melhor que a maioria das pilsen, então 2018-04-06 Wäls Petroleum. Sinceramente, esta passou do ponto; intensamente intensa, feita para quem gosta de café forte e está muito bêbado para perceber nuances; harmonizar com socos na cara. 2018-04-06 Insana APA. Segunda prova desta APA nacional deu a sensação dela ser mais aromática que saborosa; mas continuemos tentando. 2018-03-16 Schornstein Witbier. Esta Witbier combina perfeitamente com o peixe do Uokatsu, que começou a oferecer a linha dessa pequena e consistente cervejaria de Pomerode; corpo fraco pra médio, amargor quase inexistente; uma pilsen com sabor, elegância e refrescância. 2018-03-15 Mohave Yucca Witbier. Mais uma Witbier interessante dessa cerejaria artesanal carioca que nasceu entre amigos; em corpo médio é um ótimo começo de noite com comidinhas. 2018-03-10 Madalena Double IPA. É forte, densa, corpo violento, mas que não mantém um amargor; o lúpulo vira outra coisa, toma forma própria e te ataca ou te abraça; um dos dois irá acontecer. 2018-03-10 Goose IPA. Um pequeno soco no estômago que te manda acordar da vida e saborear esta cerveja lupulada com intensidade sem perder o frescor; colarinho de respeito. 2018-03-10 Colorado Appia. Uma nuvem de bitter e frescor que se aproxima da mescla entre uma Pilsen e algo a mais que ela e a Serra Malte possuem. 2018-02-23 RedCor Intrigante American Wheat Rye. A cervejaria de Maringá que agora produz suas cervejas em Blumenau oferece um ponto de entrada entre uma Blonde e uma IPA com esta Wheat Rye frutada de corpo médio e amargor constante; é difícil não perceber que ela consegue ser refrescante mesmo mais forte que uma pilsen. 2018-01-30 Serra Malte. Semi gelada em um dia gelado ela oferece a manutenção da temperatura do corpo um pouco abaixo; seu amargo maltado é agradável e perene. Tomando no japonês da Bom Pastor com carne e gengibre. 2018-01-08 Ouropretana Pale Ale. Não havia a Ouropretana mais amarga, mas essa quebrou o galho no pub de Ouro Preto. 2018-01-07 Wee Heavy Bodebrown Strong Scotch Ale. Cerveja que o Rodrigo da Kelly guardou por um ano e maio. Uma cerveja com xarope forte, amargo e levemente doce com corpo médio. Bom com torresmo que trouxemos do Recanto do Antônio. 2018-01-07 Diamantina Blonde Ale. Com IBU 20, é bem leve e equilibrada. Uma das cervejas mais equilibradas, embora de corpo fraco, dessa viagem. Uma das cervejas de presente pro Rodrigo que ele abriu conosco. 2018-01-05 Dos Caras American Wheat. Para um trigado não muito doce nem denso. Tomado no Pub Catedral. 2018-01-03 Dos Caras California Common. Uma das cervejas dessa cervejaria de Nova Lima, próximo de BH, mas tomado em Diamantina (no restaurante de esquina próximo da descida). 2018-01-03 Ashby Pale Ale. Um pale ale de Minas (Amparo) com corpo fraco para médio como uma Lagger e ligeiramente amarga. Primeira visita no restaurante Recanto do Antônio tomado com o PF do dia (frango). 2018-01-02 Krug Bier Chope. Um blonde equlibrado, denso, corpo médio. Produzido artesanalmente na região de Diamantina e tomado primeira tarde na viagem do ano-novo de 2018 no Pub Catedral, sentado no bar. 2017-10-20 Paulaner Salvator Doppelbock. Boa, mas acho que doce além do que gosto. Tomando com pão e carne louca. 2017-10-07 Bohemia 838 Pale Ale Corpo leve demais para um Pale Ale, chega a ser Pilsen. Com salsicha e queijo na airfryer. 2017-10-05 Bohemia 14-Weiss. Doce, equilibrada, aromáticas; corpo fraco pra uma Weiss, perde gás fácil. Tomei com pizza que achamos perto de casa. 2017-09-28 Colorado Indica Pale Ale. Amarga ligeiramente acima do ponto, corpo médio pra forte. Acompanhando batatas ao forno com bacon, salsichão e alho. 2017-09-13 Eisenbahn Extra Escura Dunkel. Combina perfeitamente com carne reduzina na pressão, como a que a Mitiko fez no almoço de hoje. 2017-09-12 Eisenbahn Extra Escura Dunkel. Não tão doce quanto a última vez que provei; uma dunkel que tem gosto de café por conta do malte cerrado; bom corpo e não-enjoativo. Almoço com bifum e purê apimentado. 2017-09-09 Chope Gonçalvez IPA Poços de Caldas. Não tão forte, mas muito equilibrada. Tomada direto na cervejaria na avenida em Poços. 2017-09-08 Chope Gorillaz Lager Poços de Caldas. Encorpada e não tão doce; colarinho cheio de aromas. Tirada perfeitamente no Justo no Terraço em Poços. 2017-08-07 Paulistânia IPA Caminho das Índias. Forte quase além do limite... mas aguenta bem. No Recanto encontro da BF owners. 2017-08-07 Hacker-Pschorr Munich Gold. Para uma cerveja puro malte ainda falta bastante malte; voltar para a Proibida. Bebi com o Strauss na reunião de acionistas no laguinho. 2017-07-27 Colorado Indica Pale Ale. Amarga no ponto, corpo médio pra forte. Acompanhou bem as azeitonas pretas pós-hambúrguer com chips de batata-doce. 2017-07-25 Ravache Puro Malte. Corpo leve demais para um puro malte; muita propaganda para nada. 2017-07-20 Wäls Session Citra. Refrescante, leve, fácil de tomar com comidinhas. Como no almoço com o Taz no Chez. 2017-07-20 Wäls Hop Corn IPA. Encorpado e um pouco além de amargo. Não acompanhou muito bem com a comida do Chez, onde eu e o Taz almoçamos. 2017-06-07 Colorado Appia. Ele tem um doce sutil, assim como amargo; lembrar de tomar por inteiro, como Weiss. Em casa, não lembro o que comia. 2017-06-07 Baden Baden American IPA. O doce sobrepõe o amargo e não fica agradável, mesmo com amendoim de wassabi. Em casa com amendoim de wassabi. 2017-06-01 Baden Baden American IPA. Muito doce para uma IPA; sobressai ao amargo e fica enjoativo. 2017-05-31 Chope Guiness. Equilíbrio entre doce, amargo e um toque de café. 2017-05-29 London Pride (garrafa). Um amargor intenso sem agredir o paladar. 2017-05-24 Wild River Double Hopped Pale Ale. Red Ale que parece Pale Ale não tão amarga. 2017-05-15 Imperial Lager. Meio refrescante, meio amarga. Penúltimo almoço no Dubai, restaurante árabe de Salta. 2017-05-14 Salta Negra. Gosto de café, pouco doce, after espumoso. Primeiro jantar no Dubai, restaurante árabe de Salta. 2017-03-25 Kirin Ichiban Puro Malte. Uma cerveja pilsen maltada que rivaliza com a Proibida. 2017-03-25 Dom Casmurro IPA. Excelente equilíbrio de amargor, frutado e muito aromático. 2017-03-21 Lohns Bier IPA. Bem amargo, quase demais. 2017-01-05 Patagonia Weiss. Doce, mas não tanto. Agradável. 2017-01-05 Cervejaria Nacional Stout. Equilíbrio entre amargo e doce. 2016-12-27 Chimay Pères Trappistes. Ela é bem amarga para uma trigada, mas possui um equilíbrio interessante. 2016-12-04 Patagonia Amber Lager. Pouco densa, pouco amarga e pouco doce; uma combinação equilibrada. 2016-12-04 Ashby Ganesha IPA Ambar. Cor âmbar densa, amargor constante, bem pesada para tomar desacompanhado. 2016-11-24 Budweiser Lager. Tem um ótimo custo benefício. Parece ter voltado a ser levemente mais forte que as outras. 2016-06-01 Ipaipim. É uma IPA com aipim (mandioca), mas quase não dá pra notar com esse amargor todo. 2016-05-29 Shorstein Pale Ale. Amargor equilibrado, não muito intenso. Não muito barato. 2016-05-29 Shorstein Imperial Stout. Gosto de defumado, pouco melado e amargo. Bem caro. 2016-03-05 Serra Malte. A pequena é ótima, pois enjoa mais devagar, e é tão intensa... 2016-01-31 Löwenbräu. Um pouco fraca, mas agradável; um pouco espumosa demais. 2016-01-30 Bäcker Pale Ale. Balanceada, um ótimo custo/benefício. 2015-11-09 Caá Yari. Doce com o amargor característico de uma Belgian Blonde Ale. 2015-10-27 Jabutipa IPA. O amargo da Boemia, cujo amargor não tem muito aroma ou sensação, mas foda-se: É amargo pra caralho. 2015-09-28 Eisenbahn Pilsen. Mais consistente, menos aguada que a maioria; não muito forte. 2015-09-24 Hoegaarden trigada. É trigada, mas não tão doce; bem encorpada. 2015-09-13 Colorado Café. Equilibrando doce e amargo, um pouco aguada (sem lúpulo), e talvez lembre café. 2015-08-30 Therezopolis Gold Malte Dunkel. Um pouco doce demais, o amargo no ponto; não tomar muito gelado, nem quente; vai bem com Yakissoba. 2015-08-06 Original. Tomei com o Strauss no almoço PF, meio aguado e incha demais. 2015-07-25 Serra Malte. Experimentei ao visitar a tia Margarete, muito bom ainda. 2015-07-17 Brahma. Aguada, muito gás, depois de um tempo é impossível tomar mais. 2015-07-10 Serra Malte. Experimentei de novo em Minas, é muito bom e forte (e lá barato). 2015-06-21 Therezopolis Gold. Agradável, mas bem forte; não combina muito bem com comida apimentada. 2015-06-21 Ravache Pale Ale. Bem amarga, bom para acompanhar algo, mas sozinha fica um pouco demais. 2015-05-01 1906. Importada, um amargo que dá pro gasto. 2015-01-27 Tiradentes: Áustria Krug Bier Premium 100% Malte. Uma Pilsen equilibrada, que não parece aguada, e um ótimo custo-benefício (se não estivesse em Tiradentes) 2015-01-13 Ouro Pretana Americana Brown Porter. Muito equilibrada, pouco doce e pouco amargo com pouca espuma; ímpar. 2015-01-07 3 Lobos Bravos. Muito espumoso, e o gosto de açúcar não é muito bom, é enjoativo; não aguentei. 2015-01-04 Ouro Pretana Pale Ale. Bem equilibrado; refrescante com amargor e um pouco de doce.  </description>
</item>

     
        <item>
  <title>TIL: Today I Learned</title>
  <link>http://www.caloni.com.br/til/</link>
  <pubDate>2020-12-08</pubDate>
  
  <guid>http://www.caloni.com.br/til/</guid>
  <description>Se você guardar o mínimo de conhecimento que aprendeu em um dia de sua vida e relembrá-lo ao longo dos anos não vai perceber qualquer diferença, pois com a internet fica fácil recuperar o conhecimento com nova pesquisa. No entanto, na internet está também você e seu conhecimento em forma de posts, comentários, podcasts ou qualquer tipo de conteúdo que você produziu. Não custa manter a rotina de gravar o que foi aprendido em um dia para tentar capturar a essência de cada um deles. Quem sabe algo de esclarecedor sobre nós mesmos não pode surgir disso.
  2020-08-07: ao usar ponto (.) antes de rodar um comando no terminal Linux é possível definir variáveis de ambiente. Com isso consigo definir o ambiente para fazer cross compiling em Golang no Linux para Windows, gravando as variáveis em um arquivo executável &amp;quot;export GOOS=windows; export GOARCH=amd64; etc&amp;quot; e chamando com &amp;quot;. meu_arquivo&amp;quot; no terminal.
  2020-10-22: para desabilitar expiração de senhas no Oracle o comando alter user user_name identified by new_password account unlock; resolve. Para as senhas não expirarem novamente em ambiente de desenv é só usar o comando ALTER PROFILE &amp;quot;DEFAULT&amp;quot; LIMIT PASSWORD_VERIFY_FUNCTION NULL; uma vez no banco.
  2020-10-22: para apagar tags dos posts é possível usar o seguinte comando sed -e &amp;quot;s/\[ \&amp;quot;tag\&amp;quot;[,]*/[/&amp;quot; -e &amp;quot;s/[,]* \&amp;quot;tag\&amp;quot; ]/ ]/&amp;quot; -e &amp;quot;s/, \&amp;quot;tag\&amp;quot;, /, /&amp;quot;.
  2020-10-26: para dar sleep em C&#43;&#43; moderno com resolução de milissegundos é std::this_thread::sleep_for(std::chrono::milliseconds(200));. É tão intuitivo que achei preciso anotar.
  2020-11-21: para eliminar qualquer nova-linha em uma string C após ler uma linha da entrada usar uma desconhecida função padrão: buffer[strcspn(buffer, &amp;quot;\r\n&amp;quot;)] = 0;.
  2020-12-08: é possível abrir uma VPN pelo WSL e direcionar a porta RDP de uma máquina remota para uma porta local no Windows e acessar máquinas via RDP em uma porta local. Para a VPN uso o Openvpn. Para o redirect um projeto no GitHub chamado rinetd.
  </description>
</item>

     
        <item>
  <title>Transmatrix</title>
  <link>http://www.caloni.com.br/transmatrix/</link>
  <pubDate>2020-12-06</pubDate>
  
  <guid>http://www.caloni.com.br/transmatrix/</guid>
  <description>Os irmãos Wachowski hoje são irmãs. Ambos passaram por cirurgias de mudança de sexo. Recentemente, durante entrevistas sobre a produção de Matrix 4, foi comentado por uma delas que o primeiro Matrix era uma alegoria sobre transexualidade.
De fato. Ao reassistir com essa visão é possível observar a dedicação dos diretores em mostrar o esforço sobrehumano do resgate de Neo. Antes de ser abduzido pela nave comandada por Morpheus ele era um ser do underground sem nenhuma marca de injeção de drogas ou substâncias alteradoras de humor. Logo após isso vemos o lento e doloroso processo em transformá-lo em um ser humano funcional fora da realidade virtual mantida pelas máquinas. Ele possui vários orifícios em torno do corpo, nos membros e tórax, sendo o principal deles, o mais sensível, na nuca, em uma conexão direta com o cérebro.
A analogia é forte demais com os transexuais. Dispostos a ir em busca da verdade eles submetem seu corpo a todo tipo de manipulação e humilhação. O resultado é alguém que aprendeu sobre a realidade em um outro nível, mas que nunca mais poderá se tornar um ser humano completo. Sua existência é ser um mutilado vivendo no esgoto.
Claro que Matrix permite fazer analogias com várias filosofias diferentes, pois o conceito, desde A Caverna de Platão, é muito vasta. Peço apenas que note o quão a produção é dedicada a esmiuçar o processo de transformação de Neo. É um foco que havia passado despercebido por muita gente porque ninguém imaginou a reviravolta na vida das agora irmãs diretoras, nem sabe a desgraça que é viver vilipendiado em nossa realidade. É uma dor nunca antes mostrada em uma ficção científica com tanto afinco.
</description>
</item>

     
        <item>
  <title>Festa de Família</title>
  <link>http://www.caloni.com.br/festa-de-familia/</link>
  <pubDate>2020-09-29</pubDate>
  
  <guid>http://www.caloni.com.br/festa-de-familia/</guid>
  <description>O Dogma 95 foi um movimento iniciado por diretores escandinavos como Lars von Trier (conhecido fã de Hitler e seu trabalho) que &amp;quot;prega&amp;quot; que um filme para fazer parte do Dogma deve seguir uma série de limitações em sua produção, como ausência de sons inseridos, a câmera deve acompanhar os atores onde eles forem (então ausência de iluminação artificial também). Ausência de qualquer peça de cenário que já não fizesse parte da locação. A lista é bem extensa e torna a tarefa do diretor mais desafiadora e interessante.
E por isso que este representante do Dogma 95 até que é bem feito, o que faz pensar se não estamos saturados de efeitos no cinema que nos impedem de ver a coisa real. A edição, os diálogos e o movimento da câmera fazem todo o serviço de não sentirmos falta de ver algum filtro específico para dramas familiares. E neste filme o que mais pesa é o seu drama de família escancarado para todos verem. É um vexame a céu aberto. E ele escala como você nunca viu em suas festas de fim de ano com os cunhados que gostam de falar de política junto das piadas de pavê.
</description>
</item>

     
        <item>
  <title>Kaynã</title>
  <link>http://www.caloni.com.br/kayna/</link>
  <pubDate>2020-09-29</pubDate>
  
  <guid>http://www.caloni.com.br/kayna/</guid>
  <description>Doce, pouco ácido. Feito em uma fazenda orgânica que visitei com amigos há um ou dois anos, a fazenda produz alimentos sustentáveis e tentam diminuir ao máximo as pegadas de carbono. A torra deste café é média, mas possui bom corpo e amargor leve. Você pode encontrá-lo moído ou em grãos no mercado Santa Luzia em São Paulo. Eles entregam na capital de bike. É muito esforço para deixar de ser admirável. E é um bom café de verdade.
</description>
</item>

     
        <item>
  <title>Mr. Bean</title>
  <link>http://www.caloni.com.br/mr-bean/</link>
  <pubDate>2020-09-29</pubDate>
  
  <guid>http://www.caloni.com.br/mr-bean/</guid>
  <description>Apesar das ideias e piadas ultrapassadas, o que não acometeu o experimental Monty Python, por exemplo, essa série britânica dos anos 90 brilha mais pelo humor físico de seu protagonista, Mr. Bean, que brinca de referenciar as piadas internas sobre os comportamentos condenáveis de um britânico. Bean faz um Chaplin da Rainha com um timing e expressões admiráveis. Figura no imaginário popular até hoje, mais até que Jim Carrey. É difícil lembrar de como Carrey era bom no humor físico porque suas piadas eram muito boas. É fácil lembrar de Mr. Bean porque sendo as piadas medíocres o ator tinha todo o palco para ele. E brilhava.
</description>
</item>

     
        <item>
  <title>Parks and Recreation</title>
  <link>http://www.caloni.com.br/parks-and-recreation/</link>
  <pubDate>2020-09-29</pubDate>
  
  <guid>http://www.caloni.com.br/parks-and-recreation/</guid>
  <description>Já vi episódios espalhados dessa série em alguns momentos nos últimos dez anos. A primeira ou segunda temporada já concluí com certeza. Mas ainda estou incerto se vale a pena assistir até o final, assim como The Office, embora este arrisque um pouco mais nos perder (uma coisa boa em séries e filmes que geralmente é menosprezado). Amy Poehler é tudo de bom, mas os personagens secundários empalidecem. Inexplicável como alguns deles se deram bem no show business, seja como comediante de standup e série netflixiana ou como heróis de sagas multimilionárias. Já a série é uma comédia leve para passar o tempo e pensar em como o governo ser inútil não é uma questão de opinião, mas de tempo.
</description>
</item>

     
        <item>
  <title>Seinfeld</title>
  <link>http://www.caloni.com.br/seinfeld/</link>
  <pubDate>2020-09-29</pubDate>
  
  <guid>http://www.caloni.com.br/seinfeld/</guid>
  <description>Seinfeld é um comediante nerd: passou boa parte de sua carreira atrás dos holofotes criando piadas diariamente e catalogando sua estreia na TV. Já nele ele encaixa boa parte delas em episódios que misturam sua vida como o personagem do comediante de standup. Ou estou confundindo com o modelo de Louie, que é infinitamente melhor? Ele não é ator, está longe de ser, e a série é de improviso. Funciona médio, mas se tornou cult, assim como Friends, ou qualquer série que você assista demais e simpatize com aquelas pessoas como velhos amigos de sofá. Hoje é uma curiosidade.
</description>
</item>

     
        <item>
  <title>The Boys</title>
  <link>http://www.caloni.com.br/the-boys/</link>
  <pubDate>2020-09-29</pubDate>
  
  <guid>http://www.caloni.com.br/the-boys/</guid>
  <description>Quando você assiste uma série com quase uma hora o episódio você espera o mínimo de profundidade. Mas todos moram na mesma vizinhança em The Boys, e isso me entedia em uma série com heróis inseridos em uma realidade Watchmen em uma fase mais trumpiana, menos pesada que Nixon (ou como Watchmen entendia esse período da história americana). O cinismo e mal-caratismo também faz parte do pacote do que significa ser um herói nesta realidade, que envolve ser uma celebridade acima de tudo, mas por detrás das câmeras um político. Quando um deles mata uma cidadã inocente por estar passando em velocidade super-sônica isso desencadeia a aparição de todos os personagens que veremos na série, que se conectam logo no primeiro episódio, como deve ser, mas de maneira preguiçosa, como só o streaming faz por você. Porque todos moram na mesma rua e podem se encontrar casualmente no Personal Central Park da vizinhança. Até Homem-Aranha e sua Nova-York bairrista soa mais realista. Não sei, estou rimando hoje.
</description>
</item>

     
        <item>
  <title>The Feed</title>
  <link>http://www.caloni.com.br/the-feed/</link>
  <pubDate>2020-09-29</pubDate>
  
  <guid>http://www.caloni.com.br/the-feed/</guid>
  <description>Um thriller futurista meio dark. O mistério no ar no primeiro episódio não é tão eficiente para querermos ver mais, e o universo concebido para a trama minimalista. O conceito, no entanto, é curioso. Ainda que pouco explorado. Um elenco britânico misturado com outras etnias são um plus, mas não convence. Nem os atores negros, claramente escalados por cotas de diversidade (mas competentes, só que sem função na narrativa). Todas as ideias que constrõem as teorias do mundo conspiratório de hoje traduzidas nesse conceito de mentes conectadas. Daria um bom episódio de Black Mirror, mas não uma série inteira.
</description>
</item>

     
        <item>
  <title>Bispo e Cavalo</title>
  <link>http://www.caloni.com.br/bispo-e-cavalo/</link>
  <pubDate>2020-09-05</pubDate>
  
  <guid>http://www.caloni.com.br/bispo-e-cavalo/</guid>
  <description>Já havia estudado este final há muito tempo e nem lembrava mais. Ter empatada uma partida porque não consegui dar mate forçado com bispo e cavalo é o que me fez rever o estudo. Assisti alguns vídeos e pratiquei com alguns estudos no Lichess. Por fim, me pus a jogar com o computador até entender a dinâmica de cercar o rei e realizar o movimento de W com o cavalo. Eu sei que ainda terão partidas que me sentirei acuado por conta do tempo, mas é bom agora voltar a ter o mínimo de arcabouço lógico por trás desse fascinante e difícil final. Tão difícil que até GMs não conseguem aplicar às vezes.
</description>
</item>

     
        <item>
  <title>Jejum de Dopamina</title>
  <link>http://www.caloni.com.br/jejum-de-dopamina/</link>
  <pubDate>2020-08-29</pubDate>
  
  <guid>http://www.caloni.com.br/jejum-de-dopamina/</guid>
  <description>Na verdade é um jejum de super estímulos, que tem por objetivo apagar o incêndio causado pelos neuroreceptores de dopamina de hábitos compulsivos em busca de prazer fácil para uma vez estabilizado em níveis saudáveis observarmos os gatilhos que nos faz voltar para esses hábitos, observando nossos impulsos para voltar a essas atividades, geralmente associados ao nosso estado emocional interno. Apenas dessa forma, seguindo o modelo de terapia cognitiva, para que o equilíbrio do sistema dopamínico se mantenha, e possamos apreciar como se deve atividades vistas hoje como chatas, como ler, escrever, meditar, passear ao ar livre. Ouvir.
</description>
</item>

     
        <item>
  <title>CPU Fritando com Intel Turbo Boost</title>
  <link>http://www.caloni.com.br/cpu-fritando/</link>
  <pubDate>2020-08-24</pubDate>
  
  <guid>http://www.caloni.com.br/cpu-fritando/</guid>
  <description>É a segunda vez que isso acontece e esqueci quando foi a primeira. O cooler do notebook começa a assoprar que nem louco e em poucos minutos o computador desliga. O processo se repete, sempre que faço alguma atividade que exige mais processamento. Baixo o HW Monitor da CPUID e verifico que a CPU está alcançando limites acima de 90 graus celsius, e para segurança ela se auto-desliga. A solução? Ir em opções de energia do SO e trocar o limite máximo que a CPU pode ser usada de 100% para 99%. Isso mesmo, apenas abaixe um por cento. Com isso você está desabilitando o Intel Turbo Boost, que aparentemente não conhece limites físicos e sai fritando a CPU quando é necessário. Mas isso desgasta os chips e destrói a vida útil do sistema. E minha máquina já é rápida o suficiente para conseguir viver sem mais um Boost na minha vida.
</description>
</item>

     
        <item>
  <title>Pacotes Nuget Again</title>
  <link>http://www.caloni.com.br/pacotes-nuget-again/</link>
  <pubDate>2020-08-04</pubDate>
  
  <guid>http://www.caloni.com.br/pacotes-nuget-again/</guid>
  <description>Agora que mexo com .net no trabalho surgem problemas de &amp;quot;marinheiro de primeira viagem&amp;quot; (na verdade já mexi com o framework, mas há muitos anos). O que me fez gastar mais horas à toa sem dúvida é o versionamento dos pacotes nuget que viram dependências simples de colocar e difíceis de mexer.
Nesse problema em específico de tratava da lib Castle.Core na versão 4.4.0. Durante a compilação tudo estava lindo e maravilhoso. Porém, na hora de rodar, a exceção de I/O dizendo que não conseguiu carregar o assembly na versão certa pula na minha frente.
Pesquisa de lá, pesquisa de cá, fuça de cá, fuça de lá, encontrei acho que pela segunda vez a solução. Se trata mesmo da versão errada sendo utilizada, mas não na compilação, mas na execução. É preciso definir a versão correta no arquivo de configuração.
Feito isso todo o mundo maravilhoso de .nerd volta a fazer sentido.
</description>
</item>

     
        <item>
  <title>Close Remote Socket</title>
  <link>http://www.caloni.com.br/close-remote-socket/</link>
  <pubDate>2020-07-05</pubDate>
  
  <guid>http://www.caloni.com.br/close-remote-socket/</guid>
  <description>I got used to close sockets in Windows using TCP View, but I haven&#39;t learned yet how to do this in Linux. Some Google and now I know. It is kinda simple in terminal mode, as any task a programmer needs to do in your system.
You just need to find the process using netstat, find the socket descriptor using lsof, debug the process with gdb, close the socket using call command, close the debugger. You done. How simple is that, right?
</description>
</item>

     
        <item>
  <title>Find Path ou Por Que O Vcpkg Não Colocou o Path da Minha Biblioteca?</title>
  <link>http://www.caloni.com.br/find-path/</link>
  <pubDate>2020-07-01</pubDate>
  
  <guid>http://www.caloni.com.br/find-path/</guid>
  <description>Algumas bibliotecas portadas para o vcpkg, gerenciador de pacotes direto do fonte da Microsoft, não vêm exatamente como esperamos que elas venham em ambientes mais estáveis como UNIX-like. A GLib, por exemplo, uma biblioteca fenomenal se você deseja trabalhar com um framework puramente em C, está disponível pelo vcpkg através do pacote glib, mas vem encapsulado no namespace unofficial::glib::glib. Isso ocorre porque este não é um port oficial.
Se você estivesse em um ambiente UNIX precisaria fazer malabarismos com o PkgConfig, o gerenciador de pacotes do GTK (onde a GLib pertence). No entanto, depois de configurado, tudo o que precisaria fazer é incluir uma macro para os diretórios de include e outra macro para os diretórios de libraries e o programa compilaria. No caso do Windows essa macros não existem.
Lendo a documentação de como instalar o SQLite na documentação do vcpkg me deparei com uma informação até então oculta para mim: &amp;quot;Unlike other platforms, we do not automatically add the include directory to your compilation line by default. If you&#39;re using a library that does not provide CMake integration, you will need to explicitly search for the files and add them yourself using find_path and find_library.&amp;quot;
Então tá. Feito isso, e rodando o cmake com o -DCMAKE_TOOLCHAIN_FILE passando o diretório de instalação do vcpkg, tudo se resolve. O solution do Visual Studio finalmente consegue encontrar os includes e libraries da glib. Ou qualquer outra biblioteca portada que você queira usar.
</description>
</item>

     
        <item>
  <title>Pgn2art</title>
  <link>http://www.caloni.com.br/pgn2art/</link>
  <pubDate>2020-06-27</pubDate>
  
  <guid>http://www.caloni.com.br/pgn2art/</guid>
  <description>Meu sonho de consumo para acompanhar partidas de xadrez é às cegas, apenas lendo ou ouvindo o próximo lance e imaginando em minha cabeça o tabuleiro. Porém, enquanto não tenho essa habilidade, um meio-termo aceitável é ver um tabuleiro em ascii art se modificando a cada lance. É possível acompanhar uma partida dessa forma como se estivesse lendo um livro, e por isso esse formato é prático, também, pois posso jogar esse ascii art no meu Kindle.
Usando a biblioteca python-chess fiz um pequeno script que recebe o endereço de PGNs (o formato com que se grava partidas de xadrez) por URL ou path local e cospe esses tabuleiros em ascii art. Com isso pode redirecionar para um arquivo texto e enviar para o Kindle ou ler de qualquer lugar, em formato estático, a tradução da partida.
O próximo passo, antes de ler às cegas, é transformar a leitura do tabuleiro bidimensional para a leitura do formato FEN, que é o formato usado para gravar posições de um tabuleiro.
</description>
</item>

     
        <item>
  <title>C&#43;&#43; Co Routines</title>
  <link>http://www.caloni.com.br/cpp-co-routines/</link>
  <pubDate>2020-06-21</pubDate>
  
  <guid>http://www.caloni.com.br/cpp-co-routines/</guid>
  <description>Entre os gêneros mais famosos do cinema e da programação está o terror, esse estado mental que se caracteriza pelo medo ou pela aversão a uma situação que envolve a perda de controle. Nesse quesito se encaixam as novas corrotinas que serão adotadas pelo padrão C&#43;&#43;.
No último Caloni Bode Cast Live Privado, aqueles que não estão publicados no YouTube, conversei com um amigo por mais uma vez (já perdi a conta quantas foram) sobre a famigerada implementação, mas acho que dessa vez detectei melhor o que torna essa nova biblioteca de C&#43;&#43; tão repugnante para os amantes de boas soluções de engenharia e do padrão da linguagem.
A primeira ressalva diz respeito à alocação dinâmica. Ao usar esse modelo de rotinas cooperativas o programador é obrigado a alocar espaço para o estado dinamicamente, o que fere duas premissas da linguagem: o controle absoluto do modelo de execução para o programador e a certeza que ele irá apenas pagar em performance o que ele usar. Se os fãs da linguagem fossem religiosos, eles diriam agora que esta não foi uma decisão muito cristã do comitê.
Eu continuo defendendo que a linguagem C seja usada caso surjam contra-indicações na prática da STL.
</description>
</item>

     
        <item>
  <title>Oscar</title>
  <link>http://www.caloni.com.br/oscar/</link>
  <pubDate>2020-06-21</pubDate>
  
  <guid>http://www.caloni.com.br/oscar/</guid>
  <description>Quando o chefão do Oscar faz um discurso dizendo que agora oficialmente serão dez os indicados a melhor filme para promover representatividade, diversidade e todos os ades de quem é ista, ele não está sendo um cara legal. Ele está apenas revelando o quanto o Oscar e/ou a sociedade como um todo funciona e o que irão fazer a respeito: nada. Porque nada é o que este povo que se diz politicamente consciente está acostumado a fazer para mostrar que sabe de algo que você, alienado, não sabe, e farão algo a respeito. Bom, resumo da história como sempre: não, não sabem e não, não farão. Não sabem matemática e não farão uma revolução. Provarão ignorância na arte dos números e hipocrisia e conveniência na arte política.
Vamos abrir o discurso para a lógica: eu tenho mil filmes disputando a lista entre os indicados. Apenas cinco poderão ser escolhidos. Os cinco imediatamente abaixo destes cinco ficarão de fora. Pelas novas regras esses cinco também entrariam pelo tapete vermelho, e com isso, de acordo com o resto da divulgação, aumentaria a representatividade para o prêmio principal da noite. Essa palavra, diversidade, vale lembrar, atualmente quer dizer indicar não apenas homens héteros brancos, mas também mulheres e homens de todas as cores, sexualidade e planeta.
Bom, essa conta não vai fechar. Não existem apenas dez tipos combinados de gênero, cor e sexualidade (e planeta) para que todos estejam de fato representados na premiação. Se já não é suficiente entre os cinco mais votados, qual a mágica estatística que reza que os dez primeiros o serão suficientes? Vou repetir com outras palavras e deixar a pergunta no ar: se os cinco indicados de hoje são de homens héteros brancos por que os cinco imediatamente abaixo na colocação serão com gêneros, cores e sexualidade diversos?
Se você é de humanas não precisa responder, mas continue levantando suas bandeiras para outro canto.
</description>
</item>

     
        <item>
  <title>Teoria, Prática e Código</title>
  <link>http://www.caloni.com.br/teoria-pratica-codigo/</link>
  <pubDate>2020-06-21</pubDate>
  
  <guid>http://www.caloni.com.br/teoria-pratica-codigo/</guid>
  <description>Quando se está aprendendo programação é muito bom praticar escrevendo código. Muitos querem aprender a programar e não começam programando, e se você já começou colocando a mão na massa, parabéns por isso.
Agora, para avançar nos estudos, além da prática, a teoria tem que avançar. E teoria vai além dos estudos de livros e vídeo-aulas. É possível aprender muito mais rápido lendo o código dos outros, disponível aos milhões pela internet. A vinda do GitHub veio para democratizar esse acesso e descomplicar os caminhos de colaboração. Agora você pode encontrar um bug no código de uma pessoa do outro lado do mundo e mandar a correção para todos envolvidos no projeto validarem. O quão sensacional é isso?
Ler código de outra pessoa pode ser desafiador no começo porque é necessário seguir um raciocínio diferente, que não saiu de sua cabeça. Não é a maneira que você resolveria um problema, mas, se o código estiver correto, é uma maneira igualmente válida. E possivelmente melhor. Por estar fora da zona de conforto se torna uma oportunidade para aprender coisas que não estão exatamente nem na teoria nem na prática. É a experiência de outra pessoa traduzida em código.
Note que não digo essas coisas apenas do meu código, que não é perfeito nem exemplar, mas de qualquer código que resolva um problema que você está estudando resolver. Ler código é como ter o texto de um livro, mas compactado. Tem muitas ideias legais para copiar e usar, uma vez que você aprendeu o que o código faz.
Mas para isso é necessário quase o mesmo esforço usado para programar. Parece fácil, mas está longe disso. A boa notícia é que vai economizar muito tempo se persistir em entender.
</description>
</item>

     
        <item>
  <title>Printf</title>
  <link>http://www.caloni.com.br/printf/</link>
  <pubDate>2020-06-18</pubDate>
  
  <guid>http://www.caloni.com.br/printf/</guid>
  <description>Entre os segredos escondidos das funções básicas da lib padrão da linguagem C o printf e o scanf lideram o ranking. O printf possui a capacidade de alinhamento de colunas das string impressas com tamanho variável. Sabia disso? Pois é, isso não se ensina nas escolas.
A impressão básica de uma string passada como argumento com printf deve ser feita usando na string de formatação os caracteres &amp;quot;%s&amp;quot;. Agora, se você colocar um sinal de menos entre esses dois caracteres essa string será alinhada à esquerda. Mas o que é direita e esquerda se o tamanho usado pela impressão vai ser exatamente o tamanho da string? Aí é que entra o especificador de tamanho, logo após o opcional sinal de menos e antes do s que determina o tipo string. Dessa forma a string de formatação final para uma string variável alinhada à esquerda em uma coluna de trinta caracteres de tamanho seria &amp;quot;%-30s&amp;quot;.
Porém, existe um problema com essa abordagem: a string variável pode ter mais de trinta caracteres. Nesse caso existe mais uma opção &amp;quot;escondida&amp;quot; do printf, que é especificar esse trinta em um argumento passado junto dos valores. Para isso basta trocar o número por asterisco e passar o tamanho como se passa qualquer outro valor à função, seguindo a ordem de recebimento. Por exemplo, um printf(&amp;quot;%-30s&amp;quot;, &amp;quot;minha_string&amp;quot;) poderia virar printf(&amp;quot;%-*s&amp;quot;, 30, &amp;quot;minha_string&amp;quot;). Note que agora o tamanho trinta não está mais fixo no código e pode ser uma variável inteira.
Fiz um exemplo bem sucinto, que pede o nome das branches master e slave de um controle de fonte e imprime as duas no final, alinhando o nome das branches à esquerda e o número de commits de cada uma à direita, incluindo um header. É assim que o printf resolve esse tipo de problema de saída formatada: de maneira simples e elegante, sem inventar moda nem querer &amp;quot;revolucionar&amp;quot; a computação.
</description>
</item>

     
        <item>
  <title>Historical Price</title>
  <link>http://www.caloni.com.br/historical-price/</link>
  <pubDate>2020-06-13</pubDate>
  
  <guid>http://www.caloni.com.br/historical-price/</guid>
  <description>Havia um job esta semana de um assunto que me encanta desde a época de investidor: base histórica de cotações. Estamos falando de ações da Bovespa. Na época que era investidor frequente mantinha uma base que era atualizada por um programinha em Java (esqueci o nome), mas nunca tive certeza se os ajustes feitos pelo programa eram os corretos. Surgiu agora a possibilidade de eu realizar código que converte uma base histórica recebida com um minuto por linha em campos divididos por ponto-e-vírgula (o CSV do Windows) para candles de várias periodicidades. E isso justo agora que ando estudando awk. Então não deu outra: usei esta linguagem clássica como ferramenta para esta conversão.
O código ficou, em minha humilde opinião, elegante e pequeno, pois se aproveita da composição das periodicidades. Ou seja, o período de cinco minutos é a consolidação de cinco linhas de um minuto, mas a de quinze minutos não são quinze linhas de um minuto, mas três de cinco minutos, que já estão sendo calculados a cada cinco linha. E assim por diante. Usando os arrays associativos do awk é possível manter o estado de cada candle até o momento de gerar a saída desejada, que no exemplo que codifiquei ficou como um comando SQL de insert em um banco fictício que grava cada tipo de candle em uma tabela.
O uso de um array por candle simplificou o código, pois ao criar uma função que manipula o candle que está finalizando e o próximo eu posso simplesmente passá-los como argumentos. Dessa forma eu só preciso compor os filtros de linhas de acordo com o resto da divisão do seu número. No exemplo inicial, o candle de cinco minutos está finalizando quando RN é igual a cinco ou múltiplos de cinco, enquanto um novo candle se inicia em múltiplos de seis.
</description>
</item>

     
        <item>
  <title>The Eyes of Fritz Lang</title>
  <link>http://www.caloni.com.br/the-eyes-of-fritz-lang/</link>
  <pubDate>2020-06-13</pubDate>
  
  <guid>http://www.caloni.com.br/the-eyes-of-fritz-lang/</guid>
  <description>Um documentário chato, cheio de pessoas elogiando a figura de Fritz Lang em sua fase nos EUA sem substância. Meia-hora quase insuportável de velhos babando ovo para este alemão que narrou sua fuga da Alemanha nazista quando se descobriu que ele fugiu &amp;quot;aos poucos&amp;quot;, e que dizem ser judeu quando apenas sua avó era (e se converteu católica). Sua visão cinematográfica não está descrita aqui, apenas opiniões pessoas sobre este cineasta. Uma perda de tempo para os que buscam informação, e uma curiosidade boba para os fãs desse cinema.
</description>
</item>

     
        <item>
  <title>Leak de Memória</title>
  <link>http://www.caloni.com.br/leak-de-memoria/</link>
  <pubDate>2020-06-07</pubDate>
  
  <guid>http://www.caloni.com.br/leak-de-memoria/</guid>
  <description>Esse fim de semana vi um programa, sem leak de memória, que só de ficar alocando e desalocando apresentava um consumo crescente no Process Explorer. Imaginando que poderia ser alguma lib externa, como o redis, fui eliminando uma por uma as variáveis do sistema, até chegar em um loop em que a única coisa feita no corpo do código era alocar e desalocar memória. E ela apenas subia.
Essa memória é alocada para um objeto acessível por uma interface. Abaixo dessa abstração reside uma mensagem do protocol buffers, ainda na versão 2. Isso quer dizer que cada new e delete construía uma nova mensagem protobuf, além da vtable da interface, e destruía em seguida. Apenas um campo int era preenchido como teste. Para monitorar melhor a memória usei um segundo campo string, pois daí posso alocar quantos bytes quiser para ele e o gráfico do Process Explorer fica dando um berro que não dá para ignorar.
Então me veio o pensamento sobre a versão debug, que não é confiável. Uma versão debug de uma lib pode decidir que é importante manter coisas na memória que o programa não pediu, mas que é importante para diagnóstico. Então compilei a versão release. O padrão de consumo se repetiu, embora em um ritmo menor porque versão release é mais performática. O consumo crescente ainda estava aí.
O jeito foi ir destroçando o código, classe por classe, até fazer o padrão de consumo crescente estabilizar. Este projeto tem uma arquitetura complexa, cheia de interfaces e classes que manipulam dados internos através delas. É complicado destrinchar e me custou o domingo inteiro. E quando finalmente encontrei o problema, não tinha nada a ver com o que eu imaginava. Se tratava da fila de linhas de log que não eram apagadas porque o servidor de log não havia sido configurado no componente, e como ele nunca conectava, a lib de log decidia manter as linhas em memória até conseguir. Pode ser um erro de arquitetura ou uma decisão de segurança. De qualquer forma, não há leak. Apenas um sintoma.
Essa sessão de debugging me deu alguns insights, entre eles um que é sempre mais frequente: nunca supor nada antes de analisar um problema. Minha estratégia de dividir para conquistar sempre foi a única que gerou resultados rápidos, ainda que às custas de não confiar em minha intuição. A longo prazo essa estratégia é vencedora, pois a intuição não utilizada sem critérios fica mais afiada conforme você acumula conhecimento. É como o cara dos Axiomas de Zurique (o livro) dizia, intuição é um quase-conhecimento. Saber cada vez mais irá fazer com que você consiga caminhar mais rapidamente por onde quer chegar.
</description>
</item>

     
        <item>
  <title>Azure Missing Lines: Submodules no Git (SSH Version)</title>
  <link>http://www.caloni.com.br/azure-missing-lines/</link>
  <pubDate>2020-06-04</pubDate>
  
  <guid>http://www.caloni.com.br/azure-missing-lines/</guid>
  <description>É curioso como os problemas mais triviais não são resolvidos em ferramentas feitas para resolver esses problemas. No Azure Pipelines existe um fluxo padrão para configurar um build em que você primeiro cria uma tarefa para obter o código de um repositório git remoto e em seguida configura, compila e empacota através de uma máquina chamada de agente. O problema surge logo nesses primeiros passos, para desespero do iniciante.
Para se autenticar no repositório remoto é claro que a ferramenta irá se integrar por algum endpoint com o serviço, seja BitBucket, GitHub ou outros. Uma conta desse serviço é usada e o acesso está liberado. Porém, se o repositório possui submodules, e estes foram configurados como acessos via ssh, a automação do Azure já para de funcionar neste momento.
A causa desse bug é simples: não existe ambiente para as chaves SSH estarem configuradas antes de existir um agente (uma máquina) onde o build irá acontecer. A correção, felizmente, também é simples, apesar de inapropriada: primeiro deve-se baixar o repo sem submodules, instalar a chave SSH, e apenas agora iniciar e atualizar os submodules.
</description>
</item>

     
        <item>
  <title>Transmission</title>
  <link>http://www.caloni.com.br/transmission/</link>
  <pubDate>2020-06-01</pubDate>
  
  <guid>http://www.caloni.com.br/transmission/</guid>
  <description>Dia de fazer funcionar o download automágico de legendas depois que o Transmission baixou meu Netflix caseiro. O download funcionou, mas não foi dos melhores, pois o sincronismo e o encoding veio errado, e o rename de _pb para o nome do arquivo não está acontecendo rodando pelo transmission-daemon. Fora isso tá com tudo em cima.
No final do dia a correção era mais simples que imaginava: eu só precisava desabilitar duas flags: o uso de sufixo no nome do arquivo salvo e a flag que força todo arquivo a ser salvo como utf8 (os arquivos em português do Brasil são salvos no encoding do Windows, o ISO-8859-1 ou Windows 1252 para os mais íntimos).
No final do dia todos os bugs conterão uma correção trivial escondida do outro lado do muro chinês.
</description>
</item>

     
        <item>
  <title>A Padeira do Bairro</title>
  <link>http://www.caloni.com.br/a-padeira-do-bairro/</link>
  <pubDate>2020-05-19</pubDate>
  
  <guid>http://www.caloni.com.br/a-padeira-do-bairro/</guid>
  <description>Este curta de Éric Rohmer veio de brinde no DVD de A Carreira de Suzane, mas é até bem longo, com 20 minutos de duração. É uma sessão dupla, praticamente, pois com a atração principal tendo menos de uma hora é natural assistir esse em seguida. E ele trata também da análise de mulheres a partir do pensamento de um homem obcecado por uma dama alta e que se veste bem que sempre encontra pelos seus caminhos no bairro. Após o primeiro contato ela some por três semanas, o que faz com que ele desenvolva o péssimo hábito de comer todo dia um doce da padaria da esquina. Se a moça demorasse mais ele muito provavelmente teria engordado muito e ela nem o reconheceria.
Este é um filme que se constrói na tensão da espera. Possui assim como a atração principal um narrador protagonista. E há algumas brincadeiras cinematográficas de Rohmer o suficiente para nos entreter. Como o corte abrupto para acelerar os passos de um homem na rua. Um curta sobre relacionamentos nunca pode ser ruim. Esse tem o jeito de um causo contado por um amigo. Ou seja, delicioso de acompanhar. Como um doce da padaria do bairro quando não temos nada mais o que fazer.
</description>
</item>

     
        <item>
  <title>Fechado Para Reformas</title>
  <link>http://www.caloni.com.br/fechado-para-reformas/</link>
  <pubDate>2020-05-19</pubDate>
  
  <guid>http://www.caloni.com.br/fechado-para-reformas/</guid>
  <description>Quase três mil posts durante quinze anos nessa vida de blogue e percebo que chegou a hora de atingir a maioridade. Escrever um rascunho e publicá-lo na internet não me torna melhor escritor que qualquer YouTuber de primeira viagem que não edita seu conteúdo ou tuítes que simplificam o pensamento humano de tal forma que ele parece totalmente válido ou inválido. Perde-se as nuances. A voz do autor fica solta demais para ser relevante nesse mar de informação que nos afogamos todos os dias (e noites).
Para me tornar um escritor profissional eu devo revisar. Revisar é o que irá extrair valor dos meus textos. Brutos como estão nem eu consigo mais enxergar a virtude de escrever. O conteúdo não é nada se não for seguido pela arte da composição. E essa arte só se conquista compondo, lapidando, com o esforço de conseguir acabar uma obra com esmero e excelência, e ainda que não se consiga por completo esse é o caminho a ser seguido.
Portanto, coloquei todos meus textos antigos para revisão, e os novos nascem no repositório como rascunhos, o que quer dizer que o texto não aparecerá em sua primeira versão no blog. O bebê não está pronto ainda. É durante a gestação que ele irá ganhar corpo e desenvolver sua mente. A edição, além de correções gramaticais, reorganiza o pensamento contido já no rascunho, mas não totalmente consolidado para ser consumido por outro ser humano que não seja o autor.
Escrever é coisa séria. Depois de tanto praticar, acredito que seja a hora de constatar este fato, tirar a poeira das milhares de páginas que já compus e tentar arrumar tempo para me atualizar na arte de criar telepatia para leitores do futuro.
</description>
</item>

     
        <item>
  <title>Bode Caloni Cast Live</title>
  <link>http://www.caloni.com.br/bode-caloni-cast-live/</link>
  <pubDate>2020-05-14</pubDate>
  
  <guid>http://www.caloni.com.br/bode-caloni-cast-live/</guid>
  <description>Alguns caras em uma noite de quinta-feira falando sobre aleatoriedades que giram em torno de cinema, social justice (justiça social), anime e o melhor filme de todos: The Room. O primeiro bodecast live do grupo C/C&#43;&#43; Brasil foi sucesso de participantes e fracasso de público (só veio o Matheus e o Elias). Descobrimos que o Gianni, fundador do grupo do Telegram, tem o péssimo costume de largar os filmes pela metade. Também descobrimos que Cosmos é o projeto secreto de @drmadera para criar vida no fundo de seu home-office. E de quebra houve uma invasão de neo-São-Joseenses, um povo muito simpático que citou alguns filmes malucos para comentarmos.
Infelizmente a live terminou mais cedo porque o Gianni não pagou a conta de internet o sinal caiu e nos derrubou a todos ao mesmo tempo. Se quiser que façamos mais como esse dê um curtir no vídeo e comente com sugestões, críticas, etc. Comente por lá. Aqui só eu tenho voz.
</description>
</item>

     
        <item>
  <title>Bug no Calonibot Rodando Como Serviço</title>
  <link>http://www.caloni.com.br/bug-no-calonibot-rodando-como-servico/</link>
  <pubDate>2020-05-10</pubDate>
  
  <guid>http://www.caloni.com.br/bug-no-calonibot-rodando-como-servico/</guid>
  <description>Esse não é o primeiro bug, nem será o último, mas serve de lição. Se quiser rodar um daemon no seu raspberrypi que atualize seu repo git de tempos em tempos ele poderá falhar, já que que roda em conta de root e essa conta não possui suas credenciais. Nem deveria, para ser sincero...
Uma maneira de tornar a leitura de seu repo relativamente segura é entregar credenciais de somente leitura para seu serviço. Foi o que eu fiz no caso do calonibot, que atualiza seu próprio repositório de tempos em tempos porque nele está contido o index.xml principal do site para ele realizar uma busca mais completa quando você pedir a ele (que é atualizado sempre que publico um novo artigo).
Para que isso funcione para repositórios configurados com chave ssh você terá que copiar essa chave para o diretório /root/.ssh, como se fosse a home do seu usuário. Depois de feito isso reinicie o serviço e ele deverá funcionar como novo.
</description>
</item>

     
        <item>
  <title>O Bug Mais Bizarro que já Resolvi</title>
  <link>http://www.caloni.com.br/o-bug-mais-bizarro-que-ja-resolvi/</link>
  <pubDate>2020-05-10</pubDate>
  
  <guid>http://www.caloni.com.br/o-bug-mais-bizarro-que-ja-resolvi/</guid>
  <description>Máquina IBM velha e empoeirada. Criptografia blowfish. Assembly 16 bits. Programa residente. E nenhum depurador funcionando. Tudo o que eu tinha se resumia em dois itens de inventário: o conhecimento, adquirido aos poucos do sistema, e minha imaginação. Era uma amena semana de abril em 2008 isolado em uma sala. Tudo que havia em volta eram papéis com anotações feitas. Observava uma nova pista todo dia, embora sem ter muita certeza. Àquela altura qualquer coisa serviria.
Do outro lado da sala, uma estagiária recém-chegada na empresa observava de longe, talvez com uma certa curiosidade, ou medo, daquele rapaz ligar e desligar um desktop empoeirado enquanto a cada aperto do botão de ligar ele olhava fixamente para a tela por uma ou às vezes duas horas seguidas. Ficava a manhã inteira observando um único boot em câmera lenta. A câmera mais lenta possível, dessas que capturam o bater de asas de um beija-flor. Cada movimentação de um registrador demorava vários minutos de reflexão.
Toda essa odisseia começou com o cara do suporte, um sujeito bonachão que atraía os bugs mais bizarros para nossos sistemas só de olhar para eles. Não eram os piores bugs, mas com certeza os mais bizarros. E quando digo bizarro estou falando de bugs que não dá para imaginar acontecendo na vida real. Quando esse sujeito aparecia junto surgiam bugs na própria Matrix; um gato preto passa duas vezes seguidas pela porta, mas não caminhando: flutuando próximo do teto.
O sujeito chegou na sala de desenvolvimento falando dessa máquina que tinha acabado de chegar do cliente. Haviam instalado a criptografia de disco. Os dados não estavam perdidos, pois o Windows ainda mostrava o seu logo esvoaçante segundos depois de ligarmos o velho desktop de guerra, que já havia vivido pelo menos duas décadas a vida de escritório e não seria agora que deixaria seus dados sumirem sem mais nem menos. Nada disso. O problema era que se você desligasse e ligasse de novo, nada mais aparecia. Tela preta. Sem logo esvoaçante ou cursor piscando. O disco rígido não se mexia. Era um mistério completo.
Mas o bizarro mesmo não era isso, mas o que vinha depois. Você desligava a pobre máquina, novamente. Apertava o botão de ligar. E como uma mulher nos seus trinta ainda não vividos, ela subia com tudo no lugar: logo do Windows, barulhinho irritante da sua tela de boas vindas e as agulhas do disco magnético piscando freneticamente. Tudo certo mais uma vez na terra do Tio Bill. Era possível logar na máquina e usá-la o resto do dia com todos os dados criptografados íntegros.
Agora, sim, o bug está completamente descrito: nos boots ímpares a máquina não bootava. Nos boots pares não havia nada de errado (ou vice-versa). Antes que você comece a confabular o que poderia ser, um cacoete que todos nós, programadores, costumamos ter, já aviso que nesse bug não há relação com energia ou memória RAM. Você podia desligar a máquina e tirar da tomada. Ir tomar um café. Uma hora depois coloca a tomada de novo e a liga. A bendita não funciona. Tire a tomada novamente. Mais um café. Desenergizada novamente, botão de ligar. E tudo estava certinho.
A criptografia desse sistema operava em dois níveis, necessários naquela época. O PC é uma monstruosidade construída em camadas legadas, uma em cima da outra. Abaixo de tudo existe a BIOS que controla todo mundo. Até um certo ponto, pelo menos. O que importa é que nesse primeiro momento do boot não existe sistema operacional. Não existe a querida proteção de memória que os SOs implementam (com a ajuda da arquitetura) para isolar os programas, onde qualquer violação de memória é tratada graciosamente com uma mensagem de erro. Não, mano. Aqui é o modo real. Fica esperto, que se um ponteiro ficar doido você vai levar tiro pra tudo quanto é lado. Ou como diria Morpheus: &amp;quot;Welcome... to the desert... of the real.&amp;quot;
Nesse ambiente pesadão e promíscuo, onde as memórias se encostam e trocam de valores sem qualquer pudor, programas residentes se mantém em memória através do famigerado hook de interrupções. Interrupções é como chamamos as funções originais escritas e armazenadas na BIOS. Ponteiros de funções com código carregado da sua memória. Fazer um hook de uma interrupção é se colocar na frente de uma função dessas, trocando o ponteiro de função pelo endereço de sua função na memória. Então, por exemplo, se um programa roda e consegue sobrescrever o endereço da interrupção responsável por escrever na tela, esse programa pode ligar e desligar pixels que o programa original nem imagina. E em vez do logo esvoaçante e inofensivo do Windows, você poderia escrever o que seria o antepassado do gemidão do zap, versão ASCII Art.
No caso de um programa de criptografia de disco a interrupção mais importantes é... acertou: a de disco. Uma interrupção de disco é responsável por ler e escrever dados de e para o disco. No primeiro momento do boot é vital para o sistema operacional que ele consiga ler setores do disco onde ele próprio está armazenado. Ele deve conseguir ler seus dados do disco, mesmo criptografados, e esses dados precisam ser descriptografados antes que exista um driver de criptografia instalado no Sistema Operacional no ar. É o dilema do ovo e da galinha. É aí que entra o que chamamos de programa residente, o que contém a função de criptografia e cujo endereço é colocado no lugar da interrupção da BIOS para comandos de disco.
É claro que contando isso para vocês a posteriori parece mais fácil, mas meu primeiro instinto foi espetar o WinDbg, o depurador de sistema do Windows, nessa máquina. Porém, rapidamente descobri que não existia sistema operacional para ser depurado. O Windows nem conseguiu subir ainda, quanto mais deixar as pessoas depurarem ele. Então a solução foi apelar para o SoftIce 16 bits, um depurador em modo real, que funciona até que bem sozinho. Porém, o próprio depurador já é um programa residente, e não funciona tão bem quando existem outros programas residentes querendo espaço no disco. Como o programa de criptografia instalava um hook na int13 (essa é a interrupção de disco), as sessões de depuração nessa fase ficavam estranhas rapidamente. O depurador de modo real travava nas primeiras passadas de código. Não havia memória o suficiente ou as chamadas das ints entravam em conflito. De qualquer forma, quando memória entra em conflito no modo real, o barato fica loko, e o jeito é começar tudo de novo em um novo boot (par ou ímpar, mas sempre o segundo).
Então o jeito foi usar o debug.com. Este era um programa que vinha no pacote MS-DOS e em alguns Windows mais velhos que consistia em um depurador de modo real. Era possível carregar um segmento de um arquivo ou da memória real para este depurador e ele seguia passo a passo para você a execução do programa. Em assembly de modo real, claro. Esse foi o jeito que eu consegui ir entendendo o fluxo de execução, pois eram muitos valores e variáveis. Eventualmente até o debug.com também travava, mas isso não importava tanto, pois era possível ir mapeando seu funcionamento aos poucos, anotando as descoberta uma a uma em um pedaço de papel. Uma técnica que pode ser interessante se você se encontrar em tal situação é escrever as ints 3 (interrupção de breakpoint) diretamente na memória do programa e deixar ela ser ativada para depois que capotar sobrescrever com o código antigo. Eventualmente isso também travava. Daí nesse momento o jeito era fingir que estava tudo bem e continuar a execução de um outro ponto, anotando em um pedaço de papel o estado dos registradores e da memória até o momento, para depois ir ligando os pontos.
Depois de alguns dias nesse modus operandi o mundo externo importava cada vez menos. Eu só enxergava registradores sendo movidos, valores sendo empilhados e desempilhados. Na hora do café, esse era o meu tema favorito, para desespero dos meus colegas. Comecei a vislumbrar a possibilidade de existir um bug no código do algoritmo de criptografia. O algoritmo usado se chama Blowfish, um cifrador simétrico em bloco. Seu funcionamento é basicamente pegar um bloco de dados a serem criptografados, aplicar uma chave, e cuspir o mesmo tamanho do bloco de volta. Ele se chama simétrico porque aplicando a mesma chave a um bloco criptografado obtém-se o bloco original.
Não lembro como tive esse insight, mas essa alternância típica dos algoritmos simétricos fazia tocar alguns sinos na minha cabeça de que o bug bizarro dos boots ímpares e pares poderia estar relacionado de alguma forma. Só não sabia ainda como.
Pois bem: bora aprender como funciona esse algoritmo, passo a passo, pois o código usado no sistema estava obviamente escrito em assembly. Não é um código difícil em C, mas um tanto extenso em Assembly. De qualquer forma, tudo é possível se você está trancado em uma sala sem ninguém para importunar. Tudo que você precisa é de tempo e paciência. E café. Não se esqueça do café.
A semana passou rápido. Tudo que me lembro é que de fato foi uma semana de 40 ou mais horas, embora para mim o tempo tivesse parado. A mágica de estar compenetrado em um problema e fazer parte do problema, e eventualmente da solução, me fez descobrir a origem do bug. E a semana inteira se condensou em alguns poucos momentos de prazer em ter capturado esse desgraçado. Irei descrevê-lo agora.
Tudo começa com o IV: o Initialization Vector. Ele é um array de bytes usado em algoritmos criptográficos para diminuir a previsibilidade da série de bytes resultantes do algoritmo. Sem o IV pode-se usar força bruta com várias chaves até encontrar a certa. Com o IV, que é alterado de maneira previsível, mas difícil de rastrear, a mesma chave gera séries de bytes completamente diferentes, impedindo esse tipo de ataque.
O que estava acontecendo nesse caso para o boot estar intermitente era que, como comentado no commit que gloriosamente assinei, as escritas em disco durante o boot gravavam a série de bytes com um IV invertido. Portanto, na hora de ler bytes do disco ele entregaria os dados errados, obviamente, e a máquina não bootaria. Porém, como o algoritmo blowfish é simétrico, e pelo boot conter sempre os mesmos dados no disco, uma segunda escrita feita em um segundo boot inverteria o IV já invertido, gravando os dados originalmente invertidos da maneira correta, e a vida nessa versão de boot seguia feliz e contente, com logo esvoaçante até a música de boas vindas do Windows. Bootando pela terceira vez era repetido o problema do boot pela primeira vez, e assim por diante. Essa era a mágica do boot bizarro desta máquina, a única máquina que descobrimos que escrevia nos setores do disco durante o boot. A maioria apenas lia setores onde estava o sistema operacional para carregá-lo.
Descrevendo a descoberta desse bug hoje, doze anos após o ocorrido, ainda não entendo como consegui descobri-lo. Porém, ele exigiu tanta concentração que me lembro com um prazer indescritível de ter sido capaz de fazê-lo. Todo o tempo despendido se tornou uma marca de felicidade em minha memória, gravada em meu HD temporário desta vida. Lembrarei desses momentos com carinho, e como ela está criptografada também, entenderei que em alguns momentos ela irá soar amarga, mas em vários outros irei ter certeza de ter sido um feito e tanto para um ser humano entender uma máquina em seus detalhes mais obscuros. Esta é a verdadeira felicidade da profissão.
</description>
</item>

     
        <item>
  <title>A Pista (La Jetée)</title>
  <link>http://www.caloni.com.br/la-jetee/</link>
  <pubDate>2020-04-26</pubDate>
  
  <guid>http://www.caloni.com.br/la-jetee/</guid>
  <description>Este curta de Chris Marker ficou conhecido como um dos melhores filmes já feitos pela lista de críticos consecutivas vezes. E não é à toa. Sua história é uma poesia do começo ao fim, uma ode à fragilidade da existência humana e aos seus sentimentos e desejos. É uma narrativa pautada em fotos desastrosa no sentido humano, e igualmente aterradora. Nos faz pensar sobre as próprias escolhas da vida, sobre o passado e o futuro, e como o tempo, o nosso tempo, se dissolve a olho nu.
</description>
</item>

     
        <item>
  <title>Cast Operator</title>
  <link>http://www.caloni.com.br/cast-operator/</link>
  <pubDate>2020-04-22</pubDate>
  
  <guid>http://www.caloni.com.br/cast-operator/</guid>
  <description>O código abaixo não é C&#43;&#43; moderno. É 98. Porém, ele já demonstra alguns problemas na linguagem que foram aumentados desde então. Não se sabe exatamente qual a tradução semântica de construções tão parecidas quanto o operador-função e o operador-cast. Enquanto o primeiro serve para transformar objetos em funções chamáveis o segundo serve para extrair tipos de maneira educada.
struct T{explicitoperator int(){return 10;}};int main(){T t;// error: term does not// evaluate to a function// taking 0 argumentst();int i = (int) t;} O operador de cast só funciona se um cast estiver envolvido. Caso ele seja um método com explicit o cast precisa ser explícito como no exemplo. Se ele não fosse bastaria uma atribuição normal.
int i = t; Ele não pode simplesmente ser chamado como um operador-função. Até porque podem haver vários deles. Enquanto o operador de função trabalha com overload nos parâmetros o operador de cast trabalha com o retorno. Uma vez eu fiz uma brincadeira que meu amigo Fernando tinha me pedido: como fazer sobrecarga de função pelo retorno. Acredito que o exemplo desse post antigo possa exemplificar melhor o que quero dizer.
Já a diferença sintática e semântica dos operadores de função e cast é sutil, quase inexistente. Como muitas coisas em C&#43;&#43; moderno:
// cast-operatoroperator int();// function-operatorint operator(); </description>
</item>

     
        <item>
  <title>Minha Palestra Sobre Windbg</title>
  <link>http://www.caloni.com.br/mbconf-at-home-2020-palestra-windbg/</link>
  <pubDate>2020-04-18</pubDate>
  
  <guid>http://www.caloni.com.br/mbconf-at-home-2020-palestra-windbg/</guid>
  <description>A MBConf@Home2020 foi um sucesso. Parabéns aos organizadores, palestrantes e apoiadores. Eu nunca fui em um evento de tecnologia em que tudo funcionou do começo ao fim. Simplesmente fantástico o nível de qualidade da organização. Fora que trezentas pessoas ficaram em casa e participaram conosco dessa troca de conhecimento =).
Minha palestra foi a seguinte: dei uma pincelada no que é o WinDbg para os que ainda não conhecem e realizei algumas manobras pouco usuais de depuração, tentando fugir um pouco da rotina do programador e me enfiando no que seriam minhas sessões antigas de hacking ou cracking da época que analisava trojans ou depurava serviços que saíam depois que meu depurador remoto já tinha ido embora. Segue mais ou menos o roteiro e os pontos levantados.
Hoje em dia o caminho mais fácil é pelo Visual Studio Community, que instala por padrão um Windows SDK. Nessa instalação é possível modificar os itens checando o &amp;quot;Debugging Tools for Windows&amp;quot;, que é o pacote que contém o ecossistema do WinDbg.
Pulei essa parte. Tempo curto e me enrolei um pouco. E não era o caso de ficar focado na rotina de programador.
Não fui eu que escrevi o MessageBox... juro. E nesse caso não ter o código-fonte é a rotina do crackudo, que vai ter que explorar no assembly o funcionamento de um programa. Depuramos um que chama MessageBox alterando a mensagem exibida (em 32 bits). Foi legal essa diferença entre Ansi e Unicode que me perdi no começo, pois serviu para exemplificar questões de API que precisam ser conhecidas.
void chama_eu(){MessageBox(NULL,&amp;quot;Welcome to &amp;quot;&amp;quot;MBConf@Home2020&amp;quot;,&amp;quot;MBConf2020&amp;quot;, 0);} Abordamos o boot do Windows com NT, o uso do kd.exe por baixo dos panos do WinDbg (o DarkMode) e configuramos o cabo. Cabo? Cabo virtual, sargento. Usamos a VMWare, pré-configurada após alguns pesadelos de impressora se metendo no meio do caminho. Configuramos a porta serial, que é a melhor ever. E apontamos como named pipe para o WinDbg &amp;quot;de fora&amp;quot; conectar. Ou o kd.exe. As linhas abaixo são equivalentes.
windbg.exe -b -k com:pipe,port=\\.\pipe\com_1,resets=0kd.exe -b -k com:pipe,port=\\.\pipe\com_1,resets=0 Para exemplificar a depuração de um serviço bem no início (ou fim) ou o load de processos antes dele existir checamos uma flag na gflags.exe da máquina depurada para que quando o notepad.exe subisse o ntsd fosse depurá-lo e passasse o controle para o debug do sistema. E com isso fechamos o círculo sagrado da depuração holística.
Não. Para depurar a BIOS local há o caminho do debug.com (um depurador bem simples da época do Windows 95) ou o Softice DOS, embora eu me lembre que tive umas dores de cabeça com ele por causa dos conflitos entre interrupções e programas residentes. A depuração estática acaba ganhando nesse quesito, que é basicamente abrir o assembly, papel e caneta. E imaginação.
Já para debug de BIOS em rede. Bem... esse é um nível hackudo. Sei que a Intel tem desenvolvido chips para diagnóstico e obtenção de dados de hardware pela rede antes mesmo do SO estar ligado, mas não cheguei a pesquisar a fundo.
Sim. Como o Mercês me ajudou a lembrar, existe um rundll32.exe, um executável que já vem no Windows e que pode carregar a DLL para você. Daí tudo que você precisa fazer é colocar o breakpoint das funções exportadas que deseja chamar. Dá para especificar essas funções pelo rundll32.exe também: rundll32.exe project.dll,chama_eu
Recomendo sempre o WinDbg.info como cheat sheet e docs.microsoft.com em seus artigos &amp;quot;Getting Started with WinDbg (User-Mode)&amp;quot; e &amp;quot;Getting Started with WinDbg (Kernel-Mode)&amp;quot; (sorry, m$, vcs mudam os links demais para eu colocar aqui).
</description>
</item>

     
        <item>
  <title>Ilha das Flores</title>
  <link>http://www.caloni.com.br/ilha-das-flores/</link>
  <pubDate>2020-04-15</pubDate>
  
  <guid>http://www.caloni.com.br/ilha-das-flores/</guid>
  <description>Esse curta passava na escola. Muitos de vocês devem lembrar. Eu me lembro. O que eu mais me lembro era o uso cômico das palavras. A cadência em definir o que é um ser humano, um porco, um tomate, e repetir essas definições, cria humor, uma quase conexão com o espectador, e ao final se torna intenso, choca e nos faz, ou deveria fazer, pensar na pobreza, miséria, etc. É um curta sociológico, do pessoal de humanas, e pode impactar crianças e pessoas de humanas. Mas por trás da emoção há Jorge Furtado e seu jogo de palavras em seu primeiro curta documental. É um roteiro esperto, dinâmico e didático. E enviesado. Aquelas questões que pairam no ar quando abaixo desse ar repousa um cérebro condicionado de humanas. Ainda assim, uma ótima reflexão. Reflete até hoje em nossos pensamentos. Quase parece que tem algo a dizer.
</description>
</item>

     
        <item>
  <title>Barbosa</title>
  <link>http://www.caloni.com.br/barbosa/</link>
  <pubDate>2020-04-11</pubDate>
  
  <guid>http://www.caloni.com.br/barbosa/</guid>
  <description>Barbosa foi o goleiro que deixou passar o segundo gol do Uruguai na Copa do Mundo no Brasil em 1950, arrebatando a taça de nossas mãos nos últimos minutos do campeonato. Certos da vitória, os duzentos mil espectadores e todo o Brasil por tabela saíram do estádio boquiabertos. A magia deste curta de Jorge Furtado e Ana Luiza Azevedo é explorar gêneros e possibilidades em uma história auto-contida que usa trucagens para disfarçar seu baixo orçamento, como uma profundidade de campo reduzidíssima. A história se passa em um estádio, e é difícil conseguir dezenas de milhares de figurantes para esta tarefa. De qualquer forma, o resultado é ainda melhor, pois mescla com filmagens da época, e realiza na montagem uma brincadeira que nos deixa imersos naquele pesadelo dos 2x1.
</description>
</item>

     
        <item>
  <title>O Dia em que Dorival Encarou a Guarda</title>
  <link>http://www.caloni.com.br/o-dia-em-que-dorival-encarou-a-guarda/</link>
  <pubDate>2020-04-11</pubDate>
  
  <guid>http://www.caloni.com.br/o-dia-em-que-dorival-encarou-a-guarda/</guid>
  <description>Filme conceitual que brinca com as voltas que a vida dá. É o segundo curta-metragem do diretor Jorge Furtado junto de José Pedro Goulart e nele já podemos ver algumas ideias de recursividade, de como o homem se olha no espelho e vê ele mesmo. Nada muda nesta vida, e as brincadeiras de metalinguagem que Furtado escreve com Giba Assis Brasil e Ana Luiza Azevedo contém a semente dos seus longas, assim como seu próximo curta, que fala sobre a inevitabilidade do nosso passado por sermos parte de tudo isso.
</description>
</item>

     
        <item>
  <title>Temporal</title>
  <link>http://www.caloni.com.br/temporal/</link>
  <pubDate>2020-04-11</pubDate>
  
  <guid>http://www.caloni.com.br/temporal/</guid>
  <description>Este curta capenga foi o primeiro assinado por Jorge Furtado, diretor sulista de O Homem Que Copiava. Ele mistura toda a miscelânea de pensamentos pseudo-liberais-progressitas da juventude que faz faculdade de artes. Essa tentativa de ridicularizar a sociedade brasileira tradicional cristã pode dar bons frutos, mas Furtado e Goulart estão mais interessados em tentar ridicularizar ambos os lados. Uma festa a fantasia nos faz pensar quem está vestindo fantasia de fato: uma congregação cristã ou um bando de jovens desmiolados. E no âmago desse simples curta, os efeitos visuais são de péssima qualidade. Digno de um trabalho de conclusão de curso e para se divertir com os amigos, passando para eles e para impressionar as menininhas.
</description>
</item>

     
        <item>
  <title>Winmock</title>
  <link>http://www.caloni.com.br/winsock-mock/</link>
  <pubDate>2020-04-10</pubDate>
  
  <guid>http://www.caloni.com.br/winsock-mock/</guid>
  <description>Testar sistemas com rede simulada pode ser muito complexo ou muito simples. Se for feito em C ou se os endpoints forem em C é muito simples: basta trocar as funções originais pelas suas. Como tudo em C são funções com nome bem definido e assinatura flexível você não precisa declarar a assinatura da função, ou pode mudar no meio do caminho.
Existe um recurso interessante da winsock, um define chamado INCLWINSOCKAPIPROTOTYPES, que pode desabilitar a publicação das assinaturas das funções de socket do header winsock2.h. E por que isso é importante? Porque essas assinaturas já possuem a informação que essas funções deverão ser importadas de uma DLL (no caso a Ws232.dll). Isso muda o nome da função C. Além disso, a convenção de chamada da API do Windows é baseada em Pascal, e não cdecl, sendo a desvantagem não existir número de argumentos variáveis na pilha.
As funções C do winsock/socket, connect, send, recv, select, etc, são apenas funções C cujos nomes são conhecidíssimos. Elas são linkadas com programas que usam alguma biblioteca de socket. Nada impede que nós mesmos sobrescrevamos essas funções para implementá-las em nosso programa. É isso o que o uso do define acima possibilita: ele evita a importação direto da DLL da Microsoft e com isso você pode usar uma implementação de terceiros ou a sua própria, que não precisa se comunicar com a rede.
</description>
</item>

     
        <item>
  <title>Callback Hell</title>
  <link>http://www.caloni.com.br/callback-hell/</link>
  <pubDate>2020-04-09</pubDate>
  
  <guid>http://www.caloni.com.br/callback-hell/</guid>
  <description>Foi aprendendo sobre kernel do Windows que eu descobri que a linguagem C suporta todas as abstrações que um homem crescido precisa para desenvolver sistemas. Também aprendi que você precisa ser um homem crescido para saber usar direito.
A linguagem C possui 32 palavras-chave e nenhuma parafusadeira elétrica. Existe um motivo para isso: fazer tudo na mão desenvolve o caráter. Se não desenvolve, pelo menos escancara a má pessoa que você é.
Olhe para o sistema de callbacks, por exemplo. É uma ferramenta poderosa. Com ponteiros de função e endereços de estrutura você pode chamar quem você quiser a hora que quiser. Há tantas possibilidades que é muito fácil errar.
Aí que surge o famigerado Callback Hell.
Esse termo se popularizou através da linguagem Javascript por causa que em Javascript é muito fácil deixar a coisas pra depois. Você deixa seu callback pra ser chamado uma outra hora e esquece dele. E ele faz o mesmo. E mais uma vez. E de novo. Você entendeu a ideia.
No final das contas, depurar código Javascript escrito por outra pessoa seria uma sala no inferno reservada para aqueles programadores que acharam durante a vida que resolveriam todos os problemas do mundo até às 18:00. Tudo que eles precisavam fazer era criar mais um pequeno callback no finalzinho daquela função. Como se diz em Go Horse Power, &amp;quot;commit e era isso&amp;quot;.
A linguagem C permite você fazer a mesma coisa. Basta que o endereço da estrutura que você passou como contexto do seu callback tenha um ponteiro de função que vai ser chamado passando mais um membro dessa estrutura como contexto, que irá conter outro ponteiro de função que... você entendeu a ideia.
No final das contas, depurar um código em C escrito por uma pessoa que evita resolver problemas de arquitetura criando mais um callback deve demonstrar como existem pessoas sem caráter que sabem declarar um ponteiro de função. Cuidado com essas pessoas. Elas podem te levar até uma salinha reservada no inferno.
</description>
</item>

     
        <item>
  <title>Meu Try Lock de Pelúcia</title>
  <link>http://www.caloni.com.br/try-lock-de-pelucia/</link>
  <pubDate>2020-04-07</pubDate>
  
  <guid>http://www.caloni.com.br/try-lock-de-pelucia/</guid>
  <description>Alguns implementam o famigerado &amp;quot;mutex pero no mucho&amp;quot;, que é aquele mutex que não faz nada porque ele sabe que só tem uma thread rodando no processo. É uma solução elegante para abstrair o uso de lock em um processo que pode ou não rodar multithread.
Mas isso é uma coisa. Outra coisa é o try lock de pelúcia de um driver de uma empresa que trabalhei certa vez. Como havia situações onde o lock não era nunca liberado, e a thread estava rodando em um nível de interrupção que não poderia mais voltar, ou ela agendava uma execução menos prioritária ou obtia o lock. Mas baixar a prioridade não era uma opção para o programador MacGyver. Então o código acabou pegando o lock na marra.
if( ! try_aquire_mutex() )// dá um tempo...if( ! try_aquire_mutex() )// dá um tempo...// ...// ah, dane-se,// eu vou pegar esse mutex!aquire_mutex(); </description>
</item>

     
        <item>
  <title>Code Jam 2020</title>
  <link>http://www.caloni.com.br/code-jam-2020/</link>
  <pubDate>2020-04-05</pubDate>
  
  <guid>http://www.caloni.com.br/code-jam-2020/</guid>
  <description>O Code Jam esse ano terminou rápido para mim. Estou enferrujado? Nem tanto. Apenas dei menos atenção ao evento no seu início, mas apesar de me concentrar nas últimas 11 horas não tive um resultado satisfatório, obtendo 24 pontos ao total, o que não me dá direito para o torneio, que exige pelo menos 30.
Minha abordagem no primeiro problema foi o feijão com arroz de ir lendo os valores e verificando para cada novo elemento da linha se havia repetição nos valores já lidos da mesma linha. Eu me compliquei na hora de fazer a mesma coisa para as colunas, pois inseri essa checagem dentro do loop da linha, evitando, assim, sempre a última coluna. Foi a parte que mais perdi tempo útil de todo o torneio (não li todos os exercícios antes).
O segundo problema foi o mais simples de todos para mim. Entendendo o enunciado, em que o título dá uma dica valiosa sobre o comportamento do algoritmo (aninhado), foi só usar a mesma lógica que nós programadores usamos na hora de aninhar parênteses.
O terceiro exercício me parecia fácil no começo. Desenhei na minha janela um esboço da ideia inicial, que era manter um registro de todos os minutos de um dia e a cada nova tarefa popular cada minuto. Meu erro principal foi não considerar que todos os minutos de uma tarefa devem estar sob a responsabilidade de apenas uma pessoa. Corrigido isso, meu código passou nos poucos testes disponíveis no problema, mas não passou na hora de submeter. Estou sem saber até agora o que fiz de errado.
E, por fim, o último foi o mais divertido porque envolveu mexer em ambiente. O script iterativo do Google não funcionou direito no Windows, mas depois de uns testes no WSL percebi que o erro mesmo é não dar flush nos printf do meu lado. Sempre haverá problemas de buffer em stdin/stdout.
De qualquer forma, não consegui resolver mais do que 10 bits. Já estava ficando tarde e eu me perdi em digressões de como tornar o código maleável para adivinhar mais que duas viradas quânticas. Deixei esse código experimental de lado e fui ler o próximo.
Apenas li o enunciado. Ele falava sobre o quadrado latino, assim como o problema original. E como tive dores de cabeça por causa desse primeiro exercício, e faltava apenas uma hora e meia para terminar a prova, dei por satisfeito mais um ano brincando de programar.
</description>
</item>

     
        <item>
  <title>MBConf</title>
  <link>http://www.caloni.com.br/mbconf/</link>
  <pubDate>2020-04-05</pubDate>
  
  <guid>http://www.caloni.com.br/mbconf/</guid>
  <description>Daqui a 12 dias acontecerá um evento online com palestras organizadas pela Mente Binária, uma galera muito afiada nos SOs, ferramentas e programação mais baixo nível. Estarei colaborando com algumas dicas de uso do WinDbg. O custo é zero. Para se inscrever, basta ir no site do evento e... se inscrever? No vemos lá =).
</description>
</item>

     
        <item>
  <title>Git Subtree</title>
  <link>http://www.caloni.com.br/git-subtree/</link>
  <pubDate>2020-03-22</pubDate>
  
  <guid>http://www.caloni.com.br/git-subtree/</guid>
  <description>É a segunda vez que uso subtrees no Git. Não é algo que me acostumei usar por rotina, mas é uma técnica que eu recomendo que todo programador conheça para unir repositórios que não dependa dos pesadelos de configurar submodules.
Há vários tutoriais na internet sobre seu uso (como o da Atlasian), além do próprio manual do Git e sua ajuda. Só quero enfatizar neste post que ele existe, é fácil de usar, e pode resolver alguns problemas de gerenciamento de projeto:
 Unir repositórios que foram separados em algum momento ou que nasceram separados. Unir dependências que não estão online, mas que precisam estar caminhando em paralelo. Compor árvores de histórico distintas e não se preocupar muito de onde elas vieram (exceto quando for necessário juntar de novo, e nesse caso o commit que as une possui algumas informações).  </description>
</item>

     
        <item>
  <title>What Did Jack Do?</title>
  <link>http://www.caloni.com.br/what-did-jack-do/</link>
  <pubDate>2020-03-22</pubDate>
  
  <guid>http://www.caloni.com.br/what-did-jack-do/</guid>
  <description>O diretor David Lynch coloca à prova nossa capacidade de avaliação de um trabalho cinematográfico. A Netflix coloca no ar este curta experimental desse diretor experimental em que um macaco é interrogado por um investigador (o próprio Lynch) e sua boca se mexe através de um truque dos mais baratos de colocar uma boca humana falando em cima da boca do animal. Funciona? Eu não me arrisco dizer. Não há nada para se ver por aqui senão uma cópia barata digital que brinca com noir e diálogos que tentam fugir do comum. Mas não adianta: o trabalho de Lynch com o macaquinho é fofinho demais para sair algo além disso.
</description>
</item>

     
        <item>
  <title>Projeto Hu Cpp: Not Fast Enough</title>
  <link>http://www.caloni.com.br/projeto-hu-cpp-not-fast-enough/</link>
  <pubDate>2020-03-17</pubDate>
  
  <guid>http://www.caloni.com.br/projeto-hu-cpp-not-fast-enough/</guid>
  <description>Continuando minhas aventuras em tentar ser mais rápido que o Hugo, fiz uma versão que gera um html porco com os parágrafos obtidos no parser porco de markdown, rodando em cima dos meus 2740 posts. Este é o resultado.
Hugo: 16.527 msHu-Cpp: 89.573 s Noventa segundos para 2700 posts! É uma vergonha! Programadores C&#43;&#43;/Boost/Asio, vamos nos matar.
</description>
</item>

     
        <item>
  <title>Projeto Hu Cpp</title>
  <link>http://www.caloni.com.br/projeto-hu-cpp/</link>
  <pubDate>2020-03-15</pubDate>
  
  <guid>http://www.caloni.com.br/projeto-hu-cpp/</guid>
  <description>Utilizo o Hugo como renderizador do meu saite já faz um tempo. Depois que juntei os posts do finado Cine Tênis Verde e do meu blogue técnico a soma dos textos ultrapassou a marca dos dois mil. Atualmente levo cerca de quinze segundos para renderizar todo o saite antes de publicá-lo.
Não é uma marca ruim, considerando que estamos com quase três mil textos, e embora o leiaute do saite seja muito simples, é justamente o que eu desejo para rápido carregamento e busca. Não tenho do que reclamar.
Porém, um programador C nunca fica satisfeito com uma solução Golang.
Sabe esses pensamentos que não saem da cabeça? Estava devaneando há uns dias sobre se não seria interessante renderizar meu saite usando uma solução em C ou C&#43;&#43; e ver qual seria o resultado. Claro que seria uma solução in house, cheia de bugs e completamente limitado. Mas quem liga? Meu único objetivo é a diversão, e não pretendo criar um produto genérico. Hugo já satisfaz até o mais exigente dos programadores (exceto o Elias), pois resolve vários problemas do interminável conflito entre conteúdo e design.
Por falar no dito cujo, me lembrei da nossa disputa no saite Os Programadores. Era uma resolução de exercício envolvendo leitura e parseamento de um arquivo json. Tive o insight de usar algo parecido com o que desenvolvi naquela vez.
O código que bolei lê um arquivo markdown e divide o header nos campos que eu utilizo e o texto em parágrafos. Esse é o começo mínimo para começar a converter os arquivos em html. Ele usa o mapeamento de arquivo em memória como no desafio do saite. Não precisaria, mas já que a diversão é fazer mais rápido que o Hugo, por que não?
Meu próximo passo é pegar esse parser e converter todos os arquivos para html, da maneira mais porca possível. Quer dizer, quase da maneira mais porca. Não estou usando Pascal.
</description>
</item>

     
        <item>
  <title>Vcpkg: openssl.cnf</title>
  <link>http://www.caloni.com.br/vcpkg-openssl-cnf/</link>
  <pubDate>2019-09-17</pubDate>
  
  <guid>http://www.caloni.com.br/vcpkg-openssl-cnf/</guid>
  <description>Mais uma aventura em vcpkg. Dessa vez o projeto openssl, a biblioteca de SSL open-source multiplataforma. O vcpkg divide esse port por SO, sendo o openssl-windows o port que alterei. A alteração foi enviada como PR para a Microsoft, mas no momento está apenas no repo da BitForge.
O que acontece é que alguns comandos executados no openssl.exe compilado e instalado do vcpkg precisam conter o arquivo de configuração disponível, como o genrsa. A compilação do openssl-windows pelo vcpkg gera o arquivo, mas o apaga após o build. Há uma checagem pós-build no vcpkg.exe que verifica se há arquivos sobrando na estrutura de diretórios que será copiada para a pasta installed/triplet após a conclusão da instalação no módulo postbuildlint. A função checknofilesindir verifica se há arquivos sobrando nos diretórios onde eles não deveriam estar e cancela a instalação. Por isso que originalmente o openssl-windows/portfile.cmake apaga o openssl.cnf gerado na pasta raiz e na subpasta debug do build.
Minha mudança foi apenas não apagar o arquivo openssl.cnf release e movê-lo para a pasta onde está localizado o openssl.exe. Dessa forma fica simples de detectá-lo, mas ainda assim é necessário apontar para a ferramenta onde ele está, definindo a variável de ambiente OPENSSLCONF ou passando como parâmetro.
</description>
</item>

     
        <item>
  <title>Como Publicar Seu Blog Em Hugo Para Ebook</title>
  <link>http://www.caloni.com.br/como-publicar-seu-blog-em-hugo-para-ebook/</link>
  <pubDate>2019-07-10</pubDate>
  
  <guid>http://www.caloni.com.br/como-publicar-seu-blog-em-hugo-para-ebook/</guid>
  <description>Eu publico meu blog inteiro de tempos em tempos para um ebook que construo formatando primeiro em html através de um tema do Hugo, o parser de blog que estou usando no momento porque ele suporta 2500 posts sem reclamar. É uma receita simples de sucesso se você precisar ter todo seu conteúdo indexado para rápida referência ou leitura cronológica.
A primeira coisa a ser feita é preparar um tema para formatar seu html. Eu já tenho um linkado no meu blogue e que precisa apenas formatar o index.html, pois todo o conteúdo e índices estarão lá. Segue um exemplo atual que uso. Ele possui índice alfabético, inclusão de um arquivo-diário que mantenho, listagem das categorias (com índices para cada uma delas) e listagem cronológica (e link para pular direto para o conteúdo).
&amp;lt;!DOCTYPE html&amp;gt;&amp;lt;head&amp;gt;&amp;lt;title&amp;gt;Blogue do Caloni&amp;lt;/title&amp;gt;&amp;lt;meta http-equiv=&amp;#34;content-type&amp;#34; content=&amp;#34;text/html; charset=utf8&amp;#34;&amp;gt;&amp;lt;/head&amp;gt;&amp;lt;body style=&amp;#34;min-height:100vh;display:flex;flex-direction:column&amp;#34;&amp;gt;&amp;lt;section class=&amp;#34;section&amp;#34; style=&amp;#34;flex:1&amp;#34;&amp;gt;&amp;lt;div class=&amp;#34;container&amp;#34;&amp;gt;&amp;lt;div class=&amp;#34;columns&amp;#34;&amp;gt;&amp;lt;div class=&amp;#34;column&amp;#34;&amp;gt;&amp;lt;h2 id=&amp;#34;begin&amp;#34; style=&amp;#34;page-break-before: always;&amp;#34;&amp;gt;Índices&amp;lt;/h2&amp;gt;&amp;lt;ul&amp;gt;&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#daytoday&amp;#34;&amp;gt;DayToDay&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#idx&amp;#34;&amp;gt;Alfabético&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;&amp;lt;ul&amp;gt;&amp;lt;li&amp;gt;{{ $letters := split &amp;#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ&amp;#34; &amp;#34;&amp;#34; }}{{ range $letters }}&amp;lt;a href=&amp;#34;#letter{{ . }}&amp;#34;&amp;gt;{{ . }}&amp;lt;/a&amp;gt;{{ end }}&amp;lt;/li&amp;gt;&amp;lt;/ul&amp;gt;&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#cat&amp;#34;&amp;gt;Categorias&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;&amp;lt;ul&amp;gt;{{ range $key, $value := .Site.Taxonomies.categories }}&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#{{ $key }}&amp;#34;&amp;gt;{{ $key | humanize }}({{ len $value }})&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;{{ end }}&amp;lt;/ul&amp;gt;&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#posts&amp;#34;&amp;gt;Data (ir para Conteúdo)&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;&amp;lt;ul&amp;gt;{{ range .Site.RegularPages }}&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#{{ .UniqueID }}&amp;#34;&amp;gt;{{ .Title }} &amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;{{ end }}&amp;lt;/ul&amp;gt;&amp;lt;/ul&amp;gt;&amp;lt;h2 id=&amp;#34;daytoday&amp;#34; style=&amp;#34;page-break-before: always;&amp;#34;&amp;gt;DayToDay&amp;lt;/h2&amp;gt;&amp;lt;pre&amp;gt; {{readFile &amp;#34;..\\caloni.txt&amp;#34;}} &amp;lt;/pre&amp;gt;&amp;lt;h2 id=&amp;#34;idx&amp;#34; style=&amp;#34;page-break-before: always;&amp;#34;&amp;gt;Índice Alfabético&amp;lt;/h2&amp;gt;&amp;lt;ul&amp;gt;&amp;lt;!-- create a list with all uppercase letters --&amp;gt;{{ $letters := split &amp;#34;ABCDEFGHIJKLMNOPQRSTUVWXYZ&amp;#34; &amp;#34;&amp;#34; }}&amp;lt;!-- range all pages sorted by their title --&amp;gt;{{ range .Data.Pages.ByTitle }}&amp;lt;!-- get the first character of each title. Assumes that the title is never empty! --&amp;gt;{{ $firstChar := substr .Title 0 1 | upper }}&amp;lt;!-- in case $firstChar is a letter --&amp;gt;{{ if $firstChar | in $letters }}&amp;lt;!-- get the current letter --&amp;gt;{{ $curLetter := $.Scratch.Get &amp;#34;curLetter&amp;#34; }}&amp;lt;!-- if $curLetter isn&amp;#39;t set or the letter has changed --&amp;gt;{{ if ne $firstChar $curLetter }}&amp;lt;!-- update the current letter and print it --&amp;gt;{{ $.Scratch.Set &amp;#34;curLetter&amp;#34; $firstChar }}&amp;lt;h3 id=&amp;#34;letter{{ $firstChar }}&amp;#34;&amp;gt;{{ $firstChar }}&amp;lt;/h3&amp;gt;{{ end }}&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#{{ .UniqueID }}&amp;#34;&amp;gt;{{ .Title }}&amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;{{ end }}{{ end }}&amp;lt;/ul&amp;gt;&amp;lt;h2 id=&amp;#34;cat&amp;#34; style=&amp;#34;page-break-before: always;&amp;#34;&amp;gt;Índice por Categoria&amp;lt;/h2&amp;gt;&amp;lt;ul&amp;gt;{{ range $taxonomyname, $taxonomy := .Site.Taxonomies }}{{ if eq &amp;#34;categories&amp;#34; $taxonomyname }}{{ range $key, $value := $taxonomy }}&amp;lt;h3 id=&amp;#34;{{ $key }}&amp;#34;&amp;gt;{{ $key | humanize }}&amp;lt;/h3&amp;gt;&amp;lt;ul&amp;gt;{{ range $value.Pages }}&amp;lt;li&amp;gt;&amp;lt;a href=&amp;#34;#{{ .UniqueID }}&amp;#34;&amp;gt;{{ .Title }} &amp;lt;/a&amp;gt;&amp;lt;/li&amp;gt;{{ end }}&amp;lt;/ul&amp;gt;{{ end }}{{ end }}{{ end }}&amp;lt;/ul&amp;gt;&amp;lt;h2 id=&amp;#34;posts&amp;#34; style=&amp;#34;page-break-before: always;&amp;#34;&amp;gt;Conteúdo&amp;lt;/h2&amp;gt;{{ range .Site.RegularPages }}&amp;lt;h3 style=&amp;#34;page-break-before: always&amp;#34; id=&amp;#34;{{ .UniqueID }}&amp;#34;&amp;gt;{{ .Title }}&amp;lt;/h3&amp;gt; {{ dateFormat &amp;#34;2006-01-02&amp;#34; .Date }} {{ .Content }}{{ partial &amp;#34;taglist.html&amp;#34; . }}{{ end }}&amp;lt;/div&amp;gt;&amp;lt;br&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;/div&amp;gt;&amp;lt;/section&amp;gt;&amp;lt;/body&amp;gt;&amp;lt;/html&amp;gt;Como eu uso Kindle eu construo a partir desse html um arquivo .mobi, mas creio ser simples de construir qualquer outro formato através desse html final. No caso do Kindle preciso de alguns arquivos para usar o kindlegen (a ferramenta da Amazon) que mantenho na pasta static do hugo, como o .ncx e o .opf (além da capa, cover.jpg). Uso uma batch muito pequena para fazer todos os passos e copiar o .mobi resultante para meu Kindle (conectado por um cabo USB e com um drive montado em K:).
rem @echo off hugo -D --theme book --destination bookpushd bookrem iconv -f UTF-8 -t LATIN1 index.html &amp;gt; book.html cp index.html book.htmlkindlegen.exe book.opf -o caloni.mobiif exist k:\ copy /y caloni.mobi k:\documentspopdImportante lembrar que a codificação do hugo (utf8) deve bater com a codificação esperada pelo gerador de ebook. Que me lembre não há muito mais segredos. Basta escrever e de vez em quando rodar o script novamente =)
</description>
</item>

     
        <item>
  <title>Coroutines Em C: Picoro</title>
  <link>http://www.caloni.com.br/coroutines-em-c-picoro/</link>
  <pubDate>2019-05-08</pubDate>
  
  <guid>http://www.caloni.com.br/coroutines-em-c-picoro/</guid>
  <description>Tantas linguagens hoje em dia tentando implementar a abstração de corrotinas e inserindo mais camadas de abstração (fibras e cereais)... há duas implementações já no Boost, ambas dependendo de uma biblioteca de contexto de stack que é dependente de arquitetura (programada em Assembly).
E aqui está a linguagem C com sua elegância, minimalismo e a filosofia &amp;quot;just works&amp;quot;, por mais ou menos 50 anos.
Estava pesquisando sobre bibliotecas de corrotinas em C e encontrei a Picoro, de Tony Finch. O repositório pode ser baixado por este link. Três coisas me encantaram nela:
 portabilidade (fácil de testar em qualquer arquitetura). simplificade (um header e um .c com menos de 200 linhas, e a maioria são comentários). manutenção (o último commit é de 2010, ou seja, ninguém mais mexeu nela por nove anos).  Ela é uma biblioteca feita para resolver o problema mais básico de toda corrotina: troca de contexto. Isso é feito de maneira descentralizada, embora ela inicie com uma corrotina principal: a primeira que constrói uma corrotina. A partir dessa é possível criar outras e dar resume em qualquer uma delas que não tenha terminado.
A linguagem C já implementa troca de contexto através das funções padrão setjmp e longjmp. Há um tipo dependente de arquitetura, jmp_buf, que é usado para guardar o contexto. O salto é feito no estilo da função fork do Unix, ou seja, não há inclusão de mais nenhuma sintaxe diferente do usual: é um if que retorna 0 (contexto principal) ou não-0 (estamos em outro contexto).
O picoro organiza tudo isso em torno de uma lista ligada. Aliás, de duas listas ligadas: running e idle, onde o head de cada uma delas é usado para verificar se há corrotinas paradas ou em execução. Há algumas regras básicas para que tudo funcione. Por exemplo, uma corrotina que já foi executada até o final ou que está bloqueada pela chamada de resume não pode ser posta para rodar.
Vamos começar com um exemplo simples: apenas um corrotina que recebe um inteiro e incrementa três vezes. A cada vez que ele incrementa ele devolve o controle de execução via yield. O main cria três dessas corrotinas e dá resume em cada uma delas três vezes, finalizando a execução de todas. Ao final, o counter final é de 9.
#include &amp;#34;..\picoro\picoro.h&amp;#34;#include &amp;lt;stdio.h&amp;gt;void* mycoroutine(void* arg){int* counter = (int*) arg;(*counter) &#43;= 1;yield(arg);(*counter) &#43;= 1;yield(arg);(*counter) &#43;= 1;return arg;}int main(){int counter = 0;int i;coro coroutines[3];int maxi = sizeof(coroutines) / sizeof(coro);for (i = 0; i &amp;lt; maxi; &#43;&#43;i)coroutines[i] = coroutine(mycoroutine);for (i = 0; i &amp;lt; maxi; &#43;&#43;i)resume(coroutines[i], &amp;amp;counter);for (i = 0; i &amp;lt; maxi; &#43;&#43;i)resume(coroutines[i], &amp;amp;counter);for (i = 0; i &amp;lt; maxi; &#43;&#43;i)resume(coroutines[i], &amp;amp;counter);printf(&amp;#34;final counter: %d\n&amp;#34;, counter);return 0;}É importante observar que o uso de troca de contexto pode facilmente consumir a pilha, pois ela está sendo compartilhada com muitas funções em paralelo. Para reservar espaço a coroutine_start aloca um array de 16 KB (fixo). Esses detalhes de implementação podem ser alterados, pois a biblioteca é tão mínima e simples de entender que construir qualquer coisa em cima dela é trivial.
</description>
</item>

     
        <item>
  <title>Visual Studio Unit Test (C&#43;&#43;)</title>
  <link>http://www.caloni.com.br/visual-studio-unit-test/</link>
  <pubDate>2019-05-06</pubDate>
  
  <guid>http://www.caloni.com.br/visual-studio-unit-test/</guid>
  <description>Desde o Visual Studio 2015 há suporte a unit tests em C&#43;&#43; automatizado na IDE. Porém, a partir do VS 2017 15.5 o suporte aumentou drasticamente, vindo embutidos os suportes para as bibliotecas de teste Google Test, Boost.Test e CTest. Além, é claro, do Microsoft Unit Testing Framework for C&#43;&#43;, o caseiro da M$.
Além disso, é possível você mesmo integrar o Visual Studio com outra lib de testes. Mas para que gastar tempo? Várias integrações já estão disponíveis no Visual Studio Marketplace. Ligue já!
OK, parei com o merchan. Até porque não ganho nada com isso. Vamos ao código.
Pelo Wizard do VS podemos criar para um projeto C&#43;&#43; qualquer um projeto de teste. No momento estou vendo os tipos de projeto Native Unit Test e Google Test.
Este é nosso projeto de exemplo:
#include &amp;#34;CalculatorTabajara.h&amp;#34;int soma(int x, int y){return x &#43; y;}int subtrai(int x, int y){return x - y;}int multiplica(int x, int y){return x * y;}int divide(int x, int y){return x / y;}int main(){}Para conseguir testar o projeto principal adicione-o como referência.
Após isso basta incluir algum header que contenha os tipos, funções, classes e métodos que deseja testar e vá criando métodos de teste dentro da classe de exemplo:
#include &amp;#34;pch.h&amp;#34;#include &amp;#34;CppUnitTest.h&amp;#34;#include &amp;#34;..\CalculatorTabajara.h&amp;#34;using namespace Microsoft::VisualStudio::CppUnitTestFramework;namespace UnitTest1{TEST_CLASS(UnitTest1){public:TEST_METHOD(TestaSoma){int z = soma(3, 2);Assert::AreEqual(z, 5);}TEST_METHOD(TestaSubtracao){int z = subtrai(3, 2);Assert::AreEqual(z, 1);}TEST_METHOD(TestaMultiplicacao){int z = multiplica(3, 2);Assert::AreEqual(z, 6);}TEST_METHOD(TestaDivisao){int z = divide(3, 2);Assert::AreEqual(z, 1);}};}Agora abrindo o jogo para você, amigo programador C&#43;&#43; que gosta de saber tudo que ocorre debaixo dos panos:
 Um projeto Unit Test é apenas uma DLL com uns códigos de template. Esse código já adiciona a lib de unit test da Microsoft e cria uma classe com exemplo de uso. Adicione todo código do projeto original que ele precisa para compilar.  Por isso eu tirei a tranqueira de precompiled header do projeto de unit test, retirei a referência (sugestão do tutorial da Microsoft) e apenas adicionei o mesmo cpp para ser compilado.
Agora mais mágica: se você abrir a janela Test Explorer ele irá encontrar seus testes e enumerá-los!
Se você já programou um pouco em Windows com C&#43;&#43; já deve saber o truque: como o Unit Test é uma DLL ela simplesmente exporta os símbolos necessários para que o Visual Studio encontre o que precisa. O básico que um plugin dos velhos tempos faz: exportar interfaces com um pouco de reflection.
Se você habilitar Undecorate C&#43;&#43; Functions no Dependency Walker verá que ele exporta justamente uma espécie de reflection, na forma de structs:
E se você prestar atenção na ordem de exportação desse símbolos verá que o primeiro se chama GetTestClassInfo. Acabou a magia, não é mesmo?
Os headers e fontes do CppUnitTest ficam em paths do Visual Studio como VC\Auxiliary\VS\UnitTest, nas pastas include e lib. Nele é possível dar uma olhada no significado das macros e das classes disponibilizadas. Logo abaixo das macros, no arquivo principal, é possível ver como funciona o reflection:
namespace Microsoft{ namespace VisualStudio {namespace CppUnitTestFramework{struct ClassMetadata{const wchar_t *tag;const unsigned char *helpMethodName;const unsigned char *helpMethodDecoratedName;};struct MethodMetadata{const wchar_t *tag;const wchar_t *methodName;const unsigned char *helpMethodName;const unsigned char *helpMethodDecoratedName;const wchar_t *sourceFile;int lineNo;};struct ModuleAttributeMetadata{enum AttributeType { MODULE_ATTRIBUTE };const wchar_t *tag;const wchar_t *attributeName;//...É uma lib pequena e elegante que permite uma interação não apenas com a IDE, como poderia ser automatizada por um script, uma vez que sabe-se o funcionamento interno e algumas interfaces.
</description>
</item>

     
        <item>
  <title>OpenSSH no Windows</title>
  <link>http://www.caloni.com.br/openssh-windows/</link>
  <pubDate>2019-04-29</pubDate>
  
  <guid>http://www.caloni.com.br/openssh-windows/</guid>
  <description>O Secure Shell (SSH) é um protocolo de sucesso nos unixes da vida para terminal remoto e seguro por décadas, mas no Windows nunca houve uma forma simples e protegida de abrir um terminal ou copiar arquivos. A opção é instalar um cygwin com esse componente ou tentar compilar um protocolo SSL e em cima dele o SSH. Porém, há detalhes na autenticação que estão relacionadas com o Sistema Operacional e que precisa ser feito. O OpenSSH é uma maneira de compilar tudo isso e ainda funcionar no Windows.
O software WinSCP, um client SFTP para Windows, possui um guia sobre como instalar essa opção no Windows. A partir do Windows Server 2019 e Windows 10 1809 isso não será mais necessário, pois já estará disponível entre as ferramentas opcionais instaláveis do SO (Apps &amp;gt; Apps &amp;amp; features &amp;gt; Manage optional features, &amp;quot;OpenSSH server&amp;quot;). Para os que ainda precisam manter o passado há uma maneira.
Se você preferir não compilar a partir dos fontes você pode baixar um pacote dos binários pelo GitHub. Basta extrair tudo para uma pasta e rodar o script PowerShell de instalação e o serviço sshd estará instalado no modo manual (se você já usou o cygwin sabe que o nome é o mesmo). O local indicado para conter os arquivos é em C:\Program Files\OpenSSH, conforme o tutorial do WinSCP.
Após instalado você deve abrir a porta 22 pelo firewall do Windows (há uma maneira PowerShell de fazer se tiver um Windows novo ou usar a interface mesmo se tiver um antigo). Após esse último passo tudo deverá estar funcionando, e basta criar seu par de chaves pública/privada com o ssh-keygen.exe e adicionar no servidor com ssh-add.exe, além de copiar para um arquivo chamado authorized_keys... enfim, está tudo no tutorial.
Menos a parte de mudar o sshd_config.
Como nos informa um post do Stack Overflow, é preciso comentar no arquivo c:\programdata\ssh\ssh_config, próximo do final, essas duas linhas:
Match Group administratorsAuthorizedKeysFile __PROGRAMDATA__/ssh/administrators_authorized_keysPara isso:
#Match Group administrators# AuthorizedKeysFile __PROGRAMDATA__/ssh/administrators_authorized_keysAí, sim. Reiniciar, o serviço e testar a conexão:
ssh -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no domain\user@hostOs programas ssh.exe (shell remoto) e scp.exe (cópia remota de arquivos) também estão disponíveis no pacote OpenSSH, mas a versão do Cygwin ou até do Git (que vem com um pacote de ferramentas básicas de Linux) funcionam.
Serviço de cópia remota de arquivos Se seu objetivo é realizar backups remotos silenciosos e para isso você instalar um serviço que irá executar o scp.exe de tempos em tempos é preciso tomar cuidado com as credenciais usadas e onde estarão as chaves de criptografia. O padrão usado pelo OpenSSH no Windows é na pasta C:\Users\Usuário\.ssh, mas para um processo na conta de sistema esse valor deve ser diferente. No caso de um terminal executando pelo psexec.exe ele ficou apontando para c:\windows\system32\.ssh, mas para serviços rodando como SYSTEM é capaz que seja outro valor. Enfim, é necessário testar e verificar os resultados dos testes.
</description>
</item>

     
        <item>
  <title>Code Jam 2019 Qualification Round</title>
  <link>http://www.caloni.com.br/code-jam-2019-qualification-round/</link>
  <pubDate>2019-04-07</pubDate>
  
  <guid>http://www.caloni.com.br/code-jam-2019-qualification-round/</guid>
  <description>Estou viajando e com poucas horas de acesso a um computador, mas os dois primeiros desafios do Code Jam esse ano foram tão simples que sequer precisaram de meia-hora. Isso para um chinês, campeões em campeonatos de programação, deve ser equivalente a cinco minutos com um código C enxuto. Mas estou apenas aprendendo.
Foreground Solution Resuminho: o problema é receber um número e retornar dois números cuja soma seja igual ao primeiro. A única restrição é que nesses números não poderá ter o algarismo quatro.
Solução: copiar como string o número para o primeiro deles e colocar zero no segundo; sempre que houver a incidência do caractere &#39;4&#39; trocar por &#39;3&#39; no primeiro número e &#39;1&#39; no segundo (ou a soma que lhe convier).
#include &amp;lt;iostream&amp;gt;#include &amp;lt;string&amp;gt;using namespace std;void calc(string&amp;amp; N, string&amp;amp; A, string&amp;amp; B){for( size_t i = 0; i &amp;lt; N.size(); &#43;&#43; i){if( N[i] == &amp;#39;4&amp;#39; ){A.push_back(&amp;#39;3&amp;#39;);B.push_back(&amp;#39;1&amp;#39;);}else{A.push_back(N[i]);B.push_back(&amp;#39;0&amp;#39;);}}}int main(){int T;cin &amp;gt;&amp;gt; T;for( int i = 0; i &amp;lt; T; &#43;&#43; i){string N;cin &amp;gt;&amp;gt; N;string A, B;calc(N, A, B);cout &amp;lt;&amp;lt; &amp;#34;Case #&amp;#34; &amp;lt;&amp;lt; i&#43;1 &amp;lt;&amp;lt; &amp;#34;: &amp;#34; &amp;lt;&amp;lt; stoi(A) &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; stoi(B) &amp;lt;&amp;lt; endl;} }You can go your own way Resuminho: tem que atravessar um labirinto formado por quadrados de N x N começando acima à esquerda saindo abaixo na direita. Enviar uma string com os comandos E ou S (East/South) para sair do labirinto. A pegadinha é não repetir nenhum dos comandos de uma garota que resolveu o labirinto antes.
Solução: essa pegadinha é o que ironicamente resolve o problema, pois basta inverter os comandos S e E da string recebida como o caminho da garota e ele nunca se repete e sai do mesmo jeito, pois é o labirinto mais fácil do mundo.
#include &amp;lt;iostream&amp;gt;#include &amp;lt;string&amp;gt;using namespace std;void calc(string&amp;amp; P){for( size_t i = 0; i &amp;lt; P.size(); &#43;&#43; i){P[i] = P[i] == &amp;#39;S&amp;#39; ? &amp;#39;E&amp;#39; : &amp;#39;S&amp;#39;;}}int main(){int T;cin &amp;gt;&amp;gt; T;for( int i = 0; i &amp;lt; T; &#43;&#43; i){string N, P;cin &amp;gt;&amp;gt; N &amp;gt;&amp;gt; P;calc(P);cout &amp;lt;&amp;lt; &amp;#34;Case #&amp;#34; &amp;lt;&amp;lt; i&#43;1 &amp;lt;&amp;lt; &amp;#34;: &amp;#34; &amp;lt;&amp;lt; P &amp;lt;&amp;lt; endl;} }Cryptopangrams (failed) Resuminho: encontrar quais números primos são usados como letras do alfabeto baseado em uma sequência em que o primeiro número é a multiplicação do primo da primeira letra pela segunda, o segundo número é a multiplicação da segunda pela terceira e assim por diante.
Solução: tentei fazer na força bruta criando o dicionário de primos usado procurando o resto zero das divisões dos números e depois já com o alfabeto montado reproduzir as reproduções. Apesar do sample funcionar devo ter perdido pelo tempo ou um erro que não descobri.
#include &amp;lt;iostream&amp;gt;#include &amp;lt;map&amp;gt;#include &amp;lt;string&amp;gt;#include &amp;lt;vector&amp;gt;using namespace std;void calc(int N, vector&amp;lt;int&amp;gt;&amp;amp;LS, string&amp;amp; LSS){map&amp;lt;int, char&amp;gt; alpha;int first1 = 0, first2 = 0;for( int l: LS ){int na = 0;for( auto a: alpha){if( l % a.first == 0 ){na = l / a.first;break;}}if( na ){alpha[na] = &amp;#39; &amp;#39;;continue;}for( size_t i = 2; i &amp;lt; N; &#43;&#43;i ){if( l % i == 0 ){int na1 = l / i;int na2 = i;if( first1 == 0 ){first1 = na1;first2 = na2;}alpha[na1] = &amp;#39; &amp;#39;;alpha[na2] = &amp;#39; &amp;#39;;break;}}}const char Alphabet[] = { &amp;#39;A&amp;#39;, &amp;#39;B&amp;#39;, &amp;#39;C&amp;#39;, &amp;#39;D&amp;#39;, &amp;#39;E&amp;#39;, &amp;#39;F&amp;#39;, &amp;#39;G&amp;#39;, &amp;#39;H&amp;#39;, &amp;#39;I&amp;#39;, &amp;#39;J&amp;#39;, &amp;#39;K&amp;#39;, &amp;#39;L&amp;#39;, &amp;#39;M&amp;#39;, &amp;#39;N&amp;#39;, &amp;#39;O&amp;#39;, &amp;#39;P&amp;#39;, &amp;#39;Q&amp;#39;, &amp;#39;R&amp;#39;, &amp;#39;S&amp;#39;, &amp;#39;T&amp;#39;, &amp;#39;U&amp;#39;, &amp;#39;V&amp;#39;, &amp;#39;W&amp;#39;, &amp;#39;X&amp;#39;, &amp;#39;Y&amp;#39;, &amp;#39;Z&amp;#39; };size_t pos = 0;for( auto&amp;amp; a: alpha )a.second = Alphabet[pos&#43;&#43;];int first = LS[1] % first1 == 0 ? first2 : first1;LSS.push_back(alpha[first]);for( int i: LS ){int second = i / first;char c = alpha[second];LSS.push_back(c);first = second;}}int main(){int T;cin &amp;gt;&amp;gt; T;for( int i = 0; i &amp;lt; T; &#43;&#43;i){vector&amp;lt;int&amp;gt; LS;int N, L;cin &amp;gt;&amp;gt; N &amp;gt;&amp;gt; L;int l;for( int n = 0; n &amp;lt; L; &#43;&#43; n){cin &amp;gt;&amp;gt; l;LS.push_back(l);}string LSS;calc(N, LS, LSS);cout &amp;lt;&amp;lt; &amp;#34;Case #&amp;#34; &amp;lt;&amp;lt; i&#43;1 &amp;lt;&amp;lt; &amp;#34;: &amp;#34; &amp;lt;&amp;lt; LSS &amp;lt;&amp;lt; endl;}} Dat Bae Resuminho: descobrir quais bits não estão sendo retornados em um echo (ex: manda-se &#39;1010&#39; e recebe &#39;010&#39;) com um limite de envios para o servidor (este é um problema interativo).
Solução: imaginei dividir o envio pelo número de blocos defeituosos para alternar os 0s e 1s e assim ir dividindo pela metade de acordo com as respostas até ter as posições que não estão retornando. Não cheguei a terminar o código, mas a ideia geral era que como o limite de blocos defeituosos era de 15 ou N-1 (N é o número de bits) e o máximo de chutes é 5, imaginei que a divisão de 2 elevado a 5 fosse o limite da solução.
</description>
</item>

     
        <item>
  <title>A Maneira Errada de Começar um Projeto é com Visual Studio</title>
  <link>http://www.caloni.com.br/a-maneira-errada-de-comecar-um-projeto-e-com-visual-studio/</link>
  <pubDate>2018-12-11</pubDate>
  
  <guid>http://www.caloni.com.br/a-maneira-errada-de-comecar-um-projeto-e-com-visual-studio/</guid>
  <description>Estava eu trabalhando com um sample e resolvi colocar controle de fonte para analisar as mudanças. E a mudança mais inesperada que eu vi quando digitei git diff foi que ele achou que meus arquivos de código-fonte estivessem em binário.
&amp;gt;git diff&amp;gt;Binary files differ&amp;gt;xxd -l 10 -g 1 -c 4 -u source.cpp00000000: FF FE 23 00 ÿ##.00000004: 69 00 6E 00 i.n.00000008: 63 00 6C 00 c.l. Essa lambança ocorreu com uma versão atual do Visual Studio 2017 após eu resolver ser preguiçoso e deixar o template dele criar o projeto para mim.
Particularmente não sou fã de deixar as IDEs criarem arquivos, porque geralmente elas estão cheias de más intenções disfarçadas de boas envolvendo alguma tecnologia proprietária. No caso da Microsoft há os precompiled headers, que sujam o projeto antes mesmo do tempo de compilação ser um problema. E agora descobri que os arquivos estão sendo gerados em UNICODE Windows.
Se você tiver o mesmo problema e quiser corrigir segue o passo-a-passo: salve os arquivos com um encoding de gente grande como utf8. Fim do passo-a-passo.
Isso pode ser obtido na janela de &amp;quot;Save As&amp;quot; do Visual Studio. Há uma flecha para baixo do lado do botão Save onde você pode abrir a opção &amp;quot;Save with Encoding&amp;quot;.
Na prática, troque possivelmente de &amp;quot;Unicode - Codepage 1200&amp;quot; para &amp;quot;Unicode (UTF-8 without signature) - Codepage 65001&amp;quot;. A partir do segundo commit o git começará a entender que você atingiu a maioridade e vai comparar os arquivos como gente grande para você.
A partir do segundo commit o git começará a entender que você atingiu a maioridade e vai comparar os arquivos como gente grande para você.
</description>
</item>

     
        <item>
  <title>Boost.Bind e os Erros Escrotos</title>
  <link>http://www.caloni.com.br/boost-bind-e-os-erros-escrotos/</link>
  <pubDate>2018-10-01</pubDate>
  
  <guid>http://www.caloni.com.br/boost-bind-e-os-erros-escrotos/</guid>
  <description>Estou voltando a programar algumas coisas no boost. Algo que eu perdi ao me isolar do movimento de modernização do C&#43;&#43; foi a capacidade brilhante da biblioteca boost em encapsular e abstrair conceitos de engenharia de software de maneira portável e mantendo a filosofia por trás da STL, que ainda é a melhor maneira de trabalhar algoritmos já criada em qualquer linguagem de programação séria.
Isso não quer dizer que a linguagem C&#43;&#43; está indo para um bom caminho. Muito pelo contrário. Uma miríade de questões semânticas dividem opiniões e nunca resolvem de fato problemas do mundo real. Verdadeiros arcabouços masturbatórios, o comitê da linguagem se debate em vão quando tenta buscar maneiras de tornar uma linguagem arcaica em um exemplo de expressividade.
Isso às vezes não importa muito para o dia-a-dia, mas outras vezes importa. Veja o caso da biblioteca Boost.Bind, uma das mais antigas a entrar para o projeto. Sua função é simples: expandir o conceito do std::bind para quantos argumentos for necessário. Isso foi criado na época com a ajuda de inúmeros overloads da função (em modo template), mas hoje é possível fazer com variadic templates. Seu uso é simples, intuitivo, direto, e resolve muitos problemas de encaixe de código:
#include &amp;lt;iostream&amp;gt;#include &amp;lt;boost/bind.hpp&amp;gt;template&amp;lt;class Handler&amp;gt;void CallHandler(Handler&amp;amp;&amp;amp; handler){handler();}void handler1(int x, int y){std::cout &amp;lt;&amp;lt; &amp;#34;handler1: x=&amp;#34; &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &amp;#34;, y=&amp;#34; &amp;lt;&amp;lt; y &amp;lt;&amp;lt; std::endl;}int main(){CallHandler(boost::bind(handler1, 10, 20));}No entanto, o que era para ser um uso simples e direto de uma feature bem-vinda ao cinto de utilidades do programador C&#43;&#43; se transforma em um pesadelo quando as coisas não se encaixam tão bem:
#include &amp;lt;iostream&amp;gt;#include &amp;lt;boost/bind.hpp&amp;gt;template&amp;lt;class Handler&amp;gt;void CallHandler(Handler&amp;amp;&amp;amp; handler){handler();}void handler1(int x, int y){std::cout &amp;lt;&amp;lt; &amp;#34;handler1: x=&amp;#34; &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &amp;#34;, y=&amp;#34; &amp;lt;&amp;lt; y &amp;lt;&amp;lt; std::endl;}void handler2_fail(int x, int y, int z){std::cout &amp;lt;&amp;lt; &amp;#34;handler1: x=&amp;#34; &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &amp;#34;, y=&amp;#34; &amp;lt;&amp;lt; y &amp;lt;&amp;lt; &amp;#34;, z=&amp;#34; &amp;lt;&amp;lt; z &amp;lt;&amp;lt; std::endl;}int main(){CallHandler(boost::bind(handler1, 10, 20));CallHandler(boost::bind(handler2_fail, 10, 20));}Vou plotar aqui todas as mensagens de erro para sentir o drama:
1&amp;gt;------ Build started: Project: boost_bind_result_type_error, Configuration: Debug Win32 ------1&amp;gt;boost_bind_result_type_error.cpp1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(75): error C2825: &#39;F&#39;: must be a class or namespace when followed by &#39;::&#39;1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(1284): note: see reference to class template instantiation &#39;boost::_bi::result_traits&amp;lt;R,F&amp;gt;&#39; being compiled1&amp;gt; with1&amp;gt; [1&amp;gt; R=boost::_bi::unspecified,1&amp;gt; F=void (__cdecl *)(int,int,int)1&amp;gt; ]1&amp;gt;c:\projects\caloni\static\samples\boost_bind_result_type_error\boost_bind_result_type_error.cpp(23): note: see reference to class template instantiation &#39;boost::_bi::bind_t&amp;lt;boost::_bi::unspecified,void (__cdecl *)(int,int,int),boost::_bi::list2&amp;lt;boost::_bi::value&amp;lt;T&amp;gt;,boost::_bi::value&amp;lt;T&amp;gt;&amp;gt;&amp;gt;&#39; being compiled1&amp;gt; with1&amp;gt; [1&amp;gt; T=int1&amp;gt; ]1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\placeholders.hpp(54): note: see reference to class template instantiation &#39;boost::arg&amp;lt;9&amp;gt;&#39; being compiled1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\placeholders.hpp(53): note: see reference to class template instantiation &#39;boost::arg&amp;lt;8&amp;gt;&#39; being compiled1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\placeholders.hpp(52): note: see reference to class template instantiation &#39;boost::arg&amp;lt;7&amp;gt;&#39; being compiled1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\placeholders.hpp(51): note: see reference to class template instantiation &#39;boost::arg&amp;lt;6&amp;gt;&#39; being compiled1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\placeholders.hpp(50): note: see reference to class template instantiation &#39;boost::arg&amp;lt;5&amp;gt;&#39; being compiled1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\placeholders.hpp(49): note: see reference to class template instantiation &#39;boost::arg&amp;lt;4&amp;gt;&#39; being compiled1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\placeholders.hpp(48): note: see reference to class template instantiation &#39;boost::arg&amp;lt;3&amp;gt;&#39; being compiled1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\placeholders.hpp(47): note: see reference to class template instantiation &#39;boost::arg&amp;lt;2&amp;gt;&#39; being compiled1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\placeholders.hpp(46): note: see reference to class template instantiation &#39;boost::arg&amp;lt;1&amp;gt;&#39; being compiled1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(75): error C2510: &#39;F&#39;: left of &#39;::&#39; must be a class/struct/union1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(75): error C3646: &#39;type&#39;: unknown override specifier1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(75): error C4430: missing type specifier - int assumed. Note: C&#43;&#43; does not support default-int1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(1284): error C2039: &#39;type&#39;: is not a member of &#39;boost::_bi::result_traits&amp;lt;R,F&amp;gt;&#39;1&amp;gt; with1&amp;gt; [1&amp;gt; R=boost::_bi::unspecified,1&amp;gt; F=void (__cdecl *)(int,int,int)1&amp;gt; ]1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(1284): note: see declaration of &#39;boost::_bi::result_traits&amp;lt;R,F&amp;gt;&#39;1&amp;gt; with1&amp;gt; [1&amp;gt; R=boost::_bi::unspecified,1&amp;gt; F=void (__cdecl *)(int,int,int)1&amp;gt; ]1&amp;gt;Done building project &amp;quot;boost_bind_result_type_error.vcxproj&amp;quot; -- FAILED.========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========Este é o erro encontrado usando o último Visual Studio (2017 15.9.0 Preview 2.0) e o Boost 1.68.0. A primeira linha deveria significar alguma coisa (que é para onde todo programador C&#43;&#43; deve olhar):
1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(75): error C2825: &#39;F&#39;: must be a class or namespace when followed by &#39;::&#39;Mas não. Se olharmos para o código-fonte onde ocorreu o problema, a caixa de encaixe perfeito se quebra:
O que isso quer dizer? O que aconteceu? Onde que eu errei?
Claro que ao final da longa listagem de erros (que se torna ainda mais longa, dependendo de quantos argumentos sua função tem) há alguma luz no fim do túnel:
1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(1284): error C2039: &#39;type&#39;: is not a member of &#39;boost::_bi::result_traits&amp;lt;R,F&amp;gt;&#39;1&amp;gt; with1&amp;gt; [1&amp;gt; R=boost::_bi::unspecified,1&amp;gt; F=void (__cdecl *)(int,int,int)1&amp;gt; ]1&amp;gt;c:\libs\vcpkg\installed\x86-windows\include\boost\bind\bind.hpp(1284): note: see declaration of &#39;boost::_bi::result_traits&amp;lt;R,F&amp;gt;&#39;1&amp;gt; with1&amp;gt; [1&amp;gt; R=boost::_bi::unspecified,1&amp;gt; F=void (__cdecl *)(int,int,int)1&amp;gt; ]Mas claro que essa luz pode estar ofuscada quando os tipos dos argumentos são templates de templates de templates... enfim. Deu pra entender onde o caos consegue chegar quando se trata de harmonizar uma biblioteca perfeita com uma linguagem em constante construção.
</description>
</item>

     
        <item>
  <title>Native Floripa 2018</title>
  <link>http://www.caloni.com.br/native-floripa-2018/</link>
  <pubDate>2018-09-28</pubDate>
  
  <guid>http://www.caloni.com.br/native-floripa-2018/</guid>
  <description>O Native Floripa desse ano foi um evento de nerds que adoro e também uma viagem e encontro de nerds (que também adoro). Isso quer dizer que este é um post duplo, onde analiso tanto a viagem quanto o evento.
Como viagem Floripa é uma cidade que se divide em ilha e continente. Na ilha há um emaranhado de rodovias que circulam pelos morros e que se cruzam onde percebemos que a prefeitura não tem o mínimo de cuidado e investimento em fazer conexões decentes. Há dois elevados em obras que facilitaram a transição entre rodovias. Vimos um no caminho do aeroporto para Barra da Lagoa, e o motorista do Uber comentou que está há dez anos em obras, já tendo gasto todo o dinheiro em um amontoado de madeira e concreto inúteis, o que resume o que tenho a dizer sobre a organização da cidade como um todo.
Felizmente o povo do sul é um povo decente, de respeito e que graças a Deus não parece ter dado muita atenção nos movimentos de &amp;quot;justiça social&amp;quot; que assolam o país. Há uma casa de coxinhas muito boa, a Maria Coxinha, onde um dos pratos se chama Kibexinha. Isso é tudo que precisa ser dito sobre a saúde do povo da cidade.
O evento teve lugar, como no ano passado, na Acate, uma incubadora de startups, nos dias 22 e 23 de setembro de 2018 (sábado e domingo). Houve em alguns momentos duas trilhas, que eu condeno por ser um evento pequeno, mas no salão principal houve a filmagem para publicação na internet, que eu invejo, pois logo teremos disponível para todos as palestras da trilha principal. Essa filmagem se torna ainda mais especial quando se percebe que houve muitos poucos participante no evento, girando em torno de 20 no sábado e 10 no domingo. As palestras do ano passado já se encontram publicadas, mas como houve uma demora de alguns meses talvez esse ano teremos a mesma espera.
Confesso que fazia um bom tempo que não participava de um evento como esses. Nossa tentativa de realizar o próximo encontro em sp miou por falta de público em um momento em que C&#43;&#43; está em obras e com discussões importantíssimas sobre a linguagem e bibliotecas necessárias. O Native Floripa atendeu essa necessidade em pelo menos algumas palestras.
O destaque do evento com certeza foram as corrotinas em C&#43;&#43;. Verdadeiras máquinas de performance onde se economiza troca de contexto, houve três palestras sobre o assunto, podemos dizer. Duas delas ministradas por Vinicius, mantenedor da Boost.Http, onde ambas dialogam sobre a fascinante questão de como adequar o uso de corrotinas sem interferir no fluxo do programa. A terceira palestra é minha, onde discurso sobre a dificuldade atual de depurar corrotinas sem ferramentas atualizadas para este &amp;quot;novo&amp;quot; paradigma.
Outra palestra que me lembro com muita empolgação é a sobre WebAssenbly. Não torça o nariz antes de entender. O palestrante nos apresenta algo ainda em andamento sobre transpilar código C/C&#43;&#43; para uma máquina virtual criada a partir de JavaScript. A estrutura da palestra é muito boa e o palestrante melhor ainda. Ele chegou a alterar o código durante a palestra para nos demonstrar diversos usos dessa tecnologia. Ainda em testes, mas muito promissora.
Por fim, as conversas entre os palestrantes e os participantes foi muito frutífera. Assim como nosso grupo do Telegram, importa menos o tema do que as pessoas envolvidas. E todos concordam que não há nada melhor no mundo que conversar com pessoas inteligentes e beber chopes do Sul. E lá na Acate há a melhor praça de alimentação que já vi na vida. Comida e bebida (chopes e vinhos por taça) boa e barata. Há massas e carnes de muita qualidade. O Madero do lado, que já não é nada de mais, ficou ainda menor.
O chope Putz IPA têm lúpulos cheirosos e corpo leve, pouco alcoólico e bem agradável gelado. Ou seja, nem parece IPA.Coruja Pilsen é uma... pilsen? Bom, tem um salgadinho próximo de uma witbier prestes a ser esquecida.O chope da Strappa Gingerberry é um chá preto fermentado com gengibre e gradação alcoólica ridícula de 0.6%. Ele é ainda frutado (possui morango) e deixa a garganta quentinha. Ótima opção entre bebidas mais fortes. Dá uma pausa etílica e estilosa na balada.Kairós Sol Poente é uma West Coast IPA de respeito. Equilibrada de corpo leve, seu chope é aromático e um pouco salgado com amargor presente sem exageros.Ficamos hospedados em uma casa na Barra da Lagoa pelo AirBnB em alta concentração de temas filosóficos. Fizemos um churrasco imprestável, fomos em restaurantes medíocres da orla, mas a conversa foi sempre interessante. Era como se o grupo de filosofia do Telegram tivesse se mudado temporariamente para lá. Temas como metafísica, política, social justice, auto ajuda e imprint de traumas eram frequentes. A paisagem belíssima, a casa aconchegante e a companhia agradável.
Native Floripa virou já uma tradição. Ano que vem nos vemos de novo.
Minhas palestras  Vcpkg e vc td a ver Co co-co-co-co-corrotinas  </description>
</item>

     
        <item>
  <title>Python27, protobuf, py2exe e build_exe</title>
  <link>http://www.caloni.com.br/python27-protobuf-py2exe-cx_freeze/</link>
  <pubDate>2018-07-14</pubDate>
  
  <guid>http://www.caloni.com.br/python27-protobuf-py2exe-cx_freeze/</guid>
  <description>Para quem está tentando compilar um executável usando py2exe e protobuf, #ficadica: desista. Ele não vai funcionar ou se funcionar vai dar trabalho. Em vez disso melhor usar build_exe (através do pacote cx_freeze), que é um esquema marotinho que permite configurar tudo e há apenas um patchzinho que precisa ser feito.
Para entender como as coisas dão errado primeiro vamos instalar os requisitos de um pacote fictício em um ambiente virtualizado do Python (para evitar mexer na instalação padrão):
D:\&amp;gt;cd deployD:\deploy&amp;gt;virtualenv python27New python executable in D:\deploy\python27\Scripts\python.exeInstalling setuptools, pip, wheel...done.D:\deploy&amp;gt;Depois instalamos os requisitos de nosso pacote fictício:
D:\deploy&amp;gt;python27\Scripts\activate.bat(python27) D:\deploy&amp;gt;pushd d:\src\MyFictionalPackage(python27) d:\src\MyFictionalPackage&amp;gt;pip install -r requirements.txtCollecting cx-Freeze==5.1.1 (from -r requirements.txt (line 1))Using cached https://files.pythonhosted.org/packages/ba/d7/e5a699abbc04df31d28750bd4f7715f75452c57c6ea7f05acff0bc26873d/cx_Freeze-5.1.1-cp27-cp27m-win32.whlCollecting protobuf==3.6.0 (from -r requirements.txt (line 2))Using cached https://files.pythonhosted.org/packages/85/f8/d09e4bf21c4de65405ce053e90542e728c5b7cf296b9df36b0bf0488f534/protobuf-3.6.0-py2.py3-none-any.whlCollecting pyodbc==4.0.23 (from -r requirements.txt (line 3))Using cached https://files.pythonhosted.org/packages/fe/0c/3fa53bf0f1779ef3e3a81e474d1e8db924b7398dc12f2fe9b2c9f1bf392d/pyodbc-4.0.23-cp27-cp27m-win32.whlCollecting six==1.11.0 (from -r requirements.txt (line 4))Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whlRequirement already satisfied: setuptools in d:\deploy\python27\lib\site-packages (from protobuf==3.6.0-&amp;gt;-r requirements.txt (line 2)) (40.0.0)Installing collected packages: cx-Freeze, six, protobuf, pyodbcSuccessfully installed cx-Freeze-5.1.1 protobuf-3.6.0 pyodbc-4.0.23 six-1.11.0(python27) d:\src\MyFictionalPackage&amp;gt;Agora vem a hora do erro. O protobuf que foi instalado possui um pequeno bug que impede que o build_exe obtenha essa dependência corretamente na hora de gerar o executável:
(python27) d:\src\MyFictionalPackage&amp;gt;python setup.py build_exerunning build_exeTraceback (most recent call last):File &amp;quot;setup.py&amp;quot;, line 19, in &amp;lt;module&amp;gt;executables=exeFile &amp;quot;D:\deploy\python27\lib\site-packages\cx_Freeze\dist.py&amp;quot;, line 349, in setupdistutils.core.setup(**attrs)File &amp;quot;c:\programs\python27\Lib\distutils\core.py&amp;quot;, line 151, in setupdist.run_commands()File &amp;quot;c:\programs\python27\Lib\distutils\dist.py&amp;quot;, line 953, in run_commandsself.run_command(cmd)File &amp;quot;c:\programs\python27\Lib\distutils\dist.py&amp;quot;, line 972, in run_commandcmd_obj.run()File &amp;quot;D:\deploy\python27\lib\site-packages\cx_Freeze\dist.py&amp;quot;, line 219, in runfreezer.Freeze()File &amp;quot;D:\deploy\python27\lib\site-packages\cx_Freeze\freezer.py&amp;quot;, line 616, in Freezeself.finder = self._GetModuleFinder()File &amp;quot;D:\deploy\python27\lib\site-packages\cx_Freeze\freezer.py&amp;quot;, line 340, in _GetModuleFinderfinder.IncludeModule(name)File &amp;quot;D:\deploy\python27\lib\site-packages\cx_Freeze\finder.py&amp;quot;, line 651, in IncludeModulenamespace = namespace)File &amp;quot;D:\deploy\python27\lib\site-packages\cx_Freeze\finder.py&amp;quot;, line 351, in _ImportModuleraise ImportError(&amp;quot;No module named %r&amp;quot; % name)ImportError: No module named &#39;google.protobuf&#39;(python27) d:\src\MyFictionalPackage&amp;gt;Para fazer funcionar há um pequeno patch: criar um arquivo __init__.py dentro da pasta google onde está instalado o pacote do protobuf:
(python27) d:\src\MyFictionalPackage&amp;gt;dir d:\deploy\python27\Lib\site-packages\googleVolume in drive D is SYSTEMVolume Serial Number is 5C08-36EEDirectory of d:\deploy\python27\Lib\site-packages\google14/07/2018 14:15 &amp;lt;DIR&amp;gt; .14/07/2018 14:15 &amp;lt;DIR&amp;gt; ..14/07/2018 14:15 &amp;lt;DIR&amp;gt; protobuf0 File(s) 0 bytes3 Dir(s) 102.341.001.216 bytes free(python27) d:\src\MyFictionalPackage&amp;gt;copy con d:\deploy\python27\Lib\site-packages\google\\_\_init\_\_.py^Z1 file(s) copied.(python27) d:\src\MyFictionalPackage&amp;gt;dir d:\deploy\python27\Lib\site-packages\googleVolume in drive D is SYSTEMVolume Serial Number is 5C08-36EEDirectory of d:\deploy\python27\Lib\site-packages\google14/07/2018 14:19 &amp;lt;DIR&amp;gt; .14/07/2018 14:19 &amp;lt;DIR&amp;gt; ..14/07/2018 14:15 &amp;lt;DIR&amp;gt; protobuf14/07/2018 14:19 0 __init__.py1 File(s) 0 bytes3 Dir(s) 102.341.001.216 bytes free(python27) d:\src\MyFictionalPackage&amp;gt;Após essa pequena operação já será possível gerar o executável com sucesso:
(python27) d:\src\MyFictionalPackage&amp;gt;python setup.py build_exerunning build_execopying D:\deploy\python27\lib\site-packages\cx_Freeze\bases\Console.exe -&amp;gt; build\exe.win32-2.7\MyFictionalPackage.execopying C:\WINDOWS\SYSTEM32\python27.dll -&amp;gt; build\exe.win32-2.7\python27.dll*** WARNING *** unable to create version resourceinstall pywin32 extensions firstwriting zip file build\exe.win32-2.7\lib\library.zipName File---- ----m BUILD_CONSTANTSm Objects_pb2 d:\src\MyFictionalPackage\Objects_pb2.pyP Scripts d:\src\MyFictionalPackage\Scripts\__init__.pym StringIO c:\programs\python27\Lib\StringIO.pym UserDict D:\deploy\python27\lib\UserDict.pym __builtin__m __future__ c:\programs\python27\Lib\__future__.pym __main__m __startup__ D:\deploy\python27\lib\site-packages\cx_Freeze\initscripts\__startup__.pym _abcoll D:\deploy\python27\lib\_abcoll.pym _codecsm _codecs_cnm _codecs_hkm _codecs_iso2022... lots and lots of dependencies ...m unittest.result c:\programs\python27\Lib\unittest\result.pym unittest.runner c:\programs\python27\Lib\unittest\runner.pym unittest.signals c:\programs\python27\Lib\unittest\signals.pym unittest.suite c:\programs\python27\Lib\unittest\suite.pym unittest.util c:\programs\python27\Lib\unittest\util.pym warnings D:\deploy\python27\lib\warnings.pym weakref c:\programs\python27\Lib\weakref.pym zipimportm zlibMissing modules:? _emx_link imported from os? ce imported from os? fcntl imported from subprocess? google.protobuf._use_fast_cpp_protos imported from google.protobuf.internal.api_implementation? google.protobuf.enable_deterministic_proto_serialization imported from google.protobuf.internal.api_implementation? google.protobuf.internal._api_implementation imported from google.protobuf.internal.api_implementation? google.protobuf.internal.use_pure_python imported from google.protobuf.internal.api_implementation? google.protobuf.pyext._message imported from google.protobuf.descriptor, google.protobuf.internal.api_implementation, google.protobuf.pyext.cpp_message? ordereddict imported from google.protobuf.json_format? org.python.core imported from copy, pickle? os.path imported from os, pkgutil, shlex? os2 imported from os? os2emxpath imported from os? posix imported from os? pwd imported from posixpath? riscos imported from os? riscosenviron imported from os? riscospath imported from osThis is not necessarily a problem - the modules may not be needed on this platform.copying c:\programs\python27\DLLs\_hashlib.pyd -&amp;gt; build\exe.win32-2.7\lib\_hashlib.pydcopying C:\WINDOWS\SYSTEM32\python27.dll -&amp;gt; build\exe.win32-2.7\lib\python27.dllcopying c:\programs\python27\DLLs\_socket.pyd -&amp;gt; build\exe.win32-2.7\lib\_socket.pydcopying c:\programs\python27\DLLs\_ssl.pyd -&amp;gt; build\exe.win32-2.7\lib\_ssl.pydcopying c:\programs\python27\DLLs\bz2.pyd -&amp;gt; build\exe.win32-2.7\lib\bz2.pydcopying D:\deploy\python27\lib\site-packages\pyodbc.pyd -&amp;gt; build\exe.win32-2.7\lib\pyodbc.pydcopying c:\programs\python27\DLLs\select.pyd -&amp;gt; build\exe.win32-2.7\lib\select.pydcopying c:\programs\python27\DLLs\unicodedata.pyd -&amp;gt; build\exe.win32-2.7\lib\unicodedata.pyd(python27) d:\src\MyFictionalPackage&amp;gt;Agora ao listarmos os executáveis gerados encontraremos nosso amigo fictício:
(python27) d:\src\MyFictionalPackage&amp;gt;dir /s /b *.exed:\src\MyFictionalPackage\build\exe.win32-2.7\MyFictionalPackage.exe(python27) d:\src\MyFictionalPackage&amp;gt;Nota: conteúdo do arquivo setup.py:
import sysimport osfrom cx_Freeze import setup, Executableexe = [Executable(&amp;#39;MyFictionalPackage.py&amp;#39;)]option = { &amp;#39;build_exe&amp;#39; : {&amp;#39;path&amp;#39; : sys.path.append(os.getcwd()),&amp;#39;includes&amp;#39; : [&amp;#39;google.protobuf&amp;#39;, &amp;#39;pkgutil&amp;#39;, &amp;#39;pyodbc&amp;#39;, &amp;#39;decimal&amp;#39;],}}setup(name = &amp;#34;teste_cx_Freeze&amp;#34;,version = &amp;#34;0.1&amp;#34;,description = &amp;#34;&amp;#34;,options = option,executables=exe)(python27) d:\src\MyFictionalPackage&amp;gt;</description>
</item>

     
        <item>
  <title>SSL e seu limite de pacote</title>
  <link>http://www.caloni.com.br/ssl-limite-de-pacote/</link>
  <pubDate>2018-05-22</pubDate>
  
  <guid>http://www.caloni.com.br/ssl-limite-de-pacote/</guid>
  <description>O protocolo TLS/SSL tem por objetivo criar uma camada de criptografia assimétrica para a aplicação. E quando eu falo em camada não estou me referindo às camadas OSI. Nem às camadas TCP/IP. Isso porque o SSL não se encaixa em nenhuma das duas. Ele interfere com muitas, inclusive a aplicação. E aprendi isso a duras penas: na ponta do depurador.
O pacote SSL tem um limite de 16 KB, ou 16384 bytes. Esse é o limite que será respeitado por qualquer implementação do protocolo, o que inclui o uso de Boost.Asio e seu uso da OpenSSL. O que isso quer dizer na teoria é que você não pode trafegar sentido server=&amp;gt;client nada maior que 16k bytes. O que isso quer dizer na prática é que sua aplicação não pode escrever mais que 16k bytes de uma vez no socket que vai dar pau.
Sim, a camada de aplicação tem que estar ligada que existe SSL abaixo dela.
Isso quer dizer que este snippet de código, por exemplo:
_sock.write_some(::boost::asio::buffer(output.data(), output.size()), err);Não é inocente e não funciona sempre. Se _sock for um socket cuja comunicação está encriptada por SSL (em outras palavras -- em Boostês -- ele for um ssl_socket) você precisa escrever output em pequenas quantidades. Como em outra implementação inocente:
do{size_t sz = std::min((size_t) LESS_THAN_16_KB, output.size());_sock.write_some(::boost::asio::buffer(output.data(), sz), err);output.erase(0, sz);}while (err.value() == boost::system::errc::success &amp;amp;&amp;amp; output.size() &amp;gt; 0 );Se isso não for feito e a ponta server escrever, digamos, 512KB, ou 17KB, ou qualquer coisa acima de 16KB, ela irá receber... 16 KB. E acabou. O resto se perder.
Portanto, quando for mexer com SSL, esqueça OSI e esqueça TCP/IP. As coisas funcionam de uma maneira muito mais esotérica que qualquer programador de redes jamais viu, e jamais verá.
</description>
</item>

     
        <item>
  <title>Boost Meta State Machine</title>
  <link>http://www.caloni.com.br/boost-meta-state-machine/</link>
  <pubDate>2018-05-21</pubDate>
  
  <guid>http://www.caloni.com.br/boost-meta-state-machine/</guid>
  <description>O Boost Meta State Machine (MSM for short) é uma das duas bibliotecas mais famosinhas de state machine do Boost. Ela é uma versão estática que permite incluir chamadas para as entradas e saídas de um estado baseado em eventos. A sua principal vantagem é poder visualizar toda a máquina de estado em um só lugar, e sua principal desvantagem é pertecer ao Boost, o que quer dizer que você vai precisar fazer seu terceiro doutorado e ler uma documentação imensa sobre UML antes de conseguir produzir alguma coisa. Ou ler este artigo de 10 minutos tops.
#include &amp;lt;iostream&amp;gt;#include &amp;lt;boost/msm/back/state_machine.hpp&amp;gt;#include &amp;lt;boost/msm/front/state_machine_def.hpp&amp;gt;#include &amp;lt;boost/msm/front/functor_row.hpp&amp;gt;using namespace std;namespace MyStateMachine{namespace msm = boost::msm;namespace msmf = boost::msm::front;namespace mpl = boost::mpl;namespace Events{struct Event1 {};struct Event2 { int data; };struct Event3 {};}struct StateMachine :msmf::state_machine_def&amp;lt;StateMachine&amp;gt;{typedef msm::back::state_machine&amp;lt;StateMachine&amp;gt; SM;struct Off :msmf::terminate_state&amp;lt;&amp;gt; // Off is the last state{template &amp;lt;class Event, class Fsm&amp;gt;void on_entry(Event const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_entry Off generic event\n&amp;quot;;}}; struct On :msmf::state&amp;lt;&amp;gt;{template &amp;lt;class Event, class Fsm&amp;gt;void on_entry(Event const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_entry On generic event\n&amp;quot;;}template &amp;lt;class Fsm&amp;gt;void on_entry(Events::Event1 const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_entry On Event1\n&amp;quot;;}template &amp;lt;class Event, class Fsm&amp;gt;void on_exit(Event const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_exit On generic event\n&amp;quot;;}template &amp;lt;class Fsm&amp;gt;void on_exit(Events::Event2 const&amp;amp; evt, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_exit On Event2 (with data &amp;quot; &amp;lt;&amp;lt; evt.data &amp;lt;&amp;lt; &amp;quot;)\n&amp;quot;;}};struct Tick :msmf::state&amp;lt;&amp;gt;{template &amp;lt;class Event, class Fsm&amp;gt;void on_entry(Event const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_entry Tick generic event\n&amp;quot;;}template &amp;lt;class Fsm&amp;gt;void on_entry(Events::Event3 const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_entry Tick Event3\n&amp;quot;;}template &amp;lt;class Event, class Fsm&amp;gt;void on_exit(Event const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_exit Tick generic event\n&amp;quot;;}};typedef On initial_state; // On is the startstruct transition_table :mpl::vector&amp;lt;// Start Event Next Action Guardmsmf::Row &amp;lt; On, Events::Event1, On, msmf::none, msmf::none &amp;gt;,msmf::Row &amp;lt; On, Events::Event2, Tick, msmf::none, msmf::none &amp;gt;,msmf::Row &amp;lt; Tick, Events::Event3, Tick, msmf::none, msmf::none &amp;gt;,msmf::Row &amp;lt; Tick, Events::Event1, On, msmf::none, msmf::none &amp;gt;,msmf::Row &amp;lt; Tick, Events::Event2, Off, msmf::none, msmf::none &amp;gt;&amp;gt; {};};int TestPathway(){StateMachine::SM sm1;sm1.start();sm1.process_event(Events::Event1()); // keep in Onsm1.process_event(Events::Event2()); // to Ticksm1.process_event(Events::Event3()); // keep in Ticksm1.process_event(Events::Event1()); // back to Onsm1.process_event(Events::Event2 { 42 }); // back to Ticksm1.process_event(Events::Event2()); // finishreturn 0;}}int main(){MyStateMachine::TestPathway();}A parte bonitinha de se ver é os eventos e estados completamente ordenados:
struct transition_table :mpl::vector&amp;lt;// Start Event Next Action Guardmsmf::Row &amp;lt; On, Events::Event1, On, msmf::none, msmf::none &amp;gt;,msmf::Row &amp;lt; On, Events::Event2, Tick, msmf::none, msmf::none &amp;gt;,msmf::Row &amp;lt; Tick, Events::Event3, Tick, msmf::none, msmf::none &amp;gt;,msmf::Row &amp;lt; Tick, Events::Event1, On, msmf::none, msmf::none &amp;gt;,msmf::Row &amp;lt; Tick, Events::Event2, Off, msmf::none, msmf::none &amp;gt;&amp;gt; {};Claro que a indentação ajuda. Para cada entrada e saída de um estado é possível utilizar os métodos on_entry e on_exit de cada struct que define um estado, seja este método um template totalmente genérico ou especificado por evento (e cada evento também é um struct, com direito a dados específicos).
template &amp;lt;class Event, class Fsm&amp;gt;void on_entry(Event const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_entry On generic event\n&amp;quot;;}template &amp;lt;class Fsm&amp;gt;void on_entry(Events::Event1 const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_entry On Event1\n&amp;quot;;}template &amp;lt;class Event, class Fsm&amp;gt;void on_exit(Event const&amp;amp;, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_exit On generic event\n&amp;quot;;}template &amp;lt;class Fsm&amp;gt;void on_exit(Events::Event2 const&amp;amp; evt, Fsm&amp;amp;) const{cout &amp;lt;&amp;lt; &amp;quot;on_exit On Event2 (with data &amp;quot; &amp;lt;&amp;lt; evt.data &amp;lt;&amp;lt; &amp;quot;)\n&amp;quot;;}Quando é criada uma nova máquina de estados o estado inicial é chamado pelo evento on_entry genérico. Como sabemos qual é o estado inicial? Isso é definido pelo typedef initial_state dentro da classe da máquina de estado (que deve herdar de state_machine_def no estilo WTL, com sobrecarga estática):
struct StateMachine :msmf::state_machine_def&amp;lt;StateMachine&amp;gt;//...typedef On initial_state; // On is the startO estado final também é definido, mas por herança. O estado final, que também é uma struct, deve herdar de terminate_state:
struct Off :msmf::terminate_state&amp;lt;&amp;gt;A partir daí o método process_event serve para enviar eventos à máquina de estado que irá alterar seu estado dependendo do fluxo criado no nome transition_table dentro da máquina de estado (a tabelinha que vimos acima). A partir daí tudo é possível; a máquina de estado está à solta:
int TestPathway(){StateMachine::SM sm1;sm1.start();sm1.process_event(Events::Event1()); // keep in Onsm1.process_event(Events::Event2()); // to Ticksm1.process_event(Events::Event3()); // keep in Ticksm1.process_event(Events::Event1()); // back to Onsm1.process_event(Events::Event2 { 42 }); // back to Ticksm1.process_event(Events::Event2()); // finishreturn 0;}Mas nesse exemplo didático está comportada em uma função apenas. Claro que cada método recebe a própria máquina de estado para ter a chance de alterá-la, ou guardá-la para uso futuro. Ela é recebida como parâmetro assim como o evento. E o evento, por ser uma struct também, pode conter outros dados relevantes para a transição.
</description>
</item>

     
        <item>
  <title>Como Apagar o Prompt do seu Programa Windows</title>
  <link>http://www.caloni.com.br/como-apagar-o-prompt-do-seu-programa-windows/</link>
  <pubDate>2018-01-23</pubDate>
  
  <guid>http://www.caloni.com.br/como-apagar-o-prompt-do-seu-programa-windows/</guid>
  <description>Geralmente se cria um projeto console/prompt quando há a necessidade de interfacear com o usuário com o uso da tela preta, saída padrão, etc. E no caso do Windows também há a possibilidade de criar um programa Win32 onde não há prompt, pois a função do programa ou é ser invisível ou criar, sabe como é, janelas. Mas nenhum dos dois possibilita ambos ao mesmo tempo. Este snippet permite que você faça isso.
void check_console() {HWND console = GetConsoleWindow(); // obtém a janela do console atualif (! console) return; // se não tiver, paciênciaunsigned long pid; // vamos pegar o pid do processo relacionado a este consoleif (! GetWindowThreadProcessId(console, &amp;amp;pid)) return; // se não der, paciência tambémif (GetCurrentProcessId() != pid) return; // se não formos nós os que criamos este prompt deixa quietoFreeConsole(); // somos nós que criamos: desaloca o console e já eras}int main(){check_console();}Para isso funcionar você criar um projeto console no Visual Studo. Essa opção está no Linker, System:
E voilà!
</description>
</item>

     
        <item>
  <title>Cmd e o encoding fake</title>
  <link>http://www.caloni.com.br/cmd-e-o-encoding-fake/</link>
  <pubDate>2017-12-26</pubDate>
  
  <guid>http://www.caloni.com.br/cmd-e-o-encoding-fake/</guid>
  <description>Qualquer um que já tenha mexido no prompt de comandos do Windows sabe que ele permite você escolher qual code page utilizar para enviar e receber comandos. O Windows é todo em UTF-16, mas as saídas podem vir de qualquer programa com qualquer encoding. A missão do cmd.exe é usar o encoding escolhido pelo usuário para exibir os caracteres na tela. Vamos supor que nós criemos uma pasta com acentos no nome (pelo Explorer para não ter erro):
Agora através de um cmd.exe podemos observar como esse nome acentuado aparece:
Note como o &amp;quot;a&amp;quot; acentuado com til aparece perfeitamente. Também note que o codepage utilizado é o 437.
Até aí tudo bem, certo?
Não! Não! Não!
O codepage 437 não possui ã. Nem õ.
Isso, meus amigos, é chamado tecnicamente na área de &amp;quot;muito louco&amp;quot;.
Curioso a respeito disso, resolvi observar a saída padrão do cmd.exe, para ver o que diabos vem como resultado. Para isso desenvolvi um simples output redirector tabajara:
#include &amp;lt;Windows.h&amp;gt;int main(int argc, char* argv[]){DWORD ret = ERROR_SUCCESS;SECURITY_ATTRIBUTES sa = { 0, NULL, TRUE };STARTUPINFOA si = { sizeof(si) };PROCESS_INFORMATION pi;CHAR cmd[4096] = &amp;#34;cmd.exe&amp;#34;;SECURITY_ATTRIBUTES saAttr;saAttr.nLength = sizeof(SECURITY_ATTRIBUTES);saAttr.bInheritHandle = TRUE;saAttr.lpSecurityDescriptor = NULL;si.dwFlags = STARTF_USESTDHANDLES;si.hStdOutput = CreateFileA(&amp;#34;cmd.log&amp;#34;, GENERIC_WRITE, FILE_SHARE_READ, &amp;amp;sa, CREATE_ALWAYS, 0, NULL);si.hStdError = si.hStdOutput;if( si.hStdOutput != NULL &amp;amp;&amp;amp; si.hStdOutput != INVALID_HANDLE_VALUE ){if (CreateProcessA(NULL, cmd, NULL, NULL, TRUE, CREATE_NEW_CONSOLE, NULL, NULL, &amp;amp;si, &amp;amp;pi)){WaitForSingleObject(pi.hProcess, INFINITE);CloseHandle(pi.hThread);CloseHandle(pi.hProcess);}CloseHandle(si.hStdOutput);}}Simples, bonito e prático. Quando executamos Redirector.exe ele executa um cmd.exe, com a diferença que a saída dele vai parar no arquivo cmd.log, que podemos observar com um BareTail da vida.
Opa, opa, opa!
O til sumiu!
Se formos analisar os bytes que vieram de saída, vamos constatar que o byte referente ao ã foi enviado para a saída padrão como o byte 0x61, ou 97 em decimal. No codepage 437 (e em qualquer derivado da tabela ASCII, na verdade) o byte 97 é representado como &amp;quot;a&amp;quot;, simplesmente, sem til.
Isso quer dizer que ao receber um &amp;quot;ã&amp;quot; o cmd.exe o reinterpreta como &amp;quot;a&amp;quot;, mesmo estando sob o encoding 437. Esse é o resultado de um prompt user friendly que quer seu amigo.
Se analisarmos a memória do cmd.exe veremos que ele armazena as coisas em UTF-16, como qualquer programa Windows nativo unicode.
@echo off:beg dir /b c:\temp\quemquer*goto beg E com isso constatamos que não necessariamente no Windows, What You See Is What You Get. Ou, em termos mais filosóficos, What You See Is Not What I Get.
</description>
</item>

     
        <item>
  <title>Se você não precisa de classe você não precisa de classe</title>
  <link>http://www.caloni.com.br/se-voce-nao-precisa-de-classe-voce-nao-precisa-de-classe/</link>
  <pubDate>2017-12-17</pubDate>
  
  <guid>http://www.caloni.com.br/se-voce-nao-precisa-de-classe-voce-nao-precisa-de-classe/</guid>
  <description>Nos últimos dias me deparei com o seguinte (pseudo-)código:
int main(int argc, const char **argv){MyClass obj;HRESULT hr = obj.init();if ( SUCCEEDED(hr) ){if ( args have &amp;#34;cmd1&amp;#34; ){hr = obj.cmd1();}else if ( args have &amp;#34;cmd2&amp;#34; ){hr = obj.cmd2();}... // você entendeu a ideia }}Dentro de MyClass a seguinte estrutura:
class MyClass{public:HRESULT m_result = S_OK;HRESULT init();HRESULT cmd1();HRESULT cmd2();// você pegou a ideia};Então eu me pergunto: qual a função da classe em um código desses?
Bjarne Stroustrup desde o começo, em seu livro The C&#43;&#43; Programming Language, sugere que C&#43;&#43; não é uma linguagem unicamente orientada a objetos, mas multi-paradigmas. Hoje, em 2017, ela é uma linguagem genérica e até funcional. Na época poderia ser usada como orientada a objetos, mas também como estruturada e imperativa comum. O goto funciona até hoje.
Então o erro no código acima é supor mecanicamente que como é C&#43;&#43; precisa ter classe.
Não. O código não precisa ter uma classe. No entanto, seu código precisa ter classe. Entendeu?
Ter classe é para poucos. É para programadores que se preocupam com a relação entre funcionalidade, estilo, arquitetura e todos os inúmeros elementos que tornam um código perfeito. Para ser perfeito, um código precisa levar em conta tantos elementos que apenas um programador acordado, obsessivo, fora da matrix, conseguiria observar o que deve ser feito.
Uma pequena sugestão:
#include &amp;lt;map&amp;gt;int main(int argc, const char **argv){MyMap cmds;if ( SUCCEEDED(init()) ){cmds[args]();}}HRESULT init();HRESULT cmd1();HRESULT cmd2();// você pegou a ideiaÉ a melhor solução? Não. Só uma ideia para tornar o código simples de entender, enxuto para manter, com apenas o modelito básico. Tem até um map para evitar encher de ifs. Mas não precisaria se você tem meia-dúzia de funções.
E note que eu disse funções, não classe. E é possível ter classe sem classes.
</description>
</item>

     
        <item>
  <title>C&#43;&#43; Moderno Arranca os Cabelos por Você (std::move e classes simples).</title>
  <link>http://www.caloni.com.br/cpp-arranca-os-cabelos-por-voce/</link>
  <pubDate>2017-09-26</pubDate>
  
  <guid>http://www.caloni.com.br/cpp-arranca-os-cabelos-por-voce/</guid>
  <description>Um dos últimos posts no grupo CCPPBR do Thiago Adams chama mais uma vez a atenção para a complexidade infinita que linguagens como C&#43;&#43; estão preferindo tomar. Esta é a geração que irá sofrer as dores de compatibilidade com o passado mais que todas as outras que virão.
Isso porque mudanças pontuais que vão sendo aplicadas na linguagem e biblioteca, como move semantics, não cabe mais em exemplos de livrinhos de C&#43;&#43; para iniciantes da década de 90:
#include &amp;lt;string.h&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;memory&amp;gt;struct X{char * pString = 0;X() {}X(const char* s){pString = _strdup(s);}~X(){free(pString);}};int main(){X x1;const X x2(&amp;#34;a&amp;#34;);x1 = std::move(x2);return 0;}Neste singelo exemplo, que está errado by design, a classe X não se preocupa em proteger-se de cópias simples. Mas o programador também não se protege da ignorância e usa std::move como se ele magicamente movesse referências const, o que é absurdo.
A questão, porém, não é sobre qual é o problema no código, mas os aspectos de design de C&#43;&#43; que podem levar futuros programadores a se depararem com o mesmo problema em versões multicamadas de complexidade. Este é um exemplo óbvio, mas até quando será?
Esta crítica pode levar (pelo menos) para dois diferentes caminhos:
 O funcionamento do std::move não é intuitivo e pode levar a erros semânticos (&amp;quot;se usar o move estou movendo referências&amp;quot;); programador não conhece o funcionamento por completo. Em C&#43;&#43; o esforço de manter uma classe é muito maior hoje do que em 98/03 (&amp;quot;tomar cuidado com reference, const reference, rvalue reference...&amp;quot;); isso concordo; as mudanças são bem-intencionadas, mas a linguagem é velha com alguns esqueletos que podem começar a balançar.  C&#43;&#43;, assim como o Brasil, desde o começo nunca foi para amadores. Hoje em dia ele é impossível. Ouço galera falar que está ficando lindo, mas, francamente, está virando é um ninho de cobras. Mantenedores de bibliotecas, se não estão já arrancando os cabelos, deveriam começar.
Mas talvez com C&#43;&#43; 17&#43; os cabelos passem a cair sozinho...
</description>
</item>

     
        <item>
  <title>Ativando Ubuntu No Windows 10</title>
  <link>http://www.caloni.com.br/ativando-ubuntu-no-windows-10/</link>
  <pubDate>2017-08-29</pubDate>
  
  <guid>http://www.caloni.com.br/ativando-ubuntu-no-windows-10/</guid>
  <description>Pensei que o Ubuntu já estivesse na Windows Store disponível para qualquer gamer instalar (não sei por que um gamer faria isso). Mas não. Ainda é necessário fazer os passos de desenvolvedor expert de Windows para ativar esta opção.
Primeiro, vá nas configurações e ative o Developer Mode:
Depois vá em Adicionar/Remover Programas e ative o Windows Subsystem for Linux (Beta):
Reinicie a máquina, abra o prompt de comando, digite bash e enter. Ele irá perguntar se quer instalar o Ubuntu, diga que sim, e depois de um tempo já terá o melhor dos dois mundos: o melhor ambiente gráfico com o melhor ambiente de programação.
Cywgin quem?
</description>
</item>

     
        <item>
  <title>Migrando Imagens Para Imgur</title>
  <link>http://www.caloni.com.br/migrando-imagens-para-imgur/</link>
  <pubDate>2017-07-28</pubDate>
  
  <guid>http://www.caloni.com.br/migrando-imagens-para-imgur/</guid>
  <description>Depois de migrar meus blogues para o Hugo decidi deixar o repositório mais magro migrando as imagens para um serviço de imagens. O imgur me pareceu uma solução simples com uma interface rápida (e uma API Python). Para realizar essa tarefa você vai precisar das ferramentas de sempre: grep, sed, python, vim. E lá vamos nós.
Meu primeiro passo foi realmente limpar a pasta de imagens, eliminando as que não estavam sendo usadas. A pasta de imagens ficou se acumulando por anos, e muitas imagens foram sendo carregadas através dos Wordpress da vida e plugins que deram resize nas imagens, gerando várias cópias no processo. Tudo inútil e dispendioso.
dir /b imagens\*.* &amp;gt; images.batrem transformar cada linha de images.bat em: rem grep -c imagem.png all.md images.bat &amp;gt; result.logrem a partir do vim juntar o resultado das linhas e apagar os resultados não-zerados rem imagem-found.png rem 1 rem imagem-not-found.png rem 0 v/^[0-9]/jv/0$/drem pronto; agora é só rodar o result.log como bat O principal problema de subir tudo para o imgur é que os nomes dos arquivos irão mudar e perder a referências usadas no texto. Para conseguir renomear os arquivos dentro dos artigos é necessário conectar no serviço do imgur e através dele obter o nome original do arquivo, disponível na propriedade name:
import authclient = auth.authenticate()f = open(&amp;#39;images.txt&amp;#39;)imgs = f.readlines()for img in imgs:img = img.strip(&amp;#39;\n&amp;#39;)imgur = client.get_image(img)origname = imgur.link[imgur.link.find(img):].replace(img, imgur.name)print origname, &amp;#39;=&amp;gt;&amp;#39;, imgExecutando este script será possível gerar um log no formato =&amp;gt; . O ID deles também é usado para link direto da imagem, de onde virá o comando sed que vai substituir nos artigos os nomes originais pelo link do imgur:
sed -i &amp;#34;s/&amp;lt;nome-original-do-arquivo&amp;gt;/http\/\/:\/&amp;lt;link-da-imagem-no-imgur&amp;gt;/&amp;lt;id-do-imgur&amp;gt;.&amp;lt;extensao&amp;gt;/&amp;#34; *.mdLembrar de apagar o all.md. Ele só foi usado para gerar a saída mais simples do grep.
</description>
</item>

     
        <item>
  <title>CppTests</title>
  <link>http://www.caloni.com.br/cpptests/</link>
  <pubDate>2017-07-25</pubDate>
  
  <guid>http://www.caloni.com.br/cpptests/</guid>
  <description>Iniciei um novo projeto no GitHub que tem por objetivo ser minha prancheta de trabalhos para minha palestra no próximo encontro ccpp. Há uma infinitude de coisinhas novas na linguagem C&#43;&#43;, fora as adições à biblioteca STL, mas que devem passar despercebidas da maioria dos programadores, que está mais é querendo terminar seus próprio projetos. Enquanto alguns conceitos, sintaxes e métodos não se solidificam, vale a pena dar uma espiada no futuro?
Depende.
Dei uma olhada nas últimas modificações adicionadas no Visual Studio 2017 (versão 15.3 preview 1, mas o último lançado é o preview 5), e há muitos elementos IMHO supérfluos, mas que tendem a ser integrados aos poucos (I hope).
A lista que achei interessante (com seu projeto):
 binary_literals_test. Perfumaria muito bem-vinda de uma linguagem feita para trabalhar também baixo nível. constexpr_test. Um teste que alguém fez na nossa lista ccpp do Telegram e que possui uma particularidade interessante (mais abaixo). for_range_generic_test. Ainda em teste, mas me parece a forma definitiva de iterar entre elementos em C&#43;&#43;; completamente genérico. generic_lambdas_test. E por falar em genérico, este lambda tem muito a ver com programação funcional. has_include_test. Uma maneira elegante (apesar do nome feio) de ir migrando projetos/libs aos poucos. initializer_list. Só demonstrando o que já é velho (mas que ainda não comentei no blogue). nodiscard_test. Essa é uma das features mais curiosas para escrita de código robusta. sfinae_test. O SFINAE é um dos pilares do C&#43;&#43;, e ele vem melhorando cada vez mais. static_assert_test. O que estava faltando que no Boost é macaco velho. user_defined_literals_test. Mais uma perfumaria; essa é bonitinha; para uso acadêmico. variable_templates_test. Mais algo já velho, que demonstro aqui com minha superlib de log.  constexpr para especialização em ifs A otimização no if através do uso da palavra-chave constexpr possibilita a criação de diferentes instâncias da chamada que não contém o if, mas um dos dois branches dependendo do tipo ser integral ou não.
Para que a compilação dessa opção funcione no Visual Studio 2017 15.3 é necessário inserir o parâmetro /std:c&#43;&#43;latest nas opções do projeto em C/C&#43;&#43;, Command Line:
Todos (ou a maioria) deles ainda está em teste. Acabei de baixar o preview 5, conforma um dos membros da ML dos MVPs C&#43;&#43; me informou que saiu quentinha do forno. Em breve novidades.
</description>
</item>

     
        <item>
  <title>Como acessar submódulos no git inacessíveis?</title>
  <link>http://www.caloni.com.br/submodules-locais-no-git/</link>
  <pubDate>2017-05-28</pubDate>
  
  <guid>http://www.caloni.com.br/submodules-locais-no-git/</guid>
  <description>Quando projetos remotos usam submodules é possível que algum deles seja acessível apenas através de chaves criptográficas. Isso exige que os sub-projetos necessários para fazer funcionar seu projeto podem estar fora do seu alcance e acesso, o que irá gerar durante seus comandos pull recursivos erros de ssh (publickey access).
A solução é ler a documentação e descobrir que é possível editar o arquivo .git/config para mudar a url de um submódulo inacessível pela forma do .gitmodules. Eis um exemplo de arquivo config dentro do .git:
[submodule &amp;#34;sbrubles&amp;#34;]url = git@github.com:user/project.gitVocê pode localmente alterar o endereço ssh deste submodule para algo que todos têm acesso ou só você tem acesso, como uma pasta local ou o endereço https:
[submodule &amp;#34;sbrubles&amp;#34;]url = https://github.com/user/project.gitNote que isso não irá interferir em nada no repositório localizado remotamente do projeto. Dessa forma diferentes membros da equipe podem usar diferentes formas de acessar um submódulo.
</description>
</item>

     
        <item>
  <title>SystemRescueCD: um CD cheio de ferramentas Linux para desenvolvedores e suporte</title>
  <link>http://www.caloni.com.br/systemrescuecd-um-cd-cheio-de-ferramentas/</link>
  <pubDate>2017-05-28</pubDate>
  
  <guid>http://www.caloni.com.br/systemrescuecd-um-cd-cheio-de-ferramentas/</guid>
  <description>Há diversas distros Linux capazes de bootar via CD e com uma penca de ferramentas. Conheci há alguns anos uma delas: a SystemRescueCd: um disco de recuperação de HDs com diversas ferramentas embutidas. Dentro dele pode ser inserido outras ferramentas que achar interessante, e o mais importante, desenvolver através do próprio CD suas ferramentas.
A modificação do CD pode ser feita bootando com ele mesmo, seguinto o tutorial da própria SystemRescueCd. No entanto, para facilitar o uso, é possível utilizá-lo em um ambiente virtualizado (criar uma VMWare que boote pelo CD, por exemplo, e depois instalar no HD virtual).
Outra opção interessante é montar outras partições partindo do próprio CD. Ao bootar com o CD da SystemRescue, após ter acesso ao terminal pela primeira vez, detecte e formate o HD Linux usando a ferramenta fdisk. Dentro da ferramenta use as opções padrão e crie uma particão Linux. Ao final, escreva com &#39;w&#39;, formate a partição (ex: mkfs.ext4) e a partição já deverá estar disponível no próximo boot.
ls /dev/sd*/dev/sda /dev/sdbfdisk /dev/sdamkfs.ext4 /dev/sda1Para formatar uma partição Windows é possível realizar o mesmo procedimento, mas trocar o tipo de partição para Windows FAT32. Com isso a partição estará disponível para ser montada tanto na máquina virtual quanto na real.
Desligue a VM. A partir do Windows, monte o HD Windows e formate a partição criada. Ou, se a partição ainda não foi criada é só criar pelo Gerenciador de Discos do Windows.
shutdown -h -t 0 nowObs.: Apenas a VM ou a máquina real podem utilizar o HD de uma vez. Portanto, para copiar arquivos para o HD virtualizado é necessário desligar a VM antes.
Customizando seu CD Seguindo o tutorial do SystemRescueCD (&amp;quot;Step-01: Mount the working partition&amp;quot;), vamos montar a partição Linux na pasta /mnt/custom.
% mkdir /mnt/custom% mount /dev/sda1 /mnt/customEm seguida extraia os arquivos atuais do CD para a pasta custom (essa operação pode demorar alguns minutos):
% /usr/sbin/sysresccd-custom extractApós a conclusão dessa operação, os arquivos customizados poderão ser encontrados em /mnt/custom/customcd/files/bin
ls /mnt/custom/customcd/files/binPara copiar os arquivos novos, monte a partição Windows e copie de uma pasta para outra. Já existe uma pasta em mnt chamada windows que pode ser alvo da montagem. Abaixo os comandos necessários para atualizar um possível script:
mount /dev/sdb1 /mnt/windowscp /mnt/windows/script.sh /mnt/custom/customcd/files/scriptoverwrite? yVoilá! Agora que os arquivos já foram atualizados é hora de regerar um novo ISO do CD. Para isso, executar o seguinte script do RescueCD (&amp;quot;Step-10: Create the new ISO image&amp;quot;); esse comando pode demorar alguns minutos:
/usr/sbin/sysresccd-custom isogen escolha_um_nomeApós a conclusão do comando o novo ISO deverá estar no diretório /mnt/custom/customcd/isofile/ com a data/hora atual. Copie este arquivo para a partição Windows para ter acesso ao ISO na máquina real:
cp /mnt/custom/customcd/isofile/*.iso /mnt/windowsDesligue a máquina virtual e volte a montar o HD na máquina real. O ISO do novo CD estará disponível.
</description>
</item>

     
        <item>
  <title>Forma simples de baixar atualizações remotamente de um cliente para um servidor</title>
  <link>http://www.caloni.com.br/forma-simples-de-baixar-atualizacoes-remotamente-de-um-cliente-para-um-servidor/</link>
  <pubDate>2017-03-23</pubDate>
  
  <guid>http://www.caloni.com.br/forma-simples-de-baixar-atualizacoes-remotamente-de-um-cliente-para-um-servidor/</guid>
  <description>A forma mais simples e independente de código para efetuar essa tarefa para Windows é no servidor subir um file server em qualquer porta disponível, e a forma de file server mais simples que existe é o embutido em qualquer instalação Python:
python -m SimpleHTTPServerPara que não seja necessário instalar o Python no servidor é possível transformar essa chamada em um executável e suas dependências standalone:
import SimpleHTTPServerimport SocketServerPORT = 8000Handler = SimpleHTTPServer.SimpleHTTPRequestHandlerhttpd = SocketServer.TCPServer((&amp;#34;&amp;#34;, PORT), Handler)print &amp;#34;serving at port&amp;#34;, PORThttpd.serve_forever()Esse script pode ser compilado pela ferramenta py2exe, instalável pelo próprio Python. É necessário criar um arquivo setup.py na mesma pasta do script e através desse script gerar uma pasta dist com o script &amp;quot;compilado&amp;quot; e pronto para ser executado.
from distutils.core import setupimport py2exesetup(console=[&amp;#39;fileserver.py&amp;#39;])Pelo prompt de comando executar o seguinte comando que irá gerar a pasta dist:
python setup.py py2exeUma vez gerada a pasta, renomear para fileserver e copiar no servidor em qualquer lugar (ex: pasta-raiz). Executar de qualquer pasta que se deseja tornar acessível via browser ou qualquer cliente http:
cd c:\toolsc:\fileserver\fileserver.exe Para testar basta acessar o endereço via browser:
Lado cliente Do lado cliente há ferramentas GNU como curl e wget para conseguir baixar rapidamente qualquer arquivo via HTTP. Para máquinas com Power Shell disponível há um comando que pode ser usado:
powershell wget http://127.0.0.1:8000/Procmon.exe -OutFile Procmon.exePorém, caso não seja possível usar o Power Shell o pacote básico do wget do GnuWin32, de 2MB, já consegue realizar o download.
c:\Temp\bitforge\wget&amp;gt;dirVolume in drive C is SYSTEMVolume Serial Number is 5C08-36EEDirectory of c:\Temp\bitforge\wget23/03/2017 13:25 &amp;lt;DIR&amp;gt; .23/03/2017 13:25 &amp;lt;DIR&amp;gt; ..03/09/2008 17:49 1.177.600 libeay32.dll14/03/2008 19:21 1.008.128 libiconv2.dll06/05/2005 16:52 103.424 libintl3.dll03/09/2008 17:49 232.960 libssl32.dll31/12/2008 11:03 449.024 wget.exec:\Temp\bitforge\wget&amp;gt;wget http://127.0.0.1:8000/Procmon.exeSYSTEM_WGETRC = c:/progra~1/wget/etc/wgetrcsyswgetrc = c:/progra~1/wget/etc/wgetrc--2017-03-23 13:44:13-- http://127.0.0.1:8000/Procmon.exeConnecting to 127.0.0.1:8000... connected.HTTP request sent, awaiting response... 200 OKLength: 2046608 (2,0M) [application/x-msdownload]Saving to: `Procmon.exe&#39;100%[===================================================================================================================================&amp;gt;] 2.046.608 --.-K/s in 0,006s2017-03-23 13:44:13 (348 MB/s) - `Procmon.exe&#39; saved [2046608/2046608]c:\Temp\bitforge\wget&amp;gt;E assim com poucas linhas de código já é possível iniciar um client/servidor via http que fornece arquivos de atualização. A própria versão do pacote e detalhes podem estar disponíveis na mesma pasta.
</description>
</item>

     
        <item>
  <title>Entrando na zona com Windows</title>
  <link>http://www.caloni.com.br/entrando-na-zona-com-windows/</link>
  <pubDate>2017-03-14</pubDate>
  
  <guid>http://www.caloni.com.br/entrando-na-zona-com-windows/</guid>
  <description>Update 2019-03-20: Adicionando programa para fazer tela cheia no Windows e retirados detalhes que não uso mais.
Um artigo anterior havia dado umas dicas de como transformar o Vim em uma ferramenta para toda obra, com isso limitando as distrações quando se está em um computador, e com isso facilitando a entrada e a permanência no estado de fluidez de produtividade que conhecemos como &amp;quot;flow&amp;quot;, ou estar na zona. Agora é a vez do Windows.
O Windows 10 já vem com atalhos pré-instalados assim que você loga nele. Tem browser, navegador de arquivos, notícias, e uma caralhada de coisas inúteis que ficam se mexendo na tela, chamando sua atenção, distraindo sobre o que é mais importante.
Mas é possível arrancar tudo isso e deixar na barra de tarefas pinado apenas as coisas realmente vitais para o uso do computador de trabalho, geralmente o terminal, o navegador (pesquisa, emails, etc) e o editor (não necessariamente o Vim).
Otimizando o terminal O terminal do Windows, o Command Prompt, ou cmd para os íntimos, sofreu algumas mudanças ultimamente. Entre elas há a transparência, o que o tornou cool, e a tela cheia (atalho Alt&#43;Enter), o que o tornou ideal como ferramenta de navegação para programadores (melhor do que o explorer, que virou um penduricalho de atalhos inúteis também). Você pode ativá-lo já entrando na tela cheia e com o code page de sua preferência (o meu é 65001, que é o utf8) usando esse pequeno programa:
#include &amp;lt;iostream&amp;gt;#include &amp;lt;windows.h&amp;gt;#pragma comment(lib, &amp;#34;user32&amp;#34;)int main(){if( ! SetConsoleDisplayMode(GetStdHandle(STD_OUTPUT_HANDLE), CONSOLE_FULLSCREEN_MODE | CONSOLE_WINDOWED_MODE, NULL) ){// Se falhas com GLE 120 (função não suportada) usar função abaixo. ::SendMessage(::GetConsoleWindow(), WM_SYSKEYDOWN, VK_RETURN, 0x20000000);}system(&amp;#34;chcp 65001&amp;#34;);}Configurando o git para controlar o fonte rapidamente Os comandos do git são muito verbose. Duas letras já seriam suficiente (o Windbg manipula seu programa com apenas uma...). Para otimizar a digitação no git crie uns aliases em seu HOME.gitconfig:
[user]name = Wanderley Caloniemail = wanderley.caloni@bitforge.com.br[alias]st = statusbr = branchci = commitco = checkout[core]editor = c:/Programs/Vim/vim80/gvim.exeautocrlf = trueexcludesfile = C:\\Users\\Caloni\\.gitignorefileMode = falseAtalhos da barra iniciar Agora, através dos atalhos Win&#43;1, 2, 3... pode-se abrir e alternar entre os aplicativos principais do seu dia-a-dia, que devem ficar &amp;quot;pinados&amp;quot; na barra de tarefas. Os meus atualmente são três: terminal (1 cmd), editor (2 vim) e browser (3 chrome). Não é necessário colocar coisas como Visual Studio, já que minha navegação é feita rapidamente pelo terminal para o projeto que irei mexer. Com isso o foco fica restrito a apenas uma coisa: o que você tem que fazer hoje? =)
</description>
</item>

     
        <item>
  <title>O velho problema do project out of date do Visual Studio</title>
  <link>http://www.caloni.com.br/o-velho-problema-do-project-out-of-date-do-visual-studio/</link>
  <pubDate>2017-02-20</pubDate>
  
  <guid>http://www.caloni.com.br/o-velho-problema-do-project-out-of-date-do-visual-studio/</guid>
  <description>Acho que todo mundo já passou por isso. Você compila todo o projeto bonitinho e no final, ao depurar, ele faz aquela velha pergunta: &amp;quot;o projeto está desatualizado: deseja compilar novamente?&amp;quot;. Mas como assim? Eu acabei de compilar, não faz nem cinco segundos. Está quentinho, saiu do forno agora.
Às vezes o Visual Studio cria umas esquisitices que se perpetuam por todas as versões. Isso tem algum sentido. Funciona mais ou menos assim a lógica do &amp;quot;project out of date&amp;quot;: se existir algum arquivo cuja data/hora eu não consigo verificar eu considero que o projeto está desatualizado. Por que? Pode ser que esse arquivo tenha que ser gerado automaticamente. Pode ser que houve erro de acesso. Pode ser várias coisas, mas ainda assim faz sentido.
Exceto quando o arquivo realmente não existe.
E isso é bem comum de acontecer em um projeto com algum refactory. Você acabou movendo alguns arquivos compartilhados entre projetos, mas em algum desses projetos o arquivo ainda está sendo apontado para o path errado, onde ele não mais existe. No entanto, por se tratar de um arquivo não-necessário para a compilação (ex: um header) não há erros na compilação. Apenas nessa detecção do Visual Studio.
O problema é que não existe nenhuma dica do que está errado em condições normais de temperatura e pressão. Para conseguiu olhar mais detalhes temos que ir em Tools, Options e configurar mais saída para o build. Pelo menos como detailed:
A partir daí teremos mais saída na janela de output do build. Logo no começo (talvez pela equipe do VS saber que isso é bem comum) há uma dica de quais arquivos exige o rebuild (você pode fazer isso apenas clicanco em build do projeto que sempre acusa como out of date):
Depois de detectado o arquivo faltante, é só removê-lo ou atualizar o path. Esse erro não deve mais acontecer e agora você só precisa compilar uma vez e sair depurando.
</description>
</item>

     
        <item>
  <title>Visualizando QString no Visual Studio</title>
  <link>http://www.caloni.com.br/visualizando-qstring-no-visual-studio/</link>
  <pubDate>2017-02-20</pubDate>
  
  <guid>http://www.caloni.com.br/visualizando-qstring-no-visual-studio/</guid>
  <description>O Qt não é um framework que pode apenas ser usado no QtCreator. Através de um projeto bem configurado pelo CMake, por exemplo, é possível ter um projeto que pode ser compilado e depurado tanto nas ferramentas do Qt quanto no Visual Studio. No entanto, na hora de depurar algumas coisas são difíceis de fazer. Por exemplo: como olhar o conteúdo de uma QString?
O Visual Studio utiliza um mecanismo que lembra os comandos bizarros que se usa no WinDbg, mexendo com registradores e tal. Através dessa combinação é possível dizer para o depurador como interpretar determinados tipos de objetos. Ele já vem obviamente pronto para std::string, CString (ATL) e deveria vir com QString, de tão famosa que é. Mas a versão do Visual Studio 2015 não vem. O jeito então é editar diretamente o arquivo onde ficam esses padrões.
; AutoExp.Dat - templates for automatically expanding data O nome do arquivo é autoexp.dat e ele fica em uma pasta no estilo Program Files, Microsoft Visual Studio, Common7, Packages, Debugger. É melhor você retirar ele dessa pasta antes de sobrescrevê-lo para não ter erro de acesso. Ao abri-lo verá que no começo há vários comentários que explicam como é o funcionamento desse padrão.
; type=[text]&amp;lt;member[,format]&amp;gt;... ; ; type	Name of the type (may be followed by &amp;lt;*&amp;gt; for template ;	types such as the ATL types listed below). ; ; text	Any text.Usually the name of the member to display, ;	or a shorthand name for the member. ; ; member	Name of a member to display. ; ; format	Watch format specifier. One of the following: ; ;	Letter	Description	Sample	Display ;	------	--------------------------	------------ ------------- ;	d,i	Signed decimal integer	0xF000F065,d -268373915 ;	u	Unsigned decimal integer	0x0065,u	101 ;	o	Unsigned octal integer	0xF065,o	0170145 ;	x,X	Hexadecimal integer	61541,X	0X0000F065 ;	l,h	long or short prefix for	00406042,hx 0x0c22 ;	d, i, u, o, x, X ;	f	Signed floating-point	3./2.,f	1.500000 ;	e	Signed scientific-notation	3./2.,e	1.500000e&#43;000 ;	g	Shorter of e and f	3./2.,g	1.5 ;	c	Single character	0x0065,c	&amp;#39;e&amp;#39; ;	s	Zero-terminated string	pVar,s	&amp;#34;Hello world&amp;#34; ;	su	Unicode string	pVar,su	&amp;#34;Hello world&amp;#34; ; ; For details of other format specifiers see Help under: ; &amp;#34;format specifiers/watch variable&amp;#34; Felizmente (e também obviamente) o pessoal do Qt já fez uma entrada na wiki que explica como fazer para interpretar corretamente uma QString. Eles mesmos admitem que a coisa ficou difícil desde a última versão (Qt 5), mas ainda assim é possível. E, se tudo falhar, ainda é possível usar a janela de Watch:
(char*)str.d &#43; str.d-&amp;gt;offset,suMas não foi o caso dessa vez. Tudo funcionou perfeitamente assim que incluí os valores da Wiki logo no começo da sessão Visualizer.
</description>
</item>

     
        <item>
  <title>Palestra: como criar moedas digitais em casa com C&#43;&#43; (kick-off)</title>
  <link>http://www.caloni.com.br/palestra-como-criar-moedas-digitais-em-casa-com-cpp-kick-off/</link>
  <pubDate>2017-02-19</pubDate>
  
  <guid>http://www.caloni.com.br/palestra-como-criar-moedas-digitais-em-casa-com-cpp-kick-off/</guid>
  <description>Esta palestra tem como objetivo ensinar o que são moedas digitais, como o bitcoin, e cada passo necessário o algoritmo e implementação para torná-la real. Será utilizado C&#43;&#43; como a linguagem-base e o foco está mais na implementação do que na matemática ou no algoritmo. Assim como foi criado o bitcoin, o importante a aprender é como unir diferentes tipos de conhecimento e tecnologia em torno de um objetivo único, simples e prático.
A partir da criação da moeda surge a necessidade de facilitar o seu uso, um problema recorrente em todas as mais de 700 moedas digitais existentes no mercado e no laboratório, incluindo o bitcoin. Após a palestra teremos uma discussão de como levar a tecnologia ao usuário comum.
Construindo os princípios básicos Para nossa moeda digital utilizaremos um sistema simples, rápido e prático para subir informações na memória de um nó (server) e repassar essas informações para outros nós, o tiodb. Este projeto mantém contêineres STL na memória da maneira mais enxuta possível e eles são acessíveis através do protocolo mais simples possível utilizando uma gama de linguagens (C, C&#43;&#43;, Python, .NET).
A primeira coisa é compilar o projeto tiodb, que irá disponibilizar alguns binários em sua saída:
 tio.exe é o executável central cuja instância mantém contêineres na memória; InteliHubExplorer.exe é uma interface simples para navegar por esses contêineres; tioclient.dll é a biblioteca dinâmica que pode ser usada por clientes para acessar o tio.  Podemos rodar o tio deixando ele usar os parâmetros padrão ou alterar número da porta e outros detalhes. Vamos executar da maneira mais simples:
C:\Projects\tiocoin\tiodb\bin\x64\Debug&amp;gt;tio Tio, The Information Overlord. Copyright Rodrigo Strauss (www.1bit.com.br)Starting infrastructure...Saving files to C:/Users/Caloni/AppData/Local/TempListening on port 2605Up and running!OK, tio rodando e ativo. Podemos navegar já pelos seus contêineres usando o InteliHubExplorer:
Por convenção os contêineres seguem um padrão de nomes que se assemelha a uma hierarquia de diretórios, e os nomes que começam com underline são internos/reservados. O contêiner meta/sessions, por exemplo, contém uma lista simples das conexões ativas deste nó.
A partir do servidor funcionando é possível criar novos contêineres e mantê-los, adicionando, atualizando e removendo itens. A partir dessas modificações outros clientes podem receber notícias dessas modificações e tomar suas próprias decisões.
Vamos criar e popular um contêiner inicial de transações com um GUID zerado, e a partir dele vamos adicionando novas &amp;quot;transações&amp;quot;. Também iremos permitir o monitoramento dessas transações.
try{tio::Connection conn;conn.Connect(server, port);if (args.find(&amp;#34;--build&amp;#34;) != args.end()){tio::containers::list&amp;lt;string&amp;gt; transactionsBuilder;transactionsBuilder.create(&amp;amp;conn, &amp;#34;transactions&amp;#34;, &amp;#34;volatile_list&amp;#34;);transactionsBuilder.push_back(&amp;#34;{00000000-0000-0000-0000-0000000000000&amp;#34;);}else if (args.find(&amp;#34;--add&amp;#34;) != args.end()){tio::containers::list&amp;lt;string&amp;gt; transactionsAdd;transactionsAdd.create(&amp;amp;conn, &amp;#34;transactions&amp;#34;, &amp;#34;volatile_list&amp;#34;);string newTransaction = NewGuid();if( newTransaction.size())transactionsAdd.push_back(newTransaction);elsecout &amp;lt;&amp;lt; &amp;#34;Error creating transaction\n&amp;#34;;}else if (args.find(&amp;#34;--monitor&amp;#34;) != args.end()){tio::containers::list&amp;lt;string&amp;gt; transactionsMonitor;transactionsMonitor.open(&amp;amp;conn, &amp;#34;transactions&amp;#34;);transactionsMonitor.subscribe([](auto container, auto containerEvt, auto key, auto value){int eventCode = stoi(containerEvt);switch (eventCode){case TIO_COMMAND_PING:cout &amp;lt;&amp;lt; &amp;#34;Ping!\n&amp;#34;;break;case TIO_EVENT_SNAPSHOT_END:cout &amp;lt;&amp;lt; &amp;#34;Snapshot end\n&amp;#34;;break;case TIO_COMMAND_PUSH_BACK:cout &amp;lt;&amp;lt; &amp;#34;New transaction &amp;#34; &amp;lt;&amp;lt; value &amp;lt;&amp;lt; &amp;#34; inserted\n&amp;#34;;break;default:cout &amp;lt;&amp;lt; &amp;#34;Unknown event &amp;#34; &amp;lt;&amp;lt; hex &amp;lt;&amp;lt; eventCode &amp;lt;&amp;lt; &amp;#34; with key &amp;#34; &amp;lt;&amp;lt; dec &amp;lt;&amp;lt; key &amp;lt;&amp;lt; &amp;#34; and with value &amp;#34; &amp;lt;&amp;lt; value;break;}});while (true){conn.WaitForNextEventAndDispatch(0);Sleep(1000);}}else{tio::containers::list&amp;lt;string&amp;gt; transactionsReader;transactionsReader.open(&amp;amp;conn, &amp;#34;transactions&amp;#34;);for( size_t transactionIdx = 0; transactionIdx &amp;lt; transactionsReader.size(); &#43;&#43;transactionIdx )cout &amp;lt;&amp;lt; &amp;#34;Transaction &amp;#34; &amp;lt;&amp;lt; transactionsReader.at(transactionIdx) &amp;lt;&amp;lt; endl;}break; // just testing and developing...}catch (tio::tio_exception&amp;amp; e){Log(&amp;#34;Connection error: %s&amp;#34;, e.what());break;}catch (std::runtime_error&amp;amp; e){Log(&amp;#34;Runtime error: %s&amp;#34;, e.what());break;}catch (...){Log(&amp;#34;Catastrophic error&amp;#34;);break;}Após executar esse código passando o argumento &amp;quot;--build&amp;quot; e atualizarmos o IntelihubExplorer poderemos ver o novo contêiner e seu conteúdo:
É possível ler o código rodando o mesmo programa sem passar o argumento &amp;quot;--build&amp;quot;:
Agora imagine que exista um cliente da tiocoin que está monitorando as transações deste servidor para verificar a partir de qual momento uma transação foi aceita (supondo que este contêiner possui as transações aceitas):
Voilà! Agora temos um sistema inicial com um contêiner que irá manter os IDs de supostas transações de nossa moeda digital. Está compilando e está rodando, e em cima disso poderemos ir adicionando as funcionalidades.
Atenção: você poderá encontrar o repositório do tiocoin aqui.
</description>
</item>

     
        <item>
  <title>Pacotes perdidos do NuGet em projetos C&#43;&#43; no Visual Studio</title>
  <link>http://www.caloni.com.br/pacotes-perdidos-nuget-em-projetos-cpp-no-visual-studio/</link>
  <pubDate>2017-02-08</pubDate>
  
  <guid>http://www.caloni.com.br/pacotes-perdidos-nuget-em-projetos-cpp-no-visual-studio/</guid>
  <description>É muito bom (para quem gosta) usar a IDE e viver feliz sem precisar se preocupar em digitar comandos estranhos no prompt. Porém, essa vida acaba quando ocorre o primeiro erro inexplicável, aquele tipo de erro que não importa onde você olhe, não há nada para olhar. Até você apelar para ferramentas de macho.
Que nem hoje de manhã, quando fui inocentemente baixar uma versão limpa do tiodb e após baixar todos os pacotes do NuGet, o gerenciador de pacotes do Visual Studio (inclusive para C&#43;&#43;, agora) acusou a falta do boost, sendo que ele havia acabado de baixá-lo:
Os pacotes do projeto ficam todos na raiz do diretório da solução na sub-pasta packages. Observando o que foi baixado lá, verifiquei que a versão do boost estava ok: ele havia baixado a 1.61 como pedido, mas o erro dizia respeito justamente a um desses pacotes.
C:\Projects\tiodb&amp;gt;dir /b packages boost.1.61.0.0boost_chrono-vc140.1.61.0.0boost_date_time-vc140.1.61.0.0boost_filesystem-vc140.1.61.0.0boost_program_options-vc140.1.61.0.0boost_regex-vc140.1.61.0.0boost_system-vc140.1.61.0.0boost_thread-vc140.1.61.0.0O maior problema disso é que não há muitas opções na IDE que resolvam. O arquivo packages.config deveria manter essas dependências, o que de fato ele faz. As opções do projeto (as abinhas do Visual Studio onde ficam as configurações) não possuem nada relacionado ao NuGet.
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?&amp;gt;&amp;lt;packages&amp;gt;&amp;lt;package id=&amp;#34;boost&amp;#34; version=&amp;#34;1.61.0.0&amp;#34; targetFramework=&amp;#34;native&amp;#34; /&amp;gt;&amp;lt;package id=&amp;#34;boost_chrono-vc140&amp;#34; version=&amp;#34;1.61.0.0&amp;#34; targetFramework=&amp;#34;native&amp;#34; /&amp;gt;&amp;lt;package id=&amp;#34;boost_date_time-vc140&amp;#34; version=&amp;#34;1.61.0.0&amp;#34; targetFramework=&amp;#34;native&amp;#34; /&amp;gt;&amp;lt;package id=&amp;#34;boost_filesystem-vc140&amp;#34; version=&amp;#34;1.61.0.0&amp;#34; targetFramework=&amp;#34;native&amp;#34; /&amp;gt;&amp;lt;package id=&amp;#34;boost_program_options-vc140&amp;#34; version=&amp;#34;1.61.0.0&amp;#34; targetFramework=&amp;#34;native&amp;#34; /&amp;gt;&amp;lt;package id=&amp;#34;boost_regex-vc140&amp;#34; version=&amp;#34;1.61.0.0&amp;#34; targetFramework=&amp;#34;native&amp;#34; /&amp;gt;&amp;lt;package id=&amp;#34;boost_system-vc140&amp;#34; version=&amp;#34;1.61.0.0&amp;#34; targetFramework=&amp;#34;native&amp;#34; /&amp;gt;&amp;lt;package id=&amp;#34;boost_thread-vc140&amp;#34; version=&amp;#34;1.61.0.0&amp;#34; targetFramework=&amp;#34;native&amp;#34; /&amp;gt;&amp;lt;/packages&amp;gt;Então não tem jeito. Há algo de podre dentro desse projeto e o próprio Visual Studio não vai resolver. Grep nele!
C:\Projects\tiodb&amp;gt;grep -r -i &amp;#34;boost.*1.61&amp;#34; --include=*proj . ./server/tio/tioserver.vcxproj: &amp;lt;Import Project=&amp;#34;packages\boost.1.61.0.0\build\native\boost.targets&amp;#34; Condition=&amp;#34;Exists(&amp;#39;packages\boost.1.61.0.0\build\native\boost.targets&amp;#39;)&amp;#34; /&amp;gt;./server/tio/tioserver.vcxproj: &amp;lt;Error Condition=&amp;#34;!Exists(&amp;#39;packages\boost.1.61.0.0\build\native\boost.targets&amp;#39;)&amp;#34; Text=&amp;#34;$([System.String]::Format(&amp;#39;$(ErrorText)&amp;#39;, &amp;#39;packages\boost.1.61.0.0\build\native\boost.targets&amp;#39;))&amp;#34; /&amp;gt;...Note (e é preciso prestar atenção!) que o projeto server/tio/tioserver.vcxproj referencia a pasta packages como se ela existisse dentro do projeto. Porém, como já sabemos, ela existe na raiz da solution, que fica duas pastas &amp;quot;para trás&amp;quot;. Isso nos indica que talvez o NuGet ainda não esteja tão redondo e que um possível teste é mudar esses valores na mão e ver o que acontece.
gvim server\tio\tioserver.vcxproj:%s/packages\\boost/..\\..\\packages\\boost/g :wq 1&amp;gt;------ Build started: Project: tioclientdll, Configuration: Debug x64 ------2&amp;gt;------ Build started: Project: tioserver, Configuration: Debug x64 ------2&amp;gt; tioserver.vcxproj -&amp;gt; C:\Projects\tiocoin\tiodb\server\tio\..\..\bin\x64\Debug\tio.exe2&amp;gt; tioserver.vcxproj -&amp;gt; ..\..\bin\x64\Debug\tio.pdb (Full PDB)========== Build: 2 succeeded, 0 failed, 3 up-to-date, 0 skipped ==========Recarregado o projeto no Visual Studio após a intervenção cirúrgica, tudo voltou a funcionar. A lição de hoje é: nunca confie completamente em uma IDE. Às vezes o bom e velho grep e o bom e velho editor de sua escolha podem resolver uma situação.
</description>
</item>

     
        <item>
  <title>Um commit por feature</title>
  <link>http://www.caloni.com.br/um-commit-por-feature/</link>
  <pubDate>2017-02-04</pubDate>
  
  <guid>http://www.caloni.com.br/um-commit-por-feature/</guid>
  <description>Imagine que você vai começar a trabalhar em algo novo. Daí você baixa a última versão do branch de dev e começa a codar. Então chega um momento em que o primeiro, segundo, terceiro commits são necessários para manter a ordem em sua cabeça. &amp;quot;Fiz isso logo de manhã, testei algo diferente antes do almoço e de tarde fui incrementando a solução final até passar todos os testes.&amp;quot; Tudo bonito. Mas como fica na hora de subir essa bagaça pras pessoas verem?
Vamos visualizar isso em commits. Você baixa a última versão do dev, começa a trabalhar e de duas uma:
 Percebe que dá para resolver tudo em um commit só. Percebe que o buraco é mais embaixo; vou precisar de mais tempo e mais commits.  No caso 1, a solução é simples e direta: faça as modificações, rode os testes locais e aplique o commit já no formato definido pela sua equipe (número do ticket, texto no idioma correto, detalhes nos parágrafos abaixo). Suba e mande para code review.
C:\Temp\projectX&amp;gt;git pull Already up-to-date.C:\Temp\projectX&amp;gt;git branch * devmasterC:\Temp\projectX&amp;gt;gvim main.cpp C:\Temp\projectX&amp;gt;git add main.cpp C:\Temp\projectX&amp;gt;git ci -m &amp;#34;ISS-4 Changing test function return type to int.&amp;#34; [dev 7f0121b] ISS-4 Changing test function return type to int.1 file changed, 2 insertions(&#43;), 1 deletion(-)C:\Temp\projectX&amp;gt;git status On branch devYour branch is ahead of &amp;#39;origin/dev&amp;#39; by 1 commit.(use &amp;#34;git push&amp;#34; to publish your local commits)nothing to commit, working tree cleanC:\Temp\projectX&amp;gt; Se a política de pull request estiver sendo usada, faça isso em um branch à parte, mas já mande para o reviewer aprovar o branch como se fosse um commit apenas e de preferência pronto para o rebase (o que não deve ser nem um problema se for uma mudança pontual).
C:\Temp\projectX&amp;gt;gvim main.cpp C:\Temp\projectX&amp;gt;git co -b ISS-5-changing-test-return-value M main.cppSwitched to a new branch &amp;#39;ISS-5-changing-test-return-value&amp;#39;C:\Temp\projectX&amp;gt;git add main.cpp C:\Temp\projectX&amp;gt;git ci -m &amp;#34;ISS-5 Changing test return value&amp;#34; [ISS-5-changing-test-return-value 38df69c] ISS-5 Changing test return value1 file changed, 1 insertion(&#43;), 1 deletion(-)C:\Temp\projectX&amp;gt;git status On branch ISS-5-changing-test-return-valuenothing to commit, working tree cleanC:\Temp\projectX&amp;gt;git push origin ISS-5-changing-test-return-value Counting objects: 6, done.Delta compression using up to 8 threads.Compressing objects: 100% (4/4), done.Writing objects: 100% (6/6), 618 bytes | 0 bytes/s, done.Total 6 (delta 2), reused 0 (delta 0)To ..\projectXRemote* [new branch] ISS-5-changing-test-return-value -&amp;gt; ISS-5-changing-test-return-valueQuando o buraco é mais embaixo Quando mais de um commit é necessário é porque vai rolar a festa. Vários commits com texto e modificações temporárias podem ser feitos, e caso o trabalho vire a noite, é recomendado subir tudo para um branch temporário remoto (de preferência que já seja identificado pela equipe como o branch para determinado issue).
C:\Temp\projectX&amp;gt;git branch ISS-5-changing-test-return-value* devmasterC:\Temp\projectX&amp;gt;git co -b ISS-6-very-hard-hacking Switched to a new branch &amp;#39;ISS-6-very-hard-hacking&amp;#39;C:\Temp\projectX&amp;gt;gvim main.cpp C:\Temp\projectX&amp;gt;git add main.cpp C:\Temp\projectX&amp;gt;git ci -m &amp;#34;Starting to test return 42.&amp;#34; [ISS-6-very-hard-hacking e09cf24] Starting to test return 42.1 file changed, 1 insertion(&#43;), 1 deletion(-)C:\Temp\projectX&amp;gt;gvim main.cpp C:\Temp\projectX&amp;gt;git add main.cpp C:\Temp\projectX&amp;gt;git ci -m &amp;#34;Created backup test. [ISS-6-very-hard-hacking 80a7f71] Created backup test.1 file changed, 5 insertions(&#43;)C:\Temp\projectX&amp;gt;gvim main.cpp C:\Temp\projectX&amp;gt;git add main.cpp C:\Temp\projectX&amp;gt;git ci -m &amp;#34;Deleted backup function test.&amp;#34; [ISS-6-very-hard-hacking 9620226] Deleted backup function test.1 file changed, 5 deletions(-)C:\Temp\projectX&amp;gt;gvim main.cpp C:\Temp\projectX&amp;gt;git add main.cpp C:\Temp\projectX&amp;gt;git ci -m &amp;#34;Screwing around.&amp;#34; [ISS-6-very-hard-hacking 18d3afa] Screwing around.1 file changed, 2 deletions(-)C:\Temp\projectX&amp;gt;gvim main.cpp C:\Temp\projectX&amp;gt;git add main.cpp C:\Temp\projectX&amp;gt;git ci -m &amp;#34;Getting old version back.&amp;#34; [ISS-6-very-hard-hacking f2a63d1] Getting old version back.1 file changed, 2 insertions(&#43;)C:\Temp\projectX&amp;gt;gvim main.cpp C:\Temp\projectX&amp;gt;git add main.cpp C:\Temp\projectX&amp;gt;git ci -m &amp;#34;Small fix after unit tests.&amp;#34; [ISS-6-very-hard-hacking e612339] Small fix after unit tests.1 file changed, 1 insertion(&#43;), 1 deletion(-)C:\Temp\projectX&amp;gt;git log --oneline e612339 Small fix after unit tests.f2a63d1 Getting old version back.18d3afa Screwing around.9620226 Deleted backup function test.80a7f71 Created backup test.e09cf24 Starting to test return 42.7f0121b ISS-4 Changing test function return type to int.97222ec ISS-3 Testing something new.49d28aa ISS-2 Insertind comments and whatever.bff8edf ISS-1 First version.Agora nós criamos uma bela duma bagunça, mas em um branch apartado e que ainda não foi enviado para pull requet ou inserido no branch de dev. Agora chega a hora de arrumar a casa. Para isso, como tudo no git, há várias maneiras, mas a mais direta é um rebase interativo (-i), onde você pega os commits e empacota tudo junto.
(Obs.: se sua modificação demorou algum tempo é melhor atualizar o branch de dev para ver se há algo novo e fazer o merge com o branch de feature; o rebase daí não encontrará conflitos.)
C:\Temp\projectX&amp;gt;git merge dev Already up-to-date.C:\Temp\projectX&amp;gt;git rebase -i dev Nesse momento o git irá abrir o editor com os commits trabalhados. Você deverá escolher quais operações fazer com cada commit. Se o objetivo é empacotar tudo, geralmente é pick no primeiro e squash em todos os outros:
pick e09cf24 Starting to test return 42.squash 80a7f71 Created backup test.squash 9620226 Deleted backup function test.squash 18d3afa Screwing around.squash f2a63d1 Getting old version back.squash e612339 Small fix after unit tests.Ao final da operação mais uma vez o git irá exibir o editor. Agora é hora de você escolher o texto bonitinho, formatadinho, do seu único commit que será usado no branch de dev. Em outras palavras, transformar isso:
# This is a combination of 6 commits.# The first commit&amp;#39;s message is:Starting to test return 42.# This is the commit message #2:Created backup test.# This is the commit message #3:Deleted backup function test.# This is the commit message #4:Screwing around.# This is the commit message #5:Getting old version back.# This is the commit message #6:Small fix after unit tests.Nisso:
ISS-6 A very hard hacking, tested and ready to merge.This hack involved several operations:- Starting to test return 42.- Created backup test.- Deleted backup function test.- Small fix after unit tests.Agora na hora de fazer o merge seu histórico estará redondo, sem ramificações e com o resultado final de seu hacking parecendo que foi feito bonito desde o começo (ah, vá):
C:\Temp\projectX&amp;gt;git log commit b4de47231f090e897053f4e9d19ea66c88d1f1faAuthor: Wanderley Caloni &amp;lt;wanderley.caloni@bitforge.com.br&amp;gt;Date: Sat Feb 4 10:59:18 2017 -0200ISS-6 A very hard hacking, tested and ready to merge.This hack involved several operations:- Starting to test return 42.- Created backup test.- Deleted backup function test.- Small fix after unit tests.commit 7f0121baac183eb1a832575781cca5d6e6a5489cAuthor: Wanderley Caloni &amp;lt;wanderley.caloni@bitforge.com.br&amp;gt;Date: Sat Feb 4 10:51:54 2017 -0200ISS-4 Changing test function return type to int.commit 97222ec4578f9a4bced847266739b18f933178f3Author: Wanderley Caloni &amp;lt;wanderley.caloni@bitforge.com.br&amp;gt;Date: Sat Feb 4 10:50:29 2017 -0200ISS-3 Testing something new.commit 49d28aa7faa02ff327ae9fac93676abad18ad0f3Author: Wanderley Caloni &amp;lt;wanderley.caloni@bitforge.com.br&amp;gt;Date: Sat Feb 4 10:49:26 2017 -0200ISS-2 Insertind comments and whatever.commit bff8edf06e4a30480088a9a33c9b0c2ca5b6e0b3Author: Wanderley Caloni &amp;lt;wanderley.caloni@bitforge.com.br&amp;gt;Date: Sat Feb 4 10:47:11 2017 -0200ISS-1 First version.O que aprendemos aqui Esta é uma das inúmeras formas de trabalhar com o git de maneira individual sem atrapalhar seus colegas. Basicamente você pode escolher outras estratégias de commits e branchs locais, mas através do comando rebase -i é possível sempre reorganizar a bagunça em commits comportados, e dar a impressão que esses programadores são enviados divinos que modificam o fonte e acertam de primeira.
</description>
</item>

     
        <item>
  <title>Warning de nível 4</title>
  <link>http://www.caloni.com.br/warning-de-nivel-4/</link>
  <pubDate>2017-01-17</pubDate>
  
  <guid>http://www.caloni.com.br/warning-de-nivel-4/</guid>
  <description>Você já colocou aquele seu projeto favorito em /W4? Por padrão, o Visual Studio cria seus projetos com o nível de warnings e 3, porque o nível 4 é muito, muito chato. No entanto, algumas vezes ele serve para que seu código não fique apenas correto, mas bem documentado e apresentável. Vamos tentar?
1&amp;gt;------ Build started: Project: tioserver, Configuration: Debug x64 ------1&amp;gt; pch.cpp1&amp;gt; using Boost version 1_621&amp;gt; tioclient.c1&amp;gt;cl : Command line warning D9030: &#39;/Gm&#39; is incompatible with multiprocessing; ignoring /MP switch1&amp;gt; TioTcpSession.cpp1&amp;gt; TioTcpServer.cpp1&amp;gt; TioPython.cpp1&amp;gt; tio.cpp1&amp;gt; ContainerManager.cpp1&amp;gt; Command.cpp1&amp;gt; Generating Code...1&amp;gt; tioserver.vcxproj -&amp;gt; C:\Projects\tiodb\server\tio\..\..\bin\x64\Debug\tio.exe1&amp;gt; tioserver.vcxproj -&amp;gt; ..\..\bin\x64\Debug\tio.pdb (Full PDB)========== Build: 1 succeeded, 0 failed, 0 up-to-date, 0 skipped ==========OK, este foi o nível 3 do tioserver, o projeto principal do tiodb, uma ferramenta para manter contêineres assináveis na memória e acessíveis via socket. Note que já existe um warning, mas vamos ignorar por enquanto. O objetivo aqui é descobrir quais os warnings mais comuns do projeto que você vai escolher. Vejamos o meu:
1&amp;gt;------ Rebuild All started: Project: tioserver, Configuration: Debug x64 ------1&amp;gt; pch.cpp1&amp;gt; using Boost version 1_621&amp;gt; tioclient.c1&amp;gt;c:\projects\tiodb\client\c\tioclient.c(218): warning C4701: potentially uninitialized local variable &#39;start&#39; used1&amp;gt;cl : Command line warning D9030: &#39;/Gm&#39; is incompatible with multiprocessing; ignoring /MP switch1&amp;gt; TioTcpSession.cpp1&amp;gt;c:\projects\tiodb\server\tio\tiotcpsession.h(299): warning C4458: declaration of &#39;eventName&#39; hides class member1&amp;gt; c:\projects\tiodb\server\tio\tiotcpsession.h(295): note: see declaration of &#39;tio::EXTRA_EVENT::eventName&#39;1&amp;gt;c:\projects\tiodb\server\tio\logdb.h(213): warning C4456: declaration of &#39;i&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\logdb.h(200): note: see declaration of &#39;i&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.h(81): warning C4456: declaration of &#39;handle&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.h(77): note: see declaration of &#39;handle&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.h(413): warning C4456: declaration of &#39;b&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.h(316): note: see declaration of &#39;b&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpsession.cpp(127): warning C4457: declaration of &#39;key&#39; hides function parameter1&amp;gt; c:\projects\tiodb\server\tio\tiotcpsession.cpp(114): note: see declaration of &#39;key&#39;1&amp;gt; TioTcpServer.cpp1&amp;gt;c:\projects\tiodb\server\tio\tiotcpsession.h(299): warning C4458: declaration of &#39;eventName&#39; hides class member1&amp;gt; c:\projects\tiodb\server\tio\tiotcpsession.h(295): note: see declaration of &#39;tio::EXTRA_EVENT::eventName&#39;1&amp;gt;c:\projects\tiodb\server\tio\logdb.h(213): warning C4456: declaration of &#39;i&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\logdb.h(200): note: see declaration of &#39;i&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.h(81): warning C4456: declaration of &#39;handle&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.h(77): note: see declaration of &#39;handle&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.h(413): warning C4456: declaration of &#39;b&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.h(316): note: see declaration of &#39;b&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.cpp(404): warning C4456: declaration of &#39;b&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.cpp(300): note: see declaration of &#39;b&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.cpp(563): warning C4456: declaration of &#39;b&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.cpp(300): note: see declaration of &#39;b&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.cpp(596): warning C4456: declaration of &#39;b&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.cpp(300): note: see declaration of &#39;b&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.cpp(620): warning C4456: declaration of &#39;b&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.cpp(300): note: see declaration of &#39;b&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.cpp(643): warning C4456: declaration of &#39;b&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.cpp(300): note: see declaration of &#39;b&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.cpp(661): warning C4456: declaration of &#39;b&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.cpp(300): note: see declaration of &#39;b&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.cpp(2451): warning C4456: declaration of &#39;value&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.cpp(2338): note: see declaration of &#39;value&#39;1&amp;gt; TioPython.cpp1&amp;gt; tio.cpp1&amp;gt;c:\projects\tiodb\server\tio\tiotcpsession.h(299): warning C4458: declaration of &#39;eventName&#39; hides class member1&amp;gt; c:\projects\tiodb\server\tio\tiotcpsession.h(295): note: see declaration of &#39;tio::EXTRA_EVENT::eventName&#39;1&amp;gt;c:\projects\tiodb\server\tio\logdb.h(213): warning C4456: declaration of &#39;i&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\logdb.h(200): note: see declaration of &#39;i&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.h(81): warning C4456: declaration of &#39;handle&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.h(77): note: see declaration of &#39;handle&#39;1&amp;gt;c:\projects\tiodb\server\tio\tiotcpserver.h(413): warning C4456: declaration of &#39;b&#39; hides previous local declaration1&amp;gt; c:\projects\tiodb\server\tio\tiotcpserver.h(316): note: see declaration of &#39;b&#39;1&amp;gt; ContainerManager.cpp1&amp;gt; Command.cpp1&amp;gt; Generating Code...1&amp;gt; tioserver.vcxproj -&amp;gt; C:\Projects\tiodb\server\tio\..\..\bin\x64\Debug\tio.exe1&amp;gt; tioserver.vcxproj -&amp;gt; ..\..\bin\x64\Debug\tio.pdb (Full PDB)========== Rebuild All: 1 succeeded, 0 failed, 0 skipped ==========Vamos ordenar e capturar apenas o código desses warnings para ver quantos ocorrem e quais os mais comuns:
sorts/c:\\.*: \(warning C[0-9]\&#43;\).*$/\1/sort uE a resposta é:
warning C4456: declaration of &#39;identifier&#39; hides previous local declarationwarning C4457: declaration of &#39;identifier&#39; hides function parameterwarning C4458: declaration of &#39;identifier&#39; hides class memberwarning C4701: potentially uninitialized local variable &#39;name&#39; usedApenas quatro. Tão comuns que a maioria está até em ordem numérica e diz respeito a repetição de nomes em escopos diferentes, o que esconde os nomes do escopo anterior, mais amplo. O outro, o C4701, pode ser mais problemático, já que ele representa uma variável que potencialmente não foi inicializada, fonte comum daqueles erros de &amp;quot;como é que essa variável virou isso?&amp;quot;.
Felizmente só temos em um ponto do código:
//// Contract: //	if no timeout, it will hang until all bytes are returned//	if timeout is set, we can return less bytes than requested//int socket_receive(SOCKET socket, void* buffer, int len, const unsigned* timeout_in_seconds){int ret = 0;char* char_buffer = (char*)buffer;int received = 0;time_t start;int time_left;#if _WIN32	FD_SET recvset;struct timeval tv;#endif#ifdef _DEBUG	memset(char_buffer, 0xFF, len);#endif// se esse if não for verdadeiro, start fica com valor indefinido	if(timeout_in_seconds)start = time(NULL);while(received &amp;lt; len){if(timeout_in_seconds){// C4701: potentially uninitialized local variable &amp;#39;start&amp;#39; used	time_left = *timeout_in_seconds - (int)(time(NULL) - start);A correção é simples: inicialize a p***** das suas variáveis zero (ou determine qual o comportamento no caso else).
Vamos dar uma olhada em um dos outros warnings:
string containerName = container-&amp;gt;GetName();unsigned handle = session-&amp;gt;RegisterContainer(containerName, container);if(session-&amp;gt;UsesBinaryProtocol()){// warning C4456: declaration of &amp;#39;identifier&amp;#39; hides previous local declaration unsigned handle = session-&amp;gt;RegisterContainer(containerName, container);OK, isso é meio feio. A variável handle tinha acabado de ser criada logo antes da entrada do if. A não ser que sejam de fato variáveis distintas no código (apenas analisando a função inteira) elas poderiam ser reaproveitadas em apenas uma (até porque possuem o mesmo tipo). E se forem variáveis distintas... bem, coloque nomes distintos =)
E aqui termina mais uma sessão de &amp;quot;e se eu abrir mais os warnings do meu código&amp;quot;. Espero que tenha aproveitado.
</description>
</item>

     
        <item>
  <title>Entrando na zona com Vim</title>
  <link>http://www.caloni.com.br/entrando-na-zona-com-vim/</link>
  <pubDate>2017-01-05</pubDate>
  
  <guid>http://www.caloni.com.br/entrando-na-zona-com-vim/</guid>
  <description>Se você é programador é bem provável que já tenha ouvido falar em [Flow] 1 ou [The Zone] 2. Se for leitor assíduo do Hacker News, então, nem se fala. De qualquer forma, uma das maneira mais produtivas do programador programar é entrar na famosa &amp;quot;zona&amp;quot;. É lá que muito de nós nascemos. Lembra a primeira vez que mexeu em um computador ou afim e ficou tão obcecado que não viu o tempo passar? Pois bem. Você esteve na zona. E estar nela é um bom lugar para trabalhar.
Na zona, principalmente resolvendo problemas complexos, o importante é poder construir uma estrutura em sua mente com a ajuda de alguns aparatos, como um caderno de anotações, stickers, lousa ou seu editor preferido. Meu editor preferido para navegar (flow) por um código é sem sombra de dúvida o Vim, pois ele é apenas uma tela que preenche todo meu campo de visão e possui comandos em que eu consigo facilmente acessar o conteúdo que preciso relembrar. Quando estou obtendo o diagnóstico de um log, por exemplo, posso rapidamente ir construindo um modelo mental da solução navegando entre arquivos de log e código-fonte através de tags e buscas em regex.
A primeira vantagem do Vim em relação a outros editores é sua capacidade de abrir arquivos grandes. Um log de 1GB pode ser um desafio para um Notepad da vida, e até para um Visual Studio, mas no Vim tudo que você precisa é de memória disponível. E mesmo que não tenha, o Windows se vira bem no gerenciamento de swap (ou Linux, tanto faz).
Para navegar no código, existem duas técnicas que não necessitam de nenhum plugin. A primeira é a busca por regex, que pode ser feita com os comandos :vimgrep ou :grep, sendo que o primeiro busca em um padrão de arquivos (usando wildcard) e o segundo dentro dos buffers já abertos (útil se você já tiver uma sessão ativa; mais sobre isso depois).
&amp;#34; No Vim não é necessário digitar o comando completo; note que esse wildcard busca pastas recursivamente:vimg /regex/ \Projects\SomeProject\**\*.cpp&amp;#34; Isso busca em todos os buffers abertos cujo arquivo tem a extensão de C&#43;&#43;:grep regex *.cppO bom é que, no caso de logs, se você buscar por expressões unívocas, isso já fica no histórico de seus comandos e você pode usar quando quiser para voltar para esses logs (ou se você for maluco e guardar de cabeça seus marks, pode criar um mark de vez).
A segunda técnica de navegar no código é através das tags que são montadas pela ferramenta ctags. Ela é genérica o suficiente para suportar várias linguagens, mas pode ser usada até para qualquer sequência de palavras. Há plugins que realizam essa varredura do fonte automática, mas particularmente não gosto de encher meu Vim de plugins, sendo que o único que uso que me lembro é o MRU (porque o Vim ainda não suporta algo do gênero internamente). De qualquer forma, tudo que eu preciso fazer para atualizar as tags de um projeto é abrir o readme do projeto (que geralmente fica na pasta raiz) e rodar meu atalho.
&amp;#34; Roda recursivamente e otimiza para C&#43;&#43; e Python.map &amp;lt;S-F5&amp;gt; :!ctags --tag-relative=yes --recurse --c&#43;&#43;-kinds=&#43;p --python-kinds=-i --fields=&#43;iaS --extra=&#43;q&amp;lt;CR&amp;gt;&amp;#34; Busca pelo arquivo tags na pasta atual e vai subindo a hierarquia.set tags=tags;Isso vai gerar um arquivo ctags na pasta do projeto que será usada automaticamente para procurar pelas tags que eu preciso. O pulo do gato na verdade é o ponto-e-vírgula após o nome do arquivo ao setar a variável tags. Isso faz com que o Vim não busque apenas o arquivo tags na pasta atual, mas em toda hierarquia. Então se você estiver na pasta Projects\SomeProject\Folder1\Folder2\Folder3\File.cpp e tiver gerado o arquivo tags na pasta SomeProject para todo o projeto, ao usar o comando de busca de tag ele eventualmente vai abrir esse arquivo tags, pois ele vai procurando em Folder3, Folder2, Folder1 e cai em SomeProject.
Como no Windows o atalho padrão do comando tag do Vim não funciona também preciso fazer uma pequena adaptação técnica (e de quebra já uso para navegar nos próximos resultados):
map &amp;lt;C-K&amp;gt; &amp;lt;C-]&amp;gt;&amp;#34; O bom é que o first e o next ficam um do lado do outro.map &amp;lt;C-J&amp;gt; :tnext&amp;lt;CR&amp;gt;Depois de dar uma olhada no log, encontrar os métodos que você precisa analisar, seu fluxo, etc, você terá um monte de buffers relevantes abertos nas linhas relevantes. Seria muito bom se tudo isso pudesse ser guardado em um estado para que você continue amanhã ou em sua próxima sessão de flow. Para isso existe o comando :mksession.
&amp;#34; Salva estado atual dos buffers:mksession \temp\analise.vim&amp;#34; Restaura um estado salvo anteriomente:so \temp\analise.vimO comando :source roda um script vim que possui comandos guardados. Ele é um arquivo texto semelhante ao vimrc.
Basicamente é isso. Tudo o que você precisa em sua análise de fonte e de log se encontra na ponta de seus dedos. Não é necessário abrir nenhuma pasta nem terminal. Simplesmente navegue através do Vim para descobrir o problema e seja feliz em sua zona.
</description>
</item>

     
        <item>
  <title>Quantos handles sua aplicação está abrindo?</title>
  <link>http://www.caloni.com.br/quantos-handles/</link>
  <pubDate>2016-11-29</pubDate>
  
  <guid>http://www.caloni.com.br/quantos-handles/</guid>
  <description>Mesmo que você não programe em C/C&#43;&#43;, mas programe para Windows (ex: .NET), sempre há a possibilidade de seu programa estar causando leaks de handles indefinidamente, o que não se traduz em aumento significativo de memória alocada para seu processo, mas é, sim, um problema a ser tratado.
Como isso pode ser causado?
Bom, em C/C&#43;&#43; sempre é mais simples de entender esses conceitos. Um código simples que se esquece de fechar o handle usando CloseHandle ou a função equivalente do recurso obtido já seria o suficiente. O último bug que eu encontrei em um código desses comete o clássico erro de sair no meio da função, deixando os recursos alocados:
DWORD ClassicHandleLeak(){DWORD ret = 0;HKEY hKey;if ( RegOpenKeyEx(HKEY_LOCAL_MACHINE, L&amp;#34;Software\\Something&amp;#34;, 0, GENERIC_READ, &amp;amp;hKey) == ERROR_SUCCESS ){DWORD retSz = sizeof(ret);if (RegQueryValueEx(hKey, L&amp;#34;SomeValue&amp;#34;, NULL, NULL, (PBYTE) &amp;amp;ret, &amp;amp;retSz) == ERROR_SUCCESS){// success!	return ret;}RegCloseKey(hKey);}return ret;}No exemplo acima quando as coisas dão certo elas também dão errado, já que o retorno do valor no meio da função evita que o HANDLE armazenado em hKey seja desalocado.
E como fazer para descobrir esse tipo de leak?
HandleLeaker O HandleLeaker é apenas um exemplo de aplicação que realiza o leak de um handle por segundo. Ele tenta (e consegue) abrir um handle para seu próprio processo, e deixa o handle aberto (programas em Win32 API não são muito bons em RAII).
int main(){while (true){HANDLE h = OpenProcess(PROCESS_QUERY_INFORMATION, FALSE, GetCurrentProcessId());Sleep(1000);}}Performance Monitor O Perfmon(.msc) está aí no Windows já faz algumas versões (quase todas). Tudo que você precisa para executá-lo é executar o comando perfmon no diálogo de execução (Start, Run) ou encontrar o atalho para perfmon.msc. Na busca do Windows 8/10 também é possível encontrá-lo pelo nome.
Ao executá-lo a primeira coisa que ele monitora é o processamento da máquina. Podemos eliminar ou esconder esse indicador direto na lista abaixo da ferramenta.
Existem incontáveis contadores no Perfmon. Para o que precisamos vamos em Process e escolhemos o contador de Handles:
Depois de um tempo o Perfmon irá exibir o histórico que determina para onde está indo o seu contador:
Se os valores do seu contador estão fora da faixa do histórico é possível ajustar a escala nas propriedades:
Se a frequência for muito menor do que um handle por segundo (isso acontece, principalmente com serviços que rodam por dias/semanas/meses), é possível mudar também pelas propriedades, mas gerais:
A mudança que fizemos captura o dado monitorado de dez em dez segundos e realiza essa operação por 600 segundos (10 minutos), até repetir o gráfico de histórico:
Process Explorer Outra forma de verificar como andam os handles da máquina é usando a já famosa ferramenta da SysInternals. Através das inúmeras colunas que ela fornece existe o contador de handles de cada processo, através do qual é possível verificar quais são os processos com mais handles abertos:
Se seu programa for um handle hog, vai conseguir até ver esse leak acontecendo em tempo real (como o nosso programa mal-educado):
E como encontrar o código-fonte responsável por esse leak? Mais detalhes em um próximo post.
</description>
</item>

     
        <item>
  <title>Guardando senhas com Vim</title>
  <link>http://www.caloni.com.br/guardando-senhas-com-vim/</link>
  <pubDate>2016-10-05</pubDate>
  
  <guid>http://www.caloni.com.br/guardando-senhas-com-vim/</guid>
  <description>Eu já sabia que havia um sistema de criptografia de arquivos no Vim. Isso pode ser útil para textos secretos, ou para enviar qualquer bobagem para outra pessoa que sabe de uma senha que só vocês conhecem. Porém, o método default de criptografia dele não me animava. O pkzip é usa um algoritmo fraco, e os inúmeros programas que quebram zips encriptados estão aí para demonstrar. Além do mais, o blowfish da versão 7 do Vim tem problemas em gerar seu salt que favorece ataques de força bruta tão baratos quanto um XOR. E é aí que entra em cena o Vim 8.
A nova versão do meu editor favorito não apresenta o defeito do algoritmo blowfish anterior, ou apresenta, mas dessa vez fornece uma versão atualizada (claro que, por razões de compatibilidade, foram mantidos os algoritmos anteriores).
O que eu gosto no modelo do Vim de encriptar arquivos é que eles são encriptados apenas na escrita, e na leitura o usuário deve digitar a senha. Se a senha não correponder ao que foi usado para encriptá-lo, não há mensagem de erro: o editor irá simplesmente exibir o lixo gerado pela sua senha errada. Isso gera uma situação vantajosa e uma perigosa.
A vantajosa é que não há como automatizar um brute force em cima de arquivos encriptados pelo Vim, pois não há muitos sinais de que o arquivo foi desencriptado. Claro, por amostragem de texto é possível saber se a senha foi ou não satisfatória, mas a beleza está em não existir nada específico na estrutura do editor que diga se a senha foi ou não bem sucedida.
A perigosa é que uma vez que você digite a senha errada, muito cuidado com o lixo que você verá no seu buffer. Se por força do hábito for salvar o conteúdo, poderá perder o conteúdo do arquivo original, que estava encriptado com uma senha que você conhecia, mas que agora foi salvo após ter sido desencriptado com a senha errada. Ou seja, não há como reaver o conteúdo original a não ser com muito suor.
O mais prático de tudo é usar esse modelo de arquivo encriptado pelo Vim para salvar senhas. Um arquivo de senhas pode ser tão simples quando login/senha de todas as senhas que você deseja guardar, e tão bem protegido quanto a força de sua senha master. Nada mais, nada menos. De quebra, um arquivo pequeno cujo backup pode ser sincronizado instantaneamente na nuvem (usando Google Drive, Dropbox ou One Drive), ou até mantido em um controle de fonte (embora ele seja tratado como binário).
Se você gostou desse modelo, seguem os comandos para pesquisar (:help ):
; define o algoritmo que será usado para encriptar arquivo:set cm=blowfish2; define senha de criptografia ao salvar arquivo:XEste post foi inspirado em meu próprio uso do Vim, mas mais inspirado ainda depois de ler o artigo da invert.
</description>
</item>

     
        <item>
  <title>Usando GVim com projetos do Visual Studio</title>
  <link>http://www.caloni.com.br/usando-gvim-com-projetos-do-visual-studio/</link>
  <pubDate>2016-09-18</pubDate>
  
  <guid>http://www.caloni.com.br/usando-gvim-com-projetos-do-visual-studio/</guid>
  <description>A vida dos programadores C/C&#43;&#43; Windows -- e que geralmente precisam do Visual Studio -- está um abandono total. A configuração de make dos projetos sempre foi baseada no uso de makefiles, assim como no Unix, e por isso mesmo o uso da ferramenta nmake do SDK do Windows era a maneira padrão de se compilar e ver o resultado de dentro do Vim para projetos Windows. Com o advento do .NET, do Visual Studio 2003 e dos XMLs disfarçados como arquivos de projeto e solution, o uso do makefile foi paulatinamente abandonado, gerando diferentes versões de ferramentas -- todas incompatíveis -- para conseguir compilar um ou mais cpps e conseguir ver o resultado.
Por isso mesmo é um assunto pouco explorado nos fóruns do Stack Overflow como configurar decentemente o comando :make do Vim para conseguir realizar o ciclor program-compile-debug que já era feito desde a época do Amiga OS (e conhecido no manual do Vim como Quickfix). Ninguém se dá ao trabalho de usar esse modelo torto.
Houve um tempo que eu mesmo pesquisei algumas soluções, e caí no velho problema de tentar conviver com diferentes versões do Visual Studio. Deixei de lado o Vim por uns anos, e passei a usar o VsVim, um plugin que roda em várias versões do Visual Studio e utiliza o vimrc de sua instalação.
Hoje voltei a fuçar esse problema e depois de algumas horas tentando entender qual a dinâmica que deve ser seguida, cheguei a dois usos legítimos do make no Visual Studio: o modo legado, através do devenv, e o modo comportado, que usa a ferramenta MsBuild para encontrar o projeto e a solution que devem ser compilados.
Colocando as coisas no path A não ser que você coloque o path das ferramentas direto nos comandos (algo que não recomendo pois as coisas no Vim começam a ficar estranhas com paths com espaços, algo abundante no Windows) é preferível que você escolha qual devenv e qual msbuild deseja utilizar e definir isso na variável de sistema path. No meu exemplo estou usando o msbuild para qualquer Visual Studio acima do 2010 (como o 2015), pois já está padronizado, e como tenho projetos no VS2003 para manter, escolhi deixar o devenv.com com ele.
set path=%path%;C:\Program Files (x86)\MSBuild\14.0\Binset path=%path%;c:\Program Files (x86)\Microsoft Visual Studio .NET 2003\Common7\IDENote que essa configuração, para ficar persistente, precisa ser definida através do Painel de Controle ou Propriedades do Sistema. Google for it.
Depois de configurado, qualquer projeto deve ser compilável em 2003 pela linha de comando (através do devenv.com):
C:\Projects\samples\FixCMake&amp;gt;devenv.com FixCMake.sln /build DebugMicrosoft (R) Development Environment Version 7.10.3077.Copyright (C) Microsoft Corp 1984-2001. All rights reserved.------ Build started: Project: FixCMake, Configuration: Debug Win32 ------Compiling...FixCMake.cppLinking...Build log was saved at &amp;quot;file://c:\Projects\samples\FixCMake\Debug\BuildLog.htm&amp;quot;FixCMake - 0 error(s), 0 warning(s)---------------------- Done ----------------------Build: 1 succeeded, 0 failed, 0 skippedC:\Projects\samples\FixCMake&amp;gt;Da mesma forma, projetos 2010&#43; devem usar o msbuild:
C:\Projects\samples\ConsoleApplication5&amp;gt;msbuildMicrosoft (R) Build Engine version 14.0.25420.1Copyright (C) Microsoft Corporation. All rights reserved.Building the projects in this solution one at a time. To enable parallel build, please add the &amp;quot;/m&amp;quot; switch.Build started 9/18/2016 6:02:19 PM.Project &amp;quot;C:\Projects\samples\ConsoleApplication5\ConsoleApplication5.sln&amp;quot; on node 1 (default targets).ValidateSolutionConfiguration:Building solution configuration &amp;quot;Debug|x64&amp;quot;.The target &amp;quot;_ConvertPdbFiles&amp;quot; listed in a BeforeTargets attribute at &amp;quot;C:\Program Files (x86)\MSBuild\14.0\Microsoft.Common.targets\IThe target &amp;quot;_CollectPdbFiles&amp;quot; listed in an AfterTargets attribute at &amp;quot;C:\Program Files (x86)\MSBuild\14.0\Microsoft.Common.targets\IThe target &amp;quot;_CollectMdbFiles&amp;quot; listed in a BeforeTargets attribute at &amp;quot;C:\Program Files (x86)\MSBuild\14.0\Microsoft.Common.targets\IThe target &amp;quot;_CopyMdbFiles&amp;quot; listed in an AfterTargets attribute at &amp;quot;C:\Program Files (x86)\MSBuild\14.0\Microsoft.Common.targets\ImpoProject &amp;quot;C:\Projects\samples\ConsoleApplication5\ConsoleApplication5.sln&amp;quot; (1) is building &amp;quot;C:\Projects\samples\ConsoleApplication5\CPrepareForBuild:Creating directory &amp;quot;x64\Debug\&amp;quot;.Creating directory &amp;quot;x64\Debug\ConsoleA.C9D4BE8C.tlog\&amp;quot;.InitializeBuildStatus:Creating &amp;quot;x64\Debug\ConsoleA.C9D4BE8C.tlog\unsuccessfulbuild&amp;quot; because &amp;quot;AlwaysCreate&amp;quot; was specified.ClCompile:C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\x86_amd64\CL.exe /c /ZI /nologo /W3 /WX- /sdl /Od /D _DEBUG /D _CONSOLE140.pdb&amp;quot; /Gd /TP /errorReport:queue stdafx.cppstdafx.cppC:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\x86_amd64\CL.exe /c /ZI /nologo /W3 /WX- /sdl /Od /D _DEBUG /D _CONSOLE140.pdb&amp;quot; /Gd /TP /errorReport:queue ConsoleApplication5.cppConsoleApplication5.cppLink:C:\Program Files (x86)\Microsoft Visual Studio 14.0\VC\bin\x86_amd64\link.exe /ERRORREPORT:QUEUE /OUT:&amp;quot;C:\Projects\samples\Consoleib odbc32.lib odbccp32.lib /MANIFEST /MANIFESTUAC:&amp;quot;level=&#39;asInvoker&#39; uiAccess=&#39;false&#39;&amp;quot; /manifest:embed /DEBUG /PDB:&amp;quot;C:\Projects\sacation5.lib&amp;quot; /MACHINE:X64 x64\Debug\ConsoleApplication5.objx64\Debug\stdafx.objConsoleApplication5.vcxproj -&amp;gt; C:\Projects\samples\ConsoleApplication5\x64\Debug\ConsoleApplication5.exeConsoleApplication5.vcxproj -&amp;gt; C:\Projects\samples\ConsoleApplication5\x64\Debug\ConsoleApplication5.pdb (Full PDB)FinalizeBuildStatus:Deleting file &amp;quot;x64\Debug\ConsoleA.C9D4BE8C.tlog\unsuccessfulbuild&amp;quot;.Touching &amp;quot;x64\Debug\ConsoleA.C9D4BE8C.tlog\ConsoleApplication5.lastbuildstate&amp;quot;.Done Building Project &amp;quot;C:\Projects\samples\ConsoleApplication5\ConsoleApplication5.vcxproj&amp;quot; (default targets).Done Building Project &amp;quot;C:\Projects\samples\ConsoleApplication5\ConsoleApplication5.sln&amp;quot; (default targets).Build succeeded.0 Warning(s)0 Error(s)Time Elapsed 00:00:02.31C:\Projects\samples\ConsoleApplication5&amp;gt;O que o Vim tem a ver com tudo isso? Pois é. Tirando essa facilidade, as coisas no Vim para msbuild rodam particularmente bem. Basta alterarmos o makeprg da seguinte maneira:
:set makeprg=msbuild\ /nologo\ /v:q\ /property:GenerateFullPaths=true&amp;lt;CR&amp;gt;As opções específicas são para gerar o path completo, as barras invertidas são por causa dessa mania do Vim de dar pau quando tem espaço em tudo.
A partir dessa configuração já é possível compilar um projeto estando em sua pasta:
Para o Visual Studio 2003 (ou qualquer um usando o devenv.com) é necessário mudar esse comando:
:set makeprg=devenv\ %\ /build\ Debug&amp;lt;CR&amp;gt;Sim, temos que escolher uma configuração (o msbuild já escolhe por você). E note que ele usa o arquivo atual (%) para compilar. Isso quer dizer que isso irá exigir do usuário de Vim abrir o sln ou o vcproj e executar o :make a partir daí. De qualquer forma, ele funciona também:
Refinando a saída Note que em nenhum dos casos erros conseguirão ser capturados para irmos direto no ponto do código-fonte onde ele está. Para isso funcionar, em nosso último passo, é necessário configurar o errorformat para que ele tenha um padrão que funcione com ambas as ferramentas. Depois de testar um pouco, cheguei nesse formato:
set errorformat=%f(%l)%mEle pega também os warnings, mas fazer o quê. Você não quer conviver com warnings em seu código pelo resto da vida, né? =)
VS2010:
VS2003:
Note que depois de clicar em Enter ele pula para o primeiro erro da lista:
E para navegar na lista é como o resultado de comandos como :vimgrep. :cnext e :cprevious vão para frente e para trás na lista, sempre pulando para o ponto no código onde está o erro.
Dica final: convivendo com dois mundos Como deu pra perceber, para conseguir usar o msbuild e o devenv ao mesmo tempo você seria obrigado a trocar o makeprg sempre que precisasse. Para facilitar seu uso, nada como fazer um mapeamento de atalhos:
map &amp;lt;F7&amp;gt; :set makeprg=devenv\ %\ /build\ Debug&amp;lt;CR&amp;gt;map &amp;lt;S-F7&amp;gt; :set makeprg=msbuild\ /nologo\ /v:q\ /property:GenerateFullPaths=true&amp;lt;CR&amp;gt;Para alguém curioso para ver minhas configurações do Vim (quem quiser compartilhar também, fique à vontade), segue.
</description>
</item>

     
        <item>
  <title>unit-menos-menos</title>
  <link>http://www.caloni.com.br/unitmenosmenos/</link>
  <pubDate>2016-09-05</pubDate>
  
  <guid>http://www.caloni.com.br/unitmenosmenos/</guid>
  <description>Fazer o setup inicial de testes unitários em seu projeto C&#43;&#43; pode ser algo enfadonho se você precisa baixar e compilar uma lib do Google ou do Boost. Há uma alternativa mais leve e bem direta, que um dia apareceu nesses CodeProject da vida, mas que hoje está, até onde eu vi, no GitHub.
E como se faz para começar a montar os testes unitários? Bom, suponha que você tenha um projeto qualque que já compila, roda e faz alguma coisa de útil:
Apenas crie um projeto do lado, console, ou copie e cole o projeto, mas use os arquivos-fonte do projeto original. Dessa forma ele irá compilar com os fontes que estão sendo modificados/compilados.
Apenas se lembra de não incluir o módulo que contém o int main. Esse módulo deve ficar apartado do projeto principal.
Depois basta incluir apenas um arquivo do projeto unit--, que é seu cpp principal.
Com isso existirá um main lá dentro, definido em algum lugar. E tudo o que você precisa fazer é ir criando seus testes em outro arquivo fonte gerado para isso. O corpo e o formato dos unit cases é bem simples. Note que tudo que você fez para já sair testando seu projeto foi copiar um projeto já existente e inserir um módulo de outro projeto. Tudo compilando junto e já podemos fazer os primeiros testes do programa original (desde, claro, que ele seja testável, algo primordial):
// Precisamos definir uma suíte de testes.testSuite(DayToDayTests)// Se eu digito uma linha, ela deve estar no arquivo daytoday.txt.testCase(GetUmaLinha, DayToDayTests){//...bool lineOk = TestAlgumaCoisa();assertTrue(lineOk);}// Se eu digito duas linhas, ambas devem estar no arquivo daytoday.txt.testCase(GeraDuasLinhas, DayToDayTests){//...bool lineOk = TestOutraCoisa();assertTrue(lineOk);}E assim por diante. O resultado é que quando você roda o executável de teste, ele execute toda a bateria e já te entregue todos os casos que você deseja testar, sem frescura:
......OKTotal 6 test cases0 sec.Press any key to continue . . .E voilà! Sistema de teste unitário pronto e rodando. Agora cada nova situação de erro ou que você precise validar, basta escrever um novo teste. Se esse projeto ir se tornando algo muito maior, a transição para testes unitários mais parrudos é apenas um regex. No momento, foque em codificar e testar muito bem o que está fazendo.
</description>
</item>

     
        <item>
  <title>Programa, Mãe Foca!</title>
  <link>http://www.caloni.com.br/programa-mae-foca/</link>
  <pubDate>2016-08-30</pubDate>
  
  <guid>http://www.caloni.com.br/programa-mae-foca/</guid>
  <description>A história das metodologias de desenvolvimento de software segue mais ou menos as oscilações naturais do próprio software: caminha em direção ao caos (e as sessões de refactory buscam desacelerar essa inevitável tendência). Assim como aquela classe que parecia perfeita assim que foi feita, uma metodologia irá se desmanchar frente à lei da mediocridade. Você não consegue software bom com programadores ruins seguindo a melhor metodologia do planeta.
Então a solução nunca parece ser a metologia, já que programadores ruins não melhorarão seguindo qualquer metologia que seja.
Porém, existe um método infalível. Um método que transforma os programadores mais UML do mundo em fazedores de código inquebrável. Programadores acostumados a 15 horas de reunião semanal fritando o processador de produtividade, esbanjando atalhos no Vim, coordenando threads como um maestro que coordena uma orquestra sinfônica tocando a trilha sonora da sua vida.
Esse método chama-se: Programa, Filho da P***
Ou, do inglês, PMF.
E o que o PMF tem a oferecer? Esse cara parece ter o esboço da resposta:
&amp;gt; Como nós iremos resolver problemas?&amp;gt; Programando, filho da p\*\*\*&amp;gt; Como nós iremos testar?&amp;gt; Programando, filho da p\*\*\*&amp;gt; Como iremos completar tarefas no prazo e abaixo do orçamento?&amp;gt; Programando, filho da p\*\*\*&amp;gt; Como nós iremos ter certeza que os programadores estão felizes e fazendo o seu serviço?&amp;gt; Programando, filho da p\*\*\*E como ele pretende fazer isso? Bom, existe um algoritmo, é claro:
 Escreva uma lista da p*** que você tem que fazer, usando software escrito por algum programador filho da p*** Faça algumas dessas p***s, novamente usando &amp;quot;programação, filho da p*** Teste se essa p*** está boa, e se não estiver então conserte com programação, filho da p***  E se você está preocupado com o foco muito no código, e não nos resultados para seu cliente, existe até um &amp;quot;capítulo&amp;quot; sobre gerência, a &amp;quot;Gerência, C*zão&amp;quot;:
 Para fazer Gerência, C*zão, você deve fazer o seguinte:
 Ache o que os clientes querem perguntando para eles. Arrume a p*** que os Programadores Filhos da P*** precisam fazer. Fale para os Programadores Filhos da P*** quando as p*** que eles fizeram não está boa o suficiente para vender.   Simples e conciso. Acho que até a gerência deve conseguir se lembrar desses três passos.
O que há de errado com metologias Bazinga? Não há nada de errado em usar outras metologias em cima da PMF, mas há tudo de errado em substituir uma coisa por outra. A PMF é primordial para terminar alguma coisa. É o suprasumo da eficiência. Com ela todas as coisas eventualmente são solucionadas. Usar apenas a metologia do seu coração sem aplicar PMF não irá entregar nada.
E por mais curioso que seja, há de fato uma tendência nas pessoas de enxergar a solução de todos os seus problemas não fazendo absolutamente nada. Apenas preenchendo cartões em um dashboard. Não é bem por aí. Claro que há uma parcela de nada que pode ajudar a organizar a bagunça que é uma equipe de programadores batucando código, mas esse nada nunca pode atrapalhar os... programadores batucando código!
Afinal, é com código que se constrói algo, certo? Seja aumentando, modificando ou apagando código. Seja transformando código em um passo-a-passo em um txt. Ou em um papel de pão. Código é apenas uma abstração de resolução de problemas. O quão bem você resolver o problema é o que conta, não a sua linguagem de programação do coração. Muitos problemas podem ser solucionados apenas com papel e caneta (ou lápis). Linguagens de programação, até certo ponto, podem virar também metodologias mágicas que prometem entregar soluções mágicas sem dor.
Mas adivinha, só? Seu cliente está c*g*n*do qual é a linguagem, a ferramenta, o tamanho da fonte. Ele só quer seu problema resolvido.
Então o jeito é: &amp;quot;Puroguramingu, Mazaafakkaa!&amp;quot; =)
</description>
</item>

     
        <item>
  <title>Rank and File (Code Jam)</title>
  <link>http://www.caloni.com.br/rank-and-file-code-jam/</link>
  <pubDate>2016-04-16</pubDate>
  
  <guid>http://www.caloni.com.br/rank-and-file-code-jam/</guid>
  <description>Passou o Round 1A do Code Jam, e para variar, fui muito mal, só respondendo a primeira questão. A segunda me fez ficar pensando um tempo desproporcional sobre como encaixar as diferentes linhas e colunas para achar a linha restante.
Basicamente, o problema pede que, dado um quadrado de tamanho N, e 2*N-1 linhas fornecidas (que podem ser linhas ou colunas), imprimir a Nésima linha. A regra das linhas é que ela possui números crescentes.
Bom, não consegui chegar numa solução para o problema errado (encaixar as linhas), mas fui, como sempre, dar uma espiada nas respostas dos competidores, em especial a do primeiro colocado. O grande barato de competições como essa é aprender com a inteligência e genialidade dos outros. Para mim, esse é um exemplo de genialidade:
int cnt[2501] = {}; // zerando o arrayint main(){for(int i = 0; i &amp;lt; n * (2 * n - 1); i&#43;&#43;){cin &amp;gt;&amp;gt; j;cnt[j] ^= 1; // inverte primeiro bit do inteiro	}printf(&amp;#34;Case #%d:&amp;#34;, t);for(int i = 1; i &amp;lt; 2500; i&#43;&#43;)if (cnt[i]) cout &amp;lt;&amp;lt; &amp;#34; &amp;#34; &amp;lt;&amp;lt; i; // se não for zero (ou seja, ímpar) imprime	cout &amp;lt;&amp;lt; endl;}Obs.: O código está higienizado, pois esse pessoal usa bastante macros, etc.
A solução basicamente decide isolar duas questões: achar os números que faltam nas sequência e imprimi-los na ordem. Para o primeiro, varre todas as sequências sinalizando qual deles tem a quantidade ímpar (ou seja, não está representado em todas as linhas e colunas, pois do contrário seria par). Depois ele resolve a segunda questão simplesmente imprimindo os números ímpares encontrados, já na ordem (no array de valores possíveis).
Simples, rápido, eficiente. E correto.
É esse tipo de coisa que faz valer a pena uma competição dessas.
</description>
</item>

     
        <item>
  <title>Testando sistema de postagem</title>
  <link>http://www.caloni.com.br/testando-sistema-de-postagem/</link>
  <pubDate>2016-04-10</pubDate>
  
  <guid>http://www.caloni.com.br/testando-sistema-de-postagem/</guid>
  <description>Bom, depois de criar um script para basicamente apenas escrever o texto dos filmes que assisto e buscar uma imagem agradável para meu blogue de Cinema, o próximo passo foi portar esse mesmo método para meus dois outros blogues: o da minha empresa, a BitForge e esse aqui. O processo envolve algo a mais: buscar as imagens usadas (que muitas vezes não é só uma). Porém, nada mais que isso.
O problema mesmo é publicar nas redes sociais.
Um detalhe típico do funcionamento dessas redes bem apontou o blogger veterano Hossein Derakhshan, que ficou preso por seis anos e descreveu a mudança que a web sofreu nesse pouquíssimo tempo para a história, mas muitíssimo para a internet. De acordo com ele, postar apenas links não farão muito efeito, mesmo que você seja um escritor conhecido (o caso dele). Para fazer efeito, você precisa de imagens. Pessoas gostam de imagens. De gatinhos, melhor ainda.
Porém, qual imagem que pode ser usada para um blogue técnico e que chame a atenção?
No Cine Tênis Verde fica fácil achar uma imagem, pois filmes são formados por elas (cerca de 170 mil delas, se for um filme de duas horas). Aqui no Blogue do Caloni, tenho que me limitar a abstrações e metáforas.
O que muitas vezes tem funcionado, como minha série Básico do Básico:
 Binário Tipos Ponteiros Assembly Programação Depuração  De qualquer forma, posso continuar utilizando o título do artigo como base para minha pesquisa.
Postando no Twitter Postar no Twitter é algo relativamente fácil. O script abaixo faz isso com dois pés no joelho:
def PublishToTwitter(postInfo):&amp;#34;&amp;#34;&amp;#34;https://pypi.python.org/pypi/twitter&amp;#34;&amp;#34;&amp;#34;t = twitter.Twitter(auth=twitter_credentials.auth)with open(&amp;#34;C:\\daytoday\\caloni.github.io\\images\\&amp;#34; &#43; postInfo[&amp;#34;permalink&amp;#34;] &#43; &amp;#34;.jpg&amp;#34;, &amp;#34;rb&amp;#34;) as imagefile:imagedata = imagefile.read()t_up = twitter.Twitter(domain=&amp;#39;upload.twitter.com&amp;#39;, auth=twitter_credentials.auth)id_img1 = t_up.media.upload(media=imagedata)[&amp;#34;media_id_string&amp;#34;]st = postInfo[&amp;#39;title&amp;#39;] &#43; &amp;#39;\n\n&amp;#39; &#43; postInfo[&amp;#39;tagline&amp;#39;] &#43; &amp;#39;\n\n&amp;#39; &#43; postInfo[&amp;#39;shortlink&amp;#39;].encode(&amp;#39;utf-8&amp;#39;)if len(st) &amp;gt; 120: # giving space to image attachment st = stars &#43; &amp;#39; &amp;#39; &#43; postInfo[&amp;#39;title&amp;#39;] &#43; &amp;#39;\n\n&amp;#39; &#43; &amp;#39;\n\n&amp;#39; &#43; postInfo[&amp;#39;shortlink&amp;#39;].encode(&amp;#39;utf-8&amp;#39;)t.statuses.update(status=st, media_ids=&amp;#34;,&amp;#34;.join([id_img1]))Postando no Facebook Já postar no Facebook é mais ou menos uma tortura. As chaves de acesso costumam expirar, e para conseguir uma que não expira este tutorial é femonenal, pois economiza muito, muito tempo de pesquisa.
Curiosamente, o código para postar é muito semelhante ao do Twitter, até mais simples, talvez:
def PublishToFacebook(postInfo):&amp;#34;&amp;#34;&amp;#34;http://nodotcom.org/python-facebook-tutorial.html&amp;#34;&amp;#34;&amp;#34;with open(&amp;#34;C:\\daytoday\\caloni.github.io\\images\\&amp;#34; &#43; postInfo[&amp;#34;permalink&amp;#34;] &#43; &amp;#34;.jpg&amp;#34;, &amp;#34;rb&amp;#34;) as imagefile:imagedata = imagefile.read()st = postInfo[&amp;#39;title&amp;#39;] &#43; &amp;#39;\n\n&amp;#39; &#43; postInfo[&amp;#39;paragraph&amp;#39;] &#43; &amp;#39;\n\n&amp;#39; &#43; baseUrl &#43; postInfo[&amp;#39;permalink&amp;#39;]post = facebook_credentials.auth.put_photo(image=imagedata, message=st)</description>
</item>

     
        <item>
  <title>Exportando repositórios antigos do Bazaar para Git</title>
  <link>http://www.caloni.com.br/exportando-repositorios-antigos-do-bazaar-para-git/</link>
  <pubDate>2016-01-27</pubDate>
  
  <guid>http://www.caloni.com.br/exportando-repositorios-antigos-do-bazaar-para-git/</guid>
  <description>Enquanto estudava sobre controle de fontes distribuído, experimentei e usei os projetos Mercurial e Bazaar, precursores desse modelo que funcionavam bem em Windows. Havia o Git, mas por conta da sua evolução assimétrica, o ambiente da Microsoft havia ficado para trás.
Hoje com o Git sendo praticamente o mainstream das conversões do SubVersion, e funcionando razoavelmente bem em ambientes Windows (64 ou 32), sobraram apenas os repositórios do Mercurial e do Bazaar. Na verdade, mais do Bazaar, pois eu havia migrado já do Hg pelo Bazaar possuir algo que hoje o Git emula, mas antes era um diferencial no projeto da Canonical: detecção de rename completo (com histórico e tudo). Isso para refatoração era vital, e suporte à refatoração pesada era o que eu precisava no momento.
Agora é hora de manter esse histórico vivo, mas convertido para o que todos usam.
A migração A primeira coisa a ser feita é converter o repositório. Depois de convertido, como todas as operações estarão no universo Git, há uma de entradas no StackOverflow para nos ajudar a reunir os repositórios em um só, meu objetivo, já que o Git é mais leve e mais versátil nesse quesito.
No Windows, nas últimas versões do Bazaar o comando fast-export não estava mais funcionando. Parado desde 2012, não há previsão de correções. No entanto, para essa operação, a versão 2.4.2 atendeu bem. O comando é um pouco diferente, mas ele é rápido e rodou sem problemas em conjunto com o fast-import do Git.
git initbzr fast-export --plain . | git fast-import12:03:59 Calculating the revisions to include ...12:03:59 Starting export of 2681 revisions ...12:04:05 Skipping empty dir Tools/Desenv in rev 12:04:05 Skipping empty dir Tools/Desenv in rev12:04:45 1000/2681 commits exported at 1308/minute12:05:12 2000/2681 commits exported at 1642/minute12:05:59 WARNING: not creating tag u&#39;1.09&#39; pointing to non-existent revision 12:05:59 WARNING: not creating tag u&#39;1.50&#39; pointing to non-existent revision 12:05:59 WARNING: not creating tag u&#39;1.51&#39; pointing to non-existent revision 12:05:59 WARNING: not creating tag u&#39;1.49&#39; pointing to non-existent revision 12:05:59 WARNING: not creating tag u&#39;1.48&#39; pointing to non-existent revision 12:05:59 WARNING: not creating tag u&#39;1.45&#39; pointing to non-existent revision 12:05:59 WARNING: not creating tag u&#39;1.47&#39; pointing to non-existent revision 12:05:59 WARNING: not creating tag u&#39;1.46&#39; pointing to non-existent revision 12:05:59 WARNING: not creating tag u&#39;1.40&#39; pointing to non-existent revision 12:05:59 WARNING: not creating tag u&#39;1.39&#39; pointing to non-existent revision 12:05:59 Exported 2681 revisions in 0:02:00C:\PROGRAM FILES (X86)\GIT\libexec\git-core\git-fast-import.exe statistics:---------------------------------------------------------------------Alloc&#39;d objects: 35000Total objects: 33979 ( 9714 duplicates )blobs : 15604 ( 6833 duplicates 7747 deltas of 15389 attempts)trees : 15694 ( 2881 duplicates 12881 deltas of 14635 attempts)commits: 2681 ( 0 duplicates 0 deltas of 0 attempts)tags : 0 ( 0 duplicates 0 deltas of 0 attempts)Total branches: 98 ( 1 loads )marks: 1048576 ( 2681 unique )atoms: 4549Memory total: 3567 KiBpools: 2200 KiBobjects: 1367 KiB---------------------------------------------------------------------pack_report: getpagesize() = 65536pack_report: core.packedGitWindowSize = 33554432pack_report: core.packedGitLimit = 268435456pack_report: pack_used_ctr = 22324pack_report: pack_mmap_calls = 10353pack_report: pack_open_windows = 4 / 6pack_report: pack_mapped = 101069594 / 163170978---------------------------------------------------------------------É óbvio que nem tudo serão mil maravilhas. Eu, por exemplo, encontrei um problema com case-sensitive que me deu algumas dores de cabeça:
fatal: Path Something/Resource.h not in branchfast-import: dumping crash report to .git/fast_import_crash_676bzr: broken pipeO Git gera um arquivo de report onde estão as informações do ocorrido. Uma forma de contornar esse tipo de problema é primeiro exportar para um arquivo e editá-lo (corrigindo o case, por exemplo):
bzr fast-export --plain . &amp;gt; plain-export.txtgvim fast-export.txthack hack hacktype fast-export.txt | git fast-importNote que talvez você precise de um editor que suporte arquivos gigantescos (como o Vim) e precise se debruçar sobre merges com arquivos com mesmo nome e diferentes cases. Isso que dá manter projetos com refactoring pesado.
Por fim, faça a conversão para todos os .bzr que tiver e haverá um .git com todo o histórico desses anos usando Bazaar. O próximo passo é montar o histórico de todos eles em apenas um repositório (se assim desejar). Segue uma série de comandos que pode ajudar para usar em uma batch:
@echo offgit remote add -f bzr ..\PathToOldConvertedRepo\%1git merge bzr/mastergit remote remove bzrmkdir Archive\%1echo Mova os arquivos importadospausegit add --allgit ci -m &amp;quot;Archiving old Bazaar repo (%1).&amp;quot;Você pode chamar um a um em cima de um repo novo:
mkdir NewRepocd NewRepogit init..\MyMergeBatch.bat OldRepoName..\MyMergeBatch.bat OldRepoName2..\MyMergeBatch.bat OldRepoName3Para conseguir ter acesso ao histórico dos arquivos movidos, basta usar a opção -all do log:
git log --all -- MyRemovedPathUpdate Tive alguns problemas em rastrear o histórico utilizando a estratégia de fazer merge no mesmo branch. A solução que encontrei, embora não exatamente direta, foi realizar os merges em branches apartados primeiro, mover os arquivos (de preferência, usando o git, para que ele detecte o rename), aplicar o commit e realizar o merge com o master. Há uma vantagem nessa estratégia, além do log --follow funcionar melhor: mantenha os branches originais, além do ponteiro para remote. Dessa forma, depois de alguns anos, saberá de onde veio esse merge maluco.
Update2 Depois de um tempo testando essa técnica, descobri que o Git se perde novamente e não encontra mais todos os logs, mesmo com --follow mesmo movendo os arquivos. O meu problema está relacionado com mesmos paths dos arquivos em repositórios diferentes. Paciência.
</description>
</item>

     
        <item>
  <title>Log de chamadas API direto do WinDbg</title>
  <link>http://www.caloni.com.br/log-de-apis-chamadas-direto-do-windbg/</link>
  <pubDate>2016-01-21</pubDate>
  
  <guid>http://www.caloni.com.br/log-de-apis-chamadas-direto-do-windbg/</guid>
  <description>Há muito tempo atrás eu havia falado sobre como a ferramenta logger.exe, do Debugging Tools for Windows, poderia ser usada para gerar um arquivo de log com centenas de APIs detalhadas em sua chamada, como parâmetros de entrada, retorno e tempo. Bom, testando isso hoje, me veio à lembrança o artigo e também a constatação que o logger é muito instável. Tão instável que não consegui logar as APIs que desejava nas inúmeras tentativas que fiz. Isso em um Windows XP!
Felizmente, as funções do logger também estão em uma DLL estilo plugin do próprio WinDbg, que pode ser chamada facilmente e que -- surpresa! -- internamente ao depurador funciona. Melhor ainda, não é necessário criar um processo para realizar o log, mas pode ser atachado em um processo já em execução, o que facilita bastante seu uso em serviços, por exemplo.
Vamos testar aqui o log da nossa cobaia de plantão, o amigo Notepad (ou Bloco de Notas), exibindo um texto que demonstra com perfeição uma das minhas características mais bizarras: confundir expressões e frases prontas.
Nota: Lembrando que estaremos testando em Windows XP 32 bits com um WinDbg igualmente 32 bits. Inicialmente comecei a testar a versão 64, mas ela também deu xabu. Aparentemente coisas periféricas do Debugging Tools nunca são muito bem testadas.
O texto ainda não foi salvo em nenhum arquivo. Iremos salvá-lo, mas antes, vamos executar o WinDbg e ver como o Notepad realiza essa operação.
A extensão/plugin que me referia é o Logexts.dll. Você pode instalar o log de API em um momento, habilitá-lo em outro, e até desabilitá-lo depois. Ou seja, é um processo ótimo para realizar inspeção pontual de chamadas API. Caso, claro, ele não exploda em um desses momentos.
(9c4.f04): Break instruction exception - code 80000003 (first chance)eax=7ffd9000 ebx=00000001 ecx=00000002 edx=00000003 esi=00000004 edi=00000005eip=7c90120e esp=003bffcc ebp=003bfff4 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=0038 gs=0000 efl=00000246*** ERROR: Symbol file could not be found. Defaulted to export symbols for C:\WINDOWS\system32\ntdll.dll - ntdll!DbgBreakPoint:7c90120e cc int 30:001&amp;gt; !logexts.logi Windows API Logging Extensions v3.01Parsing the manifest files...Location: C:\Temp\DbgTools(x86)\winext\manifest\main.hParsing file &amp;quot;main.h&amp;quot; ...Parsing file &amp;quot;winerror.h&amp;quot; ...Parsing file &amp;quot;kernel32.h&amp;quot; ......Parsing file &amp;quot;dsound.h&amp;quot; ...Parsing completed.Logexts injected. Output: &amp;quot;C:\Documents and Settings...&amp;quot;0:001&amp;gt; gModLoad: 50000000 50056000 C:\Temp\DbgTools(x86)\winext\logexts.dllParsing the manifest files...Location: C:\Temp\DbgTools(x86)\winext\manifest\main.hParsing file &amp;quot;main.h&amp;quot; ...Parsing file &amp;quot;winerror.h&amp;quot; ...Parsing file &amp;quot;kernel32.h&amp;quot; ......Parsing file &amp;quot;dsound.h&amp;quot; ...Parsing completed.(9c4.664): Break instruction exception - code 80000003 (first chance)eax=7ffd9000 ebx=00000001 ecx=00000002 edx=00000003 esi=00000004 edi=00000005eip=7c90120e esp=003bffcc ebp=003bfff4 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=0038 gs=0000 efl=00000246ntdll!DbgBreakPoint:7c90120e cc int 30:001&amp;gt; !logexts.logeLogging already initialized. Output &amp;quot;C:\Documents and Settings\...&amp;quot;Logging enabled.0:001&amp;gt; gModLoad: 77b40000 77b62000 C:\WINDOWS\system32\appHelp.dllModLoad: 76fd0000 7704f000 C:\WINDOWS\system32\CLBCATQ.DLL...(9c4.41c): Break instruction exception - code 80000003 (first chance)eax=7ffd9000 ebx=00000001 ecx=00000002 edx=00000003 esi=00000004 edi=00000005eip=7c90120e esp=00f1ffcc ebp=00f1fff4 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=0038 gs=0000 efl=00000246ntdll!DbgBreakPoint:7c90120e cc int 30:004&amp;gt; !logexts.logdLogging disabled.0:004&amp;gt; .detachDetachedDepois de gerarmos o que precisamos, podemos desatachar do processo e analisar o resultado: um arquivo LGV. Para abrir esse arquivo existe uma outra ferramenta chamada logviewer.
Para evitar procurar em dezenas de milhares de chamadas, há uma opção de filtrar com apenas o que queremos (no caso, CreateFile e WriteFile):
Depois de filtrado, podemos abrir a linha que nos interessa para ver como o programa utilizou a API (quais parâmetros, o retorno, etc).
Note, por exemplo, que houve uma falha antes na abertura do mesmo arquivo, mas isso porque houve uma tentativa de abrir um arquivo que já existe (abertura com direito de apenas leitura). Essa chamada foi feita pela DLL do diálogo comum de abertura/salvamento de arquivo do Windows (comdlg32.dll), e não pelo notepad.exe.
Como já havia dito no artigo original sobre o logview, você pode criar seu próprio header com as definições das funções de um módulo e o WinDbg graciosamente irá gerar um log de chamadas, incluindo medidas de performance. Esses dados abertos pelo logviewer podem ser exportados também para modo texto. E temos mais uma maneira de perfcounter chulé para eventualidades.
</description>
</item>

     
        <item>
  <title>A resolução do bitcoin</title>
  <link>http://www.caloni.com.br/a-resolucao-do-bitcoin/</link>
  <pubDate>2016-01-18</pubDate>
  
  <guid>http://www.caloni.com.br/a-resolucao-do-bitcoin/</guid>
  <description>Recentemente está havendo fuxicos sobre o último texto de Mike Hearn, um dos desenvolvedores do projeto &amp;quot;Bitcoin Core&amp;quot;, que desenha o comportamento da blockchain e acessórios. Nele Mike, que está sendo já há um tempo crítico das mudanças que tem ocorrido no projeto (incluindo um fork pra lá de controverso), pondera sobre o que pode ser o início do fim do experimento bitcoin, graças perifericamente à mudança mais estúpida já feita talvez no projeto, o RBF (replace by fee), que distorce completamente a visão original do paper do Satoshi, criador do Bitcoin, mas principalmente ao já conhecido controle massivo dos servidores atrás do Grande Firewall da China. O detalhe é que nem um nem outro acontecimento deveria se tornar decisivo para o futuro do Bitcoin, cujo teor é ser descentralizado &amp;quot;by design&amp;quot;. Porém, quando as questões técnicas caem no colo dos humanos, eles tendem como primatas a jogar merda para tudo que é bom e moral.
Meus amigos já sabem que considero a criação de moedas digitais um próximo passo prá lá de grande em direção a um mundo mais justo e livre, principalmente das amarras de um sistema jurássico de controle coercitivo de indivíduos chamado Estado ou governo. Falo especificamente do bitcoin, o mais famoso e o mais popular das moedas digitais. Portanto, não deixa de ser um baque entender como esses projetos poderão sucumbir mais cedo ou mais tarde ao mundo real.
De qualquer forma, como costumo dizer, serão anos interessantes no reino das criptomoedas e na economia em geral. Com isso, não quero dizer necessariamente que elas irão dominar o sistema financeiro e em breve veremos o fim do dinheiro estatal. Pode querer dizer isso, o que seria ótimo. No entanto, pode também querer dizer, como estamos presenciando hoje, que teremos dados mais concretos dos motivos por trás de por que moedas digitais são impossíveis de escalar no nível tecnológico atual. O mais provável IMHO é que no futuro vejamos algo no meio entre esses dois extremos. Mas não exatamente no meio =)
Por enquanto, resta seguir se informando sobre como o projeto do bitcoin vai evoluindo, e como as moedas alternativas, criadas ou a ser criadas, vão se adaptando a essas notícias. Uma boa fonte de conhecimento sempre é o Hacker News, que contém os links direto ao ponto e os comentários de pessoas geralmente com algo a acrescentar. Diferente de mim, mero curioso de plantão.
</description>
</item>

     
        <item>
  <title>Indexando símbolos com rapidez</title>
  <link>http://www.caloni.com.br/indexando-simbolos-com-rapidez/</link>
  <pubDate>2015-10-28</pubDate>
  
  <guid>http://www.caloni.com.br/indexando-simbolos-com-rapidez/</guid>
  <description>Trabalhar com inúmeros projetos de diferentes clientes e diferentes binários pode ser uma loucura. Quando o mundo é Windows, algumas medidas precisam ser padronizadas para evitar a perda de informação durante todo o processo de desenvolvimento, testes, deploy e manutenção.
A respeito do deploy e manutenção, um dos principais é manter o código sempre atualizado, limpo e asseado, além de estar dentro de pelo menos um controle de fonte, de preferência distribuído (Mercurial, Git, Bazaar).
Porém, voltando ao mundo Windows, os fontes não são apenas a única fonte de preocupação e zelo. Os binários também são importante. Binários eu digo os EXEs, DLLs geradas, além dos seus símbolos (PDBs), que contém o mapa entre aquele monte de 1s e 0s e o código-fonte de onde ele saiu.
Nós da BitForge costumamos pelo menos indexar binários com fonte, através dos resources do binário. Como isso é feito? Basicamente editando o arquivo RC na parte da versão do binário e inserindo o hash do commit usado para gerar aquele binário. Com isso qualquer binário produzido possui seu pai (&amp;quot;use the source, Luke!&amp;quot;). Usamos um script em Python muito simples e muito eficaz para isso, que indexa .NET e C&#43;&#43; (através do Visual Studio, mas não está com muitas amarras de ambiente):
rc_new_content = re.sub(u&amp;#39;^.*ProductVersion.*$&amp;#39;, product_version_string, rc_original_content, flags=re.MULTILINE)rc_new_content = re.sub(u&amp;#39;^.*FILEVERSION.*$&amp;#39;, file_version_string, rc_new_content, flags=re.MULTILINE)Quando algum binário parar na máquina de algum cliente em algum lugar do universo, basta olhar para os detalhes pelo Windows Explorer, e ele estará lá:
Através desse a2f3c... podemos capturar o commit exato de onde saiu o binário. Tudo, é claro, confiando no procedimento de toda a equipe: apenas gerar um binário a partir de um commit publicado.
Você também pode exibir a versão dos binários em uma pasta através das colunas do Windows Explorer:
Indexando símbolos e binários Outro detalhe de binários é que eles vivem sendo sobrescritos. Todo &amp;quot;Project, Build&amp;quot; sobrescreve o binário anterior, que pode ter sido justamente o enviado para o cliente. Se o cliente não possuir nenhum procedimento de armazenamento de versões dos binários gerados (às vezes ele nem precisa, essa é nossa função) não há como obter os símbolos de binários que podem gerar problemas futuros (todo software tem bug).
Para resolver isso, o mínimo que se deve fazer é super-simples e nada difícil: crie uma pasta em algum lugar, nomeie essa pasta seu servidor de símbolos, a cada novo binário que será entregue, indexe o binário e os seus símbolos. Como? Com o &amp;quot;Debugging Tools for Windows&amp;quot;, como dizia um amigo meu, é mamão com açúcar:
&amp;quot;c:\Tools\DbgTools(x86)\symstore&amp;quot; add /r /f &amp;lt;MINHA-PASTA-COM-BINÁRIOS&amp;gt; /s c:\Tools\Symbols /t &amp;quot;IndexSymbols&amp;quot;Essa e outra técnicas de indexar fontes e binário você pode ver no meu projeto, artigo, palestra e vídeo de demonstração. Se você for cego, ainda tem a vantagem da áudio-narração do vídeo. Brincadeira, ainda não temos isso.
Simplificando Com o poder do Windows Explorer, desde o Windows 95 podemos otimizar nossas tarefas nos baseando na extensão dos arquivos que estamos lidando. No caso do indexador de símbolos, eu simplesmente utilizo uma batch que contém exatamente a linha acima (com a diferença de %1 no lugar de &amp;lt;MINHA-PASTA-COM-BINÁRIOS&amp;gt;) que eu chamo direto do Explorer através de um comando que inseri no registro. Eis o comando:
Windows Registry Editor Version 5.00[HKEY_CLASSES_ROOT\dllfile\shell\Index Symbols][HKEY_CLASSES_ROOT\dllfile\shell\Index Symbols\command]@=&amp;quot;cmd.exe /c c:\\tools\\indexsymbols.bat \&amp;quot;%1\&amp;quot;&amp;quot;Você pode baixar um arquivo reg aqui, copiar as linhas acima em um .reg que você gerar, ou simplesmente seguir o passo-a-passo dessas linhas e gerar seu próprio registro. Após feito isso, surgirá um novo comando para qualquer DLL que você clicar com o outro botão do mouse:
Você também pode gerar o mesmo comando para EXEs, bastando realizar o mesmo passo-a-passo na pasta exefile em vez de dllfile.
Procedimentos como esse devem ser uma coisa simples, não difícil. Programadores e pessoas são preguiçosas, e precisam de algum incentivo. E nesse caso, o incentivo é: o que você vai fazer quando der um crash com um binário que você não sabe de onde veio nem qual fonte foi usado para compilá-lo? Pois é.
</description>
</item>

     
        <item>
  <title>Você sabe o que está usando no seu código?</title>
  <link>http://www.caloni.com.br/voce-sabe-o-que-esta-usando-no-seu-codigo/</link>
  <pubDate>2015-07-28</pubDate>
  
  <guid>http://www.caloni.com.br/voce-sabe-o-que-esta-usando-no-seu-codigo/</guid>
  <description>Quando se mexe com C&#43;&#43; em múltiplos fontes logo vem aquela bagunça do versionamento e do compartilhamento de código. LIBs, DLLs, COMs (de Component Object Model, da Microsoft). É difícil a partir de um binário saber quais os fontes envolvidos em sua construção, a não ser que você os amarre através de um sistema automatizado de build onde todos os binários devem ser obrigatoriamente compilados (e suas dependências, claro).
Porém, há maneiras mais descentralizadas de se trabalhar. Alguém poderia simplesmente colocar a versão em cada CPP e atualizá-la, assim como comentários de histórico, toda vez que alguma mudança for feita:
/** Estou começando esse meu CPP.** @desc Esse CPP fará mágicas nunca antes tentadas,* e portanto tende a ser perigoso para os padawans* mais chegados em um coletor de lixo.** @version 0.0.1** @remark Estou usando Version Semantics logo acima.*/OK, esse já é um modelo interessante, embora totalmente descartável se você já usa um sistema de build atrelado a um controle de fonte, já que você automaticamente já terá um número mágico para relacionar seus binários: o revno de seu commit (ou seus commits, no caso de mais de um repositório).
Uma versão um pouco mais... &amp;quot;binária&amp;quot;, seria inserir uma string no próprio fonte com essa versão, e talvez até o nome de seu módulo/lib/etc:
static const char* LIB_VERSION = &amp;quot;minhalib 0.0.1&amp;quot;;
Dessa forma, por pior que seja a situação do controle de seus binários, sempre haverá a possibilidade de procurar a string lá dentro.
![Strings na minha lib]({{ site.baseurl }}public/images/screenshots/strings-minha-lib.png)
Ops, esqueci que nesses compiladores modernos o que você não usa não será incluído no binário final. Isso quer dizer que se quisermos que essas strings de identificação de dependências apareça no binário compilado precisamos pelo menos dar a impressão de que ele esteja sendo usado:
class Using{public:Using(const char* name){static const char* st_UsingCollection = name;}};static const Using st_Using(&amp;#34;using minhalib 0.0.1&amp;#34;);Agora uma variável estática do módulo deverá ser inicializada como um objeto da classe Using e irá jogar em uma variável estática dentro do construtor. Se ela será usada fica a dúvida do compilador, que deixa tudo como está. Ou seja, ganhamos nossa string no binário:
#include &amp;#34;Using.h&amp;#34;static const Using st_Using(&amp;#34;using minhalib 0.0.1&amp;#34;);int main(){}![Strings na minha lib]({{ site.baseurl }}public/images/screenshots/strings-minha-lib-ok.png)
Uma solução mais genérica pode ser aplicada utilizando as famigeradas macros e...
O quê?!?!?!??! VOCÊ DISSE MACROS?!???!? TÁ MALUCO??!??!
Sim. Macros. São inofensivas se você usar direito.
E se reclamar vai ter goto.
// Using.h#pragma once #define USING_FILE(version) static const Using st_Using ## __LINE__(&amp;#34;using file &amp;#34; __FILE__ &amp;#34; &amp;#34; version)#define USING_CLASS(name, version) static const Using st_Using ## __LINE__(&amp;#34;using class &amp;#34; #name &amp;#34; &amp;#34; version)#define USING_LIB(name, version) static const Using st_Using ## __LINE__(&amp;#34;using lib &amp;#34; #name &amp;#34; &amp;#34; version)#define USING_FUNCTION(version) static const Using st_Using ## __LINE__(&amp;#34;using function &amp;#34; __FUNCTION__ &amp;#34; &amp;#34; version)class Using{public:Using(const char* name){static const char* st_UsingCollection = name;}};A ideia é que qualquer pedaço de código, seja um conjunto de CPPs que você chama de LIB, ou um CPP que você compila em diferentes projetos (talvez em cópias diferentes ainda sendo usadas), ou até aquela função-chave, ou classe-chave. Na verdade, quando eu digo pedaço de código, é pedaço mesmo. Está livre para você imaginar e rotular o que quiser. Depois você consegue dar uma geral no resultado:
// File1.cpp#include &amp;#34;Using.h&amp;#34;USING_LIB(extralib, &amp;#34;0.0.1&amp;#34;);void ImportantFunction(){USING_FUNCTION(&amp;#34;0.3.1&amp;#34;);}// File2.cpp#include &amp;#34;Using.h&amp;#34;USING_FILE(&amp;#34;0.0.1&amp;#34;);// File3.cpp#include &amp;#34;Using.h&amp;#34;USING_CLASS(ImportantClass, &amp;#34;1.3.4&amp;#34;);class ImportantClass{public:};#include &amp;#34;Using.h&amp;#34;USING_LIB(lib1, &amp;#34;0.0.1&amp;#34;);![Todas as strings do meu projeto]({{ site.baseurl }}public/images/screenshots/all-strings-using.png)
Com esse simples mecanismo que não gasta mais do que algumas chamadas de assembly no início da lib (antes do main) e o espaço ocupado na memória pelas strings somadas (menos de 1KB, provavelmente) você tem em suas mãos uma poderosa ferramenta de análise de como os binários estão sendo gerados pela sua equipe remota, ou por qual configuração foi usada na máquina de build para gerar aquela DLL com aquele problema antigo, ou porque algo que funcionava parou de funcionar e nada foi mexido (isso nunca acontece, não é mesmo?).
O código dessa brincadeira está no meu repositório de samples do GitHub.
</description>
</item>

     
        <item>
  <title>O novo &#39;como não dar step into&#39; do Visual Studio 2012/13</title>
  <link>http://www.caloni.com.br/o-novo-como-nao-dar-step-into-do-visual-studio-201213/</link>
  <pubDate>2014-08-01</pubDate>
  
  <guid>http://www.caloni.com.br/o-novo-como-nao-dar-step-into-do-visual-studio-201213/</guid>
  <description>Toda vez que instalo um Visual Studio novo e começo a depurar sempre surge a necessidade de fazê-lo calar a boca nos step intos da STL, Boost, ATL e coisas-que-sei-que-não-vai-dar-pau. (Obviamente, quando dá pau, preciso ir no disassembly e cutucar a STL para ela me entregar qual o problema com o meu contêiner.)
Nas edições antigas da IDE (até o 2010) existia uma configuração no registro para isso. Desde o Visual Studio 2012 isso mudou, e agora existe um arquivo em %programfiles(x86)%\Microsoft Visual Studio 11(ou12).0\Common7\Packages\Debugger\Visualizers chamado default.natstepfilter (gostei do detalhe do &amp;quot;nat&amp;quot;: &amp;quot;nat thou step into, little bestard!&amp;quot;). Ele é um XML que já vem preenchido com algumas opções interessante:
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?&amp;gt;&amp;lt;StepFilter xmlns=&amp;#34;http://schemas.microsoft.com/vstudio/debugger/natstepfilter/2010&amp;#34;&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;__security_check_cookie&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;__abi_winrt_.*&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;_ObjectStublessClient.*&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;_Invoke@12&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;_RTC_Check(Esp|StackVars)&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;_chkstk&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;ATL::CComPtrBase.*::operator&amp;amp;amp;&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;ATL::CComPtrBase.*::operator-&amp;amp;gt;&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;ATL::CHeapPtrBase.*::operator&amp;amp;amp;&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;ATL::CHeapPtrBase.*::operator-&amp;amp;gt;&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;ATL::CComBSTR::operator&amp;amp;amp;&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;std::forward&amp;amp;lt;.*&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;std::move&amp;amp;lt;.*&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;Platform::EventSource::Invoke.*&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;std::.*&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;boost::.*&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;/StepFilter&amp;gt;Podemos simplesmente adicionar mais duas opções para o parzinho STL/Boost:
&amp;lt;?xml version=&amp;#34;1.0&amp;#34; encoding=&amp;#34;utf-8&amp;#34;?&amp;gt;&amp;lt;StepFilter xmlns=&amp;#34;http://schemas.microsoft.com/vstudio/debugger/natstepfilter/2010&amp;#34;&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;std::.*&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;Function&amp;gt;&amp;lt;Name&amp;gt;boost::.*&amp;lt;/Name&amp;gt;&amp;lt;Action&amp;gt;NoStepInto&amp;lt;/Action&amp;gt;&amp;lt;/Function&amp;gt;&amp;lt;/StepFilter&amp;gt;A boa nova, pelo menos para o Visual Studio 2013, é que agora é possível, se quisermos, entrar nas funções que serão ignoradas:

Eu não sei qual vai ser a próxima novidade do step into, mas para mim, já está bem ótimo.
(Fonte da informação: Andy Pennell&#39;s Blog).
</description>
</item>

     
        <item>
  <title>Integrando BitBucket/GitHub com Trello</title>
  <link>http://www.caloni.com.br/integrando-bitbucketgithub-com-trello/</link>
  <pubDate>2014-07-22</pubDate>
  
  <guid>http://www.caloni.com.br/integrando-bitbucketgithub-com-trello/</guid>
  <description>Eu nem acredito que estou escrevendo sobre desenvolvimento web, mas como foi algo que me fez dedicar algumas horas do meu fim-de-semana, e não encontrei facilmente uma solução já feita, acredito que pode ser útil para mais alguém que usa Trello e GitHub (ou BitBucket).
Mas o que é Trello? Basicamente é um TodoList feito da maneira mais inteligente possível: uma lista de listas de listas! Os espaços, ou desktops, onde você organiza suas tarefas são chamados de Boards. Em cada board vivem L listas, e em cada lista vivem C cards. Cada card pode conter comentários, histórico de mudanças, labels, checklists, due dates e todas as tranqueiras que geralmente existe em uma lista de tarefas. É um sistema online, desenvolvido pela empresa do Joel Spolsky (o mesmo do excelente blogue de programador Joel on Software (ou em português, e que contém algo que eu adoro em sistemas web: atalhos!

A ideia que tive foi usar os webhooks dos saites de repositórios de fontes para permitir comentar dentro dos cards o commit que foi feito, sua mensagem e o linque para o commit. OK, mas por que não usar o sistema de issues dos já feitos pra isso GitHub e BitBucket? Ele já faz isso muito melhor. De fato. Porém, fica espalhado pelos repositórios, e não é sempre que uma tarefa envolve código (comprar pão, por exemplo). Além do mais, praticamente qualquer serviço desses oferece hooks para a integração de outros projetos/serviços, então se um dia nascer mais um sistema de controle de fonte ou mais um saite que organiza essas tralhas haverá um hook e consequentemente mais uma adaptação do meu código PHP.
E por que PHP? Bom, PHP é uma linguagem fácil de mexer (se parece com C, mas é um script) e praticamente qualquer servidor web do universo, mesmo o mais baratinho, vem com o pacote Apache &#43; PHP (e geralmente uma base MySql). Dessa forma, é uma solução que pode ser implantada fácil e rapidamente.
Comentando no Trello Vamos começar pelo mais difícil que o resto vai fácil: comentar pela API do Trello. Sua API é beta, assim como sua documentação, então tive arrancar significado inexistente em seu help, mas acabou funcionando. Como qualquer API web, você precisa de uma chave, segredo e a permissão do usuário. Com essa permissão é possível comentar em todas as boards que esse usuário específico tem acesso.
Pelo menos a parte de geração de chave/segredo é simples, tanto que se você clicou nesse linque, já conseguiu gerar uma =).
Depois disso, mesmo nessa página já é possível conseguir uma chave de acesso para o seu usuário.

Por fim, para fazer o código que irá comentar dentro de um card no Trello, basta usar dois ou três métodos que lidam com enviar coisas pela web (não me pergunte mais que isso):
&amp;lt;?php$url = &amp;#39;https://trello.com/1/cards/ID_DO_CARD/actions/comments&amp;#39;;$msg = &amp;#39;Hello, World!&amp;#39;;$data = array(&amp;#39;key&amp;#39; =&amp;gt; &amp;#39;AQUI_VAI_SUA_CHAVE&amp;#39;, &amp;#39;token&amp;#39; =&amp;gt; &amp;#39;AQUI_VAI_SEU_TOKEN_DE_ACESSO&amp;#39;,&amp;#39;text&amp;#39; =&amp;gt; $msg);$options = array(&amp;#39;http&amp;#39; =&amp;gt; array(&amp;#39;header&amp;#39; =&amp;gt; &amp;#34;Content-type: application/x-www-form-urlencoded\r\n&amp;#34;,&amp;#39;method&amp;#39; =&amp;gt; &amp;#39;POST&amp;#39;,&amp;#39;content&amp;#39; =&amp;gt; http_build_query($data),),);$context = stream_context_create($options);$result = file_get_contents($url, false, $context);?&amp;gt;As informações AQUI_VAI_SUA_CHAVE e AQUI_VAI_SEU_TOKEN_DE_ACESSO você já obteve no linque de geração de key/secret. Já o ID_DO_CARD é algo que depende de em qual lista seu card está, mas felizmente também existe um shortlink único e imutável para cada card no sistema:

Basta usar o ID em Base64-ou-o-que-o-valha no lugar de ID_DO_CARD que já estamos OK. Depois que este código conseguir ser executado, basta ter acesso à internet que ele irá escrever &amp;quot;Hello, World&amp;quot; no cartão referenciado:

Muito bem. Primeira parte da missão concluída.
Terminando com GitHub Como o GitHub é um dos serviços de repositório de fontes mais famoso, vamos torná-lo nosso caso de sucesso. Basicamente você deve ir no seu repositório do coração (essa é a parte ruim: se você tem mais de um coração, vai ter que repetir esse mesmo procedimento para todos os outros repositórios dos seus outros corações), Settings, Webhooks &amp;amp; Services.

Lembre-se de colocar seu código PHP em um servidor visível na web. Lembre-se também de usar o método de envio urlencoded do payload para simplificar seu tratamento. Para simplificar ainda mais o processo, coloque qualquer coisa no segredo (não validaremos neste post, mas #ficadica de segurança se você não quer que outros acessem seu PHP inadvertidamente).
Pois bem. No código que irá receber o payload do GitHub precisamos de duas coisas: saber qual a estrutura que vai ser recebida e como localizar o id do card onde iremos enviar a informação. Nesse caso, mais uma vez, para simplificar, vamos procurar pelo próprio linque permanente do cartão na mensagem do commit. Aliás, doS commitS (sendo um push, é provável que o evento seja gerado com diversos commits aninhados).
&amp;lt;?php$pushData = json_decode($_POST[&amp;#39;payload&amp;#39;]);foreach( $pushData-&amp;gt;commits as $c ){$msg = $c-&amp;gt;message;$pattern = &amp;#39;#http[s]*://trello.com/c/([A-Za-z0-9]&#43;)#&amp;#39;;if( preg_match($pattern, $msg, $matches) == 0 )continue;$url = &amp;#39;https://trello.com/1/cards/&amp;#39; . $matches[1] . &amp;#39;/actions/comments&amp;#39;;$msg = $c-&amp;gt;message . &amp;#39; Commit: &amp;#39; . $c-&amp;gt;url;$data = array(&amp;#39;key&amp;#39; =&amp;gt; &amp;#39;AQUI_VAI_SUA_CHAVE&amp;#39;, &amp;#39;token&amp;#39; =&amp;gt; &amp;#39;AQUI_VAI_SEU_TOKEN_DE_ACESSO&amp;#39;,&amp;#39;text&amp;#39; =&amp;gt; $msg);$options = array(&amp;#39;http&amp;#39; =&amp;gt; array(&amp;#39;header&amp;#39; =&amp;gt; &amp;#34;Content-type: application/x-www-form-urlencoded\r\n&amp;#34;,&amp;#39;method&amp;#39; =&amp;gt; &amp;#39;POST&amp;#39;,&amp;#39;content&amp;#39; =&amp;gt; http_build_query($data),),);$context = stream_context_create($options);$result = file_get_contents($url, false, $context);}?&amp;gt;Agora é só testar. Posso pegar esse mesmo artigo e comitá-lo no repositório do blogue usando o linque único do card da tarefa de escrever este artigo. Ou seja, aqui é Inception na veia, mermão!

O que vai deixar você perplexo é entender como esse texto está sendo comitado antes mesmo de eu comitar este texto ;).

E o negócio é rápido, viu?

Adendo: BitBucket A única coisa que muda no caso do BitBucket é a tela onde deve ser inserido seu webhook (método POST, sempre) e a estrutura JSon que é enviada. De lambuja, eis o que deve ser feito com esse payload:
&amp;lt;?php$bitData = json_decode($_POST[&amp;#34;payload&amp;#34;]);foreach( $bitData-&amp;gt;commits as $c ){$msg = $c-&amp;gt;message;$pattern = &amp;#39;#http[s]*://trello.com/c/([A-Za-z0-9]&#43;)#&amp;#39;;if( preg_match($pattern, $msg, $matches) == 0 )continue;$url = &amp;#39;https://trello.com/1/cards/&amp;#39; . $matches[1] . &amp;#39;/actions/comments&amp;#39;;$msg = $c-&amp;gt;message . &amp;#39; Commit: &amp;#39; . $bitData-&amp;gt;canon_url . $bitData-&amp;gt;repository-&amp;gt;absolute_url . &amp;#39;commits/&amp;#39; . $c-&amp;gt;raw_node;$data = array(&amp;#39;key&amp;#39; =&amp;gt; &amp;#39;AQUI_VAI_SUA_CHAVE&amp;#39;, &amp;#39;token&amp;#39; =&amp;gt; &amp;#39;AQUI_VAI_SEU_TOKEN_DE_ACESSO&amp;#39;,&amp;#39;text&amp;#39; =&amp;gt; $msg);$options = array(&amp;#39;http&amp;#39; =&amp;gt; array(&amp;#39;header&amp;#39; =&amp;gt; &amp;#34;Content-type: application/x-www-form-urlencoded\r\n&amp;#34;,&amp;#39;method&amp;#39; =&amp;gt; &amp;#39;POST&amp;#39;,&amp;#39;content&amp;#39; =&amp;gt; http_build_query($data),),);$context = stream_context_create($options);$result = file_get_contents($url, false, $context);}?&amp;gt;</description>
</item>

     
        <item>
  <title>Poker Face</title>
  <link>http://www.caloni.com.br/poker-face/</link>
  <pubDate>2014-05-06</pubDate>
  
  <guid>http://www.caloni.com.br/poker-face/</guid>
  <description>O segundo round da segunda fase do Code Jam passou nesse sábado. Disléxico que sou, consegui fazer apenas 8 pontos ¿ como todo mundo ¿ no teste small do problema B, que envolvia apenas dois loops aninhados (a versão large fica para outro post). Na verdade, estou aqui para expressar minha gratidão ao campeonato por ter aprendido mais uma bela lição vendo o código do primeiro colocado do primeiro round, vulgo Kaizero, um coreano que deu uma solução simples, rápida e prática para um problema de probabilidade tão error-prone que até os juízes do Google deram uma lambuja de alguns testes errados (sem contar que houve apenas a categoria small), e me fez pensar em quantas vezes pensamos em demasiado tentando encontrar a solução perfeita para algo que simplesmente... não precisa.
Basta um hack e commit.
É a incerteza, idiota! 
O problema reza que existem dois algoritmos para embaralhar uma sequência numérica (de 0 a N): o bom e o ruim. Ambos traçam um loop do iníco ao fim pegando aleatoriamente um elemento da lista e trocando de lugar com o elemento que está sendo varrido no momento.

A diferença entre o bom e o ruim é que o bom pega aleatoriamente apenas os elementos DEPOIS do elemento que está sendo varrido, enquanto o algoritmo ruim pega qualquer um dos elementos SEMPRE. Isso aparentemente e intuitivamente não parece interferir na aleatoriedade do embaralhamento, mas se levarmos ao extremo de embaralhar repetidas vezes somando a lista resultante percebemos uma tendência gritante do algoritmo ruim em manter o ordenamento inicial, ou pelo menos na média sempre tender para números menores no início e números maiores no fim, como pode ser visto nesse teste que fiz, gerado pelo Excel:

O que eu tentei fazer durante meu fim-de-semana retrasado e o feriado foi encontrar um detector de aleatoriedade (aliás, encontrei um bem interessante chamado ent), tanto &amp;quot;na mão&amp;quot; quanto pesquisando. O que eu não imaginava foi que o teste que eu tinha feito no início usando uma simples planilha Excel era a solução óbvia (naquelas de é óbvio só depois que você vê). E foi essa a solução adotada por Kaizero.
/** @author Kaizero@desc Versão comentada (em português) e desofuscada do código do Code Jam 2014, 1A, problema 3 (Proper Shuffle)por Wanderley Caloni (wanderley@caloni.com.br).*/#pragma warning(disable:4996) // warning, pra que te quero...#include&amp;lt;stdio.h&amp;gt;#include&amp;lt;algorithm&amp;gt;#include&amp;lt;vector&amp;gt;#include&amp;lt;time.h&amp;gt;using namespace std;// as variáveis monossilábicas...int w[1001], C[1001][1001], O[1001];// Note que uma delas (C) é uma tabela gigantesca:// 1 2 3 4 ... 1001// 2// 3// ...// 1001// tabela verdade?bool v[1001];struct A{	int ord, R;bool operator &amp;lt;(const A &amp;amp;p)const{return R &amp;lt; p.R;}}p[1000];int main(){freopen(&amp;#34;input.txt&amp;#34;, &amp;#34;r&amp;#34;, stdin);freopen(&amp;#34;output.txt&amp;#34;, &amp;#34;w&amp;#34;, stdout);int i, TC, T, n, j;srand((unsigned)time(NULL)); // mexendo o saco de bingo...// a parte mais demorada: construir um contador gigante estilo 	// Excel com 3 milhões de iterações	for (i = 0; i &amp;lt; 3000000; i&#43;&#43;){// 1. Preenchemos o array sequencial.	for (j = 0; j &amp;lt; 1000; j&#43;&#43;){w[j] = j;}// 2. Realizamos o algorimo ruim.	for (j = 0; j &amp;lt; 1000; j&#43;&#43;){swap(w[j], w[rand() % 1000]);}// 3. Pesamos o resultado do algoritmo ruim.	for (j = 0; j &amp;lt; 1000; j&#43;&#43;){C[j][w[j]]&#43;&#43;;}}// agora a parte &amp;#34;fácil&amp;#34;...// ler número de casos de teste (sempre 120)	scanf(&amp;#34;%d&amp;#34;, &amp;amp;TC);for (T = 1; T &amp;lt;= TC; T&#43;&#43;) // iterar por cada linha	{scanf(&amp;#34;%d&amp;#34;, &amp;amp;n);p[T].ord = T; // guardando sua posição// lendo os números de todos os casos	for (i = 0; i &amp;lt; n; i&#43;&#43;){scanf(&amp;#34;%d&amp;#34;, &amp;amp;O[i]);p[T].R &#43;= C[i][O[i]]; // mas gravando o peso de cada posição (cálculo de 3M)	}}// ordenando pelo peso de cada posição	sort(p &#43; 1, p &#43; TC &#43; 1);for (i = 1; i &amp;lt;= 60; i&#43;&#43;)v[p[i].ord] = true; // metade tem que ser bom (a melhor metade)for (i = 1; i &amp;lt;= TC; i&#43;&#43;){printf(&amp;#34;Case #%d: &amp;#34;, i);if (v[i])printf(&amp;#34;GOOD\n&amp;#34;);else printf(&amp;#34;BAD\n&amp;#34;);}}O que ele basicamente faz é acumular os resultados de três milhões de embaralhamentos feitos pelo algoritmo ruim e inferir através dos resultados que metade é bom e metade é ruim. O ruim fica do lado desbalanceado da sequência.

Tão óbvio, tão simples, tão elegante.
</description>
</item>

     
        <item>
  <title>Que geleia de mocotó</title>
  <link>http://www.caloni.com.br/que-geleia-de-mocoto/</link>
  <pubDate>2014-04-29</pubDate>
  
  <guid>http://www.caloni.com.br/que-geleia-de-mocoto/</guid>
  <description>
A primeira bateria de problemas da segunda fase do Code Jam me mostrou o porquê do seu nome: meu cérebro ficou feito geleia (ha ha ha). Não consegui resolver nenhum problema a tempo, mas não culpo o C&#43;&#43;, que passei a usar para essa fase. É burrice aliada a pressão. Duas horas e meia para entender um problema é o tipo de coisa que me deixa pensando mais no tempo do que no problema. Tenho que melhorar isso.
De qualquer forma, esse final de semana que passou foi dedicado a resolver o primeiro problema e quem sabe escrever um post a respeito. Imagino que todos tenham acesso ao enunciado e aos casos de teste, mas, por via das dúvidas, aqui vai uma descrição adaptada:
Você é um fazendeiro hi-tech com uma vaca que tem um tablet. Não especifica se esse cowblet é um iPad, mas é uma possibilidade, já que como nenhum plugue parece encaixar nas tomadas de sua fazenda, é muito provável que você seja um Applemaníaco com um monte de gadgets que precisam de conversor vindos direto do eBay.

Através do eBay também veio um engenheiro chinês cuja missão é resolver esse gato que o Sr. Fazendeiro fez em sua fazenda. Tudo que ele precisa fazer é girar gigantescos switches (ou disjuntores) que invertem a polaridade binária de cada um dos pino dos conectores das tomadas. Quando um plugue de dispositivo e uma tomada possuem a mesma configuração de bits é possível conectá-los. O objetivo final é que todos os N plugues conectem nas N tomadas depois de virados Y switches, sendo que quanto menos switches melhor (afinal, eles são gigantescos, e o chinês supõe-se que seja pequeno).

O primeiro pensamento do programador preguiçoso (go, horse, go!) manda que usemos a velha força bruta e testemos todas as combinações possíveis de disjuntores, peguemos o com menor número de bits setados (inicialmente, todos estão em 0) e zás! Porém, o caso de teste tamanho large pressupõe que o limite de pinos das tomadas pode chegar a 40, o que seria responsável por nada mais nada menos que 2^40 combinações diferentes, ou 1.099.511.627.776 para ser exato. Isso dá mais de 1 trilhão! Mesmo que nosso código seja extremamente rápido e demore apenas um milissegundo para cada combinação, serão mais de 34 anos desperdiçados, que poderiam estar melhor investidos minerando bitcoins.

Dessa forma, temos que traçar uma solução baseada nas combinações entre as tomadas e plugues, que, pelos limites da versão large dos casos de teste, podem ter a quantidade de 150, o que dá 150*150 = 22500 combinações de XOR.

Sim, de XOR. O XOR aqui pode ser usado para detectarmos qual a combinação de switches precisamos para que cada tomada encaixa em cada dispositivo. Esse é o nosso conjunto universo de giros de disjuntores. Com esse conjunto em mãos fica fácil saber quais combinações são possíveis de encaixar todos os dispositivos: basta contar!
#include &amp;#34;CodeJam.h&amp;#34;#include &amp;lt;algorithm&amp;gt;#include &amp;lt;map&amp;gt;#include &amp;lt;vector&amp;gt;#include &amp;lt;set&amp;gt;#include &amp;lt;string&amp;gt;using namespace std;static const int MAX_SWITCHES = 40;__int64 StringToInt(const string&amp;amp; s, int L){__int64 ret = 0;for( int l = L; l; --l ){char c = s[L-l];if( c == &amp;#39;1&amp;#39; )ret |= ((__int64)1 &amp;lt;&amp;lt; (l-1));}return ret;}int CountBits(__int64 value){int ret = 0;while( value ){if( value &amp;amp; 1 )&#43;&#43;ret;value &amp;gt;&amp;gt;= 1;}return ret;}void TestCase(std::istream&amp;amp; is, std::ostream&amp;amp; os){int N, L;is &amp;gt;&amp;gt; N &amp;gt;&amp;gt; L;vector&amp;lt;__int64&amp;gt; outlets;vector&amp;lt;__int64&amp;gt; devices;string eletricItem;for( int n = 0; n &amp;lt; N; &#43;&#43;n ){is &amp;gt;&amp;gt; eletricItem;outlets.push_back(StringToInt(eletricItem, L));}for( int n = 0; n &amp;lt; N; &#43;&#43;n ){is &amp;gt;&amp;gt; eletricItem;devices.push_back(StringToInt(eletricItem, L));}typedef map&amp;lt;__int64, set&amp;lt;int&amp;gt;&amp;gt; SwitchOcurrences;SwitchOcurrences switchOcurrences;for( int n = 0; n &amp;lt; N; &#43;&#43;n ){__int64 outlet = outlets[n];for( int n2 = 0; n2 &amp;lt; N; &#43;&#43;n2 ){__int64 device = devices[n2];__int64 connection = outlet ^ device;switchOcurrences[connection].insert(n);}}for(auto it = switchOcurrences.begin(); it != switchOcurrences.end(); ){if( it-&amp;gt;second.size() != N )it = switchOcurrences.erase(it);else&#43;&#43;it;}if( switchOcurrences.size() ){int switches = MAX_SWITCHES &#43; 1;for_each(switchOcurrences.begin(), switchOcurrences.end(), [&amp;amp;](const SwitchOcurrences::value_type&amp;amp; ocurrence){int bits = CountBits(ocurrence.first);switches = min(switches, bits);});os &amp;lt;&amp;lt; switches &amp;lt;&amp;lt; endl;}else os &amp;lt;&amp;lt; &amp;#34;NOT POSSIBLE\n&amp;#34;;}Observação: note que retirei o wrapper costumeiro dos exercícios do Code Jam para não poluir demais o exemplo com código. E, na verdade, essa parte do código está compartilhada com todas as soluções (reuse!).
O que aprendi dessa pequena aventura foi: não importa o quanto um problema pareça fácil, anotar em um pedaço de papel é o caminho mais curto entre a mente e o código.
Que venha a segunda bateria de problemas!
</description>
</item>

     
        <item>
  <title>Geleia de Código</title>
  <link>http://www.caloni.com.br/geleia-de-codigo/</link>
  <pubDate>2014-04-15</pubDate>
  
  <guid>http://www.caloni.com.br/geleia-de-codigo/</guid>
  <description>
Não costumo participar de campeonatos de programação por alguns motivos vagos: é perda de tempo (não ganho nada com isso), sou um péssimo programador (ou pasteleiro), dá preguiça (esse é o mais válido) e por aí vai o mimimi. Dessa forma, sempre passei ileso de eventos como o atual Google Code Jam, que pretende levar a categoria de código ofuscado para um novo patamar.
No entanto, esse ano apareceram dois motivos que me levaram a gastar cinco minutos de paciência com as historinhas bestas da equipe do Google. Primeiro o Python, que desde 2013 tem renovado em mim a sensação que programar ainda é divertido (e que o pessoal da Microsoft e do padrão C&#43;&#43; tinham tirado de mim há muito tempo com seus compiladores cada vez mais complexos/lentos e as IDEs que demoram o tempo do cafezinho para abrir). Segundo o que move o mundo: a concorrência. Minha digníssima esposa, levada por alguns pontos-extra na faculdade (uma iniciativa até que louvável do professor), resolveu participar da primeira fase (a classificação desta fase também dava pontos).
O fato é que depois desses cinco minutos eu simplesmente não consegui parar até o minuto final das 23 horas (horário de Brasília) de domingo, quando o tempo-limite esgotou. O aspecto mais divertido do Code Jam é que há liberdade total para a ferramenta que você pretende usar: linguagens de programação, Excel, uma calculadora ou apenas seu cérebro. Você recebe uma &amp;quot;missão&amp;quot; e um arquivo de entrada e precisa cuspir um arquivo de saída de acordo com a missão. Apenas isso. O resto fica por conta da criatividade dos codadores e gambiarreiros de plantão.
Todos os exercícios levam em consideração um arquivo de entrada que possui em sua primeira linha o número de testes que serão feitos e em seguida um número determinado de linhas e parâmetros, geralmente divididos por espaço. O primeiro problema, por exemplo, apenas considerava a suposição de cartas em pequeno truque de mágica e recebia como entrada a disposição dessas cartas junto com a escolha da fileira que o participante dizia onde estava a carta escolhida.
21 2 3 45 6 7 89 10 11 1213 14 15 1631 2 5 43 11 6 159 10 7 1213 14 8 16 import sysf = open(sys.argv[1])total = int(f.readline())for case in range(0, total):guess1 = int(f.readline())row1 = Nonefor i in range(1, 5):row = f.readline().split()if i == guess1:row1 = rowguess2 = int(f.readline())row2 = Nonefor i in range(1, 5):row = f.readline().split()if i == guess2:row2 = rowcards = list(set(row1) &amp;amp; set(row2))if len(cards) == 1:print &amp;#39;Case #&amp;#39; &#43; str(case&#43;1) &#43; &amp;#39;: &amp;#39; &#43; cards[0]elif len(cards) &amp;gt; 1:print &amp;#39;Case #&amp;#39; &#43; str(case&#43;1) &#43; &amp;#39;: Bad magician!&amp;#39;else:print &amp;#39;Case #&amp;#39; &#43; str(case&#43;1) &#43; &amp;#39;: Volunteer cheated!&amp;#39;O segundo exercício já envolvia um jogo bem divertido em que o jogador ficava clicando em cookies como se não houvese amanhã. Esse deu um pouco mais de trabalho, mas foi mais divertido que o primeiro.
import sysdef CookieClicker(farmCost, farmIncrement, cookieTarget):cookiePerSecond = 2.0bestTime = cookieTarget / cookiePerSecond # melhor tempo soh fazendo cookies cookieFarmTime = cookieTarget / (cookiePerSecond &#43; farmIncrement) # melhor tempo ja com fazenda criada farmTime = farmCost / cookiePerSecond &#43; cookieFarmTime # quanto vai custar fazer a fazenda e depois fazer cookies com a fazenda while farmTime &amp;lt; bestTime: # enquanto fazer a fazenda custar menos tempo que soh fazer cookies... bestTime = farmTime # por enquanto melhor tempo cookiePerSecond = cookiePerSecond &#43; farmIncrement # novo tempo para fazer cookies (mais uma fazenda ja criada) farmTime = farmTime - cookieFarmTime # tiramos o tempo de soh fazer cookies para fazer mais uma fazenda cookieFarmTime = cookieTarget / (cookiePerSecond &#43; farmIncrement) # novo tempo com mais uma fazenda criada farmTime = farmTime &#43; farmCost / cookiePerSecond &#43; cookieFarmTime # agora com o novo tempo de fazer outra fazenda e soh cookies return bestTimef = open(sys.argv[1])total = int(f.readline())for case in range(1, total &#43; 1):args = [float(i) for i in f.readline().split()]ret = CookieClicker(args[0], args[1], args[2])print &amp;#39;Case #&amp;#39; &#43; str(case) &#43; &amp;#39;: &amp;#39; &#43; &amp;#39;{0:.7f}&amp;#39;.format(ret)Já o terceiro... o terceiro passa. Vamos para o quarto, um dos mais instigantes, pois envolve duas regras distintas de um jogo e a otimização das melhores estratégias para ambos. Isso consumiu bem mais tempo que os outros dois iniciais, pois lembro de ter me isolado por uma hora para conseguir colocar tudo na cabeça.
import sysdef BestBlock(block, blocks):bestBlock = 0for i in range(len(blocks) - 1, -1, -1):if blocks[i] &amp;lt; block: breakbestBlock = blocks[i]if not bestBlock:bestBlock = blocks[0]return bestBlockdef War(naomi, ken):naomi = sorted(naomi)ken = sorted(ken)naomiCount = 0while len(naomi):naomiBlock = naomi[-1]kenBlock = BestBlock(naomiBlock, ken)if naomiBlock &amp;gt; kenBlock:naomiCount = naomiCount &#43; 1#print str(naomiBlock) &#43; &amp;#39; vs &amp;#39; &#43; str(kenBlock) &#43; &amp;#39;: &amp;#39; &#43; str(naomiCount) naomi.remove(naomiBlock)ken.remove(kenBlock)return naomiCountdef WarCheat(naomi, ken):naomi = sorted(naomi)ken = sorted(ken)naomiCount = 0while len(naomi):naomiTold = 0naomiBlock = naomi[-1]bestKen = ken[-1]if naomiBlock &amp;gt; bestKen:naomiTold = bestKen &#43; 0.00000001else:naomiTold = bestKen - 0.00000001kenBlock = BestBlock(naomiTold, ken)naomiBlock = BestBlock(kenBlock, naomi)if naomiBlock &amp;gt; kenBlock:naomiCount = naomiCount &#43; 1#print str(naomiTold) &#43; &amp;#39;(&amp;#39; &#43; str(naomiBlock) &#43; &amp;#39;) vs &amp;#39; &#43; str(kenBlock) &#43; &amp;#39;: &amp;#39; &#43; str(naomiCount) naomi.remove(naomiBlock)ken.remove(kenBlock)return naomiCountf = open(sys.argv[1])total = int(f.readline())for case in range(1, total &#43; 1):f.readline()naomi = [float(i) for i in f.readline().split()]ken = [float(i) for i in f.readline().split()]war = War(naomi, ken)warCheat = WarCheat(naomi, ken)print &amp;#39;Case #&amp;#39; &#43; str(case) &#43; &amp;#39;: &amp;#39; &#43; str(warCheat)&#43; &amp;#39; &amp;#39; &#43; str(war)Já o terceiro foi um fracasso total. Tentei de todas as maneiras resolver o impasse de descobrir qual disposição de um jogo de campo minado poderia ser resolvido em apenas um clique (parece o jogo oposto do viciado clicador de cookies), mas falhei miseravelmente. E desconfio o porquê. Primeiro entendo que meu perfeccionismo me impediu de realizar uma checagem padrão para exceções já conhecidas (quando há apenas uma linha ou coluna, quando há apenas um espaço sem minas, etc). Eu pensei: se o Google fez esse problema, ele deve ter bolado alguma solução genérica que independa de ifs. Bom, não que eu saiba. Depois de terminado o tempo dei uma olhada em algumas soluções dos competidores e não achei nenhuma solução que usasse algum algoritmo maluco e genérico (não achei nenhum indiano, contudo).
Eis a solução porca e mal-resolvida (alguns pontos do códido foram feitos depois de ver o código de outrem):
import sysdef FieldToString(field):ret = &amp;#39;\n&amp;#39;for r in field:for c in r:ret = ret &#43; str(c)ret = ret &#43; &amp;#39;\n&amp;#39;return retdef CountMines(field, r, c):ret = 0row = len(field)col = len(field[0])if r &amp;lt; row-1 and field[r&#43;1][c] == &amp;#39;*&amp;#39;: ret = ret &#43; 1if c &amp;lt; col-1 and field[r][c&#43;1] == &amp;#39;*&amp;#39;: ret = ret &#43; 1if r &amp;gt; 0 and field[r-1][c] == &amp;#39;*&amp;#39;: ret = ret &#43; 1if c &amp;gt; 0 and field[r][c-1] == &amp;#39;*&amp;#39;: ret = ret &#43; 1if r &amp;lt; row-1 and c &amp;lt; col-1 and field[r&#43;1][c&#43;1] == &amp;#39;*&amp;#39;: ret = ret &#43; 1if r &amp;gt; 0 and col &amp;gt; 0 and field[r-1][c-1] == &amp;#39;*&amp;#39;: ret = ret &#43; 1if r &amp;lt; row-1 and c &amp;gt; 0 and field[r&#43;1][c-1] == &amp;#39;*&amp;#39;: ret = ret &#43; 1if r &amp;gt; 0 and c &amp;lt; col-1 and field[r-1][c&#43;1] == &amp;#39;*&amp;#39;: ret = ret &#43; 1return retdef ExpandClick(field, r, c):if field[r][c] != &amp;#39;0&amp;#39;: returndef Expand(field, r, c):if field[r][c] == &amp;#39;.&amp;#39;:field[r][c] = str(CountMines(field, r, c))ExpandClick(field, r, c)row = len(field)col = len(field[0])if r &amp;lt; row-1 and field[r&#43;1][c] != &amp;#39;*&amp;#39;:Expand(field, r&#43;1, c)if c &amp;lt; col-1 and field[r][c&#43;1] != &amp;#39;*&amp;#39;:Expand(field, r, c&#43;1)if r &amp;gt; 0 and field[r-1][c] != &amp;#39;*&amp;#39;:Expand(field, r-1, c)if c &amp;gt; 0 and field[r][c-1] != &amp;#39;*&amp;#39;:Expand(field, r, c-1)if r &amp;lt; row-1 and c &amp;lt; col-1 and field[r&#43;1][c&#43;1] != &amp;#39;*&amp;#39;:Expand(field, r&#43;1, c&#43;1)if r &amp;gt; 0 and col &amp;gt; 0 and field[r-1][c-1] != &amp;#39;*&amp;#39;:Expand(field, r-1, c-1)if r &amp;lt; row-1 and c &amp;gt; 0 and field[r&#43;1][c-1] != &amp;#39;*&amp;#39;:Expand(field, r&#43;1, c-1)if r &amp;gt; 0 and c &amp;lt; col-1 and field[r-1][c&#43;1] != &amp;#39;*&amp;#39;:Expand(field, r-1, c&#43;1)def FieldClicker(field):row = len(field)col = len(field[0])for r in range(row):for c in range(col):if field[r][c] == &amp;#39;C&amp;#39;:field[r][c] = str(CountMines(field, r, c))ExpandClick(field, r, c)breakreturn fielddef FieldValidate(field):ret = Truerow = len(field)col = len(field[0])for r in range(row):for c in range(col):if field[r][c] == &amp;#39;.&amp;#39;:ret = Falsebreakreturn retdef FieldRender(row, col, mines):field = []for i in range(row):field.append([&amp;#39;.&amp;#39;] * col)if row == 2:nextRow = 0nextCol = 0while mines:field[nextRow][nextCol] = &amp;#39;*&amp;#39;nextRow = nextRow &#43; 1if nextRow == row:nextRow = 0nextCol = nextCol &#43; 1mines = mines - 1field[0][col-1] = &amp;#39;C&amp;#39;elif col == 2:nextRow = 0nextCol = 0while mines:field[nextRow][nextCol] = &amp;#39;*&amp;#39;nextCol = nextCol &#43; 1if nextCol == col:nextRow = nextRow &#43; 1nextCol = 0mines = mines - 1field[row-1][0] = &amp;#39;C&amp;#39;elif row * col - mines &amp;lt; 3:nextRow = row - 1nextCol = 0while mines:field[nextRow][nextCol] = &amp;#39;*&amp;#39;nextCol = nextCol &#43; 1if nextCol == col:nextRow = nextRow - 1nextCol = 0mines = mines - 1field[0][col-1] = &amp;#39;C&amp;#39;else:for r in range(len(field)):for c in range(len(field[0])):field[r][c] = &amp;#39;*&amp;#39;if row * col - mines &amp;gt;= 9 and row &amp;gt;= 3 and col &amp;gt;= 3:empties = row * col - minesnextRow = 0nextCol = 0while empties:return fielddef Mine(row, col, mines):if row * col - mines == 2 and row &amp;gt; 1 and col &amp;gt; 1:return &amp;#39;Impossible!&amp;#39;if row * col - mines == 3:return &amp;#39;Impossible!&amp;#39;elif row * col - mines == 5:return &amp;#39;Impossible!&amp;#39;elif row * col - mines == 7:return &amp;#39;Impossible!&amp;#39;else:return FieldToString(FieldRender(row, col, mines))f = open(sys.argv[1])total = int(f.readline())for case in range(1, total &#43; 1):field = [int(i) for i in f.readline().split()]print &amp;#39;Case #&amp;#39; &#43; str(case) &#43; &amp;#39;: &amp;#39; &#43; Mine(field[0], field[1], field[2])#############################################################################3 def FieldRenderWrong(row, col, mines):field = []for i in range(row):field.append([&amp;#39;.&amp;#39;] * col)def GetNextRow(field, clickRow, clickCol):row = len(field)col = len(field[0])nextRow = 0nextCol = 0rowDist = 0colDist = 0for r in range(row):for c in range(col):if field[r][c] == &amp;#39;.&amp;#39;:rDist = abs(r - clickRow)cDist = abs(c - clickCol)totDist = rDist &#43; cDistcurrTotDist = rowDist &#43; colDistif totDist &amp;gt; currTotDist:nextRow = rrowDist = rDistnextCol = ccolDist = cDistelse:rowCount = 0for r2 in range(row):if field[r2][c] == &amp;#39;*&amp;#39;:rowCount = rowCount &#43; 1colCount = 0for c2 in range(col):if field[r][c2] == &amp;#39;*&amp;#39;:colCount = colCount &#43; 1lastRow = rowCount == row - 1lastCol = colCount == col - 1if lastRow or lastCol:nextRow = rrowDist = rDistnextCol = ccolDist = cDistreturn nextRow, nextColclickRow = 0clickCol = col-1field[clickRow][clickCol] = &amp;#39;C&amp;#39;nextRow, nextCol = GetNextRow(field, clickRow, clickCol)while mines:field[nextRow][nextCol] = &amp;#39;*&amp;#39;nextRow, nextCol = GetNextRow(field, clickRow, clickCol)mines = mines - 1return fieldNão, eu não usei o Google para descobrir a lógica por trás do problema. Vai que os caras ficam monitorando quem fica fazendo pesquisas. E, não, tampouco usei o Bing. Não sou masoquista a esse ponto.
PS: Bom, estou na próxima fase. Veremos o que o futuro nos espera. Esse programador foi fisgado pelo campeonato de pastéis.
</description>
</item>

     
        <item>
  <title>Houaiss para Babylon em Python!</title>
  <link>http://www.caloni.com.br/houaiss-para-babylon-em-python/</link>
  <pubDate>2014-02-27</pubDate>
  
  <guid>http://www.caloni.com.br/houaiss-para-babylon-em-python/</guid>
  <description>O Fabio Montefuscolo expandiu mais ainda o acesso do conversor Houaiss para Babylon implementando uma versão em Python, uma linguagem que estou aprendendo a adorar. Tudo é mais simples, rápido e direto em Python, e o código que ele escreveu utiliza todo esse potencial:
#!/usr/bin/python2 # -*- coding: utf-8 -*- # # Coloque esse script na pasta com os arquivos dhx. # O resultado estarÃ¡ em iso-8859-1 # # # Segui o tutorial em http://www.caloni.com.br/conversor-de-houaiss-para-babylon-parte-1 # import osfiles = os.listdir(&amp;#39;.&amp;#39;)for arq in files:if not arq.endswith(&amp;#39;dhx&amp;#39;):continueprint &amp;#39;Abrindo &amp;#34;%s&amp;#34;&amp;#39; % arqorigin = open(arq, &amp;#39;r&amp;#39;)target = open(&amp;#39;%s.txt&amp;#39; % arq, &amp;#39;w&#43;&amp;#39;)char = origin.read(1)while char:byte = ord(char) &#43; 0x0Bnew_char = chr(byte % 256)target.write(new_char)char = origin.read(1)origin.close()target.close()</description>
</item>

     
        <item>
  <title>remove_if até remove, só que diferente</title>
  <link>http://www.caloni.com.br/remove_if-ate-remove-so-que-diferente/</link>
  <pubDate>2014-01-21</pubDate>
  
  <guid>http://www.caloni.com.br/remove_if-ate-remove-so-que-diferente/</guid>
  <description>A surpresa de hoje foi descobrir (vejam só) que o remove_if, como todo algoritmo da STL, deve ser olhado de perto antes de usado. Nesse caso em específico porque, apesar do nome, a função NÃO remove elementos, mas os sobrescreve.
Imagine uma função que usa remove_if para remover todas as idades de potenciais lolitas:
void RemoveIfLolita(vector&amp;lt;int&amp;gt;&amp;amp; ages){remove_if(ages.begin(), ages.end(), [&amp;amp;](int age) { return age &amp;lt; 18; } );}Ou até sua contraparte usando um array C:
void RemoveIfLolita(int* ages, int size){remove_if(ages, ages &#43; size, [&amp;amp;](int age) { return age &amp;lt; 18; } );}Um uso trivial pode não cuspir um resultado trivial, ou seja, os elementos não serão removidos como se espera:
#include &amp;lt;algorithm&amp;gt;#include &amp;lt;iostream&amp;gt;#include &amp;lt;vector&amp;gt;using namespace std;void RemoveIfLolita(int* ages, int size){remove_if(ages, ages &#43; size, [&amp;amp;](int age) { return age &amp;lt; 18; } );}void RemoveIfLolita(vector&amp;lt;int&amp;gt;&amp;amp; ages){remove_if(ages.begin(), ages.end(), [&amp;amp;](int age) { return age &amp;lt; 18; } );}int main(){vector&amp;lt;int&amp;gt; ages;ages.push_back(10);ages.push_back(21);ages.push_back(66);ages.push_back(18);ages.push_back(16);ages.push_back(15);ages.push_back(8);ages.push_back(24);ages.push_back(12);ages.push_back(20);ages.push_back(13);RemoveIfLolita(ages);cout &amp;lt;&amp;lt; &amp;#34;Vector (&amp;#34; &amp;lt;&amp;lt; ages.size() &amp;lt;&amp;lt; &amp;#34;):\n&amp;#34;;for_each(ages.begin(), ages.end(), [&amp;amp;](int age) { cout &amp;lt;&amp;lt; age &amp;lt;&amp;lt; endl; });int newAges[] = { 10, 21, 66, 18, 16, 15, 8, 24, 12, 20, 13, 13 };const int newAgesSz = (int) ( sizeof(newAges) / sizeof(int) );RemoveIfLolita(newAges, newAgesSz);cout &amp;lt;&amp;lt; &amp;#34;\n\nArray (&amp;#34; &amp;lt;&amp;lt; newAgesSz &amp;lt;&amp;lt; &amp;#34;):\n&amp;#34;;for_each(newAges, newAges &#43; newAgesSz, [&amp;amp;] (int age) { cout &amp;lt;&amp;lt; age &amp;lt;&amp;lt; endl; } );}
Isso ocorre porque o comportamento do remove_if é copiar todos os elementos que retornem false (não remova) e pular elementos que retornem true (remova). No entanto, o tamanho do contêiner, e consequentemente seu ponteiro end(), permanecem o mesmo.

De acordo com o saite cplusplus.com, o algoritmo STL é previsível, simples, e por isso mesmo sujeito a otimizações do compilador:
template &amp;lt;class ForwardIterator, class UnaryPredicate&amp;gt;ForwardIterator remove_if (ForwardIterator first, ForwardIterator last,UnaryPredicate pred){ForwardIterator result = first;while (first!=last) {if (!pred(*first)) {*result = *first;&#43;&#43;result;}&#43;&#43;first;}return result;}Para obtermos qual seria o &amp;quot;novo end()&amp;quot;, precisamos obter esse valor do retorno de remove_if. Com base nisso, podemos alterar o tamanho do contêiner ajustado:
#include &amp;lt;algorithm&amp;gt;#include &amp;lt;iostream&amp;gt;#include &amp;lt;vector&amp;gt;using namespace std;int RemoveIfLolita(int* ages, int size){auto newEnd = remove_if(ages, ages &#43; size, [&amp;amp;](int age) { return age &amp;lt; 18; } );return newEnd - ages;}void RemoveIfLolita(vector&amp;lt;int&amp;gt;&amp;amp; ages){auto newEnd = remove_if(ages.begin(), ages.end(), [&amp;amp;](int age) { return age &amp;lt; 18; } );ages.resize(distance(ages.begin(), newEnd));}int main(){vector&amp;lt;int&amp;gt; ages;ages.push_back(10);ages.push_back(21);ages.push_back(66);ages.push_back(18);ages.push_back(16);ages.push_back(15);ages.push_back(8);ages.push_back(24);ages.push_back(12);ages.push_back(20);ages.push_back(13);RemoveIfLolita(ages);cout &amp;lt;&amp;lt; &amp;#34;Vector (&amp;#34; &amp;lt;&amp;lt; ages.size() &amp;lt;&amp;lt; &amp;#34;):\n&amp;#34;;for_each(ages.begin(), ages.end(), [&amp;amp;](int age) { cout &amp;lt;&amp;lt; age &amp;lt;&amp;lt; endl; });int newAges[] = { 10, 21, 66, 18, 16, 15, 8, 24, 12, 20, 13, 13 };int newAgesSz = (int) ( sizeof(newAges) / sizeof(int) );newAgesSz = RemoveIfLolita(newAges, newAgesSz);cout &amp;lt;&amp;lt; &amp;#34;\n\nArray (&amp;#34; &amp;lt;&amp;lt; newAgesSz &amp;lt;&amp;lt; &amp;#34;):\n&amp;#34;;for_each(newAges, newAges &#43; newAgesSz, [&amp;amp;] (int age) { cout &amp;lt;&amp;lt; age &amp;lt;&amp;lt; endl; } );}
Esse C&#43;&#43;... intuitivo como nunca!
</description>
</item>

     
        <item>
  <title>BovespaBacktesting</title>
  <link>http://www.caloni.com.br/bovespabacktesting/</link>
  <pubDate>2014-01-08</pubDate>
  
  <guid>http://www.caloni.com.br/bovespabacktesting/</guid>
  <description>Eu não sou apenas um programador: sou um especulador. Ou, para quem ficou com medo, um investidor. Ficou bonito, agora? Trocando em miúdos, isso quer dizer que muitas vezes aposto na bolsa de valores, aquela onde as pessoas ganham e perdem dinheiro loucamente. Porém, assim como faço com minha carreira de desenvolvedor, não deixo de estudar e aprimorar minhas habilidades. Tirando alguns anos de estudo com livros de finanças, economia e contabilidade, foi com base nisso que eu fiz uma série de scripts que realiza operações de backtesting nos papéis da Bovespa.

Que mané backtesting? Backtesting é uma maneira dos especuladores terem uma noção de quão bom ou ruim é sua estratégia de compra e venda. É uma maneira profissional de se aproximar do mercado caótico das ações. Basicamente um backtesting simula o que o especulador faria na vida real com um histórico razoável de variação de preços das ações que pretende operar. Se esse monte de palavras novas neste blogue está te deixando com medo, recomendo dar uma passada no Senhor Mercado (lá você irá também aprender mais sobre técnicas de backtesting).
Vamos supor que minha ideia de estratégia seja comprar quando o preço de uma determinada ação estiver na metade do seu topo histórico e vender quando ele estiver no dobro do momento da compra. Uma estratégia bem tosca, mas se fizer dinheiro, quem liga para vaidade? Outra estratégia mais refinada usa médias móveis para estabelecer pontos de compra e venda dependendo da tendência do mercado. Qual das duas dá mais dinheiro? Existem duas maneiras de saber: a dolorosa e a indolor. A dolorosa seria sacar uma grana do banco e começar a operar em sua corretora favorita seguindo ambas as estratégias e ver qual te deixou mais rico e qual te levou à falência. A indolor seria baixar o histórico de preços dos papéis que está interessado em usar essas estratégias e rodar uma simulação que opere seguindo ambas as estratégias e descubra qual é a perdedora. Qual você preferiria?
OK, esse assunto já está ficando bem monótono para quem acompanha um blogue de programação. Vamos ao código!
GitHub na veia 
O projeto que mantenho no GitHub possui algumas ideias que gostaria de compartilhar com todos que estão interessados em realizar um backtesting, independente de sua estratégia. A primeira delas seria de onde baixar o histórico de preços de maneira simples e barata. Eu recomendo e uso o software Grafix, que consegue baixar as informações diretamente do saite da Bovespa e realizar os ajustes necessários para montar e exibir as informações. Com base no banco de dados do Grafix é que o BovespaBacktesting (meu projeto) importa as informações que ele precisa. Ele irá importar apenas os códigos que estiverem em uma lista disponível no arquivo data/filterCodes relativo de onde o script estiver rodando. Esse arquivo é apenas texto com um código por linha.
def import_quote_from_jgrafix(dataPath):A partir dessa importação é possível realizar queries com as variações diárias, semanais e mensais dos preços dos ativos conhecidos (a mesma lista de código). A própria lista de ativos conhecidos está disponível através de uma função, tornando a iteração simples e direta.
def load_quote_data(code):def load_week_quote_data(code):def load_month_quote_data(code):def load_known_codes():Com essas informações de preço é possível aplicar qualquer tipo de indicador. O BovespaBackteting possui apenas os mais usuais, mas basta implementar a lógica de tratamento em Python, o que não deve consumir nem muito tempo nem muitos neurônios, pois com o histórico disponível tudo fica mais fácil.
def sma(quote, days = 10):def ema(quote, days = 10):def macd(quote, shortDays = 12, longDays = 26, signalDays = 9):def stop_safeplace(quote, multiplier = 4):def stop_atr(quote, multiplier = 3):As funções-macro calculam trades (operações) a partir de alguns parâmetros definidos no código ou por parâmetros. As versões do BovespaBacktesting foram variando nesse sentido. Ainda não há uma maneira saudável de comparar diversas estratégias, pois o que eu tenho feito basicamente é alterar alguns parâmetros, rodar o backtesting e exportar para um CSV (função já disponível).
def calc_trades(code, trend, signal):def calc_all_trades():def calc_total_trades(equity, risk, b1, bs):def calc_money(trades, equity, risk, deposit, wage):def backtesting_analysis():Já existem algumas firulas caso você esteja pensando em uma estratégia em que seja viável viver de operar, como cálculo de salário e a inclusão de variáveis que levem em conta que parte do dinheiro ganho será usado. Ainda é um código bem tosco, mas funciona e pode ser o ponto de entrada de quem deseja conhecer mais sobre o mercado de ações e como os profissionais conseguem tirar dinheiro deste grande cassino.
</description>
</item>

     
        <item>
  <title>Depuração na nuvem com o novo Visual Studio</title>
  <link>http://www.caloni.com.br/depuracao-na-nuvem/</link>
  <pubDate>2013-04-02</pubDate>
  
  <guid>http://www.caloni.com.br/depuracao-na-nuvem/</guid>
  <description>Uma das novidades do futuro Visual Studio pouco comentada ainda em fóruns por seu caráter sigiloso e ainda em testes (mas que pode facilmente ser observada pela engenharia reversa dos binários do Visual C&#43;&#43;) é a possibilidade de depurar trechos de código &amp;quot;na nuvem&amp;quot;, ou seja, dentro dos gigantescos servidores de clusters de serviços de escalabilidade da Amazon, do Google e, claro, da Microsoft.

Já é conhecido que será possível inserir comentários no código-fonte com o formato @nickname e incluir na listagem de bugs o estilo das #hashtags para que programadores vinculados à sua rede social possam enxergar referências a outros programadores e verificar o Developer TrendTopics, como um #blame-joel-on-software. Porém, o que poucos sabem, é que será também possível depurar as APIs de redes sociais em tempo real. Ou seja, caso seja usado o método Twitter::Tweet(), logo após o retorno da chamada será possível aguardar por uma resposta dos usuários envolvidos:
Twitter::Tweetpush ebpmov ebp, esp000007f9`bd590000 call __internal_tweet000007f9`bd5900ac call _checkesp000007f9`bd5900af ...000007f9`bd5900ff ...000007f9`bd59015f &amp;lt;span style=&amp;quot;color: #ff0000;&amp;quot;&amp;gt;call __internal_wait_for_replies&amp;lt;/span&amp;gt;000007f9`bd59017f pop esp... Ou seja, logo será possível além de perder horas navegando em saites de rede social perder também horas depurando os comentários e respostas das pessoas nessas redes direto do Visual Studio. É a Microsoft pensando nos programadores que gostam de perder tempose envolver com pessoas (ainda que virtuais) e discussões acaloradas sobre tópicos irrelevantes e absurdos (ainda que virtuais).
</description>
</item>

     
        <item>
  <title>GetTickCount não é um gerador de IDs únicos</title>
  <link>http://www.caloni.com.br/gettickcount-nao-e-um-gerador-de-ids-unicos/</link>
  <pubDate>2012-06-25</pubDate>
  
  <guid>http://www.caloni.com.br/gettickcount-nao-e-um-gerador-de-ids-unicos/</guid>
  <description>Muitas vezes uma solução intuitiva não é exatamente o que esperamos que seja quando o código está rodando. Gerar IDs únicos, por exemplo. Se você analisar por 5 minutos pode chegar à conclusão que um simples GetTickCount, que tem resolução de clock boa e que se repete apenas depois de 50 dias pode ser um ótimo facilitador para gerar IDs exclusivos durante o dia.

Porém, nada como código para provar que estamos errados:
#include &amp;lt;windows.h&amp;gt;#include &amp;lt;iostream&amp;gt;#include &amp;lt;list&amp;gt;#include &amp;lt;algorithm&amp;gt;#include &amp;lt;stdlib.h&amp;gt;#include &amp;lt;time.h&amp;gt;using namespace std;list&amp;lt;DWORD&amp;gt; g_ticks;list&amp;lt;LONG&amp;gt; g_increments;DWORD WINAPI Ticks(PVOID){for( int i = 1; i &amp;lt;= 100; &#43;&#43;i ){DWORD tick = GetTickCount();g_ticks.push_back(tick);Sleep(rand() % 20);}return 0;}DWORD WINAPI Increment(PVOID){static LONG st_prevIncrement = 0;for( int i = 1; i &amp;lt;= 100; &#43;&#43;i ){LONG increment = InterlockedIncrement(&amp;amp;st_prevIncrement);g_increments.push_back(increment);Sleep(rand() % 20);}return 0;}int main(){const size_t threadsCount = 20;HANDLE threads[threadsCount];srand((unsigned int) time(0));for( size_t i = 0; i &amp;lt; threadsCount / 2; &#43;&#43;i )threads[i] = CreateThread(NULL, 0, Ticks, NULL, 0, NULL);for( size_t i = threadsCount / 2; i &amp;lt; threadsCount; &#43;&#43;i )threads[i] = CreateThread(NULL, 0, Increment, NULL, 0, NULL);WaitForMultipleObjects(threadsCount, threads, TRUE, INFINITE);for( auto it = g_ticks.begin(); it != g_ticks.end(); &#43;&#43;it ){DWORD tick = *it;size_t tickOccurrence = count(g_ticks.begin(), g_ticks.end(), tick);if( tickOccurrence &amp;gt; 1 ){cout &amp;lt;&amp;lt; &amp;#34;Ocorrencia de tick duplicado!\n&amp;#34;;break;}}for( auto it = g_increments.begin(); it != g_increments.end(); &#43;&#43;it ){DWORD tick = *it;size_t incrementOccurrence = count(g_increments.begin(), g_increments.end(), tick);if( incrementOccurrence &amp;gt; 1 ){cout &amp;lt;&amp;lt; &amp;#34;Ocorrencia de incremento duplicado!\n&amp;#34;;break;}}}O motivo do GetTickCount retornar números iguais remete tanto ao fato que o espaço de tempo entre uma execução e outra pode ser muito pequeno quanto ao fato de várias threads podem ser executadas efetivamente ao mesmo tempo em ambientes de dois ou mais cores.
Já o motivo do InterlockedIncrement funcionar sempre é porque aqui estamos usando uma solução de incremento atômico, ou seja, usamos a mesma base contadora e incrementamos ela em uma operação que não pode ocorrer ao mesmo tempo com outra thread.
O que aprendemos aqui? Que por mais que seja intuitiva uma solução, nunca podemos nos basear nas nossas falhas cabeças. Um computador está aí não apenas para ser mais rápido, mas para ser assertivo em nossas elucubrações. Nesse sentido, é o nosso companheiro vulcaniano.
</description>
</item>

     
        <item>
  <title>Novos Atalhos Aprendidos no Vim</title>
  <link>http://www.caloni.com.br/novos-atalhos-aprendidos-no-vim/</link>
  <pubDate>2012-06-09</pubDate>
  
  <guid>http://www.caloni.com.br/novos-atalhos-aprendidos-no-vim/</guid>
  <description>Sempre é bom reler as referências e tentar melhorar o que já está bom. No momento minha inspiração é o excelente Vim: From Essentials to Mastery, uma coleção de slides bem-humorada que a cada releitura fornece dicas importantes para aprimorar o dia-a-dia com um dos editores mais poderosos do planeta.
A lista abaixo é pessoal e, como disse Bram Moolenar, &amp;quot;You should not try to learn every command an editor offers. That would be a complete waste of time. Most people only need to learn 10 to 20 percent of the commands for their work. But it&#39;s a different set of commands for everybody&amp;quot; (grifo meu).
 &amp;lt;C-W&amp;gt;&amp;lt;C-W&amp;gt; Alterna entre janelas. &amp;lt;C-W&amp;gt;-c Fecha a janela atual. &amp;lt;C-W&amp;gt;-o Fecha todas as janelas menos a atual. :ball Abre todos os buffers em janelas distintas. g &amp;lt;C-G&amp;gt; Conta linhas, palavras, etc, no texto todo ou na seleção atual.  </description>
</item>

     
        <item>
  <title>Problemas comuns no WinDbg e suas soluções</title>
  <link>http://www.caloni.com.br/problemas-comuns-no-windbg-e-suas-solucoes/</link>
  <pubDate>2012-05-27</pubDate>
  
  <guid>http://www.caloni.com.br/problemas-comuns-no-windbg-e-suas-solucoes/</guid>
  <description>Depois de uma agradável manhã e tarde acompanhando o curso de desenvolvimento de drivers do meu amigo Ferdinando voltei para a casa para brincar um pouco mais com o mundo kernel e voltar a encontrar problemas com o WinDbg &amp;amp; Cia que há mais ou menos 1 ano atrás não tinha.
Pesquisando por um problema específico envolvendo PDBs reencontrei o blogue do Ken Johnson, MVP Microsoft e analista por profissão e diversão, é conhecido por suas excelentes contribuições no mundo da depuração de sistema (notadamente WinDbg). Existe um post específico que ele escreveu para economizar tempo com problemas que ocorrem de vez em quando em uma sessão ou outra de depuração, mas nunca paramos tempo o suficiente para resolver.
Além de outros, ele lista alguns que particularmente já aconteceram comigo ou com colegas de depuração:
O WinDbg demora um tempo absurdo para processar o carregamento dos módulos e está usando tempo máximo de processamento em apenas uma CPU.
Isso ocorre porque existem breakpoints ainda não resolvidos. Resolva deixando apenas esses tipos de breakpoints que são absolutamente necessários, pois cada vez que um módulo é carregado o depurador precisa fazer o parser de cada um deles para verificar se ele já consegue resolve-lo.
Às vezes, porém, existe algum lixo nos workspaces carregados por ele que permanecem mesmo depois de apagarmos todos os breakpoints inúteis ou reiniciar o sistema. Em último caso, sempre podemos apagar o workspace do registro, em HKCU\Software\Microsoft\Windbg\Workspaces.
O WinDbg continua demorando décadas para analisar o carregamento, mas agora nem consome tanta CPU assim.
Isso ocorre porque na cadeia de paths para procurar por símbolos existe algum endereço de rede/internet errado que faz com que ele tenha que caminhar em falso diversas vezes. Esse e outros erros de símbolos sempre poderão ser analisados através do universal !sym noisy, que imprime todo tipo de informação útil do que pode dar errado durante um .reload explícito (eu digitei) ou implícito (lazy reload).
O WinDbg continua recusando carregar um símbolo que eu sei que existe e sei que é válido.
Talvez ele exista, mas por algum motivo foi copiado corrompido para o symbol server. Mais uma vez, !sym noisy nele e deve acontecer algum erro de E_PDB_CORRUPT. Nesse caso, apague o PDB culpado e tente de novo.
E, como brinde, um grande aliado da produtividade: como evitar que o WinDbg bloqueie seu PDB enquanto você precisa constantemente recompilar seu driver:
.reload -u modulo
Fonte: Blog do Nynaeve.
</description>
</item>

     
        <item>
  <title>Cronogramas baseados em fatos reais</title>
  <link>http://www.caloni.com.br/cronogramas-baseados-em-fatos-reais/</link>
  <pubDate>2011-06-04</pubDate>
  
  <guid>http://www.caloni.com.br/cronogramas-baseados-em-fatos-reais/</guid>
  <description>Já falei sobre cronogramas por aqui e tudo que disse ainda se aplica. Contudo, comentei brevemente sobre entender seu próprio ritmo, que, instintivamente, sabia ser verdade. Depois que li um pouco mais sobre técnicas XP/Scrum (que nada mais são do que formalizações do que os programadores Agile perceberam no decorrer dos seus projetos) achei uma fórmula simples para transformar o tempo estimado em tempo realista.
Vejamos o texto original (auto-plágio):
Seja honesto consigo mesmo e com seu chefe: você realmente trabalha 8 horas por dia? É lógico que não! E não é nenhuma vergonha admitir isso. Todos nós temos emails para ler e responder, reuniões para presenciar e bloques importantes para acompanhar. Portanto, ignore essa conversa fiada de 8 horas e admita: não se deve contar os dias como se eles tivessem 8 horas.
Qual o valor de um dia, então? Cada um sabe o valor que deve ser decrementado desse valor simbólico de 8 horas, mas esse valor sempre será menor. Não se iluda!
Exatamente. Não se iluda! Isso tem seu reflexo na metodologia Agile. Basicamente quer dizer que você precisa aplicar índices que reflitam a realidade do seu próprio ritmo. Além disso:
É muito simples ilustrar e entender esse conceito com código. Voltando ao caso da função, digamos que você consiga terminar a bendita função em exata uma hora. Você é bom, hein?
Porém, essa função ainda 1) não foi comentada, 2) não foi testada e 3) não foi testada em release.
Logo, essa é uma tarefa em que você termina o mais importante em uma hora... mas não termina tudo. Deve-se sempre considerar a tarefa por completo, pois no final de quinze tarefas vai faltar comentar e testar tudo isso, o que aumentará consideravelmente a imprevisiblidade no seu cronograma.O que, novamente traduzindo, é mais um indicador a ser aplicado sobre seus números.
E o que são seus números?
Basicamente, o que a própria metodologia ensina: meça o esforço necessário para fazer código (mas é pra isso mesmo que somos contratados, não?) como se pudéssemos programar por todo esse tempo sem parar por um momento sequer (mesmo que sejam dezenas de horas). Lógico, aprenda a dividir o esforço em pequenos passos, mas estime o tempo considerando APENAS o esforço de fazer o código.
Pronto? Agora é hora de aplicar os indicadores.
1. Foco Mais uma vez, admita: programadores raramente conseguem manter o foco por muito tempo. São pessoas ao redor te desviando a atenção, o tweet que salta de uma janela ou até mesmo as necessidades orgânicas que todo ser humano tem. São elementos, enfim, que, em conjunto, nunca te possibilitarão ter 100% do foco durante todo o trabalho.
Portanto, criemos um indicador: foco. Ele é um valor entre 0 e 1 e estima a porcentagem de foco que você consegue obter, em média, durante o dia. Por exemplo: eu consigo me focar 70% do dia inteiro em apenas codificar e o resto é perdido em reuniões e e-mails. OK. Esse número é, então, 0,7. Aplique sobre seu total de horas e terá o tempo real para codificar a tarefa:
Levarei 35 horas para codificar todo o processo de autenticação por reconhecimento de face, trabalhando sem parar.
35 / 0.7 = 50 No entanto, como consigo apenas 70% de foco em média, sei que essa tarefa irá levar 50 horas na verdade.
2. Finalização Já temos o tempo para o código ficar pronto, mas... é apenas código. Temos que reescalonar o tempo do projeto inserindo testes, retrabalho, comentários e documentação. Tudo ainda nas mãos do programador, que está ainda &amp;quot;aquecido&amp;quot; e que pode resolver retrabalhos em questões de segundos, se ninguém mais passar nada pra ele.
Mesmo assim,é um indicador importante. Sem ele, a qualidade do serviço final fica muito restrita e sensível a testes de caixa preta, gerando a revolta da equipe de testes.
Vamos supor, então, que, historicamente, essa fase tem sido, digamos, 20% do período de codificação (um chute bem otimista). Agora é fácil dizer o tempo final:
Levarei 50 horas para codificar tudo considerando o quesito foco.
50 * 1,2 = 60 Porém, para poder entregar, preciso dedicar cerca de 20% aos testes, retrabalho e uma documentação mínima. Nesse caso, 60 horas é o prazo de entrega.
Conclusão O número de horas ficou muito maior que o esperado? Não me admira que os projetos geralmente atrasem, então. Por pior que pareça o cálculo final, ele foi construído com base na realidade. E não há nada melhor do que nos basearmos na realidade para estimar seriamente o quanto pode custar à empresa um projeto qualquer.
</description>
</item>

     
        <item>
  <title>Novo branch para projetos do Caloni.com.br</title>
  <link>http://www.caloni.com.br/novo-branch-para-projetos-do-caloni-com-br/</link>
  <pubDate>2011-05-29</pubDate>
  
  <guid>http://www.caloni.com.br/novo-branch-para-projetos-do-caloni-com-br/</guid>
  <description>
Reestruturei meus projetos caseiros e coloquei todos em um branch no repositório do Assembla. A partir dele começarei a reestruturas os códigos de exemplo do saite, o deve facilitar o acesso. Para usuários do Bazaar, como eu, basta puxar o branch usando seu endereço:
bzr get http://subversion.assembla.com/svn/caloni/trunk Para os usuários do Subversion, ou qualquer outro controle de fonte que consiga ler um branch feito em SVN, google for it.
</description>
</item>

     
        <item>
  <title>Bazaar com Subversion</title>
  <link>http://www.caloni.com.br/bazaar-com-subversion/</link>
  <pubDate>2011-03-23</pubDate>
  
  <guid>http://www.caloni.com.br/bazaar-com-subversion/</guid>
  <description>Para pessoas que ficaram viciadas em commits curtos e todo o histórico do fonte na própria máquina, foi uma surpresa descobrir que com o uso do plugin bzr-svn (já incluso no pacote de instalação), consigo ainda utilizar o Bazaar, mesmo que agora esteja trabalhando com um branch do Subversion.
Na verdade, melhor ainda: o bzr-svn baixa o SVN trunk com todo o histórico na máquina local, como se fosse um branch do próprio Bazaar, e permite a criação de branches desconectados para pequenos commits e o merge final para o servidor SVN.
E o melhor de tudo: não há segredo. Tudo que precisa fazer é instalar o Bazaar e fazer um get/co com o endereço do branch SVN que o plugin se vira sozinho para detectar que se trata do Subversion. (Se for um branch protegido, o usuário e senha serão pedidos durante o processo).
C:\Projetos&amp;gt;bzr co http://subversion.assembla.com/svn/caloni/ caloniInitialising Subversion metadata cache in C:\Users\Caloni\AppData\Local\svn-cache\sbrubles.C:\Projetos&amp;gt;cd caloniC:\Projetos\caloni&amp;gt;bzr qlogC:\Projetos\caloni&amp;gt;bzr get . ..\caloni.localBranched 2 revision(s).C:\Projetos\caloni&amp;gt;cd ..\caloni.localC:\Projetos\caloni.local&amp;gt;vim readme.txtC:\Projetos\caloni.local&amp;gt;bzr ci -m &amp;quot;Commit local&amp;quot;Committing to: C:/Projetos/caloni.local/modified readme.txtCommitted revision 3.C:\Projetos\caloni.local&amp;gt;vim readme.txtC:\Projetos\caloni.local&amp;gt;bzr ci -m &amp;quot;Commit local&amp;quot;Committing to: C:/Projetos/caloni.local/modified readme.txtCommitted revision 4.C:\Projetos\caloni.local&amp;gt;vim readme.txtC:\Projetos\caloni.local&amp;gt;bzr ci -m &amp;quot;Commit local&amp;quot;Committing to: C:/Projetos/caloni.local/modified readme.txtCommitted revision 5.C:\Projetos\caloni.local&amp;gt;cd ..\caloniC:\Projetos\caloni&amp;gt;bzr merge ..\caloni.localM readme.txtAll changes applied successfully.C:\Projetos\caloni&amp;gt;bzr stmodified: readme.txtpending merge tips: (use -v to see all merge revisions) Wanderley Caloni 2011-03-23 Commit localC:\Projetos\caloni&amp;gt;bzr ci -m &amp;quot;Commit pro servidor&amp;quot;Committing to: http://subversion.assembla.com/svn/calonimodified readme.txtHTTP subversion.assembla.com username: caloni&amp;lt;http://subversion.assembla.com:80&amp;gt; Restricted Area caloni password:Committed revision 3.C:\Projetos\caloni&amp;gt;bzr qlog 
</description>
</item>

     
        <item>
  <title>Mudança</title>
  <link>http://www.caloni.com.br/mudanca/</link>
  <pubDate>2011-02-07</pubDate>
  
  <guid>http://www.caloni.com.br/mudanca/</guid>
  <description>Fecha uma porta... Desde que comecei a programar profissionalmente, lá por volta de 2001, sempre estive envolvido com uma ou duas empresas de Segurança da Informação, na época uma promissora carreira, com direito a hacking, engenharia reversa e outras diversões. Até programar por programar valia!
O tempo passou, completei uma década na área, e agora está realmente na hora de tentar programar coisa nova. Dessa forma, acompanhando minha própria tendência de investidor pessoa física na bolsa de valores, resolvi dar um novo salto em minhas aspirações nesse campo igualmente fascinante e apostar meu tempo de programação também no setor financeiro, onde C/C&#43;&#43; também corre na veia.
Aprendi muito nesse tempo todo com alguns amigos entusiastas (até demais) e programei muito código que gostaria que não tivesse meu nome nos comentários. Mas a vida (e o código) é assim: melhora com os erros.
... e abre outra! A empresa que estou deixando agora está à caça de uma pessoa para se tornar minha versão 2.0. Dessa vez não é uma busca por talentos inexperientes, de forma que estaremos aceitando apenas pessoas que já se f... com larga experiência em programação Windows.
Segue a descrição da vaga, feita por mim mesmo, sozinho. Interessados: sem timidez, please.
 Analista Programador C&#43;&#43;  Conhecimentos avançados em Windows: serviços, DLLs, (drivers desejável). ** Programação**: libc, Win32 API, (STL/Boost e Assembly 8086 desejáveis). ** Ferramentas: **Visual Studio 2003, Bazaar, VMWare, (WinDbg desejável). ** Funções: **codificação, análise, reunião técnica, refatoração, (UML desejável). ** Perfil: **vontade de aprender, pró-atividade, comunicação.</description>
</item>

     
        <item>
  <title>Trabalhando em múltiplos ambientes</title>
  <link>http://www.caloni.com.br/trabalhando-em-multiplos-ambientes/</link>
  <pubDate>2010-12-27</pubDate>
  
  <guid>http://www.caloni.com.br/trabalhando-em-multiplos-ambientes/</guid>
  <description>Existem diversas maneiras de se trabalhar com o Bazaar. Eu já havia definido como fazer na máquina de desenvolvedor para modificar o mesmo código-fonte em projetos paralelos, onde basicamente tenho um branch principal conectado no servidor (assim todo commit vai pra lá) e crio branches paralelos e desconectados para fazer quantos commits eu tenho vontade durante o desenvolvimento. Após todas as mudanças e testes básicos, atualizo o branch principal (com mudanças dos meus colegas) e faço o merge com o branch paralelo onde fiz todas as mudanças. Antes de subir com o commit final, ainda realizo um build de teste local, se necessário.
Nos casos em que eu trabalho em casa (ou em outro ambiente), posso fazer basicamente a mesma coisa, só que meu branch paralelo é copiado para outra máquina:
C:\&amp;gt;cd \Src\projeto-principalC:\Src\projeto-principal&amp;gt;bzr get . ..\projeto-principal.TravamentoServico.MeuNotePessoalBranched 950 revision(s). Geralmente o que faço depois é compactar a pasta gerada (se desejar, use uma senha forte nesse passo), fazer uma cópia para um PenDrive e descompactar na máquina que irei trabalhar.
C:\Src\projeto-principal.TravamentoServico&amp;gt;hack hack hackC:\Src\projeto-principal.TravamentoServico&amp;gt;bzr ci -m &amp;quot;Uma mudancinha inicial&amp;quot;Committing to: C:/Src/projeto-principal.TravamentoServico/added teste.txtCommitted revision 951.C:\Src\projeto-principal.TravamentoServico&amp;gt;hack hack hackC:\Src\projeto-principal.TravamentoServico&amp;gt;bzr ci -m &amp;quot;Vamos ver se funciona&amp;quot;Committing to: C:/Src/projeto-principal.TravamentoServico/modified teste.txtCommitted revision 952.C:\Src\projeto-principal.TravamentoServico&amp;gt;hack hack hackC:\Src\projeto-principal.TravamentoServico&amp;gt;bzr ci -m &amp;quot;Não funcionou. Mais uma vez.&amp;quot;Committing to: C:/Src/projeto-principal.TravamentoServico/modified teste.txtCommitted revision 953.C:\Src\projeto-principal.TravamentoServico&amp;gt;hack hack hackC:\Src\projeto-principal.TravamentoServico&amp;gt;bzr ci -m &amp;quot;Desconfio de uma coisa...&amp;quot;Committing to: C:/Src/projeto-principal.TravamentoServico/modified teste.txtCommitted revision 954.C:\Src\projeto-principal.TravamentoServico&amp;gt;hack hack hackC:\Src\projeto-principal.TravamentoServico&amp;gt;bzr ci -m &amp;quot;Corrigido travamento.&amp;quot;Committing to: C:/Src/projeto-principal.TravamentoServico/modified teste.txtCommitted revision 955.C:\Src\projeto-principal.TravamentoServico&amp;gt;doc doc docC:\Src\projeto-principal.TravamentoServico&amp;gt;bzr ci -m &amp;quot;Comentando e documentando solucao.&amp;quot;Committing to: C:/Src/projeto-principal.TravamentoServico/modified teste.txtCommitted revision 956. Terminado o trabalho naquela máquina, geralmente gero um branch novo (para limpar o diretório) e recompacto a solução, copio para o Pendrive, e descompacto na máquina da empresa. O resto do caminho é como se eu tivesse feito as modificações na própria máquina:

</description>
</item>

     
        <item>
  <title>Suporte técnico</title>
  <link>http://www.caloni.com.br/suporte-tecnico/</link>
  <pubDate>2010-11-05</pubDate>
  
  <guid>http://www.caloni.com.br/suporte-tecnico/</guid>
  <description>Máquina com parte do registro corrompida, notadamente alguma sub-chave de HKEY_CLASSES_ROOT. Resultado: ao rodar um script que abre uma segunda janela e tenta usar seu método focus é exibida a seguinte mensagem:
&amp;quot;- A classe não dá suporte para automação&amp;quot; Abaixo um exemplo simples para ter uma ideia em JS:
var win = window.open(&#39;minha_url_do_coracao.htm&#39;);win.focus(); // aqui dá o erro A primeira coisa que se faz nesse caso é pesquisar no Google por pessoas que já tiveram esse problema. A maioria dizia ser necessária registrar novamente as DLLs do navegador/shell, coisa que fizemos à exaustão e não resolveu o problema. Também imaginamos haver relação com a versão da SDocVw.dll que estava alocada na lista de assemblies .NET cacheados, o chamado GAC. Ou seja, já estávamos viajando geral.
No meio dos procedimentos batidos que todos fazem a lista abaixo resume bem:
  Restaurar instalação do Internet Explorer.
  Atualizar Internet Explorer.
  Rodar Windows Update.
  Registrar novamente DLLs do Shell (ShDocVw.dll, etc).
  No meio das análises não-tão-batidas que foram feitas estavam os seguintes itens:
  Log de operações pelo Process Monitor da abertura do browser até o erro.
  Dump gerado no momento da mensagem de erro.
  Comparação de registro exportado com máquina sadia.
  Nada parecia resolver o impasse, a não ser reinstalar o Windows, coisa que o cliente não queria. Dessa forma, A última tentativa não-enlouquecida de tentar descobrir a causa do problema foi usar uma VM e importar o registro exportado da máquina defeituosa.
Que não revelou a anomalia.
Partindo disso, imaginei que o que ocorria era que havia algo faltando no registro danificado, e não algo a mais. Dessa forma, realizei a seguinte operação:
  Exportei o registro da máquina saudável.
  Transformei a exportação em exclusão total das chaves.
  Importei ambos os registros no esquema &amp;quot;apaga tudo cria tudo de novo&amp;quot;.
  Problema reproduzido.
Agora restava saber qual chave exata estava faltando e o que isso impactava no comportamento do browser.
O registro exportado da VM possuía cerca de 30.000 linhas com chaves e sub-chaves. Se fosse feita a importação por partes, dividindo-se sempre pela metade e testando o acesso à página todas as vezes, teríamos no máximo que fazer uns 15 testes.
Foi esse o procedimento seguido:
  Criar snapshot com o estado inalterado do registro.
  Apagar metade do registro original exportado (máquina real).
  Arrastar metade do registro original e importá-lo (apaga chaves).
  Importar registro danificado do cliente (já na VM).
  Se deu erro de novo, repassar os passos 2 a 3.
  Se não deu erro, testar os passos 3 e 4 com a outra metade.
  Essa série de passos foi reproduzida em menos de uma hora até chegarmos a apenas uma linha no registro:
[-HKEY_CLASSES_ROOT\CLSID\{C5598E60-B307-11D1-B27D-006008C3FBFB}] Que se revelou pertencer à DLL dispex.dll:
Pesquisando soluções de restauração achei esse KB que explica que existe um aplicativo chamado McRepair que teoricamente conserta a bagunça.
Não conserta.
Porém, ao usar o Method 1 (registrar novamente a DLL) o problema foi resolvido. Exportei o registro antes e depois da operação e por algum motivo a máquina do cliente estava com o GUID das interfaces IDispatchEx e IObjectIdentity adulteradas:
Antes: C5598E60-B307-11D1-B27D-006008C3FBFB}Depois: 10E2414A-EC59-49D2-BC51-5ADD2C36FEBC} Realizei o mesmo teste com nossa DLL que gerou o problema inicial e descobri que não houve mudanças nessa parte do registro por conta dela.
Fica assim indefinida a origem do &amp;quot;corrompimento&amp;quot; dessa parte do registro, apesar de localizada.
Esse artigo é pra mostrar que não é só de ifs e elses que vive um programador =)
</description>
</item>

     
        <item>
  <title>Então você ainda não usa controle de fonte?</title>
  <link>http://www.caloni.com.br/entao-voce-ainda-nao-usa-controle-de-fonte/</link>
  <pubDate>2010-11-02</pubDate>
  
  <guid>http://www.caloni.com.br/entao-voce-ainda-nao-usa-controle-de-fonte/</guid>
  <description>Graças aos antigos SCMs, muitos programadores hoje em dia evitam ter que configurar um controle de fonte mínimo para seus projetos. E por um bom motivo: temos que programar e resolver problemas reais no dia-a-dia e não ficar configurando servidores de controle de fonte e lidando com conflitos na calada da noite. Isso vale tanto para o pessoal do Windows e o seu Visual Source Safe (eu que o diga) quanto para o pessoal do Unix/Linux e seu CVS ;aliás, hoje o pesadelo de ambos foi substituído pelo SubVersion: um pesadelo light.
Não há nada de errado nisso. Projetos robustos com uma equipe moderada ¿ 5 a 10 programadores ¿ precisam desse tipo de organização, e tornam a resolução dos problemas do dia-a-dia mais problemática sem esse controle. A questão reside para o programador solitário ou a equipe minúscula ¿ 2 a 4 programadores. Esses geralmente questionam o custo-benefício de terem o trabalho de configurar e manter mais um sistema. Além disso, isso implica em uma mudança de grandes proporções em cada membro da equipe: uma mudança cultural.
Portanto, a primeira decisão que deve ser tomada pelo programador que quer mudar as coisas é instalar um controle de fonte moderno para seus projetos caseiros. Quando digo moderno, digo distribuído.Distribuído porque 1) é possível começar desde já com três comandos simples, 2) quando alguém copia a pasta do projeto está levando todo o histórico junto e 3) pastas duplicadas são branches distintos que podem interagir no futuro.
Os três comandos simples não são nada do outro mundo: criar o repositório, adicionar arquivos e fazer commit.
Tanto faz qual controle você pretende usar. No meu exemplo usarei o Bazaar, que é a ferramenta que uso no dia-a-dia com minha pequena equipe e serve bem para programadores solitários também. Basicamente para ter o Bazzar instalado basta baixá-lo, next next e finish.
Marcar para usar o PATH pode ser uma boa pra quem é fã de linha de comando.
Apesar de existirem firulas gráficas, gosto de usar o Bazaar na linha de comando porque faz você pensar direito antes de fazer commits, mas esteja livre para experimentar a maneira que achar melhor.
Botando a mão na massa Isso vale para qualquer projeto que você esteja trabalhando. Pela linha de comando, navegue até o diretório do projeto. Digite os comandos abaixo seguidos de :
  bzr init
  bzr add
  bzr commit -m &amp;quot;Primeiro commit no controle de fonte&amp;quot;
  Pronto! Você está oficialmente com seu projeto dentro de um controle de fonte.
C:\Users\Caloni\Documents\Projetos&amp;gt;cd MeuProjetoC:\Users\Caloni\Documents\Projetos\MeuProjeto&amp;gt;bzr initCreated a standalone tree (format: 2a)C:\Users\Caloni\Documents\Projetos\MeuProjeto&amp;gt;bzr addadding MeuProjeto.cppadding MeuProjeto.hC:\Users\Caloni\Documents\Projetos\MeuProjeto&amp;gt;bzr commit -m &amp;quot;Primeiro commit no controle de fonte&amp;quot;Committing to: C:/Users/Caloni/Documents/Projetos/MeuProjeto/added MeuProjeto.cppadded MeuProjeto.hCommitted revision 1.C:\Users\Caloni\Documents\Projetos\MeuProjeto&amp;gt; Os passos seguintes seguem o mesmo padrão, exceto o passo 1, que é substituído pelo seu trabalho:
  trabalho
  bzr add
  bzr commit -m &amp;quot;Comentário sobre modificação que fiz&amp;quot;
  C:\Users\Caloni\Documents\Projetos\MeuProjeto&amp;gt;vim MeuProjeto.cppC:\Users\Caloni\Documents\Projetos\MeuProjeto&amp;gt;bzr addC:\Users\Caloni\Documents\Projetos\MeuProjeto&amp;gt;bzr commit -m &amp;quot;Corrigido bug de nao exibir cores&amp;quot;Committing to: C:/Users/Caloni/Documents/Projetos/MeuProjeto/modified MeuProjeto.cppCommitted revision 2. É só isso? Basicamente, sim. É claro que um controle de fonte não se baseia apenas em commits. Existem arquivos a serem ignorados (os obj da vida) e eventualmente algum trabalho paralelo ou com mais programadores. No futuro poderá comparar versões diferentes do código. Porém, apenas seguindo essa simples receita acima você já pode se gabar de ter um controle de fontes confiável em seus projetos. Já estará se aproveitando desse controle no futuro, quando aprender mais sobre ele.
</description>
</item>

     
        <item>
  <title>Três em um</title>
  <link>http://www.caloni.com.br/tres-em-um/</link>
  <pubDate>2010-10-09</pubDate>
  
  <guid>http://www.caloni.com.br/tres-em-um/</guid>
  <description>Que vergonha passar tanto tempo sem postar nada. Parece que não fiz nada que valesse a pena comentar por aqui.
Na verdade, não fiz tanto, mesmo. Muitas mensagens do Outlook, gráficos UML e reuniões de alinhamento depois, sobrou um tempinho pra programar. Aprendi algumas coisas que tinha o desejo de saber há tanto tempo... Agora eu sei, quem diria, criar linques suspensos nas janelas Win32! Que novidade, não? Pois é, isso exige, de acordo com o SDK, algumas artimanhas pra fazer funcionar. Para quem está de Visual Studio 2008/2010 na mão basta seguir os passos seguintes.
Definir que estamos programando para XP ou superior:
#define _WIN32_WINNT 0x0600 Inserir suporte a linques na biblioteca de controles comuns:
INITCOMMONCONTROLSEX icc = { sizeof(icc), ICC_LINK_CLASS }; InitCommonControlsEx(&amp;amp;icc); Usar o CreateWindow com a classe certa, fazer markup html dentro do título e cuidar das mensagens de e no controle:
CreateWindowEx(0, WC_LINK, L&amp;#34;&amp;lt;a href=\&amp;#34;http://www.caloni.com.br\&amp;#34;&amp;gt;This site rocks!&amp;lt;/a&amp;gt;&amp;#34;, WS_VISIBLE | WS_CHILD | WS_TABSTOP, ...);//...case WM_NOTIFY:switch( ((LPNMHDR)lParam)-&amp;gt;code ){case NM_CLICK:case NM_RETURN:{PNMLINK pNMLink = (PNMLINK)lParam;LITEM item = pNMLink-&amp;gt;item;if( (((LPNMHDR)lParam)-&amp;gt;hwndFrom == st_linkHwnd[hWndDlg]) ){// codigo util	}Você que não está fazendo subclassing de janelas existe outra técnica que você pode utilizar: arrastar-e-soltar o controle do seu ToolBox. Qual é a graça?
 Outra coisa que aprendi foi como enviar mensagens ao usuário para impedir que este reinicie a máquina em momentos importantes:
A partir do Vista temos uma nova API para fazer isso. E é muito simples:
BOOL WINAPI ShutdownBlockReasonCreate( __in HWND hWnd, __in LPCWSTR pwszReason ); BOOL WINAPI ShutdownBlockReasonDestroy( __in HWND hWnd ); Quando ao receber a famigerada WM_QUERYENDSESSION, basta retornar FALSE. O Windows faz o resto.
_PS: E com uma ajudinha do Windows Internals ainda fiquei sabendo que dá pra se colocar na frente da fila para receber essa mensagem. _
</description>
</item>

     
        <item>
  <title>Gerando dumps automatizados</title>
  <link>http://www.caloni.com.br/gerando-dumps-automatizados/</link>
  <pubDate>2010-08-26</pubDate>
  
  <guid>http://www.caloni.com.br/gerando-dumps-automatizados/</guid>
  <description>Agora que a temporada das telas azuis passou estou às voltas com o nosso sistema de detecção de crashes, além de alguns dumps e logs pra relaxar de vez em quando.
Fiquei impressionado com a simplicidade com que podemos capturar qualquer exceção que ocorra em um programa, independente da thread, e gravar um minidump com o contexto exato em que o problema ocorreu. O uso da função API SetUnhandledExceptionFilter aliado com a já citada na palestra MiniDumpWriteDump pode agilizar muito a correção de crashes triviais como Access Violation.
A mágica é tão bela que resolvi gravar um vídeo do que ocorreu quando compilei e testei o programa abaixo. Note que o tamanho do arquivo de dump ficou em torno dos 10 KB, ridículos nessa era de barateamento de espaço.
/** @file OnCrash@brief Exemplo de como capturar exceções no seu programa.@author Wanderley Caloni &amp;lt;wanderley@caloni.com.br&amp;gt;@date 2010-08*/#include &amp;lt;windows.h&amp;gt;#include &amp;lt;dbghelp.h&amp;gt;#include &amp;lt;time.h&amp;gt;#pragma comment(lib, &amp;#34;dbghelp.lib&amp;#34;)LONG WINAPI CrashHandler(_EXCEPTION_POINTERS* ExceptionInfo){LONG ret = EXCEPTION_CONTINUE_SEARCH;MINIDUMP_EXCEPTION_INFORMATION minidumpInfo;minidumpInfo.ClientPointers = FALSE;minidumpInfo.ThreadId = GetCurrentThreadId();minidumpInfo.ExceptionPointers = ExceptionInfo;HANDLE hFile = CreateFile(&amp;#34;OnCrash.dmp&amp;#34;, GENERIC_WRITE, 0, NULL, CREATE_ALWAYS, 0, NULL);if( hFile != INVALID_HANDLE_VALUE ){MINIDUMP_TYPE dumpType = MiniDumpNormal;if( MiniDumpWriteDump(GetCurrentProcess(), GetCurrentProcessId(), hFile, MiniDumpNormal, &amp;amp;minidumpInfo, NULL, NULL) ){ret = EXCEPTION_EXECUTE_HANDLER;}CloseHandle(hFile);}return ret;}DWORD WINAPI CrashThread(PVOID){int* x = 0;*x = 13;return 0;}int main(){SetUnhandledExceptionFilter(CrashHandler);HANDLE crashThread = CreateThread(NULL, 0, CrashThread, NULL, 0, NULL);WaitForSingleObject(crashThread, INFINITE);}
Espero com isso aliviar a carga pesada de A.V.s que sempre aparece quando menos se espera. Cuidar de toneladas de código legado exige algumas pitadas de automatização nos lugares certos. Como já dizia meu primeiro chefe: se a mente não pensa...
</description>
</item>

     
        <item>
  <title>Evento C&#43;&#43;</title>
  <link>http://www.caloni.com.br/evento-c/</link>
  <pubDate>2010-08-16</pubDate>
  
  <guid>http://www.caloni.com.br/evento-c/</guid>
  <description>Esse fim-de-semana houve o tão falado evento C&#43;&#43;, com a presença de dezenas de pessoas, algo que eu sinceramente não esperava. O bom desse evento foi saber que existem tantas pessoas interessadas em manter contato com quem gosta e pratica essa linguagem e também em saber que o nível técnico das palestras estão de alto para avançado.
Infelizmente em nenhuma das duas palestras práticas (minha e do Fernando) houve participação interativa, e ninguém que eu saiba abriu meu pacote-surpresa com os dumps a serem analisados. De qualquer forma, minha palestra ficou bagunçada pelo excesso de conteúdo e falta de tempo, o que me fez dar boas risadas ao ouvir no twitter que minha palestra foi mais um brainstorm. A intenção não era essa, claro, mas meu claro despreparo para muito conteúdo gerou essa impressão. Espero que do pouco que consegui explicar alguém tenha achado utilidade.
E, pelo jeito, futuramente irei aplicar essa mesma metodologia brainstorm em um videocast, que ainda não decidi como irei preparar. A ideia é analisarmos alguns dumps em conjunto e, para os que acompanharem online, a interatividade de perguntas &amp;amp; respostas.
Mas enquanto isso não acontece vamos dar uma olhada no que tínhamos no pacote-surpresa.
1. NotMyFaultEither.exe.mdmp - Stack Trash 0:000&amp;gt; kvChildEBP RetAddr Args to Child0012b200 7c90df3c 7c8025db 000000e8 00000000 ntdll!KiFastSystemCallRet0012b204 7c8025db 000000e8 00000000 0012b238 ntdll!NtWaitForSingleObject&#43;0xc0012b268 7c802542 000000e8 000493e0 00000000 kernel32!WaitForSingleObjectEx&#43;0xa80012b27c 6998ada6 000000e8 000493e0 003a0043 kernel32!WaitForSingleObject&#43;0x120012bd70 6998aff1 000000c4 00000568 000000d0 faultrep!InternalGenerateMinidumpEx&#43;0x3350012bd9c 6998b50a 000000c4 00000568 0012c698 faultrep!InternalGenerateMinidump&#43;0x750012c678 69986652 000000c4 00000568 0012c698 faultrep!InternalGenFullAndTriageMinidumps&#43;0x8a0012dea0 69987d3d 0012df18 0015c300 00000000 faultrep!ReportFaultDWM&#43;0x4e50012e398 699882d8 0040a1dc 0012f1e0 ffffffff faultrep!StartManifestReportImmediate&#43;0x2680012f404 7c8643c6 0040a1dc ffffffff 0012fc24 faultrep!ReportFault&#43;0x55aUnable to load image C:\Documents and Settings\Administrador\Desktop\NotMyFaultEither.exe*** WARNING: Unable to verify timestamp for NotMyFaultEither.exe*** ERROR: Module load completed but symbols could not be loaded for NotMyFaultEither.exe0012f678 004018aa 0040a1dc e280eec4 1d7f113b kernel32!UnhandledExceptionFilter&#43;0x55bWARNING: Stack unwind information not available. Following frames may be wrong.0012f9ac 00401357 &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;dededede dededede dededede&amp;lt;/font&amp;gt; NotMyFaultEither&#43;0x18aa0012fbe8 &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;dededede dededede dededede dededede&amp;lt;/font&amp;gt; NotMyFaultEither&#43;0x13570012fbec &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;dededede dededede dededede dededede&amp;lt;/font&amp;gt; 0xdededede0012fbf4 &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;dededede dededede dededede dededede&amp;lt;/font&amp;gt; 0xdededede... Como foi visto na palestra, uma pilha nesse estado demonstra claramente alguma variável que estourou e corrompeu o resto da pilha de chamadas. Na hora de voltar para a função chamadora, o endereço usado foi o endereço reescrito por lixo, e daí temos o &amp;quot;crash-pattern&amp;quot; Stack Trash.
2. NotMyFaultEither.mdmp - Dead Lock 0:000&amp;gt; kvChildEBP RetAddr Args to Child0012f900 7c90df3c 7c8025db 0000007c 00000000 ntdll!KiFastSystemCallRet0012f904 7c8025db &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;0000007c &amp;lt;/font&amp;gt;00000000 00000000 ntdll!NtWaitForSingleObject&#43;0xc0012f968 7c802542 0000007c ffffffff 00000000 kernel32!WaitForSingleObjectEx&#43;0xa80012f97c 00401176 0000007c ffffffff 00000111 kernel32!WaitForSingleObject&#43;0x12WARNING: Stack unwind information not available. Following frames may be wrong.0012f9c0 7c910202 00000002 001506e8 00150000 NotMyFaultEither&#43;0x11760012f9f8 7e3746d3 01010050 00000000 00000000 ntdll!RtlpAllocateFromHeapLookaside&#43;0x420012fa5c 7e382672 01010050 01100068 7e3a4716 user32!DrawStateW&#43;0x5cd0012fae8 7e382c75 001563ac 01010050 00000003 user32!xxxBNDrawText&#43;0x3130012fb20 002d0036 00000000 00000020 0012fb3c user32!xxxDrawButton&#43;0xbb0012fb30 7e3799d8 0000800a 0012fbc8 7e375ba2 0x2d00360012fb3c 7e375ba2 0000800a 002d0036 fffffffc user32!NotifyWinEvent&#43;0xd0012fbc8 00000000 002d0036 004011b0 dcbaabcd user32!ButtonWndProcWorker&#43;0x79b0:000&amp;gt; !handle 0000007cHandle &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;0000007c&amp;lt;/font&amp;gt;Type &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;Thread&amp;lt;/font&amp;gt;0:000&amp;gt; ~* kv. 0 Id: 5e4.&amp;lt;font color=&amp;quot;#008000&amp;quot;&amp;gt;39c &amp;lt;/font&amp;gt;Suspend: 0 Teb: 7ffdd000 UnfrozenChildEBP RetAddr Args to Child0012f900 7c90df3c 7c8025db 0000007c 00000000 ntdll!KiFastSystemCallRet0012f904 7c8025db 0000007c 00000000 00000000 ntdll!NtWaitForSingleObject&#43;0xc0012f968 7c802542 0000007c ffffffff 00000000 kernel32!WaitForSingleObjectEx&#43;0xa80012f97c 00401176 0000007c ffffffff 00000111 kernel32!WaitForSingleObject&#43;0x12WARNING: Stack unwind information not available. Following frames may be wrong.0012f9c0 7c910202 00000002 001506e8 00150000 NotMyFaultEither&#43;0x11760012f9f8 7e3746d3 01010050 00000000 00000000 ntdll!RtlpAllocateFromHeapLookaside&#43;0x420012fa5c 7e382672 01010050 01100068 7e3a4716 user32!DrawStateW&#43;0x5cd0012fae8 7e382c75 001563ac 01010050 00000003 user32!xxxBNDrawText&#43;0x3130012fb20 002d0036 00000000 00000020 0012fb3c user32!xxxDrawButton&#43;0xbb0012fb30 7e3799d8 0000800a 0012fbc8 7e375ba2 0x2d00360012fb3c 7e375ba2 0000800a 002d0036 fffffffc user32!NotifyWinEvent&#43;0xd0012fbc8 00000000 002d0036 004011b0 dcbaabcd user32!ButtonWndProcWorker&#43;0x79b1 Id: 5e4.6a4 Suspend: 0 Teb: 7ffdc000 UnfrozenChildEBP RetAddr Args to Child00b8ff10 7c90df3c 7c91b22b 00000080 00000000 ntdll!KiFastSystemCallRet00b8ff14 7c91b22b 00000080 00000000 00000000 ntdll!NtWaitForSingleObject&#43;0xc00b8ff9c 7c901046 0040e940 004010e0 0040e940 ntdll!RtlpWaitForCriticalSection&#43;0x13200b8ffa4 004010e0 &amp;lt;font color=&amp;quot;#0000ff&amp;quot;&amp;gt;0040e940 &amp;lt;/font&amp;gt;00000000 00000000 ntdll!RtlEnterCriticalSection&#43;0x46WARNING: Stack unwind information not available. Following frames may be wrong.00b8ffec 00000000 004010c0 0012f99c 00000000 NotMyFaultEither&#43;0x10e00:000&amp;gt; !cs &amp;lt;font color=&amp;quot;#0000ff&amp;quot;&amp;gt;0040e940&amp;lt;/font&amp;gt;-----------------------------------------Critical section = 0x0040e940 (NotMyFaultEither&#43;0xE940)DebugInfo = 0x00154498&amp;lt;font color=&amp;quot;#0000ff&amp;quot;&amp;gt;LOCKED&amp;lt;/font&amp;gt;LockCount = 0x1OwningThread = &amp;lt;font color=&amp;quot;#008000&amp;quot;&amp;gt;0x0000039c&amp;lt;/font&amp;gt;RecursionCount = 0x1LockSemaphore = 0x80SpinCount = 0x00000000 A thread ativa no momento do dump aguardava por outra thread. Listando todas as threads do processo temos a primeira e a segunda, que tenta entrar em um critical section. Quando vemos que aquele CS estava sendo bloqueado pela primeira thread vemos claramente se tratar de um dead lock.
3. NotMyFaultEither_100808_172407.dmp - Access Violation 0:000&amp;gt; kvChildEBP RetAddr Args to ChildWARNING: Stack unwind information not available. Following frames may be wrong.0012f9cc 7e37f916 01010052 005a0049 0012f9f4 NotMyFaultEither&#43;0x10a30012fa58 7e37f991 01010052 00000043 01100076 user32!ClientFrame&#43;0xe00012fa7c 7e382909 01010052 0012fa98 00000000 user32!DrawFocusRect&#43;0x400012fae8 7e382c75 00156304 01010052 00000003 user32!xxxBNDrawText&#43;0x3e90012fb20 001100a0 00000000 00000020 0012fb3c user32!xxxDrawButton&#43;0xbb0012fb30 7e3799d8 0000800a 0012fbc8 7e375ba2 0x1100a00012fb3c 7e375ba2 0000800a 001100a0 fffffffc user32!NotifyWinEvent&#43;0xd0012fbc8 00000000 001100a0 004010f0 dcbaabcd user32!ButtonWndProcWorker&#43;0x79b0:000&amp;gt; &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;? eax&#43;edx&amp;lt;/font&amp;gt;Evaluate expression: 0 = &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;00000000&amp;lt;/font&amp;gt;0:000&amp;gt; uNotMyFaultEither&#43;0x10a3:004010a3 66890c02 mov word ptr [&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;edx&#43;eax&amp;lt;/font&amp;gt;],cx004010a7 83c002 add eax,2004010aa 6685c9 test cx,cx O disassemble da instrução inválida tenta escrever claramente em cima do endereço zerado (edx &#43; eax). Dessa forma fica fácil saber que esse tipo de escrita não é permitido, constituindo nosso famosíssimo AV.
4. NotMyFaultEither_100808_175404.dmp - Exception not Handled eax=00000000 ebx=00000111 ecx=7c91003d edx=00010000 esi=00330120 edi=7e374dfaeip=7c90120e esp=0012f9a0 ebp=00000001 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246ntdll!DbgBreakPoint:&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;7c90120e cc int 3&amp;lt;/font&amp;gt;0:000&amp;gt; kvChildEBP RetAddr Args to Child0012f99c 004011ec 0012fc24 004010d0 0012fbe8 &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;ntdll!DbgBreakPoint&amp;lt;/font&amp;gt; (FPO: [0,0,0])WARNING: Stack unwind information not available. Following frames may be wrong.0012f9cc 7e37f916 01010054 005a0049 0012f9f4 NotMyFaultEither&#43;0x11ec0012fa58 7e37f991 01010054 00000043 01100076 user32!ClientFrame&#43;0xe0 Esse foi meio de brinde. Uma exceção de breakpoint (int 3, ntdll!DbgBreakPoint) lançada sem um depurador atachado implica em derrubamento do processo, pois é uma exceção como outra qualquer. O programador deve ter esquecido um DebugBreak ou algo que o valha no código de produção, que acabou sendo executado.
5. ntdll_cliente.dll - Importação de símbolos  Essa foi a DLL encontrada no cliente quando ocorreu o problema relatado na imagem, também em anexo. Isso foi demonstrado na palestra com a ajuda do meu script que carrega DLLs, além de um pouco de sorte. Podemos analisar esse caso com mais calma em outro artigo. Acho que já falei demais por aqui.
Slides  Download dos slides usados na palestra.  </description>
</item>

     
        <item>
  <title>Breakpoints promíscuos</title>
  <link>http://www.caloni.com.br/breakpoints-promiscuos/</link>
  <pubDate>2010-07-26</pubDate>
  
  <guid>http://www.caloni.com.br/breakpoints-promiscuos/</guid>
  <description>Ontem falei sobre como &amp;quot;brincar&amp;quot; com os breakpoints promíscuos, ou seja, aqueles que topam qualquer processo. Isso
é muito simples de se fazer:
 Configure uma VM para bootar em kernel debug. Encontre um processo qualquer (vamos usar o notepad pra variar?). Reabra os símbolos de user mode nele. Defina um breakpoint em alguma DLL de user mode.  Como meus leitores são muito espertos foi partir para o momento após rodarmos um notepad.exe:
kd&amp;gt; !process 0 0 notepad.exePROCESS 81681be0 SessionId: 0 Cid: 0598 Peb: 7ffd7000 ParentCid: 0200DirBase: 08740260 ObjectTable: e18ee8d8 HandleCount: 29.Image: notepad.exekd&amp;gt; .process /i 81681be0You need to continue execution (press &#39;g&#39; &amp;lt;enter&amp;gt;) for the contextto be switched. When the debugger breaks in again, you will be inthe new process context.kd&amp;gt; gBreak instruction exception - code 80000003 (first chance)nt!RtlpBreakWithStatusInstruction:80527bdc cc int 3kd&amp;gt; .reload /userLoading User Symbols.......................kd&amp;gt; bp user32!MessageBoxExWkd&amp;gt; gBreakpoint 0 hitUSER32!MessageBoxExW:001b:7e3a0838 8bff mov edi,edikd&amp;gt; du poi(esp&#43;8)0007cfb8 &amp;quot;naoexistetralala.txt.Arquivo não&amp;quot;0007cff8 &amp;quot; encontrado..Verifique se o nome&amp;quot;0007d038 &amp;quot; do arquivo correto foi especifi&amp;quot;0007d078 &amp;quot;cado.&amp;quot;kd&amp;gt; ezu poi(esp&#43;8) &amp;quot;Esse arquivo não existe! Mas é muito mané, não é mesmo?&amp;quot;kd&amp;gt; g O screenshot diz tudo:

Agora a parte mais divertida: experimente com outro notepad, ou com o explorer =)
</description>
</item>

     
        <item>
  <title>Sétimo Encontro de Programadores C&#43;&#43;</title>
  <link>http://www.caloni.com.br/setimo-encontro-de-programadores-c/</link>
  <pubDate>2010-07-26</pubDate>
  
  <guid>http://www.caloni.com.br/setimo-encontro-de-programadores-c/</guid>
  <description>Mais um fim-de-semana no ócio e na vadiagem. Tenho que manter minhas qualidades de bom programador que sou: preguiçoso, impaciente e pretensioso.
Mas nem por isso deixei de terminar uma primeira versão do aplicativo que irei usar como base na minha palestra do nosso próximo encontro C&#43;&#43;: Crash Dump Analysis. Se alguém tiver dicas de quais os problemas mais difíceis do Universo para analisar em um dump de memória, comente a respeito e veremos o que dá pra fazer.
Enquanto isso, continuo descobrindo maravilhas do WinDbg. Essa semana fiquei brincando de colocar breakpoint em user-mode, mas depurando o kernel, como fizeram os rapazes do Ntdebugging. A conclusão é que ele vale para todos os aplicativos abertos. Tente com o MessageBox!
!process 0 0 notepad.exe.reload /userbp user32!MessageBoxW Mas devaneio. Talvez outra boa qualidade de um bom programador.
</description>
</item>

     
        <item>
  <title>Novidades no Windbg 7</title>
  <link>http://www.caloni.com.br/novidades-no-windbg-7/</link>
  <pubDate>2010-04-01</pubDate>
  
  <guid>http://www.caloni.com.br/novidades-no-windbg-7/</guid>
  <description>Semestre que vem deve sair uma nova versão do nosso depurador favorito. Alguns atrasos e novas definições do projeto fizeram com que tivéssemos mais um ou dois releases da finada versão 6 antes da revolução que será o Depurador 2010.
Entre as mudanças mais esperadas, e entre as mais inesperadas, encontramos essa pequena lista de novidades que, com certeza, deixarão o desenvolvedor de sistemas da Microsoft muito mais feliz:
Localizador automático de módulos Hoje em dia é um trabalho um pouco tedioso encontrar qual dos drivers possuía a memória de endereço 0xB8915423, mas agora, juntando o interpretador de símbolos internos e o sistema de tooltips do Windbg, será possível passar o mouse sobre um endereço qualquer e ele mostrará imediatamente quem possui a memória, como ela foi alocada e qual seu conteúdo.
Isso só é possível, é claro, com os símbolos corretamente carregados. Algo não muito difícil se você seguir as recomendações de John Robbins. E é uma mão na roda na hora de dar um feedback instantâneo para o suporte técnico quando der uma tela azul.
Edit and Continue Sim! Agora se o ddkbuild estiver no path do WinDbg e você editar o código-fonte do seu driver durante a depuração (na próxima versão a visualização não será apenas read-only) e der um step-into, automaticamente o depurador irá perguntar se deseja recompilar o projeto. Depois de ativar o processo de build, através das conexões serial/firewire/usb-debug, a nova imagem irá parar diretamente na memória kernel da máquina target.
Algumas ressalvas são colocadas pela equipe da Microsoft, no entanto. Se existirem mudanças que dizem respeito a alocação dinâmica de memória em nonpaged-pool, o Edit and Continue não será possível naquele momento, apenas depois do reboot.
O último item, mais esotérico de todos, promete ser lançado a partir da versão 7.1:
The BugCheck Fix Tip Resumidamente, é um !analyze mais esperto com o algoritmo heurístico do Visual Basic .NET. Assim que for aberto um dump de tela azul e carregados os símbolos e o caminho dos fontes, a nova versão do !analyze irá verificar os valores do BugCheck gerado e, caso seja detectado que o problema está em seu driver, irá sugerir uma correção na sua função que estiver na pilha.
Microsoft (R) Windows Debugger Version 6.9.0003.113 X86Copyright (c) Microsoft Corporation. All rights reserved.Loading Dump File [C:\Tests\BSOD\BugCheck7F\2010-03-24ClientMemory.dmp]Kernel Complete Dump File: Full address space is available************************************************************WARNING: Dump file has been truncated. Data may be missing.************************************************************Symbol search path is: SRV*c:\tools\symbols*http://msdl.microsoft.com/download/symbolsExecutable search path is:Windows XP Kernel Version 2600 (Service Pack 3) MP (2 procs) Free x86 compatibleProduct: WinNt, suite: TerminalServer SingleUserTSBuilt by: 2600.xpsp_sp3_gdr.090804-1435Kernel base = 0x804d7000 PsLoadedModuleList = 0x8055d720Debug session time: Wed Mar 24 17:51:39.216 2010 (GMT-3)System Uptime: 0 days 0:05:23.843Loading Kernel Symbols.........................................................................................Loading User Symbols............Loading unloaded module list..........................******************************************************************************** ** Bugcheck Analysis ** ********************************************************************************Use !analyze -v to get detailed debugging information.BugCheck 7F, {d, 0, 0, 0}*** ERROR: Symbol file could not be found. Defaulted to export symbols for MyDriver.sys -*** ERROR: Symbol file could not be found. Defaulted to export symbols for mfehidk.sys -Probably caused by : MyDriver.sys ( MyDriver!KeBugCheckTest&#43;2b )Followup: MachineOwner---------0: kd&amp;gt; !analyze -v******************************************************************************** ** Bugcheck Analysis ** ********************************************************************************UNEXPECTED_KERNEL_MODE_TRAP (7f)This means a trap occurred in kernel mode, and it&#39;s a trap of a kindthat the kernel isn&#39;t allowed to have/catch (bound trap) or thatis always instant death (double fault). The first number in thebugcheck params is the number of the trap (8 = double fault, etc)Consult an Intel x86 family manual to learn more about what thesetraps are. Here is a *portion* of those codes:If kv shows a taskGateuse .tss on the part before the colon, then kv.Else if kv shows a trapframeuse .trap on that valueElse.trap on the appropriate frame will show where the trap was taken(on x86, this will be the ebp that goes with the procedure KiTrap)Endifkb will then show the corrected stack.Arguments:Arg1: 0000000d, EXCEPTION_GP_FAULTArg2: 00000000Arg3: 00000000Arg4: 00000000Debugging Details:------------------BUGCHECK_STR: 0x7f_dDEFAULT_BUCKET_ID: DRIVER_FAULTPROCESS_NAME: cmd.ezeLAST_CONTROL_TRANSFER: from 80564dd2 to 80544e7bSTACK_TEXT:a7f4b6a4 80564dd2 badb0d00 89679eb0 a7f40000 nt!KiSystemFatalException&#43;0xfa7f4b774 ba182d80 e23bb528 00000002 a7f4b86c nt!NonPagedPoolDescriptor&#43;0xb2WARNING: Stack unwind information not available. Following frames may be wrong.a7f4b870 804ef19f 8a03a2e0 89665008 8972c838 MyDriver!KeBugCheckTest&#43;0x2ba7f4b880 b9da1876 89665008 8a0f3a80 00000000 nt!IopfCallDriver&#43;0x31...a7f4b940 b9c55e4d 00000002 896651e0 8972c838 mfehidk&#43;0x9128a7f4b9d8 b9c70ef5 cccccccc 8a03b9f8 8a033ab0 mfehidk&#43;0x9e4d0012f918 4ad02d98 0014efc0 00150b00 00000000 cmd!ExecPgm&#43;0x22b...0012fff0 00000000 4ad05046 00000000 78746341 kernel32!BaseProcessStart&#43;0x23STACK_COMMAND: kbFOLLOWUP_IP:MyDriver!KeBugCheckTest&#43;0x2bba182d80 668945a4 mov word ptr [ebp-5Ch],axSYMBOL_STACK_INDEX: 2SYMBOL_NAME: MyDriver!KeBugCheckTest&#43;0x2bFOLLOWUP_NAME: MachineOwnerMODULE_NAME: MyDriverIMAGE_NAME: MyDriver.sysDEBUG_FLR_IMAGE_TIMESTAMP: 4baa49d3&amp;lt;font color=&amp;quot;#0000ff&amp;quot;&amp;gt;BugCheck Fix Tip:-----------------Try to remove the spin lock aquisition in MyDriver!KeBugCheckTest&#43;2a. By doing this,the kernel IRQL priority system will not be in starvation mode.Tip Code: C:\Tests\MyDriver\dispatch-funcs.cpp&#43;345&amp;lt;/font&amp;gt;Followup: MachineOwner--------- Existem um pouco de polêmica em torno dessa funcionalidade. Alguns dizem que ela vai mais atrapalhar do que ajudar os programadores de kernel com a vinda de analistas de sistemas Júnior programando filtros de file system sem a menor discrepância entre o que é um IRP assíncrono e uma ISR. Outros dizem que existirá uma versão paga do WinDbg com essa funcionalidade, nos mesmos moldes do Visual Studio 2010, que virá com a depuração reversa no Enterprise. Essas especulações só o tempo dirá se são verdade ou não. Se eu tiver que pagar mais caro por essas features, o lobby na empresa onde eu trabalho está garantido.
</description>
</item>

     
        <item>
  <title>Bazaar gráfico</title>
  <link>http://www.caloni.com.br/bazaar-grafico/</link>
  <pubDate>2010-02-25</pubDate>
  
  <guid>http://www.caloni.com.br/bazaar-grafico/</guid>
  <description>Bom, já que por enquanto os assuntos de macho estão em falta (acabei de voltar de férias), apresento-lhes o maravilhoso mundo do Bazaar para boiolasuser-friendly!
Ele é leve, vem enrustidoembutido na última versão e pode economizar alguns page ups/downs no prompt do DOS. Ah, sim, antes que comentem, eu não uso o Tortoise for Bazaar porque instalar shell extensions, só os muito bem feitos. (Do contrário, bem-feito para quem instalou.)
Para exibir a lista de comandos &amp;quot;amigáveis&amp;quot;, digite no prompt os comandos do Bazaar filtrando-os para os que começam com &amp;quot;q&amp;quot;:
bzr help commands | grep ^q.*qadd GUI for adding files or directories. [qbzr]qannotate Show the origin of each line in a file. [qbzr]qbranch Create a new copy of a branch. [qbzr]qbrowse Show inventory. [qbzr]qcat View the contents of a file as of a given revision. [qbzr]qcommit GUI for committing revisions. [qbzr]qconfig Configure Bazaar. [qbzr]qdiff Show differences in working tree in a GUI window. [qbzr]qgetnew Creates a new working tree (either a checkout or full branch) [qbzr]qgetupdates Fetches external changes into the working tree [qbzr]qinfo [qbzr]qinit Initializes a new (possibly shared) repository. [qbzr]qlog Show log of a repository, branch, file, or directory in a Qt window. [qbzr]qmerge Perform a three-way merge. [qbzr]qpull Turn this branch into a mirror of another branch. [qbzr]qpush Update a mirror of this branch. [qbzr]qrevert Revert changes files. [qbzr]qtag Edit tags. [qbzr] Os que eu mais uso no dia-a-dia são:
qlog e qbrowse Diversão garantida. Por meio destes simples comandos podemos ver o histórico de commits e navegar pela árvore de pastas e arquivos com a anotação do último commit para cada elemento. Só para ter uma ideia de quanto uso isso, transformei-os em opções do Explorer.
Além da utilidade básica, de quebra, o qbrowse pode te levar para um qlog filtrado, e o qlog pode te levar a um diff gráfico, que é o próximo comando que eu iria mostrar.
qdiff Coisa linda de Deus. Existem dois modos de exibição, mas o padrão já é show de bola, mostrando as mudanças em todos os arquivos de um commit de uma só vez ou do arquivo/pasta especificado pelo comando. É lógico que é possível especificar qualquer faixa de commits que você quiser ver.
Uma desvantagem desse comando é que ele oculta o resto das linhas do fonte e não mostra de jeito nenhum (pelo menos não descobri ainda como fazer isso). Sendo assim, para uma análise mais detalhada das diferenças no código-fonte sempre use um editor externo que consiga comparar arquivos inteiros (eu uso o WinMerge). Você pode colocar esse comando na forma de um diff personalizado, com o uso do qconfig.
Bônus Para quem não sabe fazer comandos de contexto no Explorer sem instalar Shell Extensions, deem uma olhada no REG exportado. Bom proveito.
</description>
</item>

     
        <item>
  <title>Restaurando o registro</title>
  <link>http://www.caloni.com.br/restauranto-o-registro/</link>
  <pubDate>2010-02-08</pubDate>
  
  <guid>http://www.caloni.com.br/restauranto-o-registro/</guid>
  <description>Algumas ferramentas viram essenciais quando o importante é tempo. As minhas favoritas são: Visual Studio e batch. Com esses dois eu faço virtualmente qualquer coisa que preciso em pouquíssimo tempo. É lógico que, na ausência dessas, alternativas são bem-vindas, como Notepad&#43;&#43;, viM, grep, cygwin.
Ontem tive que resolver uma &amp;quot;situação&amp;quot; no cliente, e graças ao bom Deus (ele também é programador) existia um Notepad&#43;&#43; na bagagem que levávamos. Além, é claro, do Excel e do sistema batch do Windows.
O problema consistia basicamente em usar a saída do RegMon para identificar e restaurar algumas modificações que danificavam a instalação do Internet Explorer. O sistema de reparo do IE não existia no cliente, pois ele estava sem Service Pack (bem-vindo ao mundo real), mas podíamos nos guiar através dele na nossa máquina virtual para saber o que faríamos. O estrago era feito durante o registro e/ou desregistro de um componente COM.
Para iniciar, filtramos os resultados do RegMon para apenas capturar escritas no registro, não importando se falharam ou deram resultado.
A partir disso executamos o registro e desregistro do componente, além da restauração do IE6, responsável por limpar a bagunça. O processo responsável por registrar componentes é o regsvr32 e o responsável por limpar a bagunça, rundll32.
Tendo a saída do RegMon exportada para formato texto, abrimos no Excel e filtramos o conteúdo pelo nome do processo. Note que existem duas instâncias de regsvr32 para usar, pois não sabemos em qual delas é danificado o registro.
Para cada um dos filtros copiamos apenas o endereço da chave alterada para dois arquivos texto: regsvr32.txt e ierestore.txt. Usaremos esse primeiro para encontrar ocorrências no segundo, provando que um modifica o que o outro consertou.
Existe um comando muito simplório em batch Windows que é o aplicativo find. Através dele podemos encontrar a ocorrência de uma string em um arquivo. Para transformar todas aquelas linhas do registro do arquivo regsvr32 em comandos find poderíamos elaborar algumas colunas no Excel ou usar o Notepad&#43;&#43; e suas macros, mais rápidas.
Para quem não conhece macros, saiba que elas são muito úteis. Às vezes até mais úteis que &amp;quot;regexes&amp;quot;, pois não é necessário pensar muito na expressão a ser usada. Macros apenas repetem os movimentos do teclado que fazemos enquanto as estamos gravando. Por exemplo, eu tenho o meu monte de linhas de registro assim:
HKLM\SOFTWARE\Microsoft\Cryptography\RNGHKLM\SOFTWARE\Microsoft\Cryptography\RNG\SeedHKCR\AppID\{EE62DE09-3A23-46DB-8FA2-266088F329CD}HKCR\AppID\{EE62DE09-3A23-46DB-8FA2-266088F329CD}\(Default)HKLM\SOFTWARE\Microsoft\Windows\CurrentVersion\Explorer\Browser Helper Objects\{C322BA70-E3E7-4737-821C-D25378A3F830}HKCR\CLSID\{684E2452-19E1-42CC-9C93-A83044BA1AF2}HKCR\CLSID\{684E2452-19E1-42CC-9C93-A83044BA1AF2}\Programmable... Quero transformar cada linha em um comando find. Iniciou a gravação da macro no início da primeira linha e digito o seguinte (em pseudo-alguma-coisa):
find, espaço, abre aspas, end, fecha aspas, espaço, ierestore.txt, linha abaixo, home
find &amp;quot;HKLM\SOFTWARE\Microsoft\Cryptography\RNG&amp;quot; ierestore.txtHKLM\SOFTWARE\Microsoft\Cryptography\RNG\SeedHKCR\AppID\{EE62DE09-3A23-46DB-8FA2-266088F329CD} Pronto. Parar macro. Terei que repetir isso dois milhões de vezes até o final do arquivo. Ora, então mando o Notepad&#43;&#43; repetir a minha macro até o final do arquivo e adio minha tendinite para os próximos anos.
Só preciso agora renomear meu arquivo para .bat e executar. Posso redirecionar a saída da tela para um terceiro arquivo, de onde irei formatar minha lista de entradas no registro que foram adulteradas por ambos os programas (o registro do componente COM e a restauração do Internet Explorer).
Nesse momento podemos ir tomar café. Bem melhor do que ficar horas e horas dando localizar, copiar, colar em todas as entradas do regsvr.

Terminada a operação, abrimos o terceiro arquivo, retiramos as entradas insignificantes (por exemplo, o gerador de sementes de números randômicos) e os cabeçalhos do comando, algo bem fácil já que se trata do mesmo arquivo.
---------- IERESTORE.TXT... A próxima tarefa seria analisar cada entrada e ver se ela é relevante. Essa parte foi manual, mas, encontrado um padrão, listamos rapidamente o que poderia estar dando errado e criamos uma lista de entradas para exportar do registro &amp;quot;sadio&amp;quot; a fim de gerar um .REG que corrigiria sistemas danificados.
Algumas passadas no Notepad&#43;&#43; para eliminar linhas duplicadas e algumas passadas pelo cérebro para eliminar chaves redundantes (chave dentro de chave) e tcharam!
...HKCR\Interface\{3050F2E3-98B5-11CF-BB82-00AA00BDCE0B}HKCR\Interface\{3050F2E5-98B5-11CF-BB82-00AA00BDCE0B}HKCR\Interface\{3050F32D-98B5-11CF-BB82-00AA00BDCE0B}HKCR\Interface\{3050F357-98B5-11CF-BB82-00AA00BDCE0B}HKCR\Interface\{3050F35C-98B5-11CF-BB82-00AA00BDCE0B}HKCR\Interface\{3050F37E-98B5-11CF-BB82-00AA00BDCE0B}HKCR\Interface\{3050F38C-98B5-11CF-BB82-00AA00BDCE0B}... O próximo passo para nossa obra-prima é outra macro que irá reproduzir o comando reg, que pode realizar operações no registro do Windows.
...reg export HKCR\Interface\{3050F240-98B5-11CF-BB82-00AA00BDCE0B} 3050F240-98B5-11CF-BB82-00AA00BDCE0B.regreg export HKCR\Interface\{3050F25A-98B5-11CF-BB82-00AA00BDCE0B} 3050F25A-98B5-11CF-BB82-00AA00BDCE0B.regreg export HKCR\Interface\{3050F25E-98B5-11CF-BB82-00AA00BDCE0B} 3050F25E-98B5-11CF-BB82-00AA00BDCE0B.regreg export HKCR\Interface\{3050F2E3-98B5-11CF-BB82-00AA00BDCE0B} 3050F2E3-98B5-11CF-BB82-00AA00BDCE0B.regreg export HKCR\Interface\{3050F2E5-98B5-11CF-BB82-00AA00BDCE0B} 3050F2E5-98B5-11CF-BB82-00AA00BDCE0B.regreg export HKCR\Interface\{3050F32D-98B5-11CF-BB82-00AA00BDCE0B} 3050F32D-98B5-11CF-BB82-00AA00BDCE0B.reg... E o último passo é juntar toda essa galera em um arquivo só.
copy *.reg ierestore.reg Claro, não se esqueça de retirar os cabeçalhos duplicados (Windows Registry Editor Version X.XX). E Voilà! Fácil, não? Não?! Bom, então é por isso que eu sou bem pago =)
</description>
</item>

     
        <item>
  <title>Devaneio nerd rápido sobre profecias</title>
  <link>http://www.caloni.com.br/devaneio-nerd-rapido-sobre-profecias/</link>
  <pubDate>2009-12-30</pubDate>
  
  <guid>http://www.caloni.com.br/devaneio-nerd-rapido-sobre-profecias/</guid>
  <description>Para quem já analisou os dados de uma tela azul sabe que, quando o Windows acha um culpado (vulgo driver) a data de sua compilação é exibida em um formato conhecido como DateStamp ou TimeStamp. Nesse formato o que temos é um número hexadecimal que segue o formato de tempo do Unix, que no caso é o número de segundos desde o dia primeiro de Janeiro de 1970. Isso, por curiosidade, nos dá uma margem de 140 anos antes dos número se repetirem se usarmos 32 bits nessa contagem.
O comando .formats do WinDbg nos consegue trazer desse número a hora exata em que determinado componente foi compilado. Se, por exemplo, um driver faltoso apresentou um DateStamp igual a 49EE9758, podemos concluir que ele foi compilado no dia 22 de abril de 2009, uma linda quarta-feira.
0:000&amp;gt; &amp;lt;font color=&amp;quot;#0000ff&amp;quot;&amp;gt;.formats 49EE9758&amp;lt;/font&amp;gt;Evaluate expression:Hex: 00000000`49ee9758Decimal: 1240373080Octal: 0000000000011173513530Binary: 00000000 00000000 00000000 00000000 01001001 11101110 10010111 01011000Chars: ....I..X&amp;lt;strong&amp;gt;&amp;lt;font color=&amp;quot;#0000ff&amp;quot;&amp;gt; Time: Wed Apr 22 01:04:40 2009&amp;lt;/font&amp;gt;&amp;lt;/strong&amp;gt;Float: low 1.95454e&#43;006 high 0Double: 6.12826e-315 Quando fazemos algo muitas vezes seguidas temos o hábito inconsciente de observar certas idiossincrasias dos dados que sempre vem e vão. No caso dos Date Stamps, sempre me veio o fato deles iniciarem com 4 e estarem prestes a &amp;quot;virar o contador&amp;quot; para 5.
Isso aos poucos - entre uma tela azul e outra - me deixou curioso a respeito de quando seria o dia fatídico em que teríamos o DateStamp 50000000, um número cabalístico em nosso sistema decimal. E, imaginem só:
0:000&amp;gt; &amp;lt;font color=&amp;quot;#0000ff&amp;quot;&amp;gt;.formats 50000000&amp;lt;/font&amp;gt;Evaluate expression:Hex: 00000000`50000000Decimal: 1342177280Octal: 0000000000012000000000Binary: 00000000 00000000 00000000 00000000 01010000 00000000 00000000 00000000Chars: ....P...&amp;lt;font color=&amp;quot;#0000ff&amp;quot;&amp;gt; Time: Fri Jul 13 08:01:20 2012&amp;lt;/font&amp;gt;Float: low 8.58993e&#43;009 high 0Double: 6.63124e-315 Pois é, meus amigos. O DateStamp para a virada do contador Unix se fará numa manhã de sexta. Para ser preciso, uma sexta-feira 13.
Curioso, não? Mais curioso que isso, só sabendo que o ano que isso vai ocorrer é o igualmente fatídico 2012. Felizmente antes de dezembro.
</description>
</item>

     
        <item>
  <title>À procura de vida extraterrestre</title>
  <link>http://www.caloni.com.br/a-procura-de-vida-extraterrestre/</link>
  <pubDate>2009-07-20</pubDate>
  
  <guid>http://www.caloni.com.br/a-procura-de-vida-extraterrestre/</guid>
  <description>Faz uns bons dez anos que eu instalei pela primeira vez em meu Pentium 133 MHz o seti@home, um programinha que se propunha a localizar vida extraterrena através de emissões de rádio capturadas pelas nossas potentes antenas de Arecibo. Ele dizia fazer isso durante o tempo ocioso do meu processador. Como eu sou uma pessoa que costuma costumava confiar bastante nas pessoas, além de ser fã incondicional do filme Contato, instalei sem medo.
Algum tempo se passou e hoje volto a instalar o mesmo programa, agora envolto em um invólucro de programas de mesmo teor chamado Boinc, que junta todas essas redes de trabalho em equipe. O computador é usado hoje em dia para diversos trabalhos que exigem um certo esforço no processamento que torna proibitivo alocar máquinas somente para isso (se não impossível do ponto de vista geográfico).
Eis uma lista dos principais projetos disponíveis através do Boinc que me chamaram a atenção:
 Climateprediction.net busca prever as possíveis consequências para o mundo das futuras transformações no clima. CPUGrid.net é uma simulação molecular de proteínas otimizada para as GPUs da NVidia e o Playstation 3. Superlink@Technion e ajude os cientistas a encontrar os prováveis genes causadores de fatalidades como câncer, a diabetes, hipertensão e esquizofrenia. Chess960@home para análise de uma variante do xadrez tradicional que sempre coloca as peças iniciais em posições aleatórias. PrimeGrid é um gerador de uma base de dados pública de números primos sequenciais, além de procurar por números primos gêmeos gigantes (vai saber). Quantum Monte Carlo at Home não é o que parece: Estudo da estrutura e da reatividade de moléculas usando a Química Quântica (?).  Dentre eles, acabei ficando mesmo com o bom e velho seti@home. Pode me chamar de egoísta, mas mesmo que encontrem a cura do câncer, não será muito produtivo para mim, que possuo questões existenciais que, acredito eu, facilitariam a compreensão das pessoas acerca da nossa extrema pequenez nesse universo, nos colocando cada vez mais no cantinho de nossa existência.
Escolha o seu!
</description>
</item>

     
        <item>
  <title>Como compilar em somente um passo</title>
  <link>http://www.caloni.com.br/como-compilar-em-somente-um-passo/</link>
  <pubDate>2009-05-25</pubDate>
  
  <guid>http://www.caloni.com.br/como-compilar-em-somente-um-passo/</guid>
  <description>Uma das primeiras perguntas do teste do Joel é saber se você pode compilar todo o projeto em apenas um passo. Essa é uma questão essencial e um desafio para muitas equipes. Perdem-se horas sagradas para gerar um novo Release.
Compilação automática geralmente está disponível nas ferramentas de desenvolvimento. Se você estiver usando o Visual Studio, por exemplo, é possível fazer isso com uma linha:
devenv minha-solução.sln /Rebuild Release Se não for exatamente o que você precisa, basta fazer uma pesquisa de quinze minutos e encontrar os parâmetros corretos. O objetivo é: eu rodo esse comando em cima do projeto inteiro em uma máquina zerada e ele simplesmente compila.
Múltiplas soluções É lógico que ter apenas um solution/workspace para guardar projetos médios e grandes é inviável. Demora para carregar no ambiente e possuem dezenas de dependências. Isso já foi tentado duas vezes nas duas empresas em que trabalhei e não funcionou. Talvez por isso seja necessário criar um script que rode o comando acima para todas as soluções do projeto, o que não muda muito o modus operandi da coisa:
call :Build ..\Libraries\Libraries.slncall :Build ..\Services\Services.slncall :Build ..\Drivers\Drivers.slncall :Build ..\Tools\Tools.slngoto :eof:Buildecho %1...devenv &amp;quot;%1&amp;quot; /Rebuild Releaseexit /b %errorlevel% Note que meu script usa a estrutura padronizada dos diretórios de um projeto, onde cada tipo de componente tem sua pasta e solução.
Aos poucos você pode ir colocando &amp;quot;frescurinhas&amp;quot; em seu build (executa Debug e Release, roda automatizado no servidor, faz testes unitários, incrementa o número da versão, ...), mas algumas premissas sempre se mantêm:
  Deve ser possível compilar o projeto inteiro em um passo
  Deve ser possível usar qualquer máquina de desenvolvimento para isso
  Regras simples de ser seguidas se você usar sempre a máxima do KISS.
</description>
</item>

     
        <item>
  <title>Meu roteiro C&#43;&#43;</title>
  <link>http://www.caloni.com.br/meu-roteiro-c/</link>
  <pubDate>2009-05-20</pubDate>
  
  <guid>http://www.caloni.com.br/meu-roteiro-c/</guid>
  <description>Como não consigo mais ter ideias para artigos, resolvi catalogar todas as coisas que já falei nesse blogue e, o mais importante, todas as coisas que ainda não falei nesse blogue (e espero um dia falar ou talvez nunca fale), começando por C&#43;&#43;, que era o intuito original (só que não é mais, porque eu uso mais a Win32 API que a STL):
C&#43;&#43;   História
 A linguagem BCPL O código-objeto A linguagem B A &amp;quot;função&amp;quot; char O primeiro printf da história A linguagem C A linguagem C&#43;&#43; As influências    Conceitos
 O conceito programa O código-objeto Processo de compilação Declaração x definição Tipos Lvalue x Rvalue A passagem por valor Ponteiros Estruturas e classes Espaços de nomes Polimorfismo estático Herança Polimorfismo dinâmico Iteradores Função-objeto Templates Algoritmos genéricos Qualificadores (traits) O conceito RAII    Linguagem
 O operador de subscrito A proteção protected Sizeof e strings literais Uso de reflexão com typeid Typeid e o polimorfismo Ponteiros de método Ponteiros de método e o this Try-catch fora do corpo da função Sobrecarga de operadores    Biblioteca
 Biblioteca C no Windows Mobilidade da pilha com prinff Erros comuns de iteradores STL Boost    Dicas
 Erros comuns de iniciantes Ponteiro nulo em entrevistas Nem todo ponteiro nulo é inválido Decifrando código obscuro Usando do-while para evitar erros de macro Sobrecarga por tipo de retorno    Espero que isso me ajude a continuar completando as lacunas do saite. Se não der certo, pelo menos já sei o que fiz.
Sugestões?
</description>
</item>

     
        <item>
  <title>A Alça Dentro do Fio Gerou um Bloqueio da Morte</title>
  <link>http://www.caloni.com.br/a-alca-dentro-do-fio-gerou-um-bloqueio-da-morte/</link>
  <pubDate>2008-10-21</pubDate>
  
  <guid>http://www.caloni.com.br/a-alca-dentro-do-fio-gerou-um-bloqueio-da-morte/</guid>
  <description>Estava folheando um livro fenomenal que meu amigo havia pedido emprestado para ler quando me deparei com algumas traduções no mínimo curiosas. O exemplar em questão era o primeiro Windows Internals, publicado após o lançamento da primeira versão do Windows NT, uma plataforma escrita (quase) inteiramente do zero para suplantar as versões 9x (Windows 95 e 98), que herdaram do DOS algumas partes indesejáveis em sistemas operacionais modernos.
Sabe-se lá por que essa edição foi traduzida. É interessante notar que naquela época foi dado um tratamento especial a alguns termos e conceitos já comuns no dia-a-dia do programador americano, apesar de quase nenhum desses termos ter se mantido em sua versão original. Os exemplos mais gritantes são as threads (fios ou linhas), os dead locks (bloqueios da morte) e os handles (alças). Apesar de não ter nada contra traduzir termos do inglês para português (e vice-versa) algumas coisas incomodam em tradução de livros técnicos.
Um bom exemplo são ponteiros. Ler em um dado capítulo &amp;quot;(...) é muito importante inicializar seus ponteiros antes de usá-los&amp;quot; para, depois de nos acostumarmos com o termo, ler em outro capítulo &amp;quot;(...) sabe-se que a pior desgraça para um programador C são os famigerados apontadores selvagens&amp;quot;. Você resolveria esse tipo de problema definindo um vocabulário em comum com todo o livro (importantíssimo se ele está sendo traduziro por mais de uma pessoa) e ainda informaria o leitor qual o termo original, caso ele precise pesquisar sobre ele fora do livro. Com essa informação, que pode ser usada apenas nos primeiros usos da palavra ou em um glossário à parte, agradaria gregos e troianos: &amp;quot;os ponteiros em C (pointers) são um recurso rico e necessário para a escrita de programas de baixo/médio nível&amp;quot;.
Um exemplo notável é o famoso livro de algoritmos em C da O&#39;Reilly, que mesmo na nova edição com uma errata de 49 itens foi possível detectar mais erros. Um exemplo que me lembro era de uma função do algoritmo bitree. Nele havia uma variável com o nome orig que três linhas abaixo estava &amp;quot;traduzida&amp;quot; para original. É importante aqui diferenciar que no original não consta esse erro da troca do nome da variável.
Isso acaba sendo pior do que não colocar a versão em inglês, pois dá a impressão que não existe significado a ser explicado. Por exemplo, ver antes do capítulo sobre threads a passagem &amp;quot;... quando um fio espera o outro e vice-versa, acontece o terrível bug da trava da morte&amp;quot;. Para quem não descobriu o que foi escrito no original, se trata de duas threads (fios) causando um deadlock (trava da morte), cujo termo inclusive é usado no seu original na Wikipédia em português.
Esses exemplos, salvo o exemplo do livro de algoritmos, foram criados para ilustrar os tipos de erros mais comuns em traduções de livros técnicos, e não estão relacionados com qualquer livro em específico. Então o que era inicialmente para ajudar as pessoas que estão iniciando alguns conceitos acaba por prejudicar ainda mais o aprendizado, gerando aquele tipo de confusão que só com ajuda extra (internet, professor, colega) pode ser resolvida.
Assim como no vocabulário comum corrente, em que existem palavras dificilmente adaptáveis ou traduzíveis em um termo comum, como shopping e show, no meio técnico brotam as mais variadas expressões &amp;quot;estrangeirísticas&amp;quot;. Algumas são muito difíceis de encontrar seu primo lusófono, como link e login. Outros, no entanto, exageram um pouco as coisas, a ponto de conjugarmos um verbo em inglês usando nosso sistema gramatical: se você &amp;quot;stopar&amp;quot; o &amp;quot;debugador&amp;quot; vai &amp;quot;crashear&amp;quot; todo o sistema, porque esse software tá &amp;quot;bugado&amp;quot;! 1
O fato é que não há escapatória para quem trabalha nessa área, e no fundo isso é uma coisa boa, pois é da leitura técnica em inglês que podemos estender o nosso conhecimento além das barreiras do ponto com ponto br e encontrar conteúdo extremamente interessante (e inédito em nossa língua) para aprender. Se não estivéssemos abarrotados de estrangeirismos talvez fosse um pouco mais difícil fazer o switch entre essas duas linguagens.
  Ironicamente 12 anos depois deste artigo ser escrito o verbo bugar virou uma gíria corrente entre jovens. &amp;#x21a9;&amp;#xfe0e;
   </description>
</item>

     
        <item>
  <title>Como usar WTL com o ATL do DDK</title>
  <link>http://www.caloni.com.br/como-usar-wtl-com-o-atl-do-ddk/</link>
  <pubDate>2008-10-15</pubDate>
  
  <guid>http://www.caloni.com.br/como-usar-wtl-com-o-atl-do-ddk/</guid>
  <description>Eu simplemente não entendo a organização dos cabeçalhos e fontes dos SDKs da Microsoft. Houve uma vez em que o ATL era distribuído junto com o SDK, e dessa forma conseguíamos usar o WTL sem ônus. Porém, um belo dia, isso é retirado do pacote, para tristeza dos que já haviam convertido a biblioteca de janelas para fonte aberto.
No entanto, num belo dia, qual não foi minha surpresa ao notar umas pastinhas chamadas atl21, atl30 e atl71 dentro da distribuição do WDK (o finado DDK, renomeado sabe-se-lá-por-quê)? Pelo visto, tem alguém arrastando coisa errada pra onde não devia nos instaladores de Seattle. Esses estagiários!
O fato é que eles fizeram isso, e agora é possível ter o WTL mais novo compilado com o WDK. E nem é tão difícil assim.
A primeira coisa a fazer é obter o tal doWDK. Para variar um pouco, agora existe um processo de registro antes de obter acesso ao download, mais ou menos nos termos da Borland para baixar o Builder / Turbo / Developer Studio.
Após instalado, em qualquer lugar da sua escolha, configure no seu Visual Studio Express o caminho de onde se encontra a pasta atl71 (ou a 30, ou a 21). Aproveite também para colocar a pasta do WTL e o diretório de LIBs:
Isso vai fazer com que pelo menos os exemplos que vêem com o WTL compilem.
No entanto, você verá o seguinte erro durante a compilação dos recursos:
------ Build started: Project: MTPad, Configuration: Debug Win32 ------Compiling resources...Microsoft (R) Windows (R) Resource Compiler Version 6.0.5724.0Copyright (C) Microsoft Corporation. All rights reserved.Linking...CVTRES : fatal error CVT1100: &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;duplicate resource&amp;lt;/font&amp;gt;. type:MANIFEST, name:1, language:0x0409LINK : fatal error LNK1123: failure during conversion to COFF: file invalid or corruptBuild log was saved at &amp;quot;file://c:\Lng\WTL\Samples\MTPad\Debug\BuildLog.htm&amp;quot;MTPad - 2 error(s), 0 warning(s)========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ========== Para resolver esse problema, remova a inclusão do arquivo de manifesto no arquivo RC:
2 TEXTINCLUDE DISCARDABLEBEGIN&amp;quot;#include &amp;quot;&amp;quot;atlres.h&amp;quot;&amp;quot;\r\n&amp;quot;&amp;quot;\0&amp;quot;END&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;3 TEXTINCLUDE DISCARDABLEBEGIN&amp;quot;CREATEPROCESS_MANIFEST_RESOURCE_ID RT_MANIFEST &amp;quot;&amp;quot;res\\\\MTPad.exe.manifest&amp;quot;&amp;quot;\r\n&amp;quot;&amp;quot;\0&amp;quot;END&amp;lt;/font&amp;gt;#endif // APSTUDIO_INVOKED...#ifndef APSTUDIO_INVOKED///////////////////////////////////////////////////////////////////////////////// Generated from the TEXTINCLUDE 3 resource.//&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;CREATEPROCESS_MANIFEST_RESOURCE_ID RT_MANIFEST &amp;quot;res\\MTPad.exe.manifest&amp;quot;&amp;lt;/font&amp;gt;/////////////////////////////////////////////////////////////////////////////#endif // not APSTUDIO_INVOKED Depois dessa alteração, deve ainda existir o seguinte erro de linquedição:
------ Build started: Project: MTPad, Configuration: Debug Win32 ------Compiling resources...Microsoft (R) Windows (R) Resource Compiler Version 6.0.5724.0Copyright (C) Microsoft Corporation. All rights reserved.Linking...&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;mtpad.obj : error LNK2019: unresolved external symbol&amp;quot;void * __stdcall ATL::__AllocStdCallThunk(void)&amp;quot; (bla bla bla)mtpad.obj : error LNK2019: unresolved external symbol&amp;quot;void __stdcall ATL::__FreeStdCallThunk(void *)&amp;quot; (bla bla bla)&amp;lt;/font&amp;gt;.\Debug/MTPad.exe : fatal error LNK1120: 2 unresolved externalsBuild log was saved at &amp;quot;file://c:\Lng\WTL\Samples\MTPad\Debug\BuildLog.htm&amp;quot;MTPad - 3 error(s), 0 warning(s)========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ========== Esse problema ocorre porque as funções de alocação e desalocação de memória da ATL estão em outra LIB que os exemplos da WTL desconhecem. Para resolver, basta incluir essa nova dependência:
#pragma comment(lib, &amp;quot;&amp;lt;strong&amp;gt;atlthunk.lib&amp;lt;/strong&amp;gt;&amp;quot;) E pronto! Agora temos todo o poder das 500 milhões de classes da ATL aliadas à ilimitada flexibilidade das classes de janelas da WTL.
Para aprender a usar WTL   Explicando a sopa de letrinhas da programação C/C&#43;&#43; para Windows: WTL
  WTL for MFC Programmers
  </description>
</item>

     
        <item>
  <title>Reúna seus comandos mais usados no WinDbg com .cmdtree</title>
  <link>http://www.caloni.com.br/reuna-seus-comandos-mais-usados-no-windbg-com-cmdtree/</link>
  <pubDate>2008-09-19</pubDate>
  
  <guid>http://www.caloni.com.br/reuna-seus-comandos-mais-usados-no-windbg-com-cmdtree/</guid>
  <description>Tudo começou com o artigo de Roberto Farah sobre o comando &amp;quot;escondido&amp;quot; do WinDbg .cmdtree. Logo depois meus outros colegas do fã-clube do WinDbg Volker von Einem e Dmitry Vostokov comentaram sobre a imensa utilidade desse comando.
E não é pra menos. É de longe o melhor comando não-documentado do ano. Tão bom que sou obrigado a comentar em português sobre ele, apesar dos três artigos já citados.
Comandos repetitivos E eu estava justamente falando sobre essa mania dos programadores sempre acharem soluções para tarefas repetitivas e monótonas que o computador possa fazer sozinho.O comando .**cmdtree **é uma dessas soluções, pois possibilita ao depurador profissional juntar em uma só guia o conjunto de comandos mais usados por ele no dia-a-dia, por mais bizarros e com mais parâmetros que eles sejam, já que é possível representá-los por um alias (apelido):
windbg ANSI Command Tree 1.0title {&amp;quot;Meus Comandos Comuns&amp;quot;}body{&amp;quot;Comandos Comuns&amp;quot;}{&amp;quot;Subsecao&amp;quot;}{&amp;quot;Breakpoint no inicio do programa&amp;quot;} {&amp;quot;bp @$exentry&amp;quot;}{&amp;quot;GetLastError&amp;quot;} {&amp;quot;!gle&amp;quot;} O resultado:
E podemos usar essa janela no nosso WinDbg, cada vez mais bonitinho e cada vez mais WYSIWYG:

Realmente não há segredos em seu uso. Esse artigo foi apenas um patrocínio do clube do WinDbg.
</description>
</item>

     
        <item>
  <title>Retorno do PathIsDirectory</title>
  <link>http://www.caloni.com.br/retorno-do-pathisdirectory/</link>
  <pubDate>2008-09-10</pubDate>
  
  <guid>http://www.caloni.com.br/retorno-do-pathisdirectory/</guid>
  <description>Estava eu outro dia programando aquele código esperto &amp;quot;para ontem&amp;quot; quando me deparei com uma situação no mínimo inusitada. Ao testar se um caminho recebido era de fato um diretório me foi retornado pela API um valor diferente de TRUE. E diferente de FALSE!
De acordo com a documentação, o retorno deveria ser TRUE caso o caminho enviado à função fosse de fato um diretório. Caso contrário, o retorno deveria ser FALSE.
Note que existem apenas dois valores possíveis para essa função. Porém, o valor retornado não é 1, o equivalente ao define TRUE, mas sim 0x10 (16 em hexadecimal). O simples exemplo abaixo deve conseguir reproduzir a situação (Windows XP Service Pack 3):
Setting environment for using Microsoft Visual Studio 2008 x86 tools.C:\Tests&amp;gt;copy con IsPathDir.cpp#include &amp;lt;shlwapi.h&amp;gt;#include &amp;lt;windows.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;#pragma comment(lib, &amp;quot;shlwapi.lib&amp;quot;)int main(){BOOL isDir = PathIsDirectory(&amp;quot;C:\\Tests&amp;quot;); // obs.: diretorio TEM que existirprintf(&amp;quot;Resultado: %d.\n&amp;quot;, isDir);}^Z1 arquivo(s) copiado(s).C:\Tests&amp;gt;cl IsPathDir.cppMicrosoft (R) 32-bit C/C&#43;&#43; Optimizing Compiler Version 15.00.21022.08 for 80x86Copyright (C) Microsoft Corporation. All rights reserved.IsPathDir.cppMicrosoft (R) Incremental Linker Version 9.00.21022.08Copyright (C) Microsoft Corporation. All rights reserved./out:IsPathDir.exeIsPathDir.objC:\Tests&amp;gt;IsPathDir.exe&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;Resultado: 16.&amp;lt;/font&amp;gt; Isso quer dizer apenas que o código abaixo vai funcionar,
if( PathIsDirectory(path) ) // legal: qualquer coisa diferente de zero o código abaixo vai funcionar
if( ! PathIsDirectory(path) ) // legal: se der zero (FALSE), OK e o código abaixo não vai funcionar:
if( PathIsDirectory(path) == TRUE ) // vixi: TRUE nem sempre é o resultado E, pior, o código abaixo também não vai funcionar!
if( PathIsDirectory(path) != TRUE ) // aff... é bom rever os seus conceitos Pesquisando um pouco descobri uma boa discussão sobre o tema, e inclusive que outras pessoas descobriram o interessante detalhe que para pastas normais o retorno é 0x10, mas para compartilhamentos o retorno é 0x1.
O bug atrás dos documentos O problema ocorre por causa da maneira que a função determina se o caminho é um diretório ou não. Uma simples vistoria sobre a função nos revela o detalhe crucial:
C:\Tests&amp;gt;cl /Zi IsPathDir.cppMicrosoft (R) 32-bit C/C&#43;&#43; Optimizing Compiler Version 15.00.21022.08 for 80x86Copyright (C) Microsoft Corporation. All rights reserved.IsPathDir.cppMicrosoft (R) Incremental Linker Version 9.00.21022.08Copyright (C) Microsoft Corporation. All rights reserved./out:IsPathDir.exe/debugIsPathDir.objC:\Tests&amp;gt;cdb IsPathDir.exeMicrosoft (R) Windows Debugger Version 6.8.0004.0 X86Copyright (c) Microsoft Corporation. All rights reserved.CommandLine: IsPathDir.exeSymbol search path is: SRV*c:\symbols*http://msdl.microsoft.com/download/symbolsExecutable search path is:ModLoad: 00400000 00426000 IsPathDir.exeModLoad: 7c900000 7c9b4000 ntdll.dllModLoad: 7c800000 7c8ff000 C:\WINDOWS\system32\kernel32.dllModLoad: 77ea0000 77f16000 C:\WINDOWS\system32\SHLWAPI.dllModLoad: 77f50000 77ffb000 C:\WINDOWS\system32\ADVAPI32.dllModLoad: 77db0000 77e41000 C:\WINDOWS\system32\RPCRT4.dllModLoad: 77e50000 77e97000 C:\WINDOWS\system32\GDI32.dllModLoad: 7e360000 7e3f0000 C:\WINDOWS\system32\USER32.dllModLoad: 77bf0000 77c48000 C:\WINDOWS\system32\msvcrt.dll(ea0.de0): Break instruction exception - code 80000003 (first chance)eax=00241eb4 ebx=7ffde000 ecx=00000004 edx=00000010 esi=00241f48 edi=00241eb4eip=7c901230 esp=0012fb20 ebp=0012fc94 iopl=0 nv up ei pl nz na po nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000202ntdll!DbgBreakPoint:7c901230 cc int 30:000&amp;gt; &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;g shlwapi!PathIsDirectoryA&amp;lt;/font&amp;gt;ModLoad: 76360000 7637d000 C:\WINDOWS\system32\IMM32.DLLModLoad: 62e80000 62e89000 C:\WINDOWS\system32\LPK.DLLModLoad: 74d50000 74dbb000 C:\WINDOWS\system32\USP10.dlleax=009836e0 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0006f4cc edi=7c911970eip=77ee7538 esp=0012ff6c ebp=0012ff78 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA:77ee7538 8bff mov edi,edi0:000&amp;gt; peax=009836e0 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0006f4cc edi=7c911970eip=77ee753a esp=0012ff6c ebp=0012ff78 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0x2:77ee753a 55 push ebp0:000&amp;gt;eax=009836e0 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0006f4cc edi=7c911970eip=77ee753b esp=0012ff68 ebp=0012ff78 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0x3:77ee753b 8bec mov ebp,esp0:000&amp;gt;eax=009836e0 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0006f4cc edi=7c911970eip=77ee753d esp=0012ff68 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0x5:77ee753d 81ec0c020000 sub esp,20Ch0:000&amp;gt;eax=009836e0 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0006f4cc edi=7c911970eip=77ee7543 esp=0012fd5c ebp=0012ff68 iopl=0 nv up ei pl nz ac pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000216SHLWAPI!PathIsDirectoryA&#43;0xb:77ee7543 a180d2f077 mov eax,dword ptr [SHLWAPI!__security_cookie0:000&amp;gt;eax=00007a43 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0006f4cc edi=7c911970eip=77ee7548 esp=0012fd5c ebp=0012ff68 iopl=0 nv up ei pl nz ac pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000216SHLWAPI!PathIsDirectoryA&#43;0x10:77ee7548 56 push esi0:000&amp;gt;eax=00007a43 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0006f4cc edi=7c911970eip=77ee7549 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz ac pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000216SHLWAPI!PathIsDirectoryA&#43;0x11:*** WARNING: Unable to verify checksum for IsPathDir.exe77ee7549 8b7508 mov esi,dword ptr [ebp&#43;8] ss:0023:0012ff70=0041dc5c0:000&amp;gt;eax=00007a43 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee754c esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz ac pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000216SHLWAPI!PathIsDirectoryA&#43;0x14:77ee754c 85f6 test esi,esi0:000&amp;gt;eax=00007a43 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee754e esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000206SHLWAPI!PathIsDirectoryA&#43;0x16:77ee754e 8945fc mov dword ptr [ebp-4],eax ss:0023:0012ff64=fffffffe0:000&amp;gt;eax=00007a43 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee7551 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000206SHLWAPI!PathIsDirectoryA&#43;0x19:77ee7551 0f8493000000 je SHLWAPI!PathIsDirectoryA&#43;0xb2 (77ee75ea) [br=0]0:000&amp;gt;eax=00007a43 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee7557 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000206SHLWAPI!PathIsDirectoryA&#43;0x1f:77ee7557 56 push esi0:000&amp;gt;eax=00007a43 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee7558 esp=0012fd54 ebp=0012ff68 iopl=0 nv up ei pl nz na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000206SHLWAPI!PathIsDirectoryA&#43;0x20:77ee7558 e85cc0fdff call SHLWAPI!PathIsUNCServerA (77ec35b9)0:000&amp;gt;eax=00000000 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee755d esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0x25:77ee755d 85c0 test eax,eax0:000&amp;gt;eax=00000000 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee755f esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0x27:77ee755f 0f8585000000 jne SHLWAPI!PathIsDirectoryA&#43;0xb2 (77ee75ea) [br=0]0:000&amp;gt;eax=00000000 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee7565 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0x2d:77ee7565 56 push esi0:000&amp;gt;eax=00000000 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee7566 esp=0012fd54 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0x2e:77ee7566 e812feffff call SHLWAPI!PathIsUNCServerShareA (77ee737d)0:000&amp;gt;eax=00000000 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee756b esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0x33:77ee756b 85c0 test eax,eax0:000&amp;gt;eax=00000000 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee756d esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0x35:77ee756d 0f8486000000 je SHLWAPI!PathIsDirectoryA&#43;0xc1 (77ee75f9) [br=1]0:000&amp;gt;eax=00000000 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee75f9 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0xc1:77ee75f9 56 push esi0:000&amp;gt;eax=00000000 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee75f9 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0xc1:77ee75f9 56 push esi0:000&amp;gt;eax=00000000 ebx=7ffde000 ecx=00000001 edx=00422828 esi=0041dc5c edi=7c911970eip=77ee75fa esp=0012fd54 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0xc2:77ee75fa ff15d411ea77 &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;call dword ptr [SHLWAPI!_imp__GetFileAttributesA (77ea11d4)]&amp;lt;/font&amp;gt;0:000&amp;gt;eax=00000011 ebx=7ffde000 ecx=7c91056d edx=00140608 esi=0041dc5c edi=7c911970eip=77ee7600 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0xc8:77ee7600 83f8ff cmp eax,0FFFFFFFFh0:000&amp;gt;eax=00000011 ebx=7ffde000 ecx=7c91056d edx=00140608 esi=0041dc5c edi=7c911970eip=77ee7603 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz ac pe cycs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000217SHLWAPI!PathIsDirectoryA&#43;0xcb:77ee7603 74e5 je SHLWAPI!PathIsDirectoryA&#43;0xb2 (77ee75ea) [br=0]0:000&amp;gt;eax=00000011 ebx=7ffde000 ecx=7c91056d edx=00140608 esi=0041dc5c edi=7c911970eip=77ee7605 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz ac pe cycs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000217SHLWAPI!PathIsDirectoryA&#43;0xcd:77ee7605 83e010 &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;and eax,10h&amp;lt;/font&amp;gt;0:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=7c91056d edx=00140608 esi=0041dc5c edi=7c911970eip=77ee7608 esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz na po nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000202SHLWAPI!PathIsDirectoryA&#43;0xd0:77ee7608 ebe2 jmp SHLWAPI!PathIsDirectoryA&#43;0xb4 (77ee75ec)0:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=7c91056d edx=00140608 esi=0041dc5c edi=7c911970eip=77ee75ec esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz na po nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000202SHLWAPI!PathIsDirectoryA&#43;0xb4:77ee75ec 8b4dfc mov ecx,dword ptr [ebp-4] ss:0023:0012ff64=00007a430:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=00007a43 edx=00140608 esi=0041dc5c edi=7c911970eip=77ee75ef esp=0012fd58 ebp=0012ff68 iopl=0 nv up ei pl nz na po nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000202SHLWAPI!PathIsDirectoryA&#43;0xb7:77ee75ef 5e pop esi0:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=00007a43 edx=00140608 esi=0006f4cc edi=7c911970eip=77ee75f0 esp=0012fd5c ebp=0012ff68 iopl=0 nv up ei pl nz na po nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000202SHLWAPI!PathIsDirectoryA&#43;0xb8:77ee75f0 e82bcafbff call SHLWAPI!__security_check_cookie (77ea4020)0:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=00007a43 edx=00140608 esi=0006f4cc edi=7c911970eip=77ee75f5 esp=0012fd5c ebp=0012ff68 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0xbd:77ee75f5 c9 leave0:000&amp;gt;&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;eax=00000010&amp;lt;/font&amp;gt; ebx=7ffde000 ecx=00007a43 edx=00140608 esi=0006f4cc edi=7c911970eip=77ee75f6 esp=0012ff6c ebp=0012ff78 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246SHLWAPI!PathIsDirectoryA&#43;0xbe:77ee75f6 c20400 ret 40:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=00007a43 edx=00140608 esi=0006f4cc edi=7c911970eip=0040101f esp=0012ff74 ebp=0012ff78 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246IsPathDir!main&#43;0xf:0040101f 8945fc mov dword ptr [ebp-4],eax ss:0023:0012ff74=000000010:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=00007a43 edx=00140608 esi=0006f4cc edi=7c911970eip=00401022 esp=0012ff74 ebp=0012ff78 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246IsPathDir!main&#43;0x12:00401022 8b45fc mov eax,dword ptr [ebp-4] ss:0023:0012ff74=000000100:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=00007a43 edx=00140608 esi=0006f4cc edi=7c911970eip=00401025 esp=0012ff74 ebp=0012ff78 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246IsPathDir!main&#43;0x15:00401025 50 push eax0:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=00007a43 edx=00140608 esi=0006f4cc edi=7c911970eip=00401026 esp=0012ff70 ebp=0012ff78 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246IsPathDir!main&#43;0x16:00401026 6868dc4100 push offset IsPathDir!__xt_z&#43;0x12c (0041dc68)0:000&amp;gt;eax=00000010 ebx=7ffde000 ecx=00007a43 edx=00140608 esi=0006f4cc edi=7c911970eip=0040102b esp=0012ff6c ebp=0012ff78 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000246IsPathDir!main&#43;0x1b:0040102b e81a000000 call IsPathDir!printf (0040104a)0:000&amp;gt;&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;Resultado: 16.&amp;lt;/font&amp;gt;eax=0000000f ebx=7ffde000 ecx=004010e5 edx=004228b8 esi=0006f4cc edi=7c911970eip=00401030 esp=0012ff6c ebp=0012ff78 iopl=0 nv up ei ng nz ac pe nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000296IsPathDir!main&#43;0x20:00401030 83c408 add esp,80:000&amp;gt; Ou seja, para pastas locais a função simplesmente usa a conhecidíssima GetFileAttributes, que retorna o flag 0x10 setado caso se trate de uma pasta, de acordo com a documentação:
&amp;quot;The attributes can be one or more of the following values.
Return code/value DescriptionFILE_ATTRIBUTE_ARCHIVE A file or directory that is an archive file or directory.320x20FILE_ATTRIBUTE_COMPRESSED A file or directory that is compressed.20480x800...&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;FILE_ATTRIBUTE_DIRECTORY The handle that identifies a directory.160x10&amp;quot;&amp;lt;/font&amp;gt; Aqui termina nossa dúvida sobre o pequenino bug na documentação. E isso nos lembra também que é sempre bom comparar as coisas da melhor maneira possível. E essa melhor maneira em se tratando de ifs é supor apenas dois valores binário: ou é zero ou é não-zero.
</description>
</item>

     
        <item>
  <title>ProcessLeaker</title>
  <link>http://www.caloni.com.br/processleaker/</link>
  <pubDate>2008-08-21</pubDate>
  
  <guid>http://www.caloni.com.br/processleaker/</guid>
  <description>O artigo anterior mostrava como detectar o leak de um processo gerado pela retenção e não-liberação de handles para o Windows Explorer. O problema fora causado por um serviço malcriado. No entanto, a título de demonstração, criei um pequeno programinha sem-vergonha para fazer as coisas parecerem difíceis. No entanto o programa é bem fácil:
#include &amp;lt;windows.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;int main(){DWORD pid;while( scanf(&amp;#34;%d&amp;#34;, &amp;amp;pid) == 1 ){HANDLE proc = OpenProcess(SYNCHRONIZE, FALSE, pid);}}Para usá-lo, basta abrir um Gerenciador de Tarefas com opção de exibir o PID dos processos.

A partir daí, é só criar e matar várias instâncias do explorer.exe. Antes de matar um, digite o PID do novo processo no ProcessLeaker.
Para listar os processos perdidos, basta usar o comando &amp;quot;!process 0 0&amp;quot; no WinDbg depurando em kernel. O resto você já sabe.
</description>
</item>

     
        <item>
  <title>Quando o navegador não quer largar um arquivo</title>
  <link>http://www.caloni.com.br/quando-o-navegador-nao-quer-largar-um-arquivo/</link>
  <pubDate>2008-08-13</pubDate>
  
  <guid>http://www.caloni.com.br/quando-o-navegador-nao-quer-largar-um-arquivo/</guid>
  <description>De vez em quando gosto muito de um vídeo que estou assistindo. Gosto tanto que faço questão de guardar para assistir mais vezes depois. O problema é que o meu Firefox ou, para ser mais técnico, o plugin de vídeo que roda em cima do meu navegador, não permite isso. Ele simplesmente cria um arquivo temporário para exibir o vídeo e logo depois o apaga, utilizando uma técnica muito útil da função CreateFile, que bloqueia o acesso do arquivo temporário e apaga-o logo após o uso:
HANDLE WINAPI CreateFile(__in LPCTSTR lpFileName,__in DWORD dwDesiredAccess,&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt; __in DWORD dwShareMode,&amp;lt;/font&amp;gt;__in_opt LPSECURITY_ATTRIBUTES lpSecurityAttributes,__in DWORD dwCreationDisposition,&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt; __in DWORD dwFlagsAndAttributes,&amp;lt;/font&amp;gt;__in_opt HANDLE hTemplateFile); dwShareMode Value Meaning0 Disables subsequent open operations on a file or device0x00000000 to request any type of access to that file or device. dwFlagsAndAttributes Value MeaningFILE_FLAG_DELETE_ON_CLOSE The file is to be deleted immediately after all of itshandles are closed, which includes the specified handleand any other open or duplicated handles. Muito bem. Isso quer dizer que é possível abrir um arquivo que mais ninguém pode abrir (nem para copiar para outro arquivo), e ao mesmo tempo garante que quando ele for fechado será apagado. Isso parece uma ótima proteção de cópia não-autorizada para a maioria das pessoas.
Infelizmente, tudo isso roda sob limites muito restritos: um navegador, rodando em user mode, usando APIs bem definidas e facilmente depuráveis.
De volta ao WinDbg Antes de iniciar a reprodução do vídeo, e conseqüentemente a criação do arquivo temporário, podemos atachar uma instância do nosso depurador do coração e colocar um breakpoint onde interessa:
windbg -pn firefox.exeMicrosoft (R) Windows Debugger Version 6.8.0004.0 X86Copyright (c) Microsoft Corporation. All rights reserved.*** wait with pending attachSymbol search path is: SRV*C:\Symbols*http://msdl.microsoft.com/download/symbols;K:\Docs\ProjectsExecutable search path is:ModLoad: 00400000 00b64000 L:\FirefoxPortable\App\firefox\firefox.exeModLoad: 7c900000 7c9b4000 C:\WINDOWS\system32\ntdll.dllModLoad: 7c800000 7c8ff000 C:\WINDOWS\system32\kernel32.dll...ModLoad: 77a00000 77a55000 C:\WINDOWS\System32\cscui.dllModLoad: 765d0000 765ed000 C:\WINDOWS\System32\CSCDLL.dll(b58.ba8): Break instruction exception - code 80000003 (first chance)eax=7ffdb000 ebx=00000001 ecx=00000002 edx=00000003 esi=00000004 edi=00000005eip=7c901230 esp=021bffcc ebp=021bfff4 iopl=0 nv up ei pl zr na pe nccs=001b ss=0023 ds=0023 es=0023 fs=0038 gs=0000 efl=00000246ntdll!DbgBreakPoint:7c901230 cc int 30:017&amp;gt; bp &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;kernel32!CreateFileA&amp;lt;/font&amp;gt;0:017&amp;gt; bp &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;kernel32!CreateFileW&amp;lt;/font&amp;gt;0:017&amp;gt; gBreakpoint 2 hiteax=00000001 ebx=00000000 ecx=05432c10 edx=0000003e esi=0532ea00 edi=00000000eip=7c831f31 esp=0317fdc4 ebp=0317fde8 iopl=0 nv up ei pl nz na po nccs=001b ss=0023 ds=0023 es=0023 fs=003b gs=0000 efl=00000202kernel32!CreateFileW:7c810760 8bff mov edi,edi Nesse momento podemos dar uma boa olhada nos parâmetros 4 e 6 da função para ver se trata-se realmente da proteção prevista (na verdade, prevista, nada; esse é um artigo baseado em uma experiência passada; vamos imaginar, contudo, que estamos descobrindo essas coisas como na primeira vez).
0:000&amp;gt; dd esp0012f30c 300afc06 03f91920 c0000000 &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;00000000&amp;lt;/font&amp;gt;0012f31c 00000000 00000002 &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;14000000&amp;lt;/font&amp;gt; 00000000 Como podemos ver, o modo de compartilhamento do arquivo é nenhum. Entre os flags definidos no sexto parâmetro, está o de apagar o arquivo ao fechar o handle, como pude constatar no header do SDK:
Nesse caso, a solução mais óbvia e simples foi deixar esse bit desabilitado, não importando se o modo de compartilhamento está desativado. Tudo que temos que fazer é assistir o vídeo mais uma vez e fechar a aba do navegador. O arquivo será fechado, o compartilhamento aberto, e o arquivo, não apagado.
0:012&amp;gt; bp kernel32!CreateFileW &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;&amp;quot;ed @esp&#43;4*6 poi(@esp&#43;4*6) &amp;amp; 0xfbffffff&amp;quot;&amp;lt;/font&amp;gt;breakpoint 1 redefined0:012&amp;gt; bp kernel32!CreateFileA &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;&amp;quot;ed @esp&#43;4*6 poi(@esp&#43;4*6) &amp;amp; 0xfbffffff&amp;quot;&amp;lt;/font&amp;gt;breakpoint 0 redefined0:012&amp;gt; g E agora posso voltar a armazenar meus vídeos favoritos.
</description>
</item>

     
        <item>
  <title>Aprendizado em kernel mode</title>
  <link>http://www.caloni.com.br/aprendizado-em-kernel-mode/</link>
  <pubDate>2008-08-07</pubDate>
  
  <guid>http://www.caloni.com.br/aprendizado-em-kernel-mode/</guid>
  <description>Hoje terminei minha primeira leitura de Memory Dump Analysis Vol. 1, e qual não foi a minha surpresa ao encontrar entre os últimos posts justamente o que eu estava precisando: um guia de livros que se deve ler para começar a programar em kernel mode.
O melhor de tudo nem é a lista de livros, cujos títulos já estão batidos na minha cabeça de tanto meu amigo Ferdinando comentar a respeito. A grande sacada foi ele ter feito um roteiro no estilo &amp;quot;leia esse livro primeiro, depois comece com esse e ao mesmo tempo acompanhe aquele, sempre atento ao Windows Internals&amp;quot;. As coisas não ficam mais fáceis (ler 8 livros, todos com média de 700 páginas), mas pelo menos ficam mais organizadas, tem começo, meio e fim (será?).
Claro, esse é o método Dmitry Vostokov, o que não quer dizer que funciona com qualquer um. No entanto, gosto de suas buscas de padrão, analogias de dumps com o mundo real, abstrações filosóficas e, principalmente, as explicações das telas azuis em UML. Se entendo facilmente essa forma de explicar, é possível que esse método facilite um poucos as coisas não-tão-fáceis de fazer para mim.
Agora só falta começar =).
</description>
</item>

     
        <item>
  <title>Aprenda a usar sua API</title>
  <link>http://www.caloni.com.br/aprenda-a-usar-sua-api/</link>
  <pubDate>2008-07-22</pubDate>
  
  <guid>http://www.caloni.com.br/aprenda-a-usar-sua-api/</guid>
  <description>É conhecido que uma das desvantagens de se programar diretamente em Win32 API é a dificuldade de se entender os parâmetros e o retorno das funções. Concordo em parte. Constituída de boa documentação, parte da culpa dos programas mal-feitos reside na preguiça do programador em olhar a documentação por completo.
A Win32 API está longe de ser perfeita, mas pelo menos está razoavelmente documentada, e é na leitura atenta da documentação que iremos encontrar as respostas que precisamos para que o programa funcione.
Vejamos alguns exemplos.
1. CreateFile O código abaixo parece bem razoável:
#include &amp;lt;windows.h&amp;gt;int main(){HANDLE hFile = CreateFile(&amp;#34;c:\\tests\\myfile.txt&amp;#34;, GENERIC_READ, FILE_SHARE_READ, NULL, OPEN_EXISTING, 0, NULL);if( hFile ){DWORD read = 0;CHAR buffer[100];if( ReadFile(hFile, buffer, sizeof(buffer), &amp;amp;read, NULL) ){WriteBuffer(buffer);}CloseHandle(hFile);}}No entanto, está errado.
É fato que a maioria das funções que retornam handles retornam NULL para indicar o erro na tentativa de obter o recurso. Ao comparar o retorno com NULL, o programador geralmente faz uma chamada a GetLastError para saber o que aconteceu. No entanto, uma das funções mais usadas, a CreateFile, não retorna NULL, mas INVALID_HANDLE_VALUE.
Sendo assim, o código acima deveria ser:
if( hFile != INVALID_HANDLE_VALUE ) 2. GetVersion Taí uma função que muitos erraram. Erraram tanto que eles fizeram uma nova versão menos complicada. Como está escrito no MSDN:
O motivo de tantos erro pode ter sido o fato que o valor retornado é uma estrutura de bits dentro de um DWORD, coisa que nem todos programadores C sabem lidar muito bem, e o fato de ser uma função muito utilizada por todos (pegar a versão do sistema operacional).
Eis a tabela de campos do retorno de GetVersion:
Platform High-order bit Next 7 bits Low-order byte------------------------------------- -------------- ------------ --------------Windows NT 3.51 0 Build number 3Windows NT 4.0 0 Build number 4Windows 2000 or Windows XP 0 Build number 5Windows 95, Windows 98, or Windows Me 1 Reserved 4Win32s with Windows 3.1 1 Build number 3 Mesmo que não seja tão difícil, pode ser ambíguo. Por exemplo, como saber se o Windows é 95, 98 ou ME?
O código abaixo, muito usado por todos que suportam ainda o Windows mais velhinhos, verifica se estamos rodando em plataforma NT ou 9x.
#include &amp;lt;windows.h&amp;gt;#include &amp;lt;stdio.h&amp;gt;int main(){DWORD winVer = GetVersion();BOOL isPlatformNT = winVer &amp;gt;= 0x80000000 ? FALSE : TRUE;if( isPlatformNT )printf(&amp;#34;Plataforma NT\n&amp;#34;);elseprintf(&amp;#34;Bem-vindo ao parque dos dinossauros!\n&amp;#34;);return isPlatformNT ? 1 : 0;}3. CloseHandle. Mesmo?? Nem sempre o handle que obtemos é fechado com CloseHandle. As funções abaixo retornam handles que devem ser desalocados com as funções à direita:
Função que obtém recurso Função que libera recurso------------------------ -------------------------LoadLibrary FreeLibraryRegOpenKey RegCloseKeyGetDC ReleaseDCBeginPaint EndPaint 4. Tem mais? Sempre tem. Algumas dicas úteis para o dia-a-dia de um programador Win32 API são:
  Leia a documentação
  Se atente aos valores de retorno em caso de sucesso e erro
  Leia sempre a seção remarks pelo menos uma vez; ela explica como desalocar recursos
  Releia a documentação
  Às vezes uma singela chamada de uma função de autenticação pode nos fazer preencher uma estrutura de 20 membros, sendo que seis deles são obtidos com mais sete chamadas de funções, todas com direito a desalocar recursos no final. O importante é sempre manter a calma, o espírito de aprendizado e aventura. Afinal, quem mandou não fazer software de telinha?
</description>
</item>

     
        <item>
  <title>Segunda versão do Houaiss2Babylon</title>
  <link>http://www.caloni.com.br/segunda-versao-do-houaiss2babylon/</link>
  <pubDate>2008-07-14</pubDate>
  
  <guid>http://www.caloni.com.br/segunda-versao-do-houaiss2babylon/</guid>
  <description>Depois de vários comentários de pessoas tendo problemas em converter seus dicionários Houaiss para o formato Babylon, resolvi criar vergonha na cara e dar uma pequena melhora na versão beta do conversor.
Agora a maioria dos erros que houver será descrita por uma mensagem no seguinte formato:
O primeiro erro acima ocorre principalmente se não houver algum Houaiss instalado que o programa possa detectar. Resolva este problema fazendo uma busca no Buscapé.
Abaixo segue a função criada para exibir essas mensagens:
void MessageError(DWORD err, PCSTR msg, ...){CHAR errBuffer[100];CHAR msgBuffer[ERR_STR_BUF_SIZE];va_list vaList;va_start(vaList, msg);vsprintf(msgBuffer, msg, vaList);va_end(vaList);sprintf(errBuffer, &amp;#34; Erro de sistema número %d.&amp;#34;, (int) err);strcat(msgBuffer, errBuffer);MessageBox(NULL, msgBuffer, STR_PROJECT_NAME, MB_OK | MB_ICONERROR);}Um pouco sobre argumentos variáveis Se você notou, a função acima pode receber um número de argumentos variáveis para formatar a string da mensagem principal do erro, além de exibir seu código. Essa mágica pode ser feita usando-se o cabeçalho padrão &amp;quot;stdarg.h&amp;quot;. Através dele temos acesso ao tipo va_list, que representa uma lista de argumentos variáveis.
Pela convenção de chamada da linguagem C (e C&#43;&#43;), quem desmonta a pilha é o chamador. Sendo assim, a função chamada não precisa conhecer o número de argumentos com que foi chamado.
A função de formatação de string é uma variante do conhecidíssimo printf, na versão que recebe um tipo va_list. Muito útil para formatação de logs.
Atualizado A versão beta do Houaiss2Babylon está para sair. Não estarei mais atualizando o saite do projeto no LaunchPad. Aguardem por mais novidades no próprio blogue.
</description>
</item>

     
        <item>
  <title>Projeto-modelo</title>
  <link>http://www.caloni.com.br/projeto-modelo/</link>
  <pubDate>2008-07-08</pubDate>
  
  <guid>http://www.caloni.com.br/projeto-modelo/</guid>
  <description>É muito difícil construir um modelo de pastas que sirva para a maioria dos projetos que tivermos que colocar na fôrma. Ainda mais se esses projetos tiverem que futuramente fazer parte da mesma ramificação. Foi pensando em várias coisas que chegamos a uma versão beta que pode ajudar aqueles que ficam pensando durantes dias antes mesmo de colocar as mãos no código.
Primeira coisa: controle de código Antes de começar a pensar em como as pastas estarão alinhadas, é importante saber como funcionará o controle de código do seu projeto. Como eu disse sobre o Bazaar, a estrutura inicial permitirá a junção de dois projetos distintos se estes compartilharem do mesmo commit no começo de suas vidas.
Portanto, trate de iniciar a estruturação em um projeto-modelo que já contenha pelo menos um commit: o das pastas vazias já estruturadas.
bzr init _Templatecd _Templatebzr mkdir Docsbzr mkdir Interfacebzr ...bzr ci -m &amp;quot;Projeto-modelo. Herde desse projeto sua estrutura inicial&amp;quot; Estruturação proposta Build. Essa pasta contém tudo que é necessário para compilar e testar o projeto como um todo. Idealmente a execução da batch build.bat deve executar todo o processo. Após a compilação, é de competência dos componentes na subpasta Tests fazer os testes básicos do projeto para se certificar de que tudo está funcionando como deveria.
Common. Aqui devem ser colocados aqueles includes que servem para vários pontos do projeto. Está exemplificado pelo arquivo de versão (Version.h), pois todos os arquivos devem referenciar uma única versão do produto. Podem existir Outras definições básicas, como nome do produto, dos arquivos, etc. É aqui que são gravadas as interfaces que permitem dependência circular entre os componentes (e.g. Interface de componentes COM).
Docs. Aqui deve ser colocada toda a documentação que diz respeito ao projeto. A organização interna ainda não foi definida, pois imagina-se ser possível usar diversas fontes, como doxygen, casos de uso, bugs, arquivos de projeto e UML. Foi exemplificado com o arquivo todo.txt e changes.txt, que deve ter sempre a lista de coisas a fazer e a lista de coisas já feitas, respectivamente, tendo, portanto, que ser sempre atualizados.
Drivers. Essa é a parte onde ficam todos os componentes que rodam em kernel mode. Por se tratar de um domínio específico e muitas vezes compartilhar código-fonte de maneira não-heterodoxa (e.g. sem uso de LIBs), faz sentido existir uma pasta que agrupe esses elementos. Dentro da pasta existem subpastas para cada driver, exemplificados em Driver1 e Driver2.
Install. Todas as coisas relacionadas com instalação, desinstalação e atualização do software deve vir nessa pasta. Foi reservada uma subpasta para cada item, não sendo obrigatória sua divisão. Também existe uma pasta de DLLs, onde possivelmente existam telas personalizadas e biblioteca de uso comum pelos instaladores (o desinstalador conversa com o instalador e assim por diante).
Interface. Todas as telas de um programa devem ser colocadas nessa pasta. Essa é uma divisão que deve ser seguida conceitualmente. Por exemplo, se existir um gerenciador de alguma coisa no produto, as telas do gerenciador e o comportamento da interface ficam nessa pasta, mas o comportamento intrínseco do sistema (regras de negócio) devem ficar em Libraries. Para exemplificar o uso, foram criadas as Interface1 e Interface2.
Libraries. O ponto central do projeto, deve conter o código mais importante. Imagine a pasta Libraries como a inteligência de um projeto, de onde todos os outros componentes se utilizam para que a lógica do software seja sempre a mesma. As outras partes do projeto lidam com aspectos técnicos, enquanto o Libraries contém as regras abstratas de funcionamento. Opcionalmente ela pode ser estática ou dinâmica, caso onde foi criada a subpasta DLLs. Porém, elas devem ser divididas por função em bibliotecas estáticas, como foi exemplificado em Library1 e Library2.
Resources. A origem de todas as imagens, sons, cursores, etc de um projeto devem residir primeiramente na pasta Resources. A divisão interna desse item fica a critério do designer responsável, pois ele pode dividir tanto por função (Install, Interface) quanto por elementos (Images, Sounds).
Services. Além dos drivers e das interfaces alguns projetos necessitam de processos &amp;quot;invisíveis&amp;quot; que devem fazer algo no sistema. Isso inclui serviços do Windows, GINAs, componentes COM e coisas do gênero. Devem ser colocados nessa pasta e distribuídos como no exemplo, em Service1 e Service2.
Tools. Além dos componentes essenciais para o funcionamento do software também existem aqueles componentes que fornecem mais poder ao usuário, ao pessoal do suporte ou ao próprio time de desenvolvimento. Essas são as ferramentas de suporte que permitem a fácil identificação de erros no programa ou a configuração mais avançada de um item que a Interface não cobre. Adicionalmente foi colocada a subpasta Develop, que deve conter ferramentas usadas estritamente durante a fase de desenvolvimento.
Testes Todos os componentes que disponibilizarem unidades de testes devem conter uma pasta Tests dentro de si. Essa padronização permite facilmente a localização de testes internos aos componentes. Além disso, os arquivos executáveis de testes devem sempre terminar seu nome com Test, o que permite a automatização do processo de teste durante o build.
Acredito que este esboço esteja muito bom. É o modelo inicial que estou utilizando nos projetos da empresa e de casa. Deixo disponível aqui para download. Críticas e sugestões são bem-vindas.
</description>
</item>

     
        <item>
  <title>VirtualBox</title>
  <link>http://www.caloni.com.br/virtualbox/</link>
  <pubDate>2008-07-04</pubDate>
  
  <guid>http://www.caloni.com.br/virtualbox/</guid>
  <description>O VirtualBox parece ser o concorrente mais próximo atualmente da VMWare. Descobrimos ele essa semana e resolvemos fazer alguns testes. O resultado foi bem animador.
Desenvolvido pela Sun Microsystems, as características do VirtualBox impressionam pelo cuidado que houve em torná-lo muito parecido com sua concorrente paga. Apenas para começar, ela suporta dispositivos USB, possui múltiplos snapshots e já suporta o modo do VMWare Fusion - chamado de &amp;quot;seamless mode&amp;quot; - , que estará integrado na versão 7 da VMWare.
No entanto, entre as coisas que testamos (instalado em um Windows Vista SP1 como host), o que não funcionou já não agradou tanto. A lista de prós e contras ainda confirma a liderança da VMWare, pelo menos em qualidade:
Funcionalidade VMWare VirtualBoxSnapshots Sim Sim. Mesma velocidade.USB Sim Sim. Não funcionou.Seamless Mode Não Sim.Clipboard Sim Sim. Não funcionou.Shared Folders Sim Sim. Erros de acesso.Ferramentas Guest Sim Sim.Pause Momentâneo Não Sim. Além da tabela de testes acima, é necessário notar que por mas três vezes a VM simplesmente parou de responder, sendo necessário reiniciar o programa Host.
Em suma, o VirtualBox tem tudo para arrasar em futuras versões. Se, é claro, conseguir competir em qualidade com a VMWare que, no momento, é a líder em soluções de virtualização. Talvez por isso sua solução não seja tão barata.
</description>
</item>

     
        <item>
  <title>Primeiros passos na documentação de código-fonte usando Doxygen</title>
  <link>http://www.caloni.com.br/primeiros-passos-na-documentacao-de-codigo-fonte-usando-doxygen/</link>
  <pubDate>2008-06-26</pubDate>
  
  <guid>http://www.caloni.com.br/primeiros-passos-na-documentacao-de-codigo-fonte-usando-doxygen/</guid>
  <description>Comentários são essenciais em um código-fonte bem feito. O código pode até fazer milagres, salvar vidas e multiplicar pães, mas se não tiver um apóstolo eficiente que escreva um evangelho para ele, as pessoas não vão conseguir usar!
OK, a analogia foi horrível.
Bom, já que é pra fazer comentários, porque não fazê-los de uma forma que seja possível extrair todo esse texto diretamente do fonte e transformá-lo em documentação? Dessa forma você evita ter que abrir o Word (arght!) e evita que a documentação fique desatualizada quando o documentador do seu projeto for embora da empresa.
Vocês não têm documentador no projeto? Ah, tá. Bem-vindo ao grupo.
Doxygen O Doxygen é uma ferramenta que consegue extrair comentários do seu código-fonte, formatados ou não, e transformar em arquivos html, doc, chm, etc. O resultado é muito impressionante, pois ele é capaz de interpretar algumas linguagens (como C&#43;&#43;) e mostrar a hierarquia de classes e funções.
Ele não obriga que o desenvolvedor formate corretamente os comentários, mas ao fazer isso podemos descrever o funcionamento exato de funções de interface, como o que cada parâmetro significa, o valor de retorno, algumas observações quanto ao uso, etc.
Aprender a usar Doxygen é muito fácil. Ele possui uma ajuda com vários exemplos com os quais podemos começar a programar um código auto-documentado.
Primeiras regras Por ser uma ferramenta bem flexível, são permitidos inúmeros formatos para se auto-documentar o código. Vou descrever como eu faço, mas pode ser que outro formato lhe agrade mais. Para conhecê-los, dê uma olhada no manual.
A primeira coisa a saber sobre comentários de documentação é que eles devem vir sempre ANTES do elemento que estamos comentando. Por exemplo, uma classe:
/** Nova classe de exemplo** Essa classe é um exemplo de como utilizar o Doxygen*/class ClasseDeExemplo{// ...}; Note que o comentário inicia com um duplo asterisco &amp;quot;/**&amp;quot;. Isso indica ao Doxygen que vem documentação por aí.
Também existe um outro formato bem popular, usado pelo pessoal do Java, que são os comentários que se iniciam com três barras:
////// Nova classe de exemplo////// Essa classe é um exemplo de como utilizar o Doxygen/// E esse comentário é equivalente ao anterior///class ClasseDeExemplo{// ...}; Além desse estilo de comentário, existem campos-chave que podemos colocar. Para definir um campo-chave, uma forma válida é usar o arroba seguido do seu nome, e a descrição. Eis um exemplo cheio deles:
/** &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;@brief&amp;lt;/font&amp;gt; Função de exemplo** Essa função tem por objetivo exemplificar o uso do Doxygen** &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;@param&amp;lt;/font&amp;gt; firstParam Serve como primeiro parâmetro da função* &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;@param[out]&amp;lt;/font&amp;gt; anotherParam Esse é outro parâmetro que recebemos** &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;@return&amp;lt;/font&amp;gt; Se der erro, retorna -1. Se der tudo certo, 0.** &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;@remarks&amp;lt;/font&amp;gt; Essa função não pode ser chamada antes de ChamaEuPrimeiro.*/int FuncaoDeExemplo(int firstParam, int anotherParam){// ...} Vejamos:
  brief. Serve como descrição inicial e sucinta do que a função faz. Mais explicações podem existir depois dessa primeira linha introdutória.
  param. Descreve o objetivo de um parâmetro, assim como se ele é de entrada ou saída.
  return. Explica os diversos retornos que a função pode ter.
  remark. Observações especiais que podem ajudar quem chama a função.
  Existem diversos outros tipos de marcadores e com certeza você encontrará muita utilidade em outros. No entanto, esse é o basico que todo desenvolvedor do seu time deve saber para já começar a documentar suas funções.
Mais artigos interessantes  Usando o Doxygen (Parte 1 e Parte 2) - Daniel Quadros  </description>
</item>

     
        <item>
  <title>Como estou trabalhando com o Bazaar</title>
  <link>http://www.caloni.com.br/como-estou-trabalhando-com-o-bazaar/</link>
  <pubDate>2008-06-24</pubDate>
  
  <guid>http://www.caloni.com.br/como-estou-trabalhando-com-o-bazaar/</guid>
  <description>Depois de alguns ajustes e muitas perguntas do meu amigo-colega desenvolvedor Rafael, conseguimos definir alguns usos e costumes em nosso código controlado pelo Bazaar. Este é um guia para Dummies de como é possível organizar um ou mais projetos de forma a favorecer o _refactoring _e a liberdade de uso.
Primeiro passo: padrão de árvore Nosso padrão de diretórios utiliza um repositório compartilhado e dentro, na mesma ramificação, os branches. O _branch _principal tem o mesmo nome do projeto. Isso na máquina de um desenvolvedor ficaria:
c:\src\project1|-- project1 (branch principal)|-- bug-da-tela-azul (branch secundário e temporário)|-- nova-tela-de-login (branch secundário e temporário) No servidor de fontes geralmente teremos apenas o _branch _principal, apesar de que o desenvolvimento em paralelo seja permitido:
c:\src\project1|-- project1 (branch principal)|-- 2.4.1 (branch secundário em desenvolvimento paralelo) Segundo passo: projeto-modelo Foi criado um projeto modelo para que todos os projetos herdassem seu histórico. Para que isso? Bom, na eventualidade de partes de um projeto irem parar em outro (isso quase nunca acontece), isso pode ser feito sem perder todo o histórico do início do projeto.
Resumindo: todos os projetos novos são _branches _do projeto-modelo.
bzr init-repo _templatecd _templatebzr init _templatehack hack hackbzr commit -m &amp;quot;Primeira versao de nosso projeto-modelo&amp;quot; Como podemos ver acima, o projeto modelo segue o mesmo padrão de repositório compartilhado. Os projetos que criarmos serão baseados nesse projeto modelo, mas em outro repositório compartilhado.
bzr init-repo novo-projetobzr branch _template\_template novo-projeto\novo-projetocd novo-projeto\novo-projetohack hack hackbzr commit -m &amp;quot;Primeira versao de nosso novo projeto&amp;quot; A ramificação dos projetos estará sempre no mesmo lugar, independente da pasta raiz.
c:\src\--_template| || -- _template|-- novo-projeto| || -- novo-projeto|-- mais-um-projeto|-- mais-um-projeto Terceiro passo: elegendo um servidor O controle distribuído de fontes não significa que não existe um servidor. Existe. O detalhe é que todos os desenvolvedores guardam todo o histórico do projeto com eles, igualzinho o servidor, que é apenas mais uma máquina com mais um branch.
O repositório do servidor pode ser criado com a opção que não cria o diretório de trabalho, que é onde os programadores mexem no código-fonte. Sendo um servidor, o código-fonte não é necessário, só a base de dados:
bzr init-repo --no-trees novo-projetobar branch \\desenvolvedor\src\novo-projeto\novo-projeto novo-projeto\novo-projeto Quarto passo: tornando disponível o servidor O Bazzar possui um esquema de servidor embutido nele, que fica escutando em uma porta e se comunica em um protocolo otimizado. Nós gostamos desse esquema, pois protege os projetos de acidentes de usuários que podem apagar uma pasta sem querer.
Para manter o Bazaar eternamente rodando, usamos o programa do DriverEntry que transforma qualquer coisa no formato de um serviço de gelo.
prog2svc -add Bazaar &amp;quot;c:\program files\Bazaar\bzr.exe serve --allow-writes --diretory=c:\src&amp;quot; Ou não sei usar direito esse programa ou ele não permite uso de aspas no nome do aplicativo junto de argumentos. Por isso tive que editar o registro onde ele fica para colocar aspas duplas em torno do bzr.exe.

Após isso, ainda temos que configurar o serviço para iniciar automaticamente e usar um usuário conhecido. Enquanto o computador estiver ligado, mesmo que sem sessões abertas, nenhuma tela irá aparecer, mas o Bazaar estará rodando e ativo, escutando em sua porta padrão:

Se estiver tudo certo, ao iniciar o serviço o Bazaar passará a ficar escutando e pronto para fazer _commits _e branches.

Agora qualquer usuário da rede consegue fazer _updates _e _commits. _Um desenvolvedor novo faria o seguinte comando:
bzr init-repo projetobzr branch bzr://servidor/projeto projeto\projeto Quinto passo: ensinando as pessoas a usar O Bazaar por ser muito flexível entra naquela categoria de &amp;quot;Difícil de acertar a maneira certa de utilizar&amp;quot;. Bom, mais ou menos. Eu sinceramente não acho que exista uma maneira errada de usar o Bazaar, mas vamos ver as maneiras mais comuns, que não são exclusivas entre si.
Desenvolvedor standalone É aquele que prefere fazer tudo localmente e só depois, bem depois, mandar seus _commits _para o servidor. Nesse caso o comando para começar a programar é branch.
bzr branch bzr://servidor/projeto projeto\projeto Nesse esquema o servidor e a máquina do desenvolvedor não trocam idéia se ele não quiser. Quando quiser, pode usar os comandos push, pull e merge. O push coloca coisas novas no servidor; o pull puxa coisas novas do servidor, e o merge é necessário quando existem conflitos entre as mudanças no fonte. Mais sobre conflitos em um futuro artigo.
Desenvolvedor conectado É o cara que quer sempre atualizar todas as modificações que ele faz imediatamente colocadas no servidor. Tudo bem. É só trabalhar no modo Source Safe (ou Subversion) com o comando checkout:
bzr checkout bzr://servidor/projeto projeto\projeto Um checkout funciona como o _branch, _só que faz um _bind _(ligação) com o servidor. O que quer dizer que qualquer _commit _feito localmente irá parar imediatamente também no servidor, a não ser que seja usado o parâmetro --local.
bzr commit -m &amp;quot;Eu sei que isso vai ser feito aqui e no servidor&amp;quot;bzr commit --local -m &amp;quot;Apenas umas mudancinhas; depois jogo no servidor&amp;quot; O modo _checkout _permite usar o comando update para ver se existem mudanças entre a máquina local e o servidor, diferente do modo _standalone, _onde o _update _apenas compara com o _branch _local e o diretório de trabalho.
bzr update Desenvolvedor polivalente Como eu havia dito, uma coisa não exclui outra. Se você está trabalhando em um _branch _e deseja se conectar ao servidor para atualizar mudanças, basta usar o comando bind.
bzr bind bzr://servidor/projeto projeto\projeto O _branch _começará a trabalhar como um checkout.
O contrário, que é fazer um _checkout _ficar desconectado é conseguido pelo comando unbind.
bzr unbind Todos os novos _commits _serão feitos apenas localmente.
Trabalhando na sua máquina Esses esquemas de conectado e desconectado podem ser usados no modo cliente x servidor ou tudo em uma máquina só. Por exemplo, uma série de mudanças em um projeto pode ser feito em um outro _branch _desconectado:
bzr branch projeto novo-branch Os _commits _de &amp;quot;novo-branch&amp;quot; não serão replicados para o _branch _&amp;quot;projeto&amp;quot;.
No entanto, se é uma série de mudanças que devem ser colocadas imediatamente no _branch _principal, pode-se usar checkout.
bzr checkout projeto novo-branch Existem diversas outras formas de usar o Bazaar, e isso está sob o controle do desenvolvedor. O importante para quem está migrando é saber definir alguns padrões (onde é o servidor principal, ramificação dos projetos) e o resto é só programar, exatamente como antes.
</description>
</item>

     
        <item>
  <title>Como fazer merge de projetos distintos no Bazaar</title>
  <link>http://www.caloni.com.br/como-fazer-merge-de-projetos-distintos-no-bazaar/</link>
  <pubDate>2008-06-16</pubDate>
  
  <guid>http://www.caloni.com.br/como-fazer-merge-de-projetos-distintos-no-bazaar/</guid>
  <description>O problema foi o seguinte: Nós iniciamos o controle de fonte pelo Bazaar na parte Linux do projeto, já que ela não iria funcionar pelo Source Safe, mesmo. Dessa forma apenas um braço do projeto estava no controle de fonte e o resto não.
No segundo momento da evolução decidimos começar a migrar os projetos para o Bazaar, inclusive a parte daquele projeto que compila no Windows. Maravilha. Ambos sendo controlados é uma beleza, não é mesmo?
Até que veio o dia de juntar.
O processo de _merge _de um controle de fonte supõe que os _branches _começaram em algum ponto em comum; do contrário não há como o controlador saber as coisas que mudaram em paralelo. Pois é achando a modificação ancestral, pai de ambos os branches, que ele irá medir a dificuldade de juntar as versões novamente. Se não existe ancestral, não existe análise. Como exemplificado na figura:

Se baseando no rebase Acontece que existe um _plugin _esperto que consegue migrar revisões (commits) entre _branches _sem qualquer parentesco. Não me pergunte como ele faz isso. Mas ele faz. E foi assim que resolvemos o problema dos _branches _órfãos.
Para instalar o _plugin _do rebase, basta baixá-lo e copiar sua pasta extraída com um nome válido no Python (rebase, por exemplo). A partir daí os comandos do _plugin _estão disponíveis no _prompt _do Bazaar, assim como a instalação de qualquer _plugin _que cria novos comandos.
&amp;gt;bzr help commandsadd Add specified files or directories.annotate Show the origin of each line in a file.bind Convert the current branch into a checkout of the supplied branch.branch Create a new copy of a branch....push Update a mirror of this branch.&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;rebase Re-base a branch. [rebase]rebase-abort Abort an interrupted rebase [rebase]rebase-continue Continue an interrupted rebase after resolving conflicts [rebase]rebase-todo Print list of revisions that still need to be replayed as part of the [rebase]&amp;lt;/font&amp;gt;reconcile Reconcile bzr metadata in a branch.reconfigure Reconfigure the type of a bzr directory.register-branch Register a branch with launchpad.net. [launchpad]remerge Redo a merge.remove Remove files or directories.remove-tree Remove the working tree from a given branch/checkout.renames Show list of renamed files.&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;replay Replay commits from another branch on top of this one. [rebase]&amp;lt;/font&amp;gt;resolve Mark a conflict as resolved.revert Revert files to a previous revision....whoami Show or set bzr user id. Fica de olho no replay! O comando que usamos foi o replay, que não é comando principal do _plugin, _mas que resolve esse problema de maneira quase satisfatória. Como era tudo o que tínhamos, valeu a pena.
O processo que usei foi de usar esse comando n vezes para buscar revisões de um branch e colocar no outro. Um grande problema com ele é que ao encontrar merges no branch origem ele se perde e o usuário tem que fazer as modificações &amp;quot;na mão&amp;quot;. Deu um pouco de trabalho, mas conseguimos migrar nossos _commits _mais importantes e deixar o projeto inteiro, Linux&#43;Windows, em um _branch _só.
C:\Tests&amp;gt;bzr init linuxC:\Tests&amp;gt;cd linuxC:\Tests\linux&amp;gt;copy con lnxlinux^Z1 arquivo(s) copiado(s).C:\Tests\linux&amp;gt;bzr addadded lnxC:\Tests\linux&amp;gt;bzr commit -m &amp;quot;Linux 1&amp;quot;Committing to: C:/Tests/linux/added lnxCommitted revision 1.C:\Tests\linux&amp;gt;copy con lnx2linux2^Z1 arquivo(s) copiado(s).C:\Tests\linux&amp;gt;bzr addadded lnx2C:\Tests\linux&amp;gt;bzr commit -m &amp;quot;Linux 2&amp;quot;Committing to: C:/Tests/linux/added lnx2Committed revision 2.C:\Tests\linux&amp;gt;cd ..C:\Tests&amp;gt;bzr init windowsC:\Tests&amp;gt;cd windowsC:\Tests\windows&amp;gt;copy con win1windows^Z1 arquivo(s) copiado(s).C:\Tests\windows&amp;gt;bzr addadded win1C:\Tests\windows&amp;gt;bzr commit -m &amp;quot;Windows 1&amp;quot;Committing to: C:/Tests/windows/added win1Committed revision 1.C:\Tests\windows&amp;gt;copy con win2windows2^Z1 arquivo(s) copiado(s).C:\Tests\windows&amp;gt;bzr addadded win2C:\Tests\windows&amp;gt;bzr commit -m &amp;quot;Windows 2&amp;quot;Committing to: C:/Tests/windows/added win2Committed revision 2.C:\Tests\linux&amp;gt;cd ..C:\Tests&amp;gt;cd linuxC:\Tests\linux&amp;gt;bzr replay ..\windows -r1..2All changes applied successfully.Committing to: C:/Tests/linux/added win1Committed revision 3.All changes applied successfully.Committing to: C:/Tests/linux/added win2Committed revision 4.C:\Tests\linux&amp;gt;bzr log------------------------------------------------------------revno: 4committer: Wanderley Caloni &amp;lt;wanderley@caloni.com.br&amp;gt;branch nick: windowstimestamp: Mon 2008-06-16 07:17:10 -0300message:Windows 2------------------------------------------------------------revno: 3committer: Wanderley Caloni &amp;lt;wanderley@caloni.com.br&amp;gt;branch nick: windowstimestamp: Mon 2008-06-16 07:16:52 -0300message:Windows 1------------------------------------------------------------revno: 2committer: Wanderley Caloni &amp;lt;wanderley@caloni.com.br&amp;gt;branch nick: linuxtimestamp: Mon 2008-06-16 07:16:24 -0300message:Linux 2------------------------------------------------------------revno: 1committer: Wanderley Caloni &amp;lt;wanderley@caloni.com.br&amp;gt;branch nick: linuxtimestamp: Mon 2008-06-16 07:16:01 -0300message:Linux 1C:\Tests\linux&amp;gt;lslnx lnx2 win1 win2C:\Tests\linux&amp;gt; </description>
</item>

     
        <item>
  <title>Primeiro ano do novo Caloni.com.br</title>
  <link>http://www.caloni.com.br/primeiro-ano-do-novo-calonicombr/</link>
  <pubDate>2008-06-13</pubDate>
  
  <guid>http://www.caloni.com.br/primeiro-ano-do-novo-calonicombr/</guid>
  <description>Melhor que ter feito aniversário de dois anos no antigo blogue foi ter feito o primeiro aninho nesse novo formato, mais atualizado, mais diversificado e mais antenado com o meu dia-a-dia real.
No dia 14 de junho de 2007 foram publicadas as boas vindas, e desde então o número de artigos tem se mantido sempre no formato três por semana, dois por semana, consecutivamente, distribuídos na segunda, quarta e sexta, terça e quinta. Esse jogo de xadrez tem me mantido bem ocupado, admito, mas no final até que vale a pena. Chegamos à marca de 130 artigos e 182 comentários dentro de 29 categorias.
E por falar em variedade, falamos de vários assuntos desde o início. Entre um devaneio e outro, conseguimos explorar algumas particularidades das linguagens C/C&#43;&#43;, o funcionamento obscuro do Windows, algumas dicas sobre programação e ferramentas, e até tivemos tempo de explorar coisas mais específicas, como depuração, engenharia reversa, controle de fonte e C&#43;&#43; Builder.
No placar, as coisas ficaram mais ou menos distribuídas:
Assunto	ArtigosProgramação	10C&#43;&#43;	31Windows	11Depuração	10WinDbg	18Dicas	27Código	15 Sobre os visitantes, eles ainda são uma incógnita. Relacho meu, admito. Não faço nem uma simples pesquisa para saber se a maioria está no nível iniciante Juquinha ou avançado &amp;quot;The Guy&amp;quot;. Prometo melhorar isso no segundo ano.
Pela quantidade crescente de visitantes, dá até pra imaginar que estou &amp;quot;no caminho certo&amp;quot;. Mas, quer saber? Que caminho é esse? Não quero fundar um fã-clube, não quero me tornar rico e famoso (talvez só a parte do rico) e, muito menos, influenciar ninguém. Além do que, quanto mais velho um saite se torna, e sendo freqüentemente atualizado, é natural ser mais visitado. Por isso que eu acredito piamente que na maioria dos casos estatística é uma merda, pois mostra uma realidade cheia de conteúdo mas sem nenhum significado.
Por outro lado, alguns dados são muito interessantes, pois podem moldar o futuro de um blogueiro profissional (não é o meu caso), como os resultados mais-mais do google:

No entanto, saber que o topo da lista é formado por buscas por &amp;quot;softice&amp;quot; não irá me fazer escrever mais artigos sobre esse depurador mais do que eu escrevi, até porque já é um depurador morto usado hoje em dia em raríssimos casos (no meu caso). Se você quer craquear um programa, mesmo que isso seja contra a lei, aprenda WinDbg que você ganha mais!
Das novidades que aconteceram durante esse ano, a maior e mais interessante foi o renascimento do nosso grupo de C&#43;&#43;, que talvez continue dessa vez a sua vida normal. Ou não. Esperemos que sim =)
Eu fico sinceramente muito feliz em saber que existem muito mais pessoas interessadas em C&#43;&#43; do que eu mesmo, até porque isso me dá muito mais tempo para escrever sobre outras coisas que não seja C&#43;&#43; que, admiro humildemente, não chego a usar 20% no meu dia-a-dia.
</description>
</item>

     
        <item>
  <title>Launchpad e a democracia do código-fonte</title>
  <link>http://www.caloni.com.br/launchpad-e-a-democracia-do-codigo-fonte/</link>
  <pubDate>2008-06-04</pubDate>
  
  <guid>http://www.caloni.com.br/launchpad-e-a-democracia-do-codigo-fonte/</guid>
  <description>Após a publicação dos projetos que ando mexendo no próprio saite do Caloni.com.br, recebi uma enxurrada de _downloads _e quase atingi meu limite de fluxo mensal no provedor.
Devido a esse problema inesperado, irei fazer o inevitável: publicar os projetos em um repositório sério. E aproveitando que já estou usando o Bazaar, nada melhor que usar o Launchpad.net.
E o que é o Launchpad.net? O Launchpad nada mais é do que um lugar onde é possível publicar seus projetos de fonte aberto para que pessoas possam ter livre acesso ao seu histórico de mudanças, assim como a liberdade de criar sua própria ramificação (branch). O esquema todo é organizado no formato comunidade, o que permite o compartilhamento não só de código, mas de bugs, traduções e, principalmente, idéias.
A idéia é uma das primeiras que usa a modalidade de controle de fonte distribuído, e permite o uso do Bazaar como o controlador oficial, ou importação de outros controles de fonte, em um processo conhecido como espelhamento. Tudo foi feito de forma a amenizar o processo de migração dos sistemas de controle de código centralizado, como CVS e Subversion.
Para ter acesso aos meus projetos iniciais é simples: basta usar o mesmo comando que é usado para obter um novo branch de um projeto do Bazaar:
  MouseTool - Simulador de clique de mouse
   bzr branch https://code.launchpad.net/mtool
  Influence Board - Complemento ao Winboard que mostra a influência das peças
   bzr branch https://code.launchpad.net/infboard
  Conversor Houaiss Babylon - Converte de um dicionário para o outro
   bzr branch https://code.launchpad.net/houaiss2babylon
   Atualização  _Aviso de plantão. Não irei mais atualizar os projetos acima no LaunchPad, pois estou considerando reorganizar os fontes para algo mais simplificado. Aguardem por novidades no próprio blogue. _Como o Bazaar foi feito integrado com o Launchpad, também é possível usar um comando bem mais fácil:
bzr branch lp:project_name Assim como é possível usar comandos de repositório, também é possível navegar pelo histórico de mudanças do projeto simplesmente usando os linques acima no navegador de sua preferência. E é nessa hora que começa a ficar interessante publicar seu projeto na web. Por falar nisso, que tal aprender como
Criar seu próprio projeto no Launchpad Tudo que precisamos é de um login, facilmente obtido na página principal, e de registrar um projeto. Para criar o primeiro _branch _e fazermos alterações precisaremos também de um par de chaves pública e privada para a conexão SSH criada automaticamente pelo Bazaar. Tudo isso é facilmente possível com o uso das ferramentas do Putty, um cliente SSH para Windows.
Dessa forma os passos são os seguintes:
  Criar um login
  Registrar um projeto
  Criar um par de chaves através do PuTTYgen
   Atualizar no cadastro do saite (item &amp;quot;Update SSH keys&amp;quot;)
  Usar o Pageant para carregar a chave privada na memória
   Use os comandos do Bazaar passando o usuário e o branch:
bzr branch lp:~seu-usuario/projeto/branch
  Simples e direto. E funciona!
</description>
</item>

     
        <item>
  <title>How to run anything as a service</title>
  <link>http://www.caloni.com.br/how-to-run-anything-as-a-service/</link>
  <pubDate>2008-05-27</pubDate>
  
  <guid>http://www.caloni.com.br/how-to-run-anything-as-a-service/</guid>
  <description>The biggest advantage running an application as a service, interactive or not, is to allow its start before a logon be performed. An example that happens to me is the need of debugging a GINA. In order to do this, I need the Visual Studio remote debugger be started before logon. The easiest and fastest solution is to run Msvcmon, the server part of debugging, as a service.
Today I&#39;ve figured out a pretty interesting shortcut to achieve it.
Service Controller (or SC) An Alex Ionescu article talks about this command line application used to create, initiate and remove services. Even not being the article focus, I found the information pretty useful, since I didn&#39;t know such app. Soon some ideas starting to born in my mind:
Well, the Notepad is the default test victim. Soon, the following line would prove possible to run it in the system account:
sc create Notepad binpath= &amp;quot;%systemroot%NOTEPAD.EXE&amp;quot; type= interact type= own However, as every service, it is supposed to communicate with the Windows Service Manager. Since Notepad even &amp;quot;knows&amp;quot; it is now a superpowerful service, the service initialization time is expired and SCM kills the process.
&amp;gt;net start notepadThe service is not responding to the control function.More help is available by typing NET HELPMSG 2186. As would say my friend Thiago, &amp;quot;not good&amp;quot;.
&amp;quot;Yet however&amp;quot;, SCM doesn&#39;t kill the child processes from the service-process. Bug? Feature? Workaround? Whatever it is, it can be used to initiate our beloved msvcmon:
set binpath=%systemroot%system32cmd.exe /c c:Toolsmsvcmon.exe -tcpip -anyuser -timeout -1sc create Msvcmon binpath= &amp;quot;%binpath%&amp;quot; type= interact type= own Now, when we start Msvcmon service, the process cmd.exe will be create, that on the other hand will run the msvcmon.exe target process. Cmd in this case will only wait for its imminent death.

</description>
</item>

     
        <item>
  <title>Busca do Google com atalhos</title>
  <link>http://www.caloni.com.br/busca-do-google-com-atalhos/</link>
  <pubDate>2008-05-19</pubDate>
  
  <guid>http://www.caloni.com.br/busca-do-google-com-atalhos/</guid>
  <description>Eu adoro atalhos de teclado. Desde meus primeiros anos usando computadores, atalhos têm se tornado minha obsessão. Sempre faço minha pesquisa pessoal de tempos em tempos, colecionando e usando novos atalhos descobertos. Por um bom tempo eu evitei ter que usar o mouse, treinando-me para lembrar de todas as seqüências de teclas que conhecia.
Até algum tempo atrás a _web _não era muito convidativa para usuários de atalhos. Então surgiu o Google e as suas aplicações que suportavam essa característica, o que me deu uma razão a mais para passar a usar seu cliente de e-mail e leitor de notícias sem pressionar constantemente a tecla . No entanto, ainda faltava a mesma funcionalidade para seu buscador. Felizmente, isso não é mais verdade.
Busca Experimental
Ainda em teste, eu comecei a usar os novos atalhos de teclado na busca do Google disponíveis no saite Google Experimental Search. Até agora existem atalhos para próximo resultado (J), resultado anterior (K), abertura da busca (O ou ) e colocação do cursor na caixa de busca (/). Eles funcionam exatamente como o Gmail e o Google Reader. Eu fiquei tão empolgado com a idéia que mudei o complemento de busca do Google de dentro do meu Firefox. E agora vou contar como isso pode ser feito facilmente (nota: minhas dicas servem para usuário de Windows apenas).
Colocando atalhos do Google dentro do Firefox
Provavelmente seu complemento de busca estará em uma das duas pastas abaixo:
%programfiles%\Mozilla Firefox\searchplugins %appdata%\Mozilla\Firefox\Profiles*.default\searchplugins
O arquivo do complemento tem o nome google.xml e você pode editá-lo usando o Bloco de Notas ou qualquer outro editor de texto simples (sem formatação). Abaixo está o ponto onde você deve inserir a nova linha que irá ativar os atalhos dentro da página de buscas do Google.
É isso aí. Agora você pode ter o melhor dos dois mundos: o melhor buscador da internete_ _com atalhos. Existirá maneira de se tornar ainda mais produtivo?
</description>
</item>

     
        <item>
  <title>Kernel Mode &gt;&gt; User Mode</title>
  <link>http://www.caloni.com.br/kernel-mode-user-mode/</link>
  <pubDate>2008-05-13</pubDate>
  
  <guid>http://www.caloni.com.br/kernel-mode-user-mode/</guid>
  <description>Existem algumas situações onde um depurador WYSIWYG é artigo de luxo.
Imagine o seguinte: temos um serviço que inicia automagicamente antes do _login _do Windows, e possivelmente antes mesmo do ambiente gráfico. Esse serviço tem algum problema que impede que ele funcione sob as circunstâncias de inicialização do sistema. O que fazer? Atachar o WinDbg no processo?
Mas que mané WinDbg? Que mané atachar? Nessa hora nós temos bem menos do que nossos sentidos são capazes de enxergar.
Nessas horas o único que pode nos ajudar é o kernel debugger.
Conversinha entre depuradores Os depuradores do pacote Debugging Tools (especialmente o ntsd e o cdb) suportam o funcionamento em modo _proxy, _ou seja, eles apenas redirecionam a saída e os comandos entre as duas pontas da depuração (o depurador e o depurado). Isso é comumente usado em depuração remota e depuração de kernel, quando o sistema inteiro está congelado. O objetivo aqui é conseguir os dois: depurar remotamente um processo em um sistema que está travado.
Para isso podemos nos utilizar do parâmetro -d, que manda o depurador redirecionar toda saída e controle para o depurador de kernel. Para que isso funcione o depurador já deve estar atachado no sistema-alvo. A coisa funciona mais ou menos assim:
Com essa configuração temos a vantagem de ter o sistema congelado só pra nós, ao mesmo tempo que conseguimos depurar nosso processo fujão, passo-a-passo.
A única desvantagem é não ter uma GUI tão poderosa quando o &amp;quot;WinDbg fonte colorido, tooltips, etc&amp;quot;. Pra quem não liga pra essas frescuras, é possível depurar processos de maneira produtiva utilizando esse cenário.
Para ativar qualquer programa que irá rodar nesse modo, basta usar o aplicativo gflags:
gflags /p /enable servico.exe /debug &amp;quot;c:\path\ntsd.exe -d&amp;quot; Fluxo de navegação pelo mundo kernel-user misturados É preciso dar uma lida bem profunda na ajuda do Debugging Tools para entender como as coisas estão funcionando nessa configuração milagrosa que estamos usando. Procure por &amp;quot;Controlling the User-Mode Debugger from the Kernel Debugger&amp;quot;. Também é possível ouvir falar parcamente sobre isso no livro Advanced Windows Debugging na parte &amp;quot;Redirecting a User Mode Debugger Through a Kernel&amp;quot;. A vantagem é que vem de brinde uma bela figura para pendurar em um quadro no escritório (embora eu possa jurar que já vi essa figura na ajuda do WinDbg):

Como podemos notar, o controlador de tudo é o _kernel debugger. _Assim que o depurador de processo entra em ação, ele se comunica com o depurador de _kernel _que entra no modo _user mode prompt, _pedindo entrada para ser redirecionada ao depurador de processo. Existem alguns caminhos para sair de um estado e entrar em outro, como o comando .breakin e o .sleep.
É necessário recomentar: estamos nos comunicando com um depurador e o seu processo depurado em um sistema totalmente travado. Isso quer dizer que o acesso a coisas como código-fonte e símbolos é extremamente limitado, porém não impossível. Apenas mantenha-os localmente na máquina-vítima, pois uma comunicação pela rede não irá funcionar.
A depuração com a linha atual no código-fonte demarcando onde estamos também não é possível, uma vez que o WinDbg da ponta de cá apenas faz o papel de garoto de recados para o &amp;quot;depurador de verdade&amp;quot; do outro lado (no nosso exemplo, o ntsd). Isso quer dizer que a forma mais &amp;quot;fácil&amp;quot; de ir passo-a-passo é usar o comando p (step) ou t (trace), além de habilitar o uso de fonte em 100%.
input&amp;gt; .srcpath c:\maquina-vitima\srcinput&amp;gt; l&#43;* $$ habilita uso de código-fonte no ntsd...0:000&amp;gt; p&amp;gt; 15: int main() $$ número da linha seguido do fonte&amp;gt; 16: {0:000&amp;gt; bp myFunction0:000&amp;gt; g0:000&amp;gt; Um tipo de problema que só pode ser depurado dessa maneira enfatiza a importância do uso de unit tests, além de um controle de qualidade mais aguçado antes de liberar uma versão para o cliente.
</description>
</item>

     
        <item>
  <title>Bazaar e Fedora 8: a saga</title>
  <link>http://www.caloni.com.br/bazaar-e-fedora-8-a-saga/</link>
  <pubDate>2008-04-29</pubDate>
  
  <guid>http://www.caloni.com.br/bazaar-e-fedora-8-a-saga/</guid>
  <description>Seria bom se as coisas simples da vida fossem simples, não é mesmo?
Ontem, sexta passada e quinta passada, no meio de outras tarefas &amp;quot;urgentes&amp;quot;, tentava desesperadamente conseguir instalar o Bazaar na minha VM de desenvolvimento, um Fedora 8 todinho configurado.
Para azar da minha pessoa, o guia simples e rápido de instalação do Bazaar não funcionava para minha distribuição Linux. Na verdade, funciona. Porém, é instalada uma versão tão antiga (0.91!) que o formato do banco de dados já se tornou incompatível.
#yum info bzr...Available PackagesName : bzrArch : i386Version : &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;0.91&amp;lt;/font&amp;gt;... O pior, no entanto, foi tentar encontrar uma solução para o problema. Fiz mil e uma pesquisas com palavras-chave que nem imaginava que seria capaz de formular. E nada. A princípio minha idéia era apenas atualizar a lista de pacotes do repositório gerenciado pelo yum, o gerenciador de pacotes oficial do Fedora. Entre minhas buscas, encontrei os seguintes itens:
  Um FAQ do Fedora (que não conseguiu responder à minha pergunta)
  O sítio do projeto do yum, gerenciador de pacotes (cujo FAQ não conseguiu responder o mínimo)
  Uma lista enorme de sítios explicando como criar seu próprio repositório (sem comentários)
  Enfim, a coisa não estava saindo do lugar. E o cronograma apertando até o dia final. Até que decidi usar o caminho mais rápido e pentelho: perguntar para quem entende do assunto. A resposta foi simples e direta:
Uia! E não é que é mais simples, mesmo?
#wget https://launchpad.net/bzr/1.3/1.3.1/&#43;download/bzr-1.3.1.tar.gz#tar -zxvf bzr-1.3.1.tar.gz /* ele teve que me explicar esse comando singelo */#cd bzr-1.3.1#cat INSTALLInstallation------------When upgrading using setup.py, it is recommended that you first delete thebzrlib directory from the install target.To install bzr as a user, runpython setup.py install --home ~To install system-wide, run (as root)python setup.py install#python setup.py install E foi isso! É a segunda vez que tento fazer algo simples no Linux e me dou mal. Com certeza os dias futuros serão melhores. Mas me bate aquela sensação que as coisas poderiam já estar em um nível mais fácil de se mexer. Opinião pessoal.
</description>
</item>

     
        <item>
  <title>Ode ao C&#43;&#43;</title>
  <link>http://www.caloni.com.br/ode-ao-c/</link>
  <pubDate>2008-04-21</pubDate>
  
  <guid>http://www.caloni.com.br/ode-ao-c/</guid>
  <description>(direto do &amp;quot;Contato do Site&amp;quot;)
Cristiano -- Olá! Sou programador em basic (Vbasic/Qbasic), fico indignado, com pessoas que sabem enteder a linguagem C&#43;&#43;, assembler... Como podem? Eu acho isto coisa de outro mundo! Será que eu tenho chances de aprender a linguagem?
**Strauss **-- A resposta é simples: estudando. Eu tb comecei com QBasic e VB. Arrume um livro de C&#43;&#43; e estude. Treine bastante. E hoje em dia é mais fácil do que quando eu comecei, pq eu não tinha acesso à Internet. É simples assim... :-)
**Caloni **-- Você pode ir tão longe quanto queira, mas pra isso a primeira coisa que vc tem que fazer é querer =).
**Strauss **-- Acho que vou fazer um post sobre isso. &amp;quot;Por que C&#43;&#43;&amp;quot; :-) Vc podia me ajudar...
**Caloni **-- Escrevi um textículo sobre o assunto da escolha, mas não visando o mercado:
/**
  @title Por que C&#43;&#43;
  @author Wanderley Caloni Jr
  @date 31.01.2005
  */
É natural que um programador tenha preferência por uma linguagem. Geralmente por motivos pessoais que se refletem nas características da linguagem. Eu, por exemplo, tenho vários motivos para amar essa linguagem:
Linguagem C. Todas as vantagens da linguagem C estão embutidas em C&#43;&#43;. E sem aquele papo erudito que deve-se programar em OO para ser C&#43;&#43;. Por ser multiparadigma, a linguagem também suporta o melhor da programação procedural e estruturada.
**Popularidade. **C&#43;&#43; é o que há. Linguagem unânime e reconhecida no mundo todo como de uso geral. Dificilmente você vai encontrar um algoritmo que não tenha representação em C&#43;&#43;.
**Economia e Expressividade. **Pode parecer bobagem, mas coisas como operador de incremento e valor em todas expressões permite que se faça muita coisa com poucas linhas. Isso a torna muito expressiva. Isso, em outras palavras, quer dizer que você pode juntar várias expressões numa só, e esse conjunto será também uma expressão.
**Liberdade. **Em C&#43;&#43; você é o culpado de virtualmente qualquer coisa de bom e ruim que aconteça no seu programa, pois você tem que seguir poucas regras e tem que ser responsável no que faz. C&#43;&#43; não te ajuda a seguir um bom modelo de programação com restrições embutidas. Isso a torna difícil para iniciantes, mas conforme aumenta a experiência, maior o prazer em programar.
**Portabilidade. **A possibilidade de compilar e rodar o seu código em vários ambientes - de compilação e execução - é uma característica útil e agradável. No meu caso é só agradável, pois dificilmente faço código portável, apesar das boas noções que tenho sobre o assunto. E são essas boas noções que me permitem afirmar que C&#43;&#43; suporta muito bem essa possibilidade.
**Rapidez. **Pode não ser importante em muitos casos, mas já é do instinto do programador o desejo de eficiência no código. E nada como programar numa linguagem extremamente eficiente em tempo de execução para se sentir feliz de ver o código rodando.
FIM
[]s
**Strauss **-- Legal. Vou colocar minha água mercadológica no feijão e colocar no site.
Nos dias de hoje... Não quis alterar o texto original, mas colocaria, além de rapidez, o título economia de recursos. É incrível o quanto progredimos no quesito hardware todos esses anos, e mesmo assim, existem linguagens e ambientes que parecem ter fome suficiente para consumir tudo e deixar um computador de última geração parecer um micro &amp;quot;meio lerdinho&amp;quot;. Felizmente não preciso dar nome aos bois, pois todos sabem ou conhecem pelo menos uma linguagem com essa característica.
Ainda acredito em tudo isso que C&#43;&#43; proporciona e irá continuar proporcionando por muto tempo. Para os que não seguiram o linque do artigo do Strauss, existe uma modesta lista de programas escritos nessa linguagem ao redor do planeta. Muitos são conhecidíssimos e usados nos quatro cantos do mundo, muitas vezes em mais de um sistema operacional. C&#43;&#43; está morto? Longe disso... talvez pareça assim em território nacional, mas esse é o motivo de meus votos de sucesso no início de nosso grupo C&#43;&#43;.
</description>
</item>

     
        <item>
  <title>Linux e o DHCP</title>
  <link>http://www.caloni.com.br/linux-e-o-dhcp/</link>
  <pubDate>2008-04-09</pubDate>
  
  <guid>http://www.caloni.com.br/linux-e-o-dhcp/</guid>
  <description>Quando procuramos no google por &amp;quot;linux dhcp&amp;quot;, o que vem em resposta são diversas dicas, tutoriais, documentos oficiais e palpites sobre como configurar um servidor Linux.
Muito bem. E a outra ponta da história?
[Testes feitos em um Fedora 8, não me pergunte mais detalhes]
O primeiro linque útil encontrado foi a documentação da Red Hat. Além disso seguem alguns macetes que eu descobri no decorrer do percurso. A primeira coisa a ser configurada é o arquivo /etc/sysconfig/network. Nele devemos, em uma configuração simplista, colocar uma única linha:
NETWORKING=yes Tive alguns problemas com a entrada NETWORKING_IPV6, ou algo do gênero. A comunicação com o servidor DHCP da rede simplesmente não funcionava com essa linha, deixando o computador sem IP durante o boot. Má configuração do servidor? Pode até ser. Porém, não quis entrar nesses meandros.
Por isso, se houver a linha sobre IPV6 e você tiver problemas, comente-a temporariamente.
O passo seguinte é configurar a interface de rede, que é no fim das contas a representação da sua placa. Para isso temos alguns arquivos em /etc/sysconfig/network-scripts no formato ifcfg-nome-da-interface. Se você digitar ifconfig na linha de comando terá os nomes de interface disponíveis. No meu caso, eth0.
vi /etc/sysconfig/network-scripts/ifcfg-eth0DEVICE=eth0BOOTPROTO=dhcpONBOOT=yes:wq Note que o valor BOOTPROTO é realmente BOOTPROTO, com um O no final. Tive alguns problemas de soletrar também nesse caso, o que me gerou mais alguns reboots mal-sucedidos.
Bem, o que isso faz? Basicamente, manda o Linux utilizar o protocolo DHCP, procurando na rede algum servidor que lhe dê algum IP válido. Só isso. O resto ele faz dinamicamente.
Inclusive alterar automaticamente o arquivo /etc/resolv.conf. Nele estão definidas algumas coisas como o domínio de nomes que estamos e os IPs de onde buscar a resolução de nomes.
Feito isso, como se costuma dizer, voilà! Temos um cliente DHCP funcionando contente e feliz. Eu reiniciei a máquina para tudo dar certo, mas provavelmente devem existir maneiras mais saudáveis de reiniciar a rede (talvez um ifdown seguido de ifup resolvesse). E agora eu posso finalmente ter acesso aos pacotes de instalação que precisava.
Notas de um Linux padawan =)
</description>
</item>

     
        <item>
  <title>Backup de pobre</title>
  <link>http://www.caloni.com.br/backup-de-pobre/</link>
  <pubDate>2008-03-28</pubDate>
  
  <guid>http://www.caloni.com.br/backup-de-pobre/</guid>
  <description>O backup - ato de fazer cópia(s) de segurança de dados considerados importantes -, como tudo na vida, para se tornar efetivo e transformador deve antes se tornar um hábito.
Hábitos, por definição, ao serem realizados repetidamente muitas vezes, podem se tornar poderosos catalisadores de tarefas, sejam elas cozinhar um bolo, compilar um programa ou fazer backups. Por isso é muito importante que o backup, antes de ser 100% seguro, seja 100% previsível e habitual.
É o hábito que faz o backup Minhas restrições para que algo vire um hábito em minha vida, quando tarefas, são que a tarefa seja, antes de tudo,:
  Simples de fazer. Quero conseguir efetuar a tafefa sem ter que toda vez preparar um ritual em noite de lua cheia, sacrificar uma virgem para os deuses pagãos e lembrar de todas as palavras proparoxítonas que terminam com x e rimam com fênix.
  Fácil de executar. É um complemento do primeiro item. Com isso eu quero dizer que, além de simples, eu não precise despender grande força e energia diariamente para efetuar a tarefa. Limpar uma pasta de arquivos temporários pode ser simples; mas é fácil?
  Fácil de lembrar. Se eu tenho que fazer um esforço mental diário tão grande para lembrar do que fazer então muito provavelmente será difícil transformá-lo em um hábito.
  Passado por esse checklist, podemos montar um esquema tão simples que qualquer bobo que tem um blogue (por exemplo, eu) conseguirá executar diariamente, ou pelo menos quando tiver vontade. A freqüência dependerá se isso irá se transformar em um hábito ou não.
O mais poderoso copiador do mundo: xcopy Ele pode não parecer, mas é beeem mais antigo do que parece. Nós, veteranos, que possuímos mais anos de vida em frente ao monitor que gostaríamos de admitir (copyright =&amp;gt; DQ), usávamos o xcopy para copiar pastas e disquetes inteiros no MS-DOS, um sistema operacional predecessor do Windows Vista que vinha em preto e branco e sem User Account Control.
No entanto, esse pequeno grande aplicativo sobreviveu todos esses anos, atingiu a maioridade, e hoje permite a nós, programadores de mouse, fazer nossos backups com um simples arquivo de batch e um pouco de imaginação.
O uso do programa pode ser aprendido dando-se uma olhada em sua ajuda (xcopy /?)
xcopy origem [destino] [opções] Algumas opções bem úteis para efetuar cópias de segurança de arquivos modificados:
/M - copia somente arquivos com atributo de arquivamento; após a cópia, desmarca atributo. Ao escrever novamente em um arquivo copiado com esse método, o arquivo volta a ter o atributo de arquivamento, e irá ser copiado novamente se especificada essa opção. Se nunca mais for mexido, não será mais copiado.
/D - copia arquivos mais novos na origem. Não costumo usar pelos problemas que podem ocorrer em sistemas com horas diferentes, mas, dependendo da ocasião, pode ser útil. Também é possível especificar uma data de início da comparação.
/EXCLUDE - permite excluir arquivo(s) de uma cópia coletiva. Isso pode ser muito útil se você não deseja gastar tempo copiando arquivo que são inúteis dentro de pastas que contém arquivos importantes. É possível especificar um arquivo que irá conter uma lista de nomes-curinga, um por linha, que irá servir como filtro da cópia. Teremos um exemplo logo abaixo.
/E - copia pastas e subpastas, mesmo que vazias. Essa opção é básica, e ao mesmo tempo essencial. Não se esqueça dela quando for criar seu script de backup!
/C - continua copiando, mesmo com erros. Se é mais importante copiar o máximo que puder do que parar no primeiro errinho de acesso negado, essa opção deve ser usada. É possível redirecionar a saída para um arquivo de _log, _que poderá ser usado para procurar por erros que ocorreram durante a operação.
/Q - não exibe nome de arquivos ao copiar. Às vezes imprimir o nome de cada arquivo na saída do prompt de comando acaba sendo mais custoso que copiar o próprio arquivo. Quando a cópia envolve muitos arquivos pequenos, é recomendável usar esta opção.
/Y - suprime perguntas para o usuário. Muito útil em arquivos _batch, _já que o usuário geralmente não estará lá para apertar enter quando o programa pedir.
/Z - copia arquivos da rede em modo reiniciável. Muito importante quando estiver fazendo _backup _pela rede. Às vezes ela pode falhar, e essa opção permite continuar após pequenas quedas de desempenho.
Estudo de caso: código-fonte Para a cópia do patrimônio mais valioso de um programador, os fontes, podemos usar um conjunto bem bolado das 0pções acima, além de generalizar um _script _para ser usado em outras situações. Inicialmente vamos definir que queremos um _backup _que altere o atributo de arquivamento, sobrescreva cópias antigas e que possa ser copiado pela rede sem maiores problemas. Além disso, não iremos copiar as pastas _Debug _e _Release _existentes geradas pela saída de algum compilador (ex: saída do Visual Studio), nem arquivos temporários muito grandes (ex: arquivos de navegação de símbolos).
O resultado é o que vemos abaixo:
xcopy &amp;lt;pasta-origem&amp;gt; &amp;lt;pasta-destino&amp;gt; /M /E /C /Y /Z /EXCLUDE:sources.flt O conteúdo de sources.flt (extensão escolhida arbitrariamente) pode ser o seguinte:
.obj.res.pch.pdb.tlb.idb.ilk.opt.ncb.sbr.sup.bsc\Debug\\Release\ Só isso já basta para um _backup _simples, pequeno e fácil de executar. Só precisamos copiar a chamada ao xcopy em um arquivo de extensão .bat ou .cmd e executarmos sempre que acharmos interessante termos um backup quentinho em folha. Por exemplo, podemos manter os fontes do projeto atual em um pen drive e, ao acessarmos uma máquina confiável, rodar um _backup _que copia os arquvos-fonte para um ambiente mais seguro e estável.
Note que esse procedimento não anula a necessidade de termos um sistema de versionamento e controle de fontes. O _backup _é para aquelas projetos que demoram um tempinho para efetuar commit, projetos temporários ou então sistemas de controle de fonte distribuído, em que podemos ter inúmeras pastas com diversos _branchs _locais.
</description>
</item>

     
        <item>
  <title>WinDbg a distância</title>
  <link>http://www.caloni.com.br/windbg-a-distancia/</link>
  <pubDate>2008-03-26</pubDate>
  
  <guid>http://www.caloni.com.br/windbg-a-distancia/</guid>
  <description>Acho que o que mais me impressionou até hoje a respeito do WinDbg é a sua capacidade de depuração remota. Não há nada como depurar problemas sentado confortavelmente na sua cadeira de programador em frente à sua mesa de programador.
Já é fato consumado que os maiores problemas da humanidade ocorrem sempre no cliente, com uma relação de dificuldade diretamente proporcional ao cargo ocupado pelo usuário da máquina que está dando problemas. Se esse cliente por acaso mora em um lugar tão tão distante, nada mais justo do que conhecermos algumas técnicas de depuração remota para continuar a mantê-lo tão tão distante.
Testes de corredor: corre que o bicho tá pegando! O ambiente de desenvolvimento (em teoria) não se deve confundir com o ambiente de testes, um lugar onde o desenvolvedor deveria colocar o pé somente quando fosse chamado e quando existisse um problema na versão Release. Por isso e portanto, a única coisa permitida em um ambiente de testes é (deveria ser) um servidor de depuração.
O servidor de depuração nada mais é do que um processo que deixa alguma porta aberta na máquina de testes para que o desenvolvedor consiga facilmente depurar problemas que ocorreram durantes os testes de produção. Ele pode ser facilmente configurado através da instalação do pacote Debugging Tools for Windows.
Existem alguns cenários muito comuns de depuração remota que serão abordados aqui. O resto dos cenários se baseia nos exemplos abaixo, e pode ser montado com uma simples releitura dos tópicos de ajuda do WinDbg sobre o assunto (procure por dbgsrv.exe).
1. Depuração de teste (VM ou máquina de teste do lado do desenvolvedor) Nesse caso podemos supor que a máquina tem total acesso e controle do desenvolvedor. Tudo o que temos que fazer é iniciar um WinDbg na máquina-vítima e outro WinDbg na máquina-programador. O WinDbg da máquina-vítima deve ser iniciado no modo-servidor, enquanto o da máquina-programador no modo-cliente.
windbg -&amp;lt;strong&amp;gt;server&amp;lt;/strong&amp;gt; tcp:port=6666windbg -&amp;lt;strong&amp;gt;remote &amp;lt;/strong&amp;gt;tcp:server=&amp;lt;strong&amp;gt;maquina-vitima&amp;lt;/strong&amp;gt;,port=6666 A vantagem dessa técnica é que tanto o WinDbg da máquina-vítima quanto o da máquina-programador podem emitir comandos, e todos vêem os resultados. Uma possível desvantagem é que os símbolos devem estar disponíveis a partir da máquina-vítima.
Se for necessário, é possível convidar mais gente pra festa, pois o WinDbg permite se transformar em uma instância servidora pelo comando .server, que possui a mesma sintaxe da linha de comando. Para a comunicação entre todos esses depuradores ambulantes um comando muito útil é o .echo.
windbg -server tcp:port=6667 -remote tcp:server=maquina-vitima,port=6666windbg -remote tcp:server=maquina-vitima,port=6666.server tcp:port=6667MAQUINA-PROGRAMADOR66\caloni (tcp 222.234.235.236:1974) connected at Mon Mar 24 11:47:55 2008.echo E ae, galera? Como que a gente vai consertar essa &amp;amp;%$*&amp;amp;?.echo Putz, sei lá. Acho que vou tomar mais café... 2. Depuração em cliente Nesse ambiente muito mais hostil, é salutar e recomendável utilizar um servidor genérico que não imprima coisa alguma na tela &amp;quot;do outro lado&amp;quot;. Após iniciar o depurador na máquina que está dando o problema, o programador tem virtualmente uma série de comandos úteis que podem ser executados remotamente, como iniciar novos processos, se anexar a processos já existentes, copiar novas versões de executáveis, etc.
O nome do processo do lado servidor para modo usuário é dbgsrv.exe. Para o modo kernel é kdsrv.exe. Os parâmetros de execução, felizmente, são os mesmos que os do WinDbg (e CDB, NTSD e KD), o que evita ter que decorar uma nova série de comandos.
 Lembre-se: kernel é kernel, user é user  Pode parecer besteira falar isso aqui, mas ao depurar um sistema em modo kernel é necessário, é claro, é óbvio, é lógico, ter uma segunda máquina do lado servidor conectada por cabo serial ou firewire ou USB-Debug na máquina-vítima. Ainda que o Debugging Tools permita uma série de flexibilidades, o depurador em modo kernel vai rodar direto do kernel (duh), ou seja, está limitado pela implementação do sistema operacional. Além de que, para travar o processo do kernel, você tem que parar todo o sistema, e nesse caso não existe pilha TCP/IP.Para iniciar o servidor de depuração e deixar as portas abertas para o depurador temos apenas que iniciar o processo dbgsrv.exe:
dbgsrv -t tcp:port=6666 Para iniciar o processo depurador, a sintaxe é quase a mesma, só que no lugar de remote especificamos premote:
windbg -premote tcp:server=maquina-vitima,port=6666 Caso não se saiba a porta usada para iniciar o servidor, ou queira-se listar todos os servidores disponíveis em uma determinada máquina, usa-se o comando -QR.
cdb -QR \\maquina-vitima  Não se prenda ao TCP-IP  O exemplo acima utilizou uma conexão TCP para montar o ambiente de depuração remota, o que possibilita inclusive correção de problemas via internet. No entanto, nem sempre podemos nos dar ao luxo de abrir portas não-autorizadas, requisito mínimo para estabelecer a conexão com o depurador. Nesse caso, podemos configurar conexões pela porta serial, por pipes nomeados, por SSL. Se for realmente necessário usar a pilha TCP, mas o lado servidor possui um firewall, ainda assim é possível configurar este tipo de conexão com a opção clicon. Dessa forma, quem estabelece a conexão é o servidor, evitando que o cliente fique bloqueado de acessar o ambiente de depuração.Notas finais É importante notar que o dbgsrv.exe não é um depurador esperto, no sentido que ele não vai carregar os símbolos para você. Isso é importante na hora de definir qual estratégia utilizar, pois nem sempre os símbolos estarão disponíveis na máquina com problemas, e nem sempre estarão com o desenvolvedor.
Uma organização mais esperta dos ambientes de teste e desenvolvimento tomaria conta de outros problemas como símbolos e fontes com o uso de outras features poderosas do Debugging Tools como servidor de símbolos e servidor de fontes. Porém, a complicação envolvida na configuração desses dois me leva a crer que eles merecem um outro artigo. E é por isso que paramos por aqui.
</description>
</item>

     
        <item>
  <title>Como rodar qualquer coisa como serviço</title>
  <link>http://www.caloni.com.br/como-rodar-qualquer-coisa-como-servico/</link>
  <pubDate>2008-03-20</pubDate>
  
  <guid>http://www.caloni.com.br/como-rodar-qualquer-coisa-como-servico/</guid>
  <description>A maior vantagem de se rodar um aplicativo como serviço, interativo ou não, é permitir que ele seja iniciado antes que seja feito um logon na máquina. Um exemplo que acontece comigo é a necessidade de depurar a GINA. Para isso, preciso que o depurador remoto do Visual Studio seja iniciado antes do logon. A solução mais fácil e rápida é rodar o Msvcmon, a parte servidora da depuração, como um serviço.
Hoje eu descobri um atalho bem interessante para isso.
Service Controller (ou SC) Um artigo do Alex Ionescu falava sobre esse aplicativo linha de comando usado para criar, iniciar e apagar serviços. Mesmo não sendo o foco do artigo, achei muito útil a informação, pois não conhecia esse utilitário. Logo começaram a borbulhar idéias na minha mente:
Bem, o Bloco de Notas é a vítima padrão de testes. Logo, a linha a seguir provaria que é possível rodá-lo na conta de sistema:
sc create Notepad binpath= &amp;quot;%systemroot%\NOTEPAD.EXE&amp;quot; type= interact type= own Porém, como todo serviço, é esperado que ele se comunique com o Gerenciador de Serviços do Windows. Como o Bloco de Notas mal imagina que agora ele é um motta-fucka service, expira o timeout de inicialização e o SCM mata o processo.
&amp;gt;net start notepadThe service is not responding to the control function.More help is available by typing NET HELPMSG 2186. Como diria meu amigo Thiago, &amp;quot;não bom&amp;quot;.
Porém porém, o SCM não mata os processos filhos do processo-serviço. Bug? Feature? Gambi? Seja o que for, pode ser usado para iniciar o nosso querido msvcmon:
set binpath=%systemroot%\system32\cmd.exe /c c:\Tools\msvcmon.exe -tcpip -anyuser -timeout -1sc create Msvcmon binpath= &amp;quot;%binpath%&amp;quot; type= interact type= own Agora, quando iniciarmos o serviço Msvcmon, o processo cmd.exe será criado, que por sua vez irá rodar o msvcmon.exe que queríamos, e ficará esperando inocentemente pela sua &amp;quot;funesta morte&amp;quot; pelo SCM.

</description>
</item>

     
        <item>
  <title>Influence Board</title>
  <link>http://www.caloni.com.br/influence-board/</link>
  <pubDate>2008-03-14</pubDate>
  
  <guid>http://www.caloni.com.br/influence-board/</guid>
  <description>Há muito tempo sou enxadrista não-praticante. Acho que os anos de programação me deixaram mais viciado em codar do que pensar no xeque-mate. No entanto, sempre que posso, dou uma escapulida do Visual Studio e jogo uma partida ou duas na rede, quase sempre, é claro, tomando um piau psicológico.
A falta de prática e estudos pesa muito para um enxadrista amador, já que facilmente esquecemos das combinações mortíferas que podemos aplicar e levar. É muito difícil ter em mente aquelas três dúzias de aberturas que já são batidas (e suas variantes), ou então as regrinhas de praxe de como detonar nas finais com um cavalo e um bispo.
Por isso mesmo aprendi em um livro uma técnica universal e independente de decoreba que levei pra vida toda, e tem me trazido algumas partidas no mínimo interessantes. Se trata de analisar o esquema de influências em cima do tabuleiro. Influências, nesse caso, se refere ao poder de fogo das peças amigas e inimigas. O interessante é que deixa-se de lado a análise das próprias peças! Se estuda tão somente o tabuleiro, e apesar de parecer um método difícil, ele melhora sua percepção gradativamente, e é responsável por muitas das partidas simultâneas jogadas às cegas por alguns ilustres GMIs.
Exemplo simples Vamos supor que a posição no tabuleiro em um dado momento seja a seguinte:
[](http://i.imgur.com/6IfiNAY.png)

Ora, é um mate inevitável, não é? Agora imagine por um momento que você não tenha percebido isso, e precise de uma ajudinha para saber onde cada peça pode ir ou atacar no próximo lance.
[](http://i.imgur.com/GByvceA.png)

Agora ficou muito mais fácil de perceber que a única saída do rei não possui nenhuma proteção, já que tanto o peão quanto o próprio rei não podem fazer muita coisa se a dama atacar a diagonal vulnerável. E ela pode fazer isso.
[](http://i.imgur.com/0Nsxat3.png)

Influence Board Essa maneira de mostrar as influências em um tabuleiro de xadrez eu apelidei de Influence Board, e criei um projeto em linha de comando para fazer as devidas considerações a respeito de uma posição determinada. Mas como ninguém hoje em dia gosta de usar o WinDbg pra jogar xadrez, transformei meu projeto em pseudo-plugin para o WinBoard, um famoso frontend de xadrez que costumo usar em minhas esporádicas partidas.
Como usar Basicamente a única coisa que o futuro usuário das influências deve fazer é baixar o projeto WinBoard, a versão disponível aqui (obs.: já contém o WinBoard completo) e compilar. Caso queira uma versão nova do programa terá que fazer o merge entre as duas versões, e por isso deixei disponívei também um patch que instala o &amp;quot;plugin&amp;quot; (obs.: a versão usada foi a 2.4.7).
C:\Projects\xboard infboard\winboard&amp;gt;nmake msvc.makMicrosoft (R) Program Maintenance Utility Version 8.00.50727.42Copyright (C) Microsoft Corporation. All rights reserved.link /DEBUG /DEBUGTYPE:cv /INCREMENTAL:NO /NOLOGO -subsystem:windows,5.0 WIN2000_DEBUG\winboard.obj WIN2000_DEBUG\backend.obj WIN2000_DEBUG\parser.obj WIN2000_DEBUG\moves.obj WIN2000_DEBUG\lists.obj WIN2000_DEBUG\gamelist.obj WIN2000_DEBUG\pgntags.obj WIN2000_DEBUG\wedittags.obj WIN2000_DEBUG\wgamelist.obj WIN2000_DEBUG\zippy.obj WIN2000_DEBUG\wsockerr.obj WIN2000_DEBUG\wclipbrd.obj WIN2000_DEBUG\woptions.obj WIN2000_DEBUG\infboard.obj wsock32.lib comctl32.lib winmm.lib oldnames.libkernel32.lib advapi32.lib user32.lib gdi32.lib comdlg32.lib winspool.lib ws2_32.lib WIN2000_DEBUG\winboard.rbj -out:WIN2000_DEBUG\winboard.exe Após compilado, basta copiar na pasta de instalação do programa, rodá-lo e habilitar a opção &amp;quot;Show Influence&amp;quot; do menu General. Voilà! É possível até jogar às cegas com esse brinquedinho (opção Blindfold).

[](http://i.imgur.com/R5SjM7r.png)

Bom divertimento!
</description>
</item>

     
        <item>
  <title>Sed, Grep e afins</title>
  <link>http://www.caloni.com.br/sed-grep-e-afins/</link>
  <pubDate>2008-03-10</pubDate>
  
  <guid>http://www.caloni.com.br/sed-grep-e-afins/</guid>
  <description>Esse artigo é resultado de eu ter me matado para conseguir encontrar a forma correta de usar o aplicativo sed para fazer uma filtragem simples nos resultados de uma listagem de arquivos.
Primeiramente, eu gostaria de expressar minha total surpresa ao não conseguir encontrar um guia simples e confiável de uso dessas ferramentas na web. Existem três teorias: ou eu não sei usar as palavras mágicas certas no Google, ou a indexação das páginas realmente importantes sobre o assunto não funcionam com o Google, ou de fato não existe documentação fácil sobre o tema.
Como esta é uma exceção em anos de &amp;quot;googadas&amp;quot;, eu fico com a terceira opção.
Algumas explicações que merecem ser explicadas Existem algumas ferramentas que já salvaram minha vida uma dúzia de vezes e devo admitir que são tão poderosas e flexíveis quanto difíceis de usar:
  Grep. Use esta se quiser fazer uma busca, qualquer busca, em um arquivo, um conjunto de arquivos ou uma enxurrada de caracteres do prompt de comando.
  Sed. Use esta se quiser processar a entrada de um arquivo, um conjunto de arquivos ou uma enxurrada de caracteres do prompt de comando.
  Sort. Use esta se quiser ordenar qualquer coisa da entrada padrão (inclusive arquivos, conjunto de arquivos...).
  O que eu queria era processar a saída de um programa de forma que eu tivesse a lista de todas as extensões dos arquivos. Por exemplo, para a seguinte entrada:
c:\path\arquivo1.cppc:\path\arquivo2.hc:\arquivo3.hppc:\path\path2\arquivo4.cpp Eu gostaria de uma saída no seguinte formato:
.cpp.h.hpp Basicamente é isso.
Sabendo que processamento de entrada estaria envolvido, logo pensei em utilizar o sed para a tarefa. Justiça seja feita, depois de eu perder uma hora e meia em pesquisa eu encontrei um tutorial muito bom para quem está começando a entender melhor o funcionamento do sed, e é nele que me baseei para resolver meu problema e escrever este artigo.
Para filtrar o _path _do arquivo, e ao mesmo tempo retirar seu nome, podemos usar o seguinte comando (fora outras trilhões de variantes):
programa | sed -e &amp;quot;s/^.*\\//&amp;quot; -e &amp;quot;s/.*\.\(.*\)/\1/&amp;quot; Após esse processamento, a saída é um monte de extensões vindas de um monte de arquivos:
cpphcpphchcpphmakvcprojhcpphcpphcpphcpphchtxtccpphmakvcprojcpph... Como podemos ver e é óbvio de imaginar, muitas extensões irão se repetir. Para eliminar as repetições e ordenar a saída da saída corretamente, usamos o comando sort:
programa | sed -e &amp;quot;s/^.*\\//&amp;quot; -e &amp;quot;s/.*\.\(.*\)/\1/&amp;quot; | sort -u Algumas coisas que eu (re)aprendi hoje   Os caracteres .*[]^$\ dão problemas se usados sem escape no sed, pois fazem parte dos comandos para procurar expressões regulares. Use-os com o caractere de escape .
  Para concatenar comandos no sed, use sempre -e &amp;quot;comando&amp;quot;. A ordem de execução dos comandos é a ordem em que eles são inseridos na linha de comando, ou seja, podemos confiar que no segundo comando o primeiro já terá sido executado e assim por diante.
  Para fazer o escape das barras do caminho de um arquivo temos que usar o conjunto / (obs.: caminhos em formato Unix). Para evitar esse uso enfadonho podemos substituir o caractere de divisão do comando s colocando-o na frente:
 s/path/muito/muito/muito/longo.cpp/outropath/muito/muito/longo.cpp/ s#/path/muito/muito/muito/longo.cpp#/outropath/muito/muito/longo.cpp#    Para agrupar expressõe, use sempre &amp;quot;(&amp;quot; e &amp;quot;)&amp;quot;. É o contrário do uso dos caracteres especiais. Coisas de Unix.
  </description>
</item>

     
        <item>
  <title>Estranho</title>
  <link>http://www.caloni.com.br/estranho/</link>
  <pubDate>2008-03-06</pubDate>
  
  <guid>http://www.caloni.com.br/estranho/</guid>
  <description>Bom, é hora de dizer tchau. Essa é minha última semana escovando bits na empresa onde estava por três anos. É estranho e esquisito dizer isso, mas me sinto um tanto aliviado. Nessa empreitada, porém, aprendi algumas coisas que valem a pena colocar na bagagem. Sempre é melhor entender do que criticar.
Por exemplo, vejamos a palavra estranho: quantas vezes você já pronunciou essa palavra quando estava diante de um problema daqueles esotéricos? Muitas vezes, não foi? E os problemas não-esotéricos?
Quando nos acostumamos a usar uma palavra para aliviar a dor de não entendermos o que está acontecendo diante de nós, visto pelos nossos próprios olhos, estamos nos condicionando a parar de cutucar nosso cérebro para encontrar uma resposta rápida e racional para o que está acontecendo. Em suma: nos fechamos ao mundo falando &amp;quot;estranho&amp;quot;.
Não por esse motivo, mas por estarmos cansados de tanto ouvir falar essa palavra, eu e meu amigo Thiago começamos a instituir uma &amp;quot;taxa simbólica&amp;quot; de 1 (um) real para os que proferirem a dita cuja, e passamos a usar o dinheiro arrecadado para o bem da comunidade, comprando o que nós, programadores, mais veneramos nos momentos de debugging: bolachas!
Essa &amp;quot;medida provisória&amp;quot; aos poucos foi se alastrando pelas mesas do departamento, ao ponto máximo de todos da área técnica, além do diretor comercial, colaborar para a nossa &amp;quot;caixinha de um real&amp;quot;.
Criamos um ambiente livre de estranhos. E criamos um trauma em nossas cabeças. A partir das primeiras semanas, toda vez que estávamos em algum lugar em que uma pessoa desconhecida (um estranho) dizia a palavra, soava um sino em nossas cabeças, quase fazendo com que nossa mão acusadoramente se erguesse e fizesse o gesto com o dedo indicando que a pessoa, a partir daquele momento, estava devendo um real para nossa caixinha comunitária.
E assim fomos indo, meses a fio, sem falar essa palavra na presença dos fiscais do um real, que éramos todos nós. A proibição foi linear e englobou todas as situações de vida social em que poderíamos nos expressar: no trabalho, no almoço, por mensagem instantânea, por e-mail, pelo celular, fora do trabalho, nos artigos do blogue...
Pois é, caro leitor, nos artigos do blogue. Se você procurar nestes últimos três anos qualquer menção à palavra &amp;quot;estranho&amp;quot; por aqui com certeza não irá encontrar.
Até agora, quando finalmente foi quebrado o encanto. Quer dizer, oficialmente a cobrança está extinta, mas nossas mentes sempre irão conter esse sino acusador tocando no ônibus, nas ruas, no cinema, no shopping, em casa. Enfim, nos códigos estranhos de nossa vida.
</description>
</item>

     
        <item>
  <title>Iteradores não são constantes</title>
  <link>http://www.caloni.com.br/iteradores-nao-sao-constantes/</link>
  <pubDate>2008-03-04</pubDate>
  
  <guid>http://www.caloni.com.br/iteradores-nao-sao-constantes/</guid>
  <description>Um bug que já encontrei uma dúzia de vezes entre os novatos da STL é a utilização de iteradores como se eles não fossem mudar nunca. Porém, a verdade é bem diferente: iteradores se tornam inválidos sim, e com muito mais freqüência do que normalmente se imagina. Entre as situações em que iteradores podem mudar estão as seguintes:
  Inserção de novo elemento no contêiner
  Remoção de novo elemento no contêiner
  Redimensionamento no tamanho do contêiner
  Por exemplo, o tradicional código do exemplo abaixo contém o tradicional erro de iterador inválido:
for( container::iterator it = obj.begin(); it != obj.end(); &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;&#43;&#43;it&amp;lt;/font&amp;gt; ){if( it-&amp;gt;member == 0 ) // condição para apagar elemento{obj.erase(&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;it&amp;lt;/font&amp;gt;); // a partir daqui it é inválido,// e não adianta incrementá-lo}} Para operações como essa, o retorno geralmente nos dá uma dica de para onde vamos na varredura do contêiner. No caso do método erase, o retorno é o próximo iterador válido, ou o final (retornado pelo método end). Um código mais esperto gera um erro mais sutil:
for( container::iterator it = obj.begin(); it != obj.end(); &amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;&#43;&#43;it&amp;lt;/font&amp;gt; ){if( it-&amp;gt;member == 0 ) // condição para apagar elemento{&amp;lt;font color=&amp;quot;#ff0000&amp;quot;&amp;gt;it&amp;lt;/font&amp;gt; = obj.erase(it); // ótimo, atualizou it. só// que se ele for o final,// será incrementado}} Algo de errado irá acontecer apenas se o elemento removido for o último localizado no contêiner.
Para resolver problemas na STL, nada como mais STL Esse é um erro comum para os acostumados com outros tipos de iteração (ex: ponteiros) e que não estudaram os princípios básicos da STL, entre eles o da reutilização de algoritmos. Se fosse usado este princípio, nada disso teria acontecido:
struct remove_if_zero{bool operator() (ObjElement&amp;amp; element){return element-&amp;gt;member == 0;}};obj.remove_if( remove_if_zero() ); // pronto! Quando precisamos fazer algo nos elementos de um contêiner STL, é quase certo que existirá um algoritmo genérico para essa tarefa, seja no próprio contêiner ou na forma de função (). Nunca se esqueça disso na hora de desenvolver seus próprios algoritmos e não precisará reinventar a roda todos os dias.
</description>
</item>

     
        <item>
  <title>Creative Commons</title>
  <link>http://www.caloni.com.br/creative-commons/</link>
  <pubDate>2008-02-19</pubDate>
  
  <guid>http://www.caloni.com.br/creative-commons/</guid>
  <description>Talvez a maioria das pessoas ignore o fato que, ao publicarem algum conteúdo, qualquer conteúdo, na internet, estarão criando algo, e esse algo tem um autor, e portanto, de acordo com nossa lei (Brasil) e alguns tratados internacionais, está protegida pelo direito autoral.
Para ajudar os autores da internet a informarem ao seu público qual o nível de proteção e liberdade dados às suas obras de maneira padronizada e internacionalizada, foi criado o Creative Commons, cuja função é exatamente essa que descrevi.
Exatamente por não ser obrigado o registro de uma obra para tornar válido o seu direito autoral, o Creative Commons apenas define alguns logos e links que simbolizam e especificam quais os direitos que um autor gostaria de aplicar à sua obra, variando de uma obra totalmente protegida até uma obra sem qualquer nível de proteção. No meu caso, por exemplo, as obras do Caloni.com.br estão publicadas sob as seguintes condições:

  Você pode:
 Copiar, distribuir, exibir e executar a obra.    Sob as seguintes condições:
  Atribuição. Você deve dar crédito ao autor original, de forma especificada pelo autor ou licenciante.
  Uso Não-Comercial. Você não pode utilizar esta obra com finalidades comerciais.
  Vedada a Criação de Obras Derivadas. Você não pode alterar, transformar ou criar outra obra com base nesta.
    Para cada novo uso ou distribuição, você deve deixar claro para outros os termos da licença desta obra.
  Qualquer uma destas condições podem ser renunciadas, desde que Você obtenha permissão do autor.
  Nothing in this license impairs or restricts the author&#39;s moral rights.
  Essa foi uma configuração que escolhi ao ler os termos do sítio e configurar minha licença. É necessário que essa licença esteja &amp;quot;assinada&amp;quot; junto da obra, através de um link disponível sempre que a obra for exibida.
</description>
</item>

     
        <item>
  <title>Silly regex trick: finding the project who failed inside a big VS solution</title>
  <link>http://www.caloni.com.br/silly-regex-trick-finding-the-project-who-failed-inside-a-vs-big-solution/</link>
  <pubDate>2008-02-07</pubDate>
  
  <guid>http://www.caloni.com.br/silly-regex-trick-finding-the-project-who-failed-inside-a-vs-big-solution/</guid>
  <description>I know what you going to think about this one: &amp;quot;silly trick&amp;quot;. That&#39;s why I just put it in the title. Anyway, that is something I use everyday, so I thought it might be useful to who cares about productivity.
Let&#39;s say you have to manage a big solution in Visual Studio made of more than 30 projects, and needs to rebuild all them. Suddenly, something goes wrong. The question is: how to discover, in a heartbeat, what project has failed?

Note that you need to enable &amp;quot;Regular Expressions&amp;quot; option in the Find Dialog (not shown here).
What I&#39;m saying inside this regex is &amp;quot;find the first number different from zero followed by a space and the letters err&amp;quot;. This lead us to the first project who has at least one error:
------ Build started: Project: FailedProj, Configuration: Release Win32 ------Compiling...stdafx.cppCompiling...FailedProj.cpp.FailedProj.cpp(2477) : error C2039: &#39;Blablabla&#39; : is not a member of &#39;IBlabla&#39;Build log was saved at &amp;quot;file://c:Projects...ReleaseBuildLog.htm&amp;quot;FailedProj - 2 err
or(s), 0 warning(s) If you think &amp;quot;what about when a project generates more than 9 errors? the regex wouldn&#39;t be able to catch this case&amp;quot;, well, you&#39;re right. Anyway, that&#39;s the quicker form to search for the unsuccessful project inside a big solution. A more complex yet complete regex would be:
[1-9][0-9]* err For me, the first version is enough. It is faster to type, simpler to catch and solves my problem. I hope it can solve yours =)
</description>
</item>

     
        <item>
  <title>Temas no WinDbg</title>
  <link>http://www.caloni.com.br/temas-no-windbg/</link>
  <pubDate>2008-01-14</pubDate>
  
  <guid>http://www.caloni.com.br/temas-no-windbg/</guid>
  <description>Desde a versão 6.4.7.2 que o WinDbg fornece uma subpasta chamada Themes, onde lá estão diversos workspaces configurados. Existe até um passo-a-passo de como organizar esses temas e escolher o seu favorito. Segue algumas dicas de como transformar corretamente sua área de trabalho para depuração (e mantê-la).
Primeira coisa: limpe todos seus dados O WinDbg salva suas configurações no registro. Para apagar os valores previamente gravados, rode o seguinte comando:
reg delete HKCU\Software\Microsoft\WinDbg Segunda coisa: execute o tema que mais gostar Você pode gravar um tema, rodar o WinDbg (sem parâmetros), ver se gosta do que viu, e tentar novamente. Quando estiver satisfeito com a aparência, fique com ela e comece o próximo passo.
Configurando o que importa Nas depurações do dia-a-dia algumas configurações devem estar sempre muito bem configuradas, para que torne seus momentos de desespero porque nada está funcionando mais agradáveis. Por isso, assim que escolher seu tema preferido trate de configurar os seguintes itens:
  Diretórios de símbolos. Você pode começar com .symfix, que vai montar uma string padrão, e adicionar mais diretórios com .sympath&#43;.
  Diretórios de código-fonte. Coloque a raiz dos seus projetos principais. Com o tempo, se você mexe muito nos seus diretórios, é necessário fazer uma manutenção desse valor.
  Diretórios de executáveis. Basicamente é o mesmo do diretório de símbolos.
  Ajuste fino Depois de configurar tudo isso, ajuste as janelas na melhor maneira e proporção que achar mais agradável. Esse será o último passo, pois depois você irá fechar o WinDbg e salvar o workspace, que a partir daí será o padrão sempre que abrir o depurador.
 Configure corretamente onde seu código-fonte vai abrir  _Para que os arquivos fonte caiam no lugar que você escolheu, durante a configuração, abra um código-fonte e coloque no lugar que gostaria de ver todos os fontes listados, junto com um placeholder (um arquivo C usado como localizador, existem 5 dentro da pasta themes). Após isso, feche o código-fonte, mas mantenha o placeholder. Depois é só fechar o WinDbg salvando as configurações. Tudo deve funcionar como previsto (ou você esqueceu alguma coisa)._Como esses passos deram algum trabalho, trate de salvar as configurações, caso tenha que usá-las em outras máquinas ou restaurá-las caso algo de ruim aconteça com seu SO (como quando você depura seus drivers na mesma máquina em que desenvolve, por exemplo).
reg save HKCU\Software\Microsoft\WinDbg c:\Tools\DbgTools\Themes\MyTheme.reg Para um guia completo Leia a documentação do WinDbg sobre temas (dentro de Themes, Themes.doc). Foi de lá que eu fiz a tradução e adaptação dos passos mais importantes. E esqueça do Visual Studio =)
</description>
</item>

     
        <item>
  <title>Gambi do dia: swap com apenas duas variáveis</title>
  <link>http://www.caloni.com.br/gambi-do-dia-swap-com-apenas-duas-variaveis/</link>
  <pubDate>2007-12-31</pubDate>
  
  <guid>http://www.caloni.com.br/gambi-do-dia-swap-com-apenas-duas-variaveis/</guid>
  <description>Essa interessantíssima questão veio do meu amigo Kabloc: como trocar o valor entre duas variáveis do tipo int sem utilizar uma variável intermediária? O algoritmo ordinário para um swap entre tipos inteiros é:
/** Troca o valor entre duas variáveis inteiras. Ou seja, ao final da funçãoa variável first irá conter o valor da variável second e vice-versa.*/void normalSwap(int &amp;amp;first, int&amp;amp; second){int third = first;first = second;second = third; // contém o valor de first}int main(){int first = 13;int second = 42;cout &amp;lt;&amp;lt; &amp;#34;first: &amp;#34; &amp;lt;&amp;lt; first &amp;lt;&amp;lt; &amp;#34;, second: &amp;#34; &amp;lt;&amp;lt; second &amp;lt;&amp;lt; endl;normalSwap(first, second);cout &amp;lt;&amp;lt; &amp;#34;first: &amp;#34; &amp;lt;&amp;lt; first &amp;lt;&amp;lt; &amp;#34;, second: &amp;#34; &amp;lt;&amp;lt; second &amp;lt;&amp;lt; endl;} Saída:first: 13, second: 42first: 42, second: 13 Uma das soluções que eu conheço é utilizar o operador de ou exclusivo, o conhecido XOR. Esse operador binário tem a não pouco bizarra habilidade de armazenar dois padrões de bits dentro de um mesmo espaço de armazenamento. Se você tiver um dos dois padrões, conseguirá o segundo. Relembremos sua tabela verdade:
void xorTable(){cout &amp;lt;&amp;lt; &amp;#34;XOR Table\n---------\n&amp;#34;&amp;lt;&amp;lt; &amp;#34;0 XOR 0 = &amp;#34; &amp;lt;&amp;lt; ( 0 ^ 0 ) &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;&amp;lt;&amp;lt; &amp;#34;1 XOR 0 = &amp;#34; &amp;lt;&amp;lt; ( 1 ^ 0 ) &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;&amp;lt;&amp;lt; &amp;#34;0 XOR 1 = &amp;#34; &amp;lt;&amp;lt; ( 0 ^ 1 ) &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;&amp;lt;&amp;lt; &amp;#34;1 XOR 1 = &amp;#34; &amp;lt;&amp;lt; ( 1 ^ 1 ) &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;;} /* Saída:XOR Table---------0 XOR 0 = 01 XOR 0 = 10 XOR 1 = 11 XOR 1 = 0*/Ou seja, imagine que temos o valor 1 e o valor 0. Armazenando os dois juntos com XOR obtemos 1, já que:
1 (primeiro padrão) XOR 0 (segundo padrão) = 1 (padrões juntos) Mais tarde, se quisermos obter o primeiro padrão, usamos o segundo:
1 (padrões juntos) XOR 0 (segundo padrão) = 1 (primeiro padrão) Para obter o segundo padrão é só utilizar o primeiro obtido:
1 (padrões juntos) XOR 1 (primeiro padrão) = 0 (segundo padrão) Calcule a mesma operação com as quatro combinações possíveis e verá que podemos sempre reaver os dados partindo de um dos padrões. Como o cálculo independe do número de bits, já que operadores bit a bit operam um bit de cada vez, podemos usar a mesma técnica para juntar dois inteiros, duas strings, dois &amp;quot;qualquer coisa armazenada numa seqüência de zeros e uns&amp;quot;:
template&amp;lt;typename T1, typename T2, typename T3&amp;gt;void universalXor(const T1&amp;amp; first, const T2&amp;amp; second, T3&amp;amp; result){typedef unsigned char byte;const byte* pFirst = reinterpret_cast&amp;lt;const byte*&amp;gt;( &amp;amp;first );const byte* pSecond = reinterpret_cast&amp;lt;const byte*&amp;gt;( &amp;amp;second );byte* pResult = reinterpret_cast&amp;lt;byte*&amp;gt;( &amp;amp;result );for( size_t i = 0; i &amp;lt; sizeof(first) &amp;amp;&amp;amp; i &amp;lt; sizeof(second); &#43;&#43;i )pResult[i] = pFirst[i] ^ pSecond[i];}int main(){// trocando ints	int x = 13, y = 42;cout &amp;lt;&amp;lt; &amp;#34;x: &amp;#34; &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &amp;#34;, y: &amp;#34; &amp;lt;&amp;lt; y &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;;universalXor(x, y, x);universalXor(x, y, y);universalXor(x, y, x);cout &amp;lt;&amp;lt; &amp;#34;x: &amp;#34; &amp;lt;&amp;lt; x &amp;lt;&amp;lt; &amp;#34;, y: &amp;#34; &amp;lt;&amp;lt; y &amp;lt;&amp;lt; &amp;#34;\n\n&amp;#34;;// trocando strings em c	char str1[50] = &amp;#34;teste de xor&amp;#34;, str2[50] = &amp;#34;aceita strings!&amp;#34;;cout &amp;lt;&amp;lt; &amp;#34;str1: &amp;#34; &amp;lt;&amp;lt; str1 &amp;lt;&amp;lt; &amp;#34;, str2: &amp;#34; &amp;lt;&amp;lt; str2 &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;;universalXor(str1, str2, str1);universalXor(str1, str2, str2);universalXor(str1, str2, str1);cout &amp;lt;&amp;lt; &amp;#34;str1: &amp;#34; &amp;lt;&amp;lt; str1 &amp;lt;&amp;lt; &amp;#34;, str2: &amp;#34; &amp;lt;&amp;lt; str2 &amp;lt;&amp;lt; &amp;#39;\n&amp;#39;;return 0;} Saída:x: 13, y: 42x: 42, y: 13str1: teste de xor, str2: aceita strings!str1: aceita strings!, str2: teste de xor Essa técnica é uma das mais básicas - se não for a mais - de criptografia simétrica. O primeiro padrão faz o papel de texto aberto, o segundo banca a senha e o terceiro será o texto encriptado. Para &amp;quot;desencriptar&amp;quot; o texto é necessária a senha (e se você souber qual o texto original, saberá a senha).
Mas, voltando ao nosso problema original, podemos trocar duas variáveis inteiras usando a técnica do XOR. Em claro:
#include &amp;lt;iostream&amp;gt;using namespace std;/** Troca o valor entre duas variáveis inteiras. Ou seja, ao final da funçãoa variável first irá conter o valor da variável second e vice-versa.*/void anormalSwap(int &amp;amp;first, int&amp;amp; second){first = first ^ second; // first contém first e second juntos	second = first ^ second; // firstXORsecond XOR second = first	first = first ^ second; // second = first. logo, firstXORsecond XOR first = second}int main(){int first = 13;int second = 42;cout &amp;lt;&amp;lt; &amp;#34;first: &amp;#34; &amp;lt;&amp;lt; first &amp;lt;&amp;lt; &amp;#34;, second: &amp;#34; &amp;lt;&amp;lt; second &amp;lt;&amp;lt; endl;anormalSwap(first, second);cout &amp;lt;&amp;lt; &amp;#34;first: &amp;#34; &amp;lt;&amp;lt; first &amp;lt;&amp;lt; &amp;#34;, second: &amp;#34; &amp;lt;&amp;lt; second &amp;lt;&amp;lt; endl;} Saída:first: 13, second: 42first: 42, second: 13 Bom, preciso dizer que isso é uma gambi das grossas? Preciso dizer que NÃO uso isso no meu dia a dia, até porque swap é uma função já consagrada da STL? Não? Então sem _Postscript _dessa vez. E sem bois-cornetas =).
</description>
</item>

     
        <item>
  <title>SDelete</title>
  <link>http://www.caloni.com.br/sdelete/</link>
  <pubDate>2007-11-15</pubDate>
  
  <guid>http://www.caloni.com.br/sdelete/</guid>
  <description>Minha vida tem que ser portátil. Existem pelo menos três lugares diferentes onde costumo ficar com um computador (não o mesmo). Por causa disso, os dados mais relevantes e que precisam fazer parte do meu sistema biológico eu carrego comigo pra cima e pra baixo em meu PenDrive/MP3Player.
Até aí tudo bem. Quer dizer, mais ou menos. Dados relevantes costumam ser sensíveis, e busco sempre manter todos os arquivos sensíveis encriptados ou com uma senha específica do programa que o abre. O grande problema mesmo é que eu sei que operações no sistema de arquivos costumam deixar lastros do que já foi escrito um dia, e que é possível reaver esses dados com um pouco de persistência e sorte. É nessa hora que entra a praticidade do SDelete.
Apagando arquivos para dummies Desde a versão NT, o Windows segue as diretivas de segurança do C2, o que entre outras coisas quer dizer que o a reutilização de um objeto no sistema operacional será protegida. Um objeto aqui está para representar recursos da máquina em geral, como páginas de memória e setores do disco. Quando um programa pede um setor de disco livre (ou uma página de memória) para uso próprio, o Windows apaga qualquer conteúdo remanescente naquele espaço de memória, evitando assim que exista uma maneira do atacante obter dados de terceiros (e.g. arquivos protegidos ou memória do sistema) sem autorização.

Ou seja, desde que o Windows esteja no comando, os dados escritos por um programa não estarão disponíveis ao usuário por meio do reaproveitamento dos setores. Ficou claro?
Se ficou claro, deve ter notado o &amp;quot;desde que o Windows esteja no comando&amp;quot;. Essa é uma condição sine qua non, mas que nem sempre é verdadeira. Um atacante que tenha acesso físico ao dispositivo de armazenamento (e.g. meu PenDrive) pode certamente usar outro sistema operacional (ou até mesmo o Windows em condições especiais) e vasculhar os dados que eu já apaguei, pois estes, como mostra a figura, não são apagados de fato até que um programa peça o espaço ocupado por eles.

A solução: SDelete! Para esse tipo de problema eu costumo usar um programinha esperto chamado SDelete (de Secure Delete). O que ele faz é zerar os setores não usados, da mesma forma com que o Windows faz quando um programa pede um setor não usado. Para isso, basta especificar um ou mais arquivos:

Uma outra coisa que ele faz, muito útil quando comecei a usá-lo, é apagar todos os setores não usados que existem no disco inteiro (ou uma pasta inteira). Com isso podemos começar uma vida nova. Apenas tome muito cuidado nessa hora para especificar o comando, pois um errinho no comando pode realmente fazer você começar uma vida nova.
sdelete -c -s p: Aos paranóicos de plantão O SDelete segue o padrão DOD 5220.22-M, o que quer dizer que ele está dentro das especificações da indústria que garantem a confidencialidade dos dados apagados. Além do mais, você pode especificar quantas &amp;quot;passadas&amp;quot; nos setores você deseja, para evitar aqueles ataques mais rebuscados em que é analisada a impedância das trilhas físicas de um disco magnético para obter os dados que uma vez estavam lá. É claro que isso não deve valer muito a pena se você está usando um PenDrive com memória flash =).
</description>
</item>

     
        <item>
  <title>Desenvolvendo em linha de comando</title>
  <link>http://www.caloni.com.br/desenvolvendo-em-linha-de-comando/</link>
  <pubDate>2007-11-01</pubDate>
  
  <guid>http://www.caloni.com.br/desenvolvendo-em-linha-de-comando/</guid>
  <description>Desde uns tempos para cá o Visual Studio tem se tornado uma das ferramentas mais pesadas de desenvolvimento já criadas. Como se não bastasse, a compilação de pequenos trechos de código é algo desnecessariamente complicado no ambiente. Por esse motivo estou ganhando o costume de usar a linha de comando para esse tipo de tarefa. Afinal de contas, na maioria das vezes a única coisa que eu preciso fazer é abrir o atalho &amp;quot;Visual Studio Command Prompt&amp;quot; e digitar uma linha:
cl meu-codigo-fonte-do-coracao.cpp O problema é ter que &amp;quot;andar&amp;quot; do diretório padrão de início até a pasta onde está o código-fonte que desejo compilar. Porém, isso é facilmente resolvido com uma linha (no registro):

A partir daí, o comando &amp;quot;Console&amp;quot; existe no menu de contexto de qualquer pasta que clicarmos no Windows Explorer.

Note que é possível criar outros comandos, como é o meu caso, onde preciso de vez em quando compilar utilizando o Visual Studio 2005 (o comando Console) e o Visual Studio 2003 (o comando VS2003). Ao escolher a opção, um prompt de comando é aberto com o ambiente de compilação montado e (adivinhe) com a pasta padrão sendo a que foi clicada no explorer.
Projetos mais complexos Nossos projetos aqui na empresa costumam ser divididos em inúmeras soluções do Visual Studio para evitar a bagunça que seria (foi) ter que abrir uma solução de 10^24324 projetos. O problema é que, se abrir um Visual Studio já pesa, imagine abrir cinco de uma vez.
Por isso mesmo que, aproveitando que agora tenho uma linha de comando personalizada com o ambiente de compilação, faço uso da compilação de soluções em modo console que o devenv (a IDE do Visual Studio) oferece:
devenv meu-solution-do-coracao.sln /build Debugdevenv meu-project-do-coracao.vcproj /build Release  Dica para programadores profissionais  _Além de ser rápido, pode ser usado em __builds automatizados, coisa que já fazemos. O que quer dizer que podemos matar os itens 2 e 3 do teste do Joel, nos deixando um passo mais próximo do purgatório._Depuração Sabe que não é uma má idéia?
Porém, se você prefere algo mais amigável, mais ainda que o WinDbg, você pode iniciar o depurador do Visual Studio por linha de comando:
vsjitdebugger notepad.exevsjitdebugger -p meu-pid-do-coracao Daí não tem jeito: você economiza no start, mas o Visual Studio vai acabar subindo. Ou um ou outro.

Por isso eu recomendo aprender a usar o WinDbg ou até o NTSD. Quer dizer, é muito melhor do que esperar por uma versão mais light do Visual Studio no próximo ano.
</description>
</item>

     
        <item>
  <title>Engenharia reversa para principiantes</title>
  <link>http://www.caloni.com.br/engenharia-reversa-para-principiantes/</link>
  <pubDate>2007-10-10</pubDate>
  
  <guid>http://www.caloni.com.br/engenharia-reversa-para-principiantes/</guid>
  <description>Dei uma reformada em minha última palestra sobre engenharia reversa. O tema escolhido foi tentar abranger os níveis de conhecimento que uma pessoa disposta a se dedicar à engenharia reversa de programas deveria ter, desde programação, passando pelo sistema operacional e terminando no uso de ferramentas. Achei interessante abordar esse tipo de conteúdo pelo fato de existirem pessoas que gostariam de começar ou já começaram e não sabem para onde ir.
Outra coisa que fiquei receoso de colocar (mas coloquei) foi a lista de tarefas para usar o conhecimento aprendido. Pode ser frustrante tentar procurar emprego nessa área aqui no Brasil e não adianta nada aprender e não usar. A engenharia reversa, assim como a área de segurança da informação, para ser efetiva, deve levar em conta como as coisas são feitas, o que quer dizer que fazer vírus e quebrar proteção de software faz parte do aprendizado.
Se houverem interessados o suficiente poderei ministrar uma palestra online, para ilustrar os slides e tirar dúvidas. Lembrando que isso não inclui as perguntas &amp;quot;como eu quebro o programa X&amp;quot; ou &amp;quot;faz um vírus pra mim&amp;quot;.
</description>
</item>

     
        <item>
  <title>Cronogramas</title>
  <link>http://www.caloni.com.br/cronograma/</link>
  <pubDate>2007-10-04</pubDate>
  
  <guid>http://www.caloni.com.br/cronograma/</guid>
  <description>Nunca fui muito bom em definir cronogramas e nunca conheci alguém que fosse. Porém, ultimamente, no conforto do lar (férias), estou me saindo razoavelmente bem ao aplicar no meu dia-a-dia algumas regras que estabeleci como sendo boas pra mim. Não são regras que baixei do sítio do Joel nem é um design pattern, mas já me ajudam um bocado. Gostaria de compartilhá-las com meus pontuais leitores, que sempre entregam seus projetos em dia e nunca se esquecem de comentar uma linha de código sequer. Vocês são meu objetivo de vida e motivo de orgulho deste humilde blogue, que se esmera a cada dia que passa para ser fiel à inegável qualidade do meu público. Quando crescer quero ser igual a vocês.
Mas enquanto não sou, vamos às regras.
O primeiro grande passo é admitir que acertar cronogramas é como acertar na loteria: milhões de pessoas tentam toda semana e uns poucos gatos pingados conseguem de vez em quando. E ainda assim por acaso. O importante nessa analogia é perceber que, independente de ser difícil de acertar, isso não impede as pessoas de tentar. Veja você, elas (normalmente) não jogam 1, 2, 3, 4, 5, 6. Por quê? Porque elas tentam jogar no que acreditam ser uma combinação mais provável. E antes que um sábio chinês diga que a chance de sair a seqüência 1, 2, 3, 4, 5, 6 é tão provável quanto qualquer outra, explico que a analogia aqui é psicológica, não matemática. As pessoas tentam acertar, por mais irracional que isso pareça. A mesma filosofia deve ser seguida para cronogramas. Não chute valores que estão dentro da sua zona de conforto, mas tente de fato chegar o mais próximo possível da realidade. E, quem sabe um dia, você não é sorteado.
A segunda regra reza que o tempo estimado vira tempo mínimo. Você fará uma tarefa em uma hora. Mas, diabos, você não sabe disso antes de fazer e coloca no cronograma três horas. Quanto tempo você vai levar agora? Três horas. Não que você não consiga em menos tempo, mas, ao &amp;quot;alargar&amp;quot; a janela de tempo para três horas, seu ritmo irá seguir essa premissa e será mais lento. Há uma explicação psicológica para isso chamada Lei de Parkinson 1. Obviamente que o inverso não é verdadeiro. Quer dizer, você não vai terminar uma tarefa de uma hora em dez minutos se colocar dez minutos na sua tabela mágica. Isso, mais uma vez, não é matemática: é psicologia.
 A mesma analogia absurda serve para valores muito altos. Se estimar três meses para uma tarefa de uma hora, terá três meses para procurar um emprego novo, e não para terminar a tarefa.
 A terceira regra diz sobre o tamanho das tarefas: as menores são mais exatas. Este é o velho ditado de dividir para conquistar. Afinal, é muito melhor estimar o tempo para fazer uma nova função do que estimar o tempo total para a nova versão do produto. Portanto, trate de dividir o seu elefante. O limite é a partir do momento em que se sentir confortável para prever o tempo necessário a ser gasto em uma subtarefa. É muito simples ilustrar e entender esse conceito com código. Voltando ao caso da função, digamos que você consiga terminar a bendita função em exata uma hora. Você é bom, hein?
Porém, essa função ainda:
 não foi comentada, não foi testada, não foi testada em release.  Logo, essa é uma tarefa em que você termina o mais importante em uma hora... mas não termina tudo. Deve-se sempre considerar a tarefa por completo, pois no final de quinze tarefas vai faltar comentar e testar tudo isso, o que aumentará consideravelmente a imprevisiblidade no seu cronograma.
Seja honesto consigo mesmo e com seu chefe: você realmente trabalha 8 horas por dia? É lógico que não! E não é nenhuma vergonha admitir isso. Todos nós temos emails para ler e responder, reuniões para presenciar e blogues importantes para acompanhar. Portanto, ignore essa conversa fiada de 8 horas e admita: não se deve contar os dias como se eles tivessem 8 horas. Ninguém é produtivo programando 8 horas seguidas. Essa pessoa está te enganando ou usando cocaína (que não pode ser usada todos os dias).
Qual o valor de um dia, então? Cada um sabe o valor que deve ser decrementado desse valor simbólico de 8 horas, mas esse valor sempre será menor. Não se iluda! Se precisar harmonizar seu cronograma com um relatório para entregar para o chefe você pode usar de maneira privada o seu contador pessoal, por exemplo, trabalho 4 horas no máximo programando por dia, e converter para torná-lo público, multiplicando por dois para dar as 8 horas diárias.
A maneira com que eu administro meu tempo tenta (eu disse tenta) seguir as regras até aqui dispostas. Além dessas eu adicionei algumas regras minhas, baseadas em valores razoáveis e premissas consideravelmente lógicas. Aliás, isso me lembra uma última regra geral: entenda o seu ritmo.
O cronograma costuma (deveria) ser considerado uma coisa pessoal. Por quê? Porque cada um tem seu tempo. O que vale mais ao executar uma tarefa geralmente é (deveria ser) qualidade, e não quantidade. Seu vizinho de baia costuma terminar as coisas na metade do tempo que você? Bom para ele. Porém, se você tenta empregar o mesmo ritmo ao seu dia-a-dia vai ter que gastar depois mais do dobro do tempo que você economizou corrigindo os erros de uma tarefa feita nas coxas. Nada é &amp;quot;de grátis&amp;quot;.
Encare o trabalho assim como dormir: cada um tem o seu número de horas noturnas para descansar. Se dormir mais ou menos que o normal isso irá influenciar mais tarde, quando acordar. Alguns dormem 4, outros 12 horas. A média é 8. Mas e daí?
Primeiro eu tento usar um princípio que a maioria das pessoas conhece e a minoria acredita: se chama princípio de Pareto. Ele diz que 20% de uma tarefa resolve 80% dos problemas. Aos poucos eu fui acreditando nele até que cheguei à conclusão que deve funcionar, porém existe um problema: definir quais são esses 20%.
Voltando novamente no caso da função, é óbvio que a parte mais importante é fazer a função. Mais uma vez, cada caso é um caso, e o importante é desenvolver esse feeling do que é mais importante. Fazendo o que é mais importante o resto virá complementar a solução.
Essa ordem do que é mais importante deve servir para dividir qualquer tarefa e as tarefas de cada dia, ordenadas por importância. Dessa forma, é fácil começar o dia ou uma tarefa maior pelo que é mais importante. Isso nos leva a um segundo problema: definir o que é importante.
A maior dificuldade em definir o que é importante é que muitas vezes ele se confunde com o que é urgente, mesmo sendo dois conceitos bem diferentes.
Por exemplo, para mim foi urgente escrever este artigo, já que estou compromissado com a freqüência do meu blogue. O importante fica por conta do conteúdo. Por exemplo, considero ter tocado em todos os pontos que julgo importantes para esse tema, o que por si só caracterizaria o fim desse artigo. E é isso aí.
Bons cronogramas!
  &amp;quot;O trabalho se expande work de forma a preencher o tempo disponível para sua conclusão.&amp;quot; - Parkinson&#39;s Law na Wikipedia &amp;#x21a9;&amp;#xfe0e;
   </description>
</item>

     
        <item>
  <title>Developer: you need to know English!</title>
  <link>http://www.caloni.com.br/developer-you-need-to-know-english/</link>
  <pubDate>2007-09-28</pubDate>
  
  <guid>http://www.caloni.com.br/developer-you-need-to-know-english/</guid>
  <description>Eu realmente gostei desse negócio de tagging. =)
Aproveitando o comentário do Ferdinando sobre o novo sistema de tradução eletrônica do MSDN, lanço aqui algumas dicas para aprender a tão falada língua de Shakespeare. Acredite, se você deseja ser um melhor programador, inglês é fundamental.
O aprendizado de qualquer idioma deve estar focado em um objetivo. Se o objetivo é se comunicar, conversação é importante. Se você deseja ser um business man, um vocabulário mais específico deve ser aprendido. No nosso caso, em que a santa leitura técnica de cada dia é a necessidade básica, alguns passos básicos em inglês instrumental é um ótimo começo para começar a desvendar 80% da internet.
 Note, contudo, que inglês instrumental não é muito bem visto por escolas conceituadas de idiomas, tanto por ensinar um inglês limitado quanto por criar vícios de linguagem. O importante a lembrar nesse caso é: estamos usando o inglês como uma ferramenta de compreensão de textos que são úteis para nosso trabalho. Se o interesse/necessidade do inglês for maior, deve-se passar para as próximas dicas.
 Seguem alguns primeiros passos para começar a se aventurar:
 Procure estudar as palavras mais faladas no idioma. Aprenda as regrinhas para saber 400 palavras de lambuja. Use e abuse dos prefixos e sufixos de ambos os idiomas, pois geralmente seguem as mesmas regras. Mantenha um dicionário de expressões mais comuns nos textos que você lê. Aprenda-as.  Como todo bom aprendizado, a parte mais importante é a prática. E nada melhor para praticar do que ler pra caramba, certo? Isso quer dizer que você terá algumas tarefas diárias a partir de agora:
 Compre um dicionário inglês-português dos mais simples, seja o tradicional ou o eletrônico. Se não tiver dinheiro nem para isso, então use os disponíveis na internet. Escolha um artigo ou notícia e leia-o em um só dia. Para não desanimar, recomendo que seja relativamente curto e seja de um tema que muito te interesse. Pode até ser uma notícia curta do Slashdot. No começo tente traduzir um ou dois parágrafos desse mesmo artigo. Com o tempo, aumente o número de parágrafos até conseguir traduzir o texto inteiro.  Se sua necessidade do inglês era apenas ler textos técnicos pode parar por aqui. Mas nem sempre o conteúdo está escrito. Pode ser que existam palestras interessantíssimas do Channel9 ou podcasts de informática que você simplesmente não pode perder. Nesse caso, não há uma dica melhor do que imitar as crianças quando aprendem suas línguas nativas: ouça pessoas falando em inglês.
Isso, aliada à sua prática diária de leitura de artigos, pode ser complementada se prestar atenção sempre na pronúncia correta das palavras que vai aprendendo. Muitas pessoas se tornam exímias leitoras de textos em inglês, mas não conseguem entender uma frase comum do dia-a-dia. Isso ocorre porque o inglês escrito difere em muito das regras de pronúncia do português escrito, o que gera muita confusão na hora de falar o fonem lido. Felizmente, na maioria dos dicionários existe sempre a transcrição fonética no início de cada vocábulo. É importante usá-la, e pelo menos uma vez você mesmo tentar pronunciar a palavra de sua boca.
Nesse momento, o importante é fazer a transição escrito-falado. Por isso, tente ouvir podcasts em que o texto falado está disponível para leitura. Dessa forma é possível acompanhar os dois. Eu costumava ouvir o Word for the Wise da Merriam-Webster, por ser curto e interessante. Mas o ideal é unir o útil ao agradável, e nisso com certeza um podcast de tecnologia seria muito melhor.
 Trapaceando: no começo, é comum haver divergências de pronúncia ou falta da capacidade de ouvir (listening). Você pode sempre apelar para as pronúncias disponíveis nos dicionários online, como o Merriam-Webster. Ouça um milhão de vezes para pegar o jeito.
 Depois de obter um feeling básico sobre o que é escrito e o que é falado pode-se partir para estudos mais ousados e voltados para o aprendizado da língua de fato. Sabendo da facilidade que já obtivemos em traduzir textos e ouvir, considero as tarefas abaixo ideais para chegarmos ao tão sonhado language aquisition:
 Ouvir música em inglês e ler a letra (original e traduzida). Uma boa banda para começar são os Beatles, cujo inglês britânico é fácil de entender. Assistir filmes em inglês com legenda (traduzida e original). Você pode começar com as comédias românticas que são lançadas quinzenalmente; como esse tipo de filme não prima pelo roteiro, eles se tornam um prato cheio para iniciantes. Assistir filmes em inglês sem legenda. Tente assistir filmes falados em diferentes lugares para ir pegando o ponto em comum, ou seja, no meio de todos os sotaques do mundo inteiro o idioma é sempre o mesmo. Descubra-o.  Nesse ponto há uma ressalva: é natural não entender patavina do que as pessoas estão falando no começo do aprendizado. Mas o importante é nunca deixar de ouvir. Com o tempo, nossos ouvidos aos poucos vão sendo treinados para perceber as sutilezas da língua falada, e começamos a abrir nosso leque de conhecimento linguístico. Experimente!
Existem inúmeros recursos hoje em dia para que duas pessoas em qualquer lugar do mundo consigam se comunicar pela grande rede. Afinal, depois de tanto aprender a ler e escutar, é hora de soltar o verbo:
 Participe de fóruns de discussão, de preferência sobre temas que te interessam muito. Comece a participar em salas de bate-papo de maneira passiva, apenas &amp;quot;ouvindo&amp;quot; o que os outros digitam. Comece a interagir em salas de bate-papo, de preferência com pessoas que também estão aprendendo inglês. Tome uma dose de coragem e instale o Skype ou outro programa de conversação e comece a freqüentar salas de conversação. Quando perder a vergonha, passe a se corresponder com pessoas que falem inglês em uma conversa mano a mano (&amp;quot;e aê manu, certu?&amp;quot;).  Como eu disse no começo desse artigo, cada pessoa tem seu objetivo em aprender uma língua. Cumprido esse objetivo, acredito que já podemos nos dar por satisfeitos. Contudo, quando se começa a aprender de fato uma língua é comum as pessoas acharem que chegarão na linha de chegada ao final do curso, ou ao conseguirem o tão sonhado certificado de proficiência. São marcos, não tenha dúvida. Mas não são o ponto onde se pode parar e descansar pelo resto da vida. Assim como usamos o português no dia-a-dia, o inglês também deve ser usado diariamente. Se não for usado, ele irá aos poucos perdendo lugar em nossas memórias, até o momento em que será necessário recomeçar de um ponto muito distante da linha de chegada que haviamos acreditado ter alcançado para sempre.
A última dica que deixo para vocês é: usem sempre o que aprenderam. A falta de uso é desperdício do tempo passado adquirindo o conhecimento.
Good luck! =)
</description>
</item>

     
        <item>
  <title>O passado torto de um programador por acaso</title>
  <link>http://www.caloni.com.br/o-passado-torto-de-um-programador-por-acaso/</link>
  <pubDate>2007-09-06</pubDate>
  
  <guid>http://www.caloni.com.br/o-passado-torto-de-um-programador-por-acaso/</guid>
  <description>Observação: este é um artigo não-técnico, o que quer dizer que você pode se deparar com termos desconhecidos. Procure ter à mão um dicionário de pessoas comuns.
Sabe aquele senso comum de que adolescente não sabe o que quer da vida? Pois é, naquela época eu não sabia mesmo. Quando iniciei minha vida queria ser desenhista. Então descobri que não conseguia desenhar sem uma régua, o que me levava a crer que seria engenheiro. Mas engenheiro de quê? Bom, como esse tipo de pergunta tem um nível de complexidade além dos limites de uma criança de 12 anos, decidi que decidiria isso na minha oitava série.
Então a oitava série chegou. Fascinado com o conceito de átomos e camadas de elétrons decidi que iria ser químico. Procurei e logo achei um curso técnico de química industrial para o segundo grau. Comecei a estudar para o chamado &amp;quot;vestibulinho&amp;quot;, empolgado com a idéia de vir a trabalhar em uma fábrica usando jaleco.
Até aquele breve momento, tudo ia bem na mente daquele promissor químico de sucesso.
Até que num belo dia minha mãe aparece com um folheto onde, escrito em letras garrafais, conseguia-se ler com um pouco de esforço: &amp;quot;curso de computação&amp;quot;. Computação é mexer com computadores. Até então só tinha visto computadores em filmes de ficção científica e nas bibliotecas da cidade (os velhos sistemas Unisys, ainda de pé na minha velha e boa São Bernardo).
Mexer com computadores (naquele folheto) até que parecia ser uma coisa legal.
E lá fui eu ficar algumas horas por semana sentado à frente daquela tela verde digitando comandos em inglês. Wordstar, Lotus 1-2-3 e o tal do MS-DOS. Havia um segundo laboratório na escola, este mais novo, onde repousava intocado um outro sistema operacional. Diziam ser revolucionário, e que vinha com um novo dispositivo futurístico conhecido como mouse (em Portugal chamavam de rato). Era uma pequena caixa com dois botões conectados à CPU por um fio (tecnicamente seu rabo). Mexemos uma única vez no final de nosso curso com o tal de Windows 3.1, o sistema operacional que vinha nesses micros novos. Foi apenas um rápido e impagável momento de test drive.
Mas, por um motivo que até hoje desconheço, gostei do tal do MS-DOS. Eu dava comandos para o computador e ele obedecia! Achei fascinante! Me diverti muito durante os três meses do curso.
E voltei a estudar para o vestibulinho de químico.
Porém, eis que chega o final de ano e pergunto para o meu amigo o que ele vai fazer.
-- &amp;quot;Processamento de Dados!&amp;quot;-- &amp;quot;Hummm... computadores.&amp;quot;-- &amp;quot;Isso!&amp;quot; Mas que coisa, hein. Balancei, balancei, e acabei mudando minha decisão do início do ano: iria tentar o curso de PD.
E foi assim. Fizemos o vestibulinho. Meu amigo não passou, mas a família dele tinha recursos, colocou ele em uma escola técnica particular. Eu também não passei. A nota de corte era 38. Tirei 37. Por um ponto fiquei sem opções de estudo. Então procurei por vagas em escolas técnicas. Minha mãe encontrou uma, onde existiam dois cursos: magistério e contabilidade.
-- &amp;quot;Magistério é legal. E se não for legal, pelo menos tem um monte de mulher.&amp;quot; Mas dessa vez meu lado numérico falou mais alto, e acabei ficando na sala mais chata. Prestei para contabilidade. Passei fácil.
E agora, após esse breve relapso, tudo estava em paz na mente daquele contador contabilista de futuro.
Dois anos se passaram. Balanços, balancetes, ativos e passivos. Mas nem tudo eram números. Tive uma professora de literatura que era ótima (no sentido bondoso da palavra). Ela me ensinou a ler estes livros não-técnicos que tanto encantam o pessoal de humanas. Também me ensinou a escrever de maneira não-vexatória, já prevendo naquela época que teria que me esforçar para ser um blogueiro de sucesso.
Naquela época comecei a escrever bastante. Gastei uns dez livros de 100 páginas rabiscando palavras. Desejava ser escritor, ficar rico e famoso e reponder às cartas dos fãs. Então lia e escrevia literatura. Quer dizer, eu acreditava que escrevia literatura. Um contador brincando de escritor.
O tempo passou, o ano final chegou e começava a despontar a grande dúvida: o que prestar no vestibular?
Naquele momento, meu lado letrado foi mais forte.
-- &amp;quot;Quero ser escritor, logo, vou fazer letras. Deve ser bem legal! Mas se não for bem legal, pelo menos tem um monte de mulher.&amp;quot; E comecei a estudar para o vestibular. Apenas um vestibular. Fuvest. Se não passasse ficaria a Deus dará. O que me importunava bastante àquela época da vida: depois de 13 anos de escola eu havia ficado um tanto condicionado a comparecer em sala de aula todos os dias de semana da minha vida.
Foi um período interessante. Matemática, Português, História, Geografia, Inglês, Química, Física, Biologia. Livros e mais livros viviam em minha mochila. Para minha sorte, meu emprego era de office-boy, o que me garantia por lei poder ler o dia inteiro, todos os dias, na fila do banco. Algumas noites também. E algumas madrugadas também. Foi um sufoco. Quase não termino meu curso.
Mas terminei. E passei. E de repente lá estava eu no antro da perdição, o início de tudo: FFLCH (lê-se &amp;quot;fefeléche&amp;quot;). E o subsolo era de fato um antro: xadrez, MPB, sebos, discussões filosóficas e muita fumaça. No meio das revoluções estratégicas do pessoal do CAELL eu me sentia extremamente &amp;quot;humanizado&amp;quot;, seja lá o que isso for. E, sim, pela primeira vez na vida, milhares de mulheres interessantes passarelavam pelos corredores dos pensadores da palavra.
-- &amp;quot;Viva a linguística!&amp;quot; Tudo estaria bem na cabeça daquele promissor &amp;quot;professor de português das escolas da rede pública de ensino&amp;quot; se não fosse o meu lado numérico.
Comprei um computador. E isso mudou minha vida. Cada vez mais a quantidade de livros de informática que eu carregava comigo ultrapassava o número de sonetos de Camões ou as prosas modernísticas de Guimarães Rosa que estudava no momento.
Desde aquele dia, o vício tem me acompanhado cronicamente, religiosamente, todo dia.
Larguei a faculdade. Comecei a me dedicar inteiramente aos livros sobre computadores, programação e &amp;quot;como as coisas funcionam&amp;quot;. Quebrei algumas vezes meu computador. Metade delas eu mesmo consegui consertar.
Aprendi como o sistema funciona por dentro enquanto tentava encontrar mais e mais conteúdo com a chegada da internet. Era mágico. Conhecimento infinito! Como não amar uma coisa dessas?
Então descobri que ser hacker era algo muito bacana. E a linguagem que os hackers usam é a linguagem C. Então eu aprendi C, de cabo a rabo. Li o padrão. Sabia de cor algumas passagens. Virei um evangélico: &amp;quot;não atribuirás uma expressão não-const para um lvalue&amp;quot;. No meio dos meus estudos tentava quebrar alguns programas. Metade eles eu consegui.
Entre internet, programação, pornografia online e os primeiros memes (em modo texto) encontro a usenet, grupos de news, e no meio deste um grupo de programadores C e C&#43;&#43;. Começo a ler freneticamente as dúvidas das pessoas. Eu mesmo começo a responder várias destas dúvidas. Entre IRC e news vou criando uma identidade virtual.
No meio das inúmeras mensagens encontro uma proposta de emprego. Aquilo era algo meio alienígena para mim. &amp;quot;Eles vão me pagar pra eu ficar me divertindo o dia inteiro?&amp;quot;. Sim, era isso mesmo. Havia empresas que pagavam um (bom) dinheiro para que resolvessem os problemas que eles precisavam serem resolvidos. Bastava ter uma curiosidade infinita e força de vontade de transformar o desconhecido em conhecimento. E aplicar.
Tremi nas bases nesse meu primeiro emprego. Foi a entrevista mais importante da minha vida. Felizmente conheci um old timer igualmente fascinado por tecnologia como eu. Naquele breve momento em que eu confessei meu amor pela linguagem C e por programação houve comunicação real. E eu fui contratado mesmo sem sequer ter pisado em uma faculdade nem trabalhado na área.
Na minha primeira semana o desafio era desenvolver uma DLL em C que servisse de callback para uma chamada específica do shell do Windows. E todo o conhecimento sobre o padrão da linguagem C não serviu de nada. Eu tive que aprender um monte de coisas novas na raça. E aquilo era empolgante. Continua sendo até hoje.
Depois de uns anos começo a escrever um blogue. E desde então o ser em que me transformei vos fala através daqui. E assim foi. Como é que o pessoal de humanas fala mesmo? Ah, sim: o resto é história.
</description>
</item>

     
        <item>
  <title>ToDoList</title>
  <link>http://www.caloni.com.br/todolist/</link>
  <pubDate>2007-08-27</pubDate>
  
  <guid>http://www.caloni.com.br/todolist/</guid>
  <description>Vou aproveitar que o recente blogue do meu amigo resolveu falar um pouco sobre administração de tempo e citar a ferramenta que venho utilizando há quase um ano para tentar organizar minhas idéias, minhas tarefas e minha vida. Assim como o Kabloc, eu estava em sérias dificuldades para tentar fazer e organizar todas as coisas que eu tinha em mente. Ainda continuo com dificuldades para fazer, mas o mais importante é que agora eu tenho um roadmap de para onde eu quero ir.
Eu sempre ouvi falar nesse programa desde que freqüento o The Code Project, um sítio onde programadores publicam seus minicódigos para serem aproveitados (e avaliados) por toda a comunidade. Possuo algumas pequenas contribuições por lá.
O fato é que por preguiça de testar e pelo seu screenshot inicial, me pareceu um programa demasiado complexo e pesado. Por isso passei vários anos sem sequer baixá-lo.
No entanto, houve um momento em minha vida em que eu precisava definitivamente reunir e organizar todas as minhas idéias e atividades para conseguir concluí-las, tanto no trabalho quanto na vida pessoal. Houve então uma pequena pesquisa de minha parte de programas que fizessem o que eu precisava. Foi aí que eu baixei e testei o ToDoList, um programa pequeno, portátil (posso levar em meu PenDrive) e muito flexível. Eis abaixo o screenshot original do artigo do Code Project:
Bem, me parecia mais do que eu precisava. No entanto ele é flexível, e suas colunas podem ser configuradas da maneira que lhe aprouver. Abaixo um screenshot de como utilizo o ToDoList:
Entre algumas coisas legais que gosto nesse programa que me fizeram ficar com ele, consigo me lembrar da seguinte lista:
 Posso levar onde quiser e salvar minhas configurações em um arquivo ini. Ele fica na área de notificação e posso ativá-lo com um atalho global. Ele conta o tempo de uma tarefa se você quiser. Ele exporta as listas em formatos como Excel, HTML e texto puro. Ele é pequeno e não precisa de instalação. O código-fonte é disponível e está sempre sendo atualizado. Posso salvar minhas listas em XML (padrão) ou encriptado. Pode ser estendido por meio de plugins.  Bem, ele sozinho não resolveu meus problemas. Assim como o Kabloc disse, é você, e unicamente você, o responsável por organizar a sua agenda. E eu tive que passar muito tempo junto da minha para conseguir encontrar a maneira ideal para eu trabalhar. Cada um tem a sua.
Há um tempo atrás não acreditava muito em idéias, mas a partir de um dado momento um outro amigo meu conseguiu me convencer que idéias são os verdadeiros motores do mundo, e um mundo sem idéias seria um mundo de fazedores de coisas sem cabeça. Não adianta ser muito bom no que se faz se não se pensa no que se faz. Essa é um boa razão para explicar por que boas idéias permanecem para sempre, mesmo que seus criadores já tenham morrido há muito tempo.
Por esse motivo que uso o ToDoList para catalogar e listar todas as idéias que tenho sobre o que pretendo fazer. Como você deve adivinhar, a lista nunca acaba e só tende a crescer. Mas tudo bem, o objetivo não é acabar, mas sim não perder a idéia que se teve, pois ela aos poucos pode ser extendida e aprimorada no próprio ToDoList, até chegar a hora de implementar. Quando for a hora de botar a mão na massa muito dos problemas já foi pensado e analisado naqueles momentos de divagação no banheiro, no ônibus, ou na sala de aula. Os momentos mais frutíferos, aliás.
Porém, é claro que catalogar tudo também não é tudo. É preciso agir. Por esse motivo costumo dividir minhas tarefas em duas listas (fora a da empresa onde trabalho): Curto Prazo e Longo Prazo. As tarefas no curto prazo são as mais imediatas, e representam as coisas que devo fazer antes da semana, do mês ou do ano acabar. Geralmente dou uma olhada diária nessa lista. As de longo prazo não são menos importantes, mas possuem um tempo de finalização mais longo, ou porque não são interessantes atualmente, ou porque fazem parte do meu projeto de vida, algo que se deve pensar mais e agir aos poucos. Costumo dar uma olhada semanal nessa lista.
Enfim, cada pessoa tem sua maneira de encarar problemas, catalogar idéias e fazer acontecer. Essa ferramenta, na minha opinião, pode ajudar.
</description>
</item>

     
        <item>
  <title>C&#43;&#43;0x parcial no novo GCC 4.3</title>
  <link>http://www.caloni.com.br/c0x-parcial-no-novo-gcc-43/</link>
  <pubDate>2007-07-24</pubDate>
  
  <guid>http://www.caloni.com.br/c0x-parcial-no-novo-gcc-43/</guid>
  <description>A nova versão do GCC implementa em caráter de teste algumas novas características da nova versão da linguagem C&#43;&#43;, que será lançada ainda nesta década (provavelmente em 2009). As novas funcionalidades são empolgantes e já fazem parte do imaginário dos programadores C&#43;&#43; já há algum tempo.
Atualmente temos duas maneiras de fazer asserções: usando a função assert (assert.h) ou utilizando a diretiva do pré-processador #error. Nenhum desses dois serve para emplates Para eles deverá ser definida a nova palavra-chave static_assert, que irá ser composta de dois parâmetros:
static_assert( expressão-constante, literal-em-cadeia ); Podemos usá-la tanto no lugar da função assert quanto da diretiva #error. Mas seu uso mais interessante é como limite para a instanciação de emplates
template&amp;lt;typename T&amp;gt;static_assert( sizeof(T) &amp;gt;= sizeof(int), &amp;quot;T is not big enough&amp;quot; ) Existem outros lugares onde esse novo comando pode ser usado. Para saber quando usá-lo, lembre-se que a verificação é feita durante a compilação, diferente do assert tradicional, que é chamada em tempo de execução.
Depois de todos esse anos o pré-processador sofrerá um upgrade. O objetivo é ser compatível com o novo padrão da linguagem C, o C99. A maior novidade fica por conta do número variável de parâmetros para macros. A linha abaixo resume tudo:
#define TRACE(format, ...) printf(format, __VA_ARGS__) Ou seja, não será mais necessário usar o truque dos &amp;quot;parênteses duplos&amp;quot; em macros de log que formatam parâmetros.
Considero a mudança dos templates com parâmetros variáveis a mais interessante. Com ela será possível usar um número variável de parâmetros em templates. Basicamente isso permite que um dado template aceite um número variável de parâmetros e esses parâmetros sejam &amp;quot;expandidos&amp;quot; em inúmeras construções dentro do escopo desse template. Nada melhor para explicar que um exemplo, como o caso da herança múltipla. Imagine um template que precisa herdar de seus parâmetros, mas não quer especificar a quantidade:
template&amp;lt;typename... Bases&amp;gt; // quantidade definida pelo usuárioclass MyTemplate : public Bases...{ Outras pequenas correções também serão feitas para tornar a linguagem mais robusta:
 Referências para lvalue. Parâmetros default em funções-template. Problema do fecha-templates duplo (&amp;gt;&amp;gt;).  Podemos esperar por outras grandes mudanças que irão ocorrer nesse novo padrão? Não exatamente. As principais estarão na biblioteca C&#43;&#43;, com a inclusão de diversas classes e funções do projeto Boost. O resto são pequenas correções e melhorias de uma linguagem que, cá entre nós, já está bem poderosa e complexa.
</description>
</item>

     
        <item>
  <title>Como ser um melhor desenvolvedor nos próximos seis meses</title>
  <link>http://www.caloni.com.br/como-ser-um-melhor-desenvolvedor-nos-proximos-seis-meses/</link>
  <pubDate>2007-07-18</pubDate>
  
  <guid>http://www.caloni.com.br/como-ser-um-melhor-desenvolvedor-nos-proximos-seis-meses/</guid>
  <description>Graças ao meu amigo Thiago estive acompanhando uma série de posts de gente renomada sobre o tema deste artigo. Eles fazem parte de uma nova modalidade entre os blogueiros (pelo menos para mim) chamada de tagging. Funciona assim: você escreve sobre algo (por exemplo, &amp;quot;como ser um melhor cozinheiro em 6 meses&amp;quot;) e manda uma tag para que outras pessoas também escrevam sobre o mesmo assunto, o que pode ser feito referenciando o sítio dessas pessoas.
Ainda não tive tempo de ler todos os artigos (nem vou ter, pela velocidade com que isso se espalha), mas acho que dá tempo de escrever um pouco sobre isso.
Acredito que nós, programadores, tentamos aprimorar nossos conhecimentos e nossas técnicas com o objetivo de enxergar os problemas do dia-a-dia de todos os ângulos e de encará-los e resolvê-los da melhor maneira possível. Quer dizer, nós achamos que é a melhor maneira possível. E exatamente por acharmos que tentamos melhorar sempre, em busca da inalcançável perfeição.
O problema existe quando nós, embriagados pela falsa crença de sabermos tudo (ou o suficiente), acreditamos realmente que estamos fazendo o melhor possível e que não há nem haverá maneira de melhorar. É lógico que sempre há. Melhor maneira de ver isso é pegar um código-fonte antigo e observar as mudanças de estilo. E nem precisa ser tão antigo assim. E nem precisa ser código. Pode ser uma idéia antiga de como implementar alguma coisa. A não ser que você seja um teimoso que quer fazer tudo em assembly verá que o que aprendemos ontem influencia nas decisões de amanhã.
Minha lista não é muito diferente da dos outros. Basicamente se resume em: ler livros e blogs, programar mais e pensar mais ainda. O importante é que já estou ciente das coisas que devo melhorar, e é nelas que devo me focar nos próximos 180 dias:
  Fazer um curso de memorização. Confesso que não ligava muito para isso e agora isso faz um diferença e tanto. Eu sei que hoje temos post-its e agendas, mas nada substitui a confiança que temos em nossa própria mente. E é frustrante ler um livro três meses atrás e não se lembrar de capítulos inteiros.
  Fazer um curso de leitura dinâmica. Minha velocidade na leitura é deplorável e eu sei disso. Minha vontade de ler sempre ultrapassa o ato (isso deve ter acontecido com alguns de vocês). Mas o objetivo não é apenas ler mais rápido. É ter foco. Ler e absorver. Não estou dizendo isso de livros de ficção, que para mim são um entretenimento prazeroso. São os livros técnicos que pertubam, e urgem pela minha atenção quando os estou lendo.
  Aprender o meu ritmo. Às vezes me impressiono com o meu descaso para comigo mesmo. Por exemplo, eu já sabia que &amp;quot;rendia&amp;quot; bem mais quando lia livros simultaneamente, e não em fila. Mas mesmo assim insistia em querer terminar um livro antes de começar o outro. O resultado? Aproveitamento 60%. Nada mau. Mas poderia ser bem melhor. Bastava seguir o método que melhor se adapte às minhas necessidades. E isso é o que eu chamo de aprender a si mesmo.
  Agora que já passei pelo sofrimento de taguear nada como escolher minhas vítimas. Não conheço pessoalmente muitos blogueiros, mas pelo menos essa minha lista é fiel e sincera. Rodrigo Strauss, Fernando Roberto e Thiago Oliveira: o que vocês farão nos próximos seis meses para se tornarem melhores desenvolvedores (ainda)?
</description>
</item>

     
        <item>
  <title>Google shortcuts</title>
  <link>http://www.caloni.com.br/google-shortcuts/</link>
  <pubDate>2007-07-06</pubDate>
  
  <guid>http://www.caloni.com.br/google-shortcuts/</guid>
  <description>I love shortcuts. Since my very first years using computers, shortcuts had become my obsession. I research them through the time, collecting them, using them. For a long time I avoid myself from touching the mouse, trainning to remember all keystroke sequences I know.
 I have nothing against using the mouse neither the people that do it. I&#39;m just not very much enthusiastic in using mice. For sometime, I even believed that the cursor pointer was getting me annoyed, so I developed a program to get rid of it from the screen (using a shortcut, of course). But, one more time, I&#39;m not againt its use, and I use it myself sometimes (when I need to).
 Until some time ago the web was not so good for shortcut users. So came out Google, plenty of web applications supporting shortcuts and giving me a true reason to use webmail and web RSS reader without pressing constantly the tab key. But there was a lack for its web search engine. Fortunately, there WAS.
Even being in test, I began to use the new keyboard shortcuts in Google search, available in the Google Experimental Search website. Until now there is shortcuts for next result (J), previous result (K), opening the search (O or ) and putting the cursor in the search box (/). It is just like Gmail and Google Reader. I was so excited with the idea that I changed the Google search plugin inside Firefox by myself. And now I&#39;m going to tell how to do it (note: Windows only).
To put Google search shortcuts inside Firefox probably your search plugin will be in one of these two folder bellow. Try one of them: %programfiles%, Mozilla Firefox, searchplugins or %appdata%, MozillaFirefoxProfiles, *.defaultsearchplugins. The search plugin file has the name google.xml and you can edit it using notepad or another simple text editor. Bellow is the point where you must insert the new line that will get the plugin able to show the shortcuts inside Google.
&amp;lt;Url type=&amp;quot;text/html&amp;quot; method=&amp;quot;GET&amp;quot; template=&amp;quot;http://www.google.com/search&amp;quot;&amp;gt;&amp;lt;Param name=&amp;quot;q&amp;quot; value=&amp;quot;{searchTerms}&amp;quot;/&amp;gt;&amp;lt;...&amp;gt;&amp;lt;Param name=&amp;quot;esrch&amp;quot; value=&amp;quot;BetaShortcuts&amp;quot;/&amp;gt; &amp;lt;!-- Google Shortcuts Here --&amp;gt;&amp;lt;!-- Dynamic parameters --&amp;gt;&amp;lt;...&amp;gt;&amp;lt;/Url&amp;gt; That&#39;s all. Now you can get all the best: the best search engine with shortcuts. How can we be even more productive?
</description>
</item>

     
        <item>
  <title>O bom filho à casa retorna</title>
  <link>http://www.caloni.com.br/hello-world/</link>
  <pubDate>2007-06-15</pubDate>
  
  <guid>http://www.caloni.com.br/hello-world/</guid>
  <description>Depois de seis meses blogueando em um novo domínio, que seria totalmente focado em C&#43;&#43;, descobri que não consigo viver escrevendo apenas sobre a linguagem em que programo. Não é que falte assunto. Simplesmente meu dia-a-dia nunca se resume apenas em regras de sintaxe e erros de compilação.
Por outro lado, aprendi muitas coisas novas desde o começo desse ano. Decorei novos comandos do Windbg, novos atalhos no Google Reader. E fiz outras tantas coisas novas também. Projetei um sistema de comunicação entre processos -- versão alfa, tudo bem, mas projetei. Decifrei o formato do banco de dados do dicionário Houaiss para poder usá-lo no Babylon. E por aí vai.
E por falar em escovação de bits, apresentei mais duas vezes aquela palestra sobre engenharia reversa. O curioso é que, em vez de eu aumentar o conteúdo da transparência, eu diminuo. Talvez isso seja uma ingênua tentativa de tornar a apresentação menos enfadonha e mais interessante para o público em geral, por mais leigos que eles sejam. Nessa última versão (3.0) cheguei a explicar o processo de análise dos cavalos de tróia dentro da Open Security, desde a descoberta da ameaça até a implementação da cura.
Depois de todas essas aventuras percebi que meus conhecimentos em C&#43;&#43; não aumentaram nem um pouco. Talvez um pouco, mas culpa da nossa fascinante lista de discussão sobre C&#43;&#43; aqui no Brasil, que esmera nos detalhes. Porém, por mim mesmo não aprendi nenhuma biblioteca nova do Boost. Não desenvolvi nenhuma artimanha nova usando templates e herança múltipla (obs: com uma perna só). Enfim, não aprendi nem fiz nada relevante com o tema C&#43;&#43; nos últimos seis meses.
E isso me leva de volta para cá, o cantinho de onde nunca deveria ter saído. Mas aprendi a lição. Estarei por aqui de agora em diante, pronto para escrever sobre o que fizer parte dos meus dias de programador. Não irei cair novamente nas ilusões de um pensamento purista e inadequado à minha realidade de escovador-de-bits-estamos-aí-para-o-que-der-e-vier. Afinal de contas, a gente depura mas se diverte.
</description>
</item>

     
        <item>
  <title>Wanderley Caloni</title>
  <link>http://www.caloni.com.br/about/</link>
  <pubDate>2007-06-14</pubDate>
  
  <guid>http://www.caloni.com.br/about/</guid>
  <description>Wanderley Caloni é um programador C/C&#43;&#43; especializado em backend para Windows que decidiu ter seu próprio blogue técnico a pedidos insistentes do seu amigo Rodrigo Strauss, que estava blogando já fazia alguns anos no www.1bit.com.br. Busco mantê-lo atualizado por esses longos anos de programação, depuração e transpiração com minhas peripécias do dia-a-dia. Eventualmente me tornei crítico de cinema e juntei aqui essas duas escovas de dentes, textos técnicos e cinematográficos, o que acabou tornando o saite gigante a ponto de eu precisar trocar meu static site generator para algo mais rápido como Hugo.
Overview geral por cima Colaborador frequente do Grupo C/C&#43;&#43; Brasil, eu e o Strauss nos consideramos fundadores do grupo por organizar e participar do Primeiro Encontro de Programadores e Aficionados da Linguagem C/C&#43;&#43; do Brasil, que ocorreu em São Paulo exatamente no dia dezessete de dezembro de dois mil e cinco, às três horas da tarde, no restaurante Outback do Shopping Eldorado. Desde então o grupo vem realizando encontros mais técnicos no decorrer dos anos, com palestras e debates. A cerveja tradicional se manteve ao final do evento.
Trabalhei por dez anos na área de Segurança da Informação, principalmente em dois sistemas. O primeiro deles, que tenho mais carinho, foi o Sistema de Controle de Acesso a Usuários e Aplicações (aka SCUA), desenvolvido totalmente no Brasil desde a época do MS-DOS. O segundo, mais contemporâneo, desenvolvido pela Open CS, protege os usuários contra ameaças bancárias virtuais, onde meu papel foi fazer análise de trojans e ataques de phishing utilizando engenharia reversa.
Depois desses dez anos migrei para a área financeira e fui trabalhar na EzMarket, uma pequena empresa iniciada pelo meu amigo Anderson Silva (mais tarde ela foi comprada pela UOL). Desenvolvi um sistema de risco que roda em uma das maiores corretoras do país (a Easynvest) e me tornei sócio desenvolvedor de uma empresa especializada nessas soluções, a Intelitrader. Em meio a isso me tornei sócio de outra empresa, a BitForge, pela qual nutro um carinho especial porque ela auxilia empresas e equipes de desenvolvimento em problemas complexos, seja em arquitetura, metodologias ou a pura escovação de bits. A metodologia da BitForge é simplesmente fazer o serviço e resolver o problema, seja ele qual for, da maneira mais indolor possível para o cliente.
No mundo acadêmico mantenho teias de aranha por muitos anos. Participei de minha primeira faculdade aos dezoito anos, no século passado, na Faculdade de Filosofia, Letras e Ciências Humanas da USP (aka FFLCH). Cursei um ano e meio antes de me descobrir perdidamente apaixonado por computação. Eventualmente me formei em Arquitetura de Redes pelo Instituto Brasileiro de Tecnologia Avançada. Finalizando a seção sobre diplomas e troféus em geral, de 2013 a 2018 fui nomeado MVP (aka Most Valued Professional) pela Microsoft, um prêmio em consideração pelas colaborações à comunidade C/C&#43;&#43;.
Entre xadrez e andar de bicicleta, o hobby que levei mais a sério foi mesmo ser cinéfilo inveterado, e com isso escritor em formação. Tendo mantido por quase dez anos um blogue especializado no assunto, o Cine Tênis Verde, desde o finalzinho de 2014 sou colaborador de um site especializado, o CinemAqui, participando de cabines de imprensa e escrevendo críticas sobre cinema, geralmente sobre estreias de filmes fora do circuito hollywoodiano. A pandemia veio a pausar um pouco essa dinâmica, mas me considero extremamente grato pela oportunidade dada pelo Vinicius Carlos Vieira, editor do site.
No detalhe Caso esteja ainda curioso e tenha chegado até aqui, abaixo temos uma breve e não-exaustiva lista das coisas que eu andei fazendo na minha não tão breve vida de escovação de bits. E espero que essa lista continue crescendo.
Desenvolvi uma solução de cópia de arquivos entre máquinas famigeradamente conhecida como &amp;quot;CopyFile que não copia&amp;quot; usando tecnologia COM e expansão de macros. Foi meu primeiro sistema a ser lançado em produção e me orgulho bastante dele ter sido concebido ainda por um programador de nível Júnior que mal sabia compilar uma DLL.
Mantive um sistema de inventário de hardware que utiliza as tecnologias WMI e SMBIOS, além dele ser também um inventário de software, pois coleta dados pelo registro da máquina.
Criei uma proteção da área de transferência, o Ctrl&#43;C Ctrl&#43;V, além do PrintScreen, através de um hook de janelas e manipulação de mensagens globais do sistema. É muito bacana para proteção de cópias fáceis dos dados de uma empresa, ainda que sempre exista a cópia difícil, pelo cérebro do funcionário, impossível (até o momento) de ser protegida.
Escrevi alertas no log de eventos do sistema usando device drivers. Sim, isso parece trivial, mas nada que você desenvolva usando Microsoft em C ou C&#43;&#43; acaba sendo trivial no final das contas.
Me comuniquei entre o user mode e kernel mode através de chamadas à função Windows DeviceIoControl, o que engloba praticamente toda solução desses dez anos em segurança da informação e envolve níveis diferentes de conhecimento, dependendo do protocolo definido entre esses dois mundos.
Acessei remotamente desktops usando ferramenta similar ao VNC com código-fonte modificado, onde a maior dificuldade é compilar de primeira.
Fiz do zero uma ferramenta de execução remota similar ao PsExec. Em alguns casos até melhor, pois vem com o código-fonte.
Controlei a impressão de documentos através de regular expressions usando uma biblioteca da Boost junto de um hook do shell do sistema.
Gerenciei as diretivas de acesso do sistema durante o logon e o logoff dos usuários. Para isso, mais uma vez, apelei para o registro e os hooks que a vida nos dá.
Migrei entre as bases de dados CTree e SQL usando classes OLEDB. Migrei novamente utilizando camadas de abstração DCOM. Migrei mais uma vez desenvolvendo ferramentas de conversão. Havia algum problema de gerência nesse projeto que nunca conseguiu abandonar a tecnologia antiga.
Autentiquei no Windows usando serviço DCOM e GINA customizada, ou até mesmo a Credential Provider, desenvolvida no Windows Vista para substituir as técnicas anteriores.
Sincronizei remotamente duas bases de dados CTree usando serviço DCOM (olha o projeto de bases de dados CTree aí de novo).
Compilei um CD Linux bootável com scripts bash e ferramentas de criptografia de discos. Tudo em linguagem C.
Também mexi no driver de criptografia de discos rígidos e armazenamento USB, como o uso de pen drives.
Já realizei dezenas de análises de telas azuis ou dumps de memória usando WinDbg, seja em kernel mode ou user mode.
Certa vez fiz um serviço COM de execução de aplicativos na conta de sistema que foi muito útil para vários pontos de um sistema gigante.
Customizei a MBR, ou Master Boot Record, os primeiros bytes que ligam um PC, adaptando de acordo com as características da BIOS, o código que está na placa que liga um PC.
Mantive uma biblioteca de criptografia Blowfish e SHA-1 em C&#43;&#43; e Assembly 16 bits, o que me rendeu uma semana de análise de um bug em modo real e um ótimo artigo aqui no blog. Com isso aprendi a usar um carregador de boot em Assembly 16 bits e depuração usando o simplório debug.com.
Outro sistema que deu certo trabalho foi o driver de auditoria de acesso, que usa memória compartilhada e eventos entre user mode e kernel mode. Mais sessões intermináveis de depuração no WinDbg.
Trabalhei com um sistema que fazia hook de API (mais um hook) em kernel mode para ambas as plataformas Windows, NT e 9X.
Protegi os executáveis através de autenticação em domínio configurado no resource dos arquivos, uma solução muito boa para centralizar instalações em um ambiente.
Mantive DLLs de proteção à navegação em Internet Explorer 6 e 7, e Firefox 1 e 2. Tudo usando injeção de código Assembly 32 bits.
Desenvolvi uma biblioteca de proteção de código, strings na memória e execução monitorada. Isso envolvia desde o alto nível da ferramenta até o uso de interrupções Win32.
Também desenvolvi uma biblioteca de geração de log centralizado, o que parece fácil, mas não quando você precisa controlar todos os processos do sistema através de memória mapeada e eventos globais.
Já mexi com os BHOs, ou Browser Helper Objects, e ActiveX, para Internet Explorer 6 e 7. Para o Mozilla e Firefox usei um plugin XPI.
Já fiz muito gerenciamento de projetos usando Source Safe, Subversion, Mercurial, Bazaar e scripts batch. Atualmente meu maior conhecimento em controle de fonte é usando git na linha de comando.
Já fiz debug de kernel em plataformas NT usando SoftIce e WinDbg. Isso em NT, mas como em 9X não existem essas coisas a solução foi uma mistura entre SoftIce e um depurador obscuro, que quase ninguém deve saber que existe, chamado WDeb98. Rodei esse cara dentro de uma máquina virtual emulada em conjunto com a interpretação das instruções em Assembly.
Como citado na introdução, fiz engenharia reversa de trojans feitos em C&#43;&#43;, Visual Basic e Delphi usando WinDbg e IDA, e posso dizer com propriedade que os mais difíceis de entender são os feitos em VB.
Fiz certa vez uma ferramenta de diagnóstico muito simpática que lista arquivos, serviços, drivers, registro, partições, processos, tudo de uma máquina Windows.
Monitorei a execução de jobs em Windows 2000 ou superior para controle de instalação e atualização de produtos.
E por falar em monitoração, também registrei a frequência de uso de aplicações usando hook de janelas, de maneira invasiva e não-invasiva. O que não travasse estava bom.
Como pet project fiz a reversa do dicionário Houaiss e importei para o formato de outro dicionário eletrônico, o Babylon.
Controlei o sistema de build quando não havia muitas soluções open source por aí com Cruise Control .NET, e mantive um servidor de símbolos, talvez um dos únicos na época fora da Microsoft, usando Debugging Tools for Windows.
Documentei projetos através de Doxygen e uma solução wiki chamada Trac. Mantive os sistemas de documentação no ar e ativos enquanto estava no projeto, embora depois essas coisas se perdem e ninguém mais sabe como fazer as coisas.
Outro projeto que lembro com carinho, quando atingi a marca de dez mil linhas de código, foram as interfaces de gerenciamento para desktop que desenvolvi usando C&#43;&#43; Builder 5 e 6 e bibliotecas Visual C&#43;&#43;. O principal deles, conhecido como Manager, roda até hoje, em um mundo onde tudo está no browser. Já mexi com interfaces de análise também, feitas em Visual C&#43;&#43; com os frameworks MFC, ATL e WTL.
Fiz análise de e-mails usando expressões regulares, dessa vez com a biblioteca da ATL, que é muito curiosa e enxuta, além de bugada. Nessa época também me especializei em análise de logs e edição global de projetos utilizando regular expressions. É impressionante o quanto você consegue economizar de tempo analisando logs e projetos gigantes se conhecer regular expressions.
Como citado na introdução, desenvolvi um sistema de risco para o mercado financeiro, corretoras da bolsa de valores. Hoje roda em uma das maiores corretoras do país, e contém o conjunto mais rebuscado de regras que alguém da área de risco poderia querer, desenvolvido com a ajuda de um especialista na área. Este é outro projeto que me dá orgulho, principalmente pelo sistema que detecta travas de opções.
Escrevi muitos artigos em português no meu blogue técnico, e mais alguns em inglês, aqui e pelo Code Project, que por muitos anos era a comunidade mais ativa de projetos Microsoft.
Desenvolvi uma API de comunicação com dispositivos HID USB, o que permite navegar pela árvore de dispositivos hoje em dia que estão conectados pelo protocolo. Isso envolve pen drives, celulares, câmeras, qualquer coisa que tenha uma entrada ou saída USB.
Já programei para interfaces mobile do finado Windows Phone e para o Android. Para um usei Visual Studio e para o outro Android Studio. É impressionante como ainda são pesadas essas interfaces de desenvolvimento para mobile.
Venho mantendo as soluções de baixo nível da Intelitrader, principalmente as que envolvem market data, pois o fluxo de dados nesses sistemas é absurdamente alto em tempos de crise. Ou seja, atualmente, todo o tempo.
 &amp;quot;Não basta saber: temos que aplicar. Não basta querer: temos que fazer.&amp;quot; Goethe
 </description>
</item>

     
    
  </channel>
</rss>
