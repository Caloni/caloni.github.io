<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>code on Blogue do Caloni</title>
    <link>http://www.caloni.com.br/tags/code/</link>
    <description>Recent content in code on Blogue do Caloni</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>pt-br</language>
    <lastBuildDate>Sun, 07 Jun 2020 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://www.caloni.com.br/tags/code/" rel="self" type="application/rss+xml" />
    
     
        <item>
  <title>Awk</title>
  <link>http://www.caloni.com.br/awk/</link>
  <pubDate>2020-06-07</pubDate>
  
  <guid>http://www.caloni.com.br/awk/</guid>
  <description>Meu amigo sugeriu que aprender awk poderia ser útil de várias maneiras. Uma delas para organizar finanças pessoais. Dei uma lida em alguns tutoriais, sendo que o melhor custo benefício foi o Awk in 20 Minutes, de Fred Hebert (ele é o mesmo autor de um livro sobre erlang). Gostei. É sobre tratamento de texto como sed, mas em uma versão estendida e criada na época com a mesma sintaxe de C.
# commentPattern1 { ACTIONS; }# commentPattern2 { ACTIONS; }# commentPattern3 { ACTIONS; }# commentPattern4 { ACTIONS; } Por ela ser uma ferramenta antiga usa conceitos antigos, como field e record. Ela foi criada para formatar texto em formato de planilha, ou banco de dados. Um field, ou campo, é uma coluna na planilha, e um record, ou registro, é uma linha dessa planilha. Imagine que você pode usar awk para manipular e extrair dados de qualquer texto que contenha esse padrão, sendo que os detalhes como o separador de campos e registros, por padrão espaço e nova-linha, podem ser alterados no começo do programa.
# can be modified by the userBEGIN {# Field# SeparatorFS = &amp;quot;,&amp;quot;;# Record# Separator (lines)RS = &amp;quot;\n&amp;quot;;# Output# Field# SeparatorOFS = &amp;quot; &amp;quot;;# Output# Record# Separator# (aka lines)ORS = &amp;quot;\n&amp;quot;;}# can&#39;t be modified by the user{# Number of Fields# in the current RecordNF# Number of Records# seen so farNR# Script ArgumentsARGV / ARGC} Como toda linguagem usada como ferramenta do dia-a-dia existem os comandos mais úteis:
# prints $0 # (just print will do it){ print $0; } # ends the program{ exit; } # skips to the # next line of input{ next; } # variable assignment{ a=$1; b=$0 } # array assignment{ c[$1] = $2 }  Existem tópicos mais avançados como funções, seja embutidas ou criadas pelo usuário (inclusive em C), e versões mais novas como nawk e gawk. Assim como existe o vim e existem plugins, sendo que passo muito bem sem usar plugins no meu vim. Acho difícil que um dia precise estender awk, exceto por curiosidade e para aguçar minha criatividade. E como o próprio guia GNU da ferramenta sugere, se seu programa awk atingir algumas centenas de linhas é melhor você refazer em outra linguagem. Python, por exemplo (brincadeira).
{ if (BOOLEAN) { ACTION }else if (BOOLEAN) { ACTION }else { ACTION }}{ for (i=1; i&amp;lt;x; i&#43;&#43;) { ACTION } }{ for (item in c) { ACTION } } </description>
</item>

     
        <item>
  <title>Golang e C</title>
  <link>http://www.caloni.com.br/golang-e-c/</link>
  <pubDate>2020-04-05</pubDate>
  
  <guid>http://www.caloni.com.br/golang-e-c/</guid>
  <description>É muito difícil configurar a linguagem Go no ambiente Windows para compilar código C. O único ambiente de compilação que o projeto leva a sério são os ports do GCC, e não o Visual Studio, que seria a ferramenta nativa. Dessa forma, realizei boa parte das travessuras desse artigo em Linux, usando o WSL com a distro Ubuntu ou CentOS. Deve funcionar em qualquer Unix da vida.
A linguagem Go na versão mais nova precisa que seja definida através da cgo, o backend C do ambiente de build da linguagem, uma função trampolim, que é uma função escrita em C que irá chamar uma função escrita em Go. Essa função pode ser passada como parâmetro de callback para uma biblioteca C que quando a biblioteca C chamar esse ponteiro de função ele irá atingir a função trampolim, que por sua vez, chama a função Go, que é onde queremos chegar depois de todo esse malabarismo.
main|C.set_callback|C.call_callback|g_callback*|GoCallback_cgo|GoCallback Em resumo: o main em Go chama C.set_callback (função C exportada) passando o endereço do seu callback (em cgo) e em uma segunda chamada ou nessa mesma pede para chamar esse callback. O módulo em C pode ou não chamar essa função nessa thread ou mais tarde, através do ponteiro de função que estocou (g_callback). Ao chamá-la, ativará a função GoCallback_cgo, que por sua vez chamará GoCallback, essa sim, já no módulo Go (embora ambas estejam no mesmo executável, já que C e Go podem ser linkados juntos de maneira transparente.
Criei um repositório com os fontes deste artigo. Bom proveito =)
</description>
</item>

     
        <item>
  <title>Projeto Hu Cpp: Not Fast Enough</title>
  <link>http://www.caloni.com.br/projeto-hu-cpp-not-fast-enough/</link>
  <pubDate>2020-03-17</pubDate>
  
  <guid>http://www.caloni.com.br/projeto-hu-cpp-not-fast-enough/</guid>
  <description>Continuando minhas aventuras em tentar ser mais rápido que o Hugo, fiz uma versão que gera um html porco com os parágrafos obtidos no parser porco de markdown, rodando em cima dos meus 2740 posts. Este é o código novo:
Lembrando o resultado do Hugo no post passado:
Agora executando o meu programinha caseiro (b.bat é uma batch que executa todos os posts usando o comando for do Windows; ptime é uma versão Windows do time do Linux, que mede performance na execução de um programa).
Noventa segundos para 2700 posts! É uma vergonha! Programadores C&#43;&#43;/Boost/Asio, vamos nos matar.
</description>
</item>

     
        <item>
  <title>Projeto Hu Cpp</title>
  <link>http://www.caloni.com.br/projeto-hu-cpp/</link>
  <pubDate>2020-03-15</pubDate>
  
  <guid>http://www.caloni.com.br/projeto-hu-cpp/</guid>
  <description>Utilizo o Hugo como renderizador do meu saite já faz um tempo. Depois que juntei os posts do finado Cine Tênis Verde e do meu blogue técnico a soma dos textos ultrapassou a marca dos dois mil. Atualmente levo cerca de quinze segundos para renderizar todo o saite antes de publicá-lo.
Não é uma marca ruim, considerando que estamos com quase três mil textos, e embora o leiaute do saite seja muito simples, é justamente o que eu desejo para rápido carregamento e busca. Não tenho do que reclamar.
Porém, um programador C nunca fica satisfeito com uma solução Golang.
Sabe esses pensamentos que não saem da cabeça? Estava devaneando há uns dias sobre se não seria interessante renderizar meu saite usando uma solução em C ou C&#43;&#43; e ver qual seria o resultado. Claro que seria uma solução in house, cheia de bugs e completamente limitado. Mas quem liga? Meu único objetivo é a diversão, e não pretendo criar um produto genérico. Hugo já satisfaz até o mais exigente dos programadores (exceto o Elias), pois resolve vários problemas do interminável conflito entre conteúdo e design.
Por falar no dito cujo, me lembrei da nossa disputa no saite Os Programadores. Era uma resolução de exercício envolvendo leitura e parseamento de um arquivo json. Tive o insight de usar algo parecido com o que desenvolvi naquela vez.
Esse código lê um arquivo markdown e divide o header nos campos que eu utilizo e o texto em parágrafos. Esse é o começo mínimo para começar a converter os arquivos em html. Ele usa o mapeamento de arquivo em memória como no desafio 5 acima. Não precisaria, mas já que a diversão é fazer mais rápido que o Hugo, por quê não?
Meu próximo passo é pegar esse parser e converter todos os arquivos para html, da maneira mais porca possível. Quer dizer, quase da maneira mais porca. Não estou usando Pascal.
</description>
</item>

     
        <item>
  <title>Como Funciona o MPTunnel</title>
  <link>http://www.caloni.com.br/como-funciona-o-mptunnel/</link>
  <pubDate>2019-12-11</pubDate>
  
  <guid>http://www.caloni.com.br/como-funciona-o-mptunnel/</guid>
  <description>A ideia por trás de um sistema multipath de rede é fornecer mais de um caminho para o tráfego de pacotes. O objetivo pode ser diminuir a perda de pacotes por causa da instabilidade da rede, mas também isso irá fazer com que o throughput da comunicação seja maior pela diminuição da razão da perda de pacotes, além da melhor rota acabar sendo por onde os pacotes irão chegar primeiro, em uma espécie de seleção natural da arquitetura.
Esta é uma implementação em user space de UDP multipath. Assim como a contraparte em sua versão TCP, você pode estabilizar várias conexões entre o servidor local e o remoto.
MPTCP (MultiPath TCP) é uma boa ideia para tornar a conexão de rede mais robusta, mas apenas funciona em TCP, e em um ambiente multiplataforma não há soluções em kernel mode exceto o ECMP desenvolvido no último Linux, cujos artigos de Jakub Sitnicki explicam os detalhes. E foi através da busca por uma implementação de MPUDP que foi escrita essa ferramenta por greensea, um usuário do GitHub.
Existem dois servidores Server A e Server B. A conexão de rede entre Server A e Server B é instável (com uma razão alta de perda de pacotes). Dessa forma, nós gostaríamos de estabilizar um túnel multipath entre Server A e Server B, esperando que a conexão entre ambos se torne mais estável (diminua a razão de perda de pacotes). Com o broadcast dos pacotes por vários caminhos o resultado a longo prazo é uma comunicação cuja performance é prioridade.
mpclient é a parte cliente do mptunnel, ele pode rodar no ServerA. Você deve dizer ao mpclient a informação dos servidores bridge. Uma vez que o mpclient é iniciado, ele abre uma porta local UDP para listen e redireciona qualquer pacote de/para os servidores bridge.
mpserver é a parte servidora do mptunnel, ele pode rodar no ServerB. Você deve dizer ao mpserver a informação do Server B. Uma vez que mpserver é iniciado, ele irá redirecionar qualquer pacote de/para o Server B.
Os servidores bridge são simples, eles apenas redirecionam os pacote do mpclient para mpserver, ou pacotes do mpserver para mpclient. Você pode usar nc ou socat para entregar um servidor bridge.
Para a solução ser rodável em Linux, Windows e Mac OS os fontes compilam em um ambiente POSIX mínimo, já disponível nos três SOs, sendo que para Windows este ambiente é o Cygwin.
O resumo para compilar em Linux é instalar o gcc, o make, o git, as dependências, baixar o projeto e compilar. Esses passos devem funcionar em qualquer Linux, mas foi testado em Ubuntu.
O primeiro passo é baixar e instalar o cygwin com os seguintes pacotes adicionais ao padrão:
 gcc-core, socat, git, make, libev, libev-devel, libintl-devel.  Em seguida deve-se baixar o repositório do mtunnel e do terminal cygwin executar o build.
Dentro deste repositório há como exemplo dois programas client/server em UDP, udpclient.c e udpserver.c. Eles se comunicam de um lado para outro enviando mensagens de hello com um número na frente que é incrementado pelo servidor.
Eu quero conectar em meu udpserver, mas a conexão é instável e a razão de perda de pacotes é alta, gerando um throughput muito pequeno. Para aumentar o throughput, ou seja, diminuir a perda de pacote, eu posso rodar um MPUDP para o servidor e estabilizar uma &amp;quot;conexão&amp;quot; UDP através da redundância das bridges.
O udpserver está em listen na porta 6666 UDP e eu executo o mpserver no servidor da seguinte forma:
Localmente executo o mpclient da seguinte forma:
Abaixo está o conteúdo do arquivo client.mpclient.conf
Em cada &amp;quot;servidor bridge&amp;quot; (no exemplo está tudo local, mas não precisaria) use socat para redirecionar os pacotes:
Os servidores bridge irão ficar em listen nas portas 4001, 4002 e 4003 e redirecionar qualquer pacote recebido para localhost:2000, e vice-versa.
Agora eu faço o cliente conectar em localhost:4000 que o mpclient está em listen ele irá estabiizar uma conexão sobre o MultiPath UDP tunnel.
Dois scripts estão disponíveis para iniciar e parar a arquitetura de exemplo acima chamados respectivamente sample.start.sh e sample.stop.sh.
Para observar a performance da solução os samples udpclient/udpserver servirão para medir a eficiência de uma comunicação onde as bridges se tornam instáveis, e para isso eles precisarão de uma rota remota entre as bridges. Este teste requer ao menos uma máquina a mais que esteja acessível na rede pelas portas a serem usadas (pode ser uma máquina virtual).
Altere a execução das bridges da seguinte forma, trocando o endereço remoto pelo correto.
Isso fará com que três dos quatros bridges sejam remotos, enquanto o último estará funcionando totalmente local. Ao iniciar o mptunnel nesta configuração a comunicação entre udpclient e udpserver continuará funcionando na mesma velocidade mesmo que a comunicação na rede seja interrompida, graças ao quarto caminho totalmente local.
Outros cenários podem ser desenhados levando em conta a velocidade de uma rede ou sua instabilidade.
Mptunnel adiciona alguma informação de controle dentro dos pacotes, incluindo informação síncrona. mpserver e mpclient devem ser iniciados ao mesmo tempo. Se o mpclient ou o mpserver terminar, você terá que reiniciar ambos para restabelecer o túnel.
Atualmente você pode especificar apenas um único host alvo. Alguém sabe se existe uma biblioteca C de proxy SOCKS5? Penso que ao tornar o mpclient como um servidor proxy SOCKS irá torná-lo mais fácil de usar.
Mptunnel não encripta os pacotes por padrão, apesar de ter essa opção, pois isso irá diminuir o throughput. Em alguns testes o throughput atual é 3Mbps enquanto usando três túneis com criptografia, e após desabilitar a criptografia o throughput sobe para 300Mbps. Se você ainda quiser que o mptunnel encripte os pacotes, defina a variável de ambiente MPTUNNELENCRYPT=1.
Para compilar o mptunnel, essas bibliotecas são requeridas:
 libev mlvpn, uma solução similar para multipath UDP.  </description>
</item>

     
        <item>
  <title>Vcpkg: Bootstrap</title>
  <link>http://www.caloni.com.br/vcpkg-bootstrap/</link>
  <pubDate>2019-11-29</pubDate>
  
  <guid>http://www.caloni.com.br/vcpkg-bootstrap/</guid>
  <description>A versatilidade do vcpkg, gerenciador de pacotes multiplataforma da Microsoft, é permitir modificar tudo no projeto, desde código-fonte, pacotes instaláveis e a própria origem do repositório. Através do controle de fonte um vcpkg pode ser alimentado por diversas fontes, e por cada pacote existir em uma pasta separada permite a coexistência de várias versões e origens. Além disso, a forma de compilar os projetos e o código-base pode ser alterado exatamente da forma com que o projeto precisa.
Sabendo de tudo isso, a única coisa que você precisa em um projeto isolado é um script de bootstrap que baixe um repositório vcpkg customizado para o projeto, compile, instale os pacotes necessários e integre com o Visual Studio antes de iniciar a compilação do próprio projeto. Dessa forma é possível montar o ambiente de maneira automática e sanitizada para qualquer membro da equipe ou máquina de build.
Vejamos como seria um bootstrap.bat:
Com esse script na pasta raiz do seu projeto ele irá criar uma subpasta chamada vcpkg e após realizar as operações descritas acima integrar ao Visual Studio. Dessa forma quando for compilar o projeto os includes e libs já estarão disponíveis para que ele funcione, mesmo diretamente de uma máquina limpa.
Esse script pode ser integrado à lib principal do projeto ou o projeto da solution que primeiro deve compilar (porque todos dependem dele). Para isso existe o Pre-Build Event nas configurações de um projeto do Visual Studio. Os comandos que estiverem lá serão executados sempre antes da compilação.
O único passo não-descrito neste artigo é baixar o projeto e iniciar o build, tarefas triviais de integração.
</description>
</item>

     
        <item>
  <title>DTLS Simples... simples?</title>
  <link>http://www.caloni.com.br/dtls-simples/</link>
  <pubDate>2019-11-13</pubDate>
  
  <guid>http://www.caloni.com.br/dtls-simples/</guid>
  <description>O protocolo DTLS, grosso modo, é um addon do TLS, que é a versão mais nova e segura do SSL, só que em vez de usar por baixo o TCP, que garante entrega na ordem certa dos pacotes, além de outras garantias, o UDP é permitido. Ou seja, datagramas. Em teoria essa forma de usar TLS é uma versão mais light, com menos overheadh e tráfico de banda. E a pergunta que tento responder aqui é: será que isso é verdade?
A primeira tarefa é conseguir compilar e rodar um sample DTLS para Windows, que é meu sistema operacional alvo. Para criar um sample client/server de DTLS usando a biblioteca OpenSSL (no momento 1.1.1d) precisei de alguns passos de setup, conforme especificado neste tutorial. O repositório DTLS-Examples possui alguns starts para começarmos a compilar e rodar um pouco de código, mas nem tudo são flores na hora de rodar para Windows.
O exemplo que peguei, dtlsudpecho.c, como diz o nome, usa DTLS em cima de UDP. As funções de setup e de definição de callbacks e settings do OpenSSL são configuradas de acordo com o esperado, mas por algum motivo quando a conexão entre um server e um client é estabelecida o server dispara vários listenings e a conexão estabelecida pelo client permanece sem escrita e leitura.
Após compilar o OpenSSL e antes de iniciar os testes gerei os certificados:
Analisando a troca de pacotes pelo Wire Shark descobri um erro no handshake envolvendo fragmentação.
Tentando descobrir o motivo encontrei alguns issues no GitHub a respeito de problemas no OpenSSL, e a solução era definir um MTU (Maximum transmission unit) em vez de deixar o OpenSSL usar o default, que é pequeno demais para poder enviar as mensagens do handshake de uma só vez, requisito do protocolo.
Isso corrigiu o envio do ClientHello, mas após isso o handshake entrou em loop no envio do resto das mensagens até retornar com erro.
Do roteiro descrito pela RFC faltam as mensagens Finished após ChangeCipherSpec, o que terminaria o fluxo, mas por algum motivo o Finished nunca chega em nenhum dos lados, e as mensagens a partir de ServerHello se repetem até o retorno de erro de conexão (SSLERRORSSL). O Sequence Number do server e client indicam que apesar da troca de mensagens estar ocorrendo existe um loop.
Encontrei um gist que acompanha passo a passo o setup necessário da biblioteca. Ao pesquisar mais a respeito encontrei um artigo de Christopher A. Wood que também está explorando esse protocolo usando OpenSSL e que é o autor do primeiro repositório de exemplo de DTLS, que falha não por não funcionar, mas por estar usando TCP em vez de UDP ao usar a flag SOCKSTREAM em vez de SOCKDGRAM na criação do socket.
Depois de muito analisar o protocolo desenhando cada pacote na janela do escritório resolvi abandonar essa miríade de detalhes e dar um passo atrás, usando o próprio openssl.exe compilado com os parâmetros abaixo. E, surpreso, mas nem tanto (afinal de contas, a compilação do OpenSSL passou pelos testes pós-build) eu consigo executar o protocolo DTLS em UDP IPV4 sem nenhuma falha:
O passo seguinte foi entender o código e as diferenças com os samples que havia tentado fazer funcionar da única maneira que penso ser possível: depurando. Sem conseguir navegar em todos os detalhes do fonte do OpenSSL recompilei o projeto com full debug alterando as flags de compilação no Makefile gerado para Windows (/Od e /Zi ajudam) e iniciei os dois modos acima depurando em duas instâncias do Visual Studio. Encontrei uma ou outra chamada à biblioteca OpenSSL que não havia notado ainda, mas nada que parece fazer a diferença.
Mas nenhuma dessas mudanças fez efeito no projeto de teste. O próximo passo seria copiar cada chamada feita à lib OpenSSL pelo openssl.exe e colar no projeto de teste para descobrir onde está o pulo do gato que nenhum dos samples na internet parece ter encontrado (ao menos para Windows), mas há uma solução preguiçosa que é muito mais efetiva e testada: usar os fontes da própria pasta apps do projeto OpenSSL.
O próximo e último passo é customizar o código-fonte base no qual a OpenSSL valida o protocolo DTLS para o uso que pretendo fazer para ele: um executador de processos remoto.
</description>
</item>

     
        <item>
  <title>Vcpkg: openssl.cnf</title>
  <link>http://www.caloni.com.br/vcpkg-openssl-cnf/</link>
  <pubDate>2019-09-17</pubDate>
  
  <guid>http://www.caloni.com.br/vcpkg-openssl-cnf/</guid>
  <description>Mais uma aventura em vcpkg. Dessa vez o projeto openssl, a biblioteca de SSL open-source multiplataforma. O vcpkg divide esse port por SO, sendo o openssl-windows o port que alterei. A alteração foi enviada como PR para a Microsoft, mas no momento está apenas no repo da BitForge.
O que acontece é que alguns comandos executados no openssl.exe compilado e instalado do vcpkg precisam conter o arquivo de configuração disponível, como o genrsa:
A compilação do openssl-windows pelo vcpkg gera o arquivo, mas o apaga após o build. Há uma checagem pós-build no vcpkg.exe que verifica se há arquivos sobrando na estrutura de diretórios que será copiada para a pasta installed/triplet após a conclusão da instalação no módulo postbuildlint. A função checknofilesindir verifica se há arquivos sobrando nos diretórios onde eles não deveriam estar e cancela a instalação. Por isso que originalmente o openssl-windows/portfile.cmake apaga o openssl.cnf gerado na pasta raiz e na subpasta debug do build.
Minha mudança foi apenas não apagar o arquivo openssl.cnf release e movê-lo para a pasta onde está localizado o openssl.exe. Dessa forma fica simples de detectá-lo, mas ainda assim é necessário apontar para a ferramenta onde ele está, definindo a variável de ambiente OPENSSLCONF ou passando como parâmetro.
</description>
</item>

     
        <item>
  <title>Vcpkg: Boost para Windows XP</title>
  <link>http://www.caloni.com.br/vcpkg-boost-windows-xp/</link>
  <pubDate>2019-09-16</pubDate>
  
  <guid>http://www.caloni.com.br/vcpkg-boost-windows-xp/</guid>
  <description>Quem programa em C&#43;&#43; no Brasil geralmente precisa estar preparado para manter velharias. Boa parte do parque de máquinas das empresas usam Windows, e não estou falando de Windows 10, mas muitas vezes XP. Apesar da Microsoft ter largado uma das melhores versões do seu SO para trás, milhares de máquinas ainda rodam esse bichinho, e muitos programadores precisam manter e desenvolver em nome da compatibilidade.
Porém, o desenvolvimento de libs C&#43;&#43; foram aos poucos largando o suporte ao XP (em C isso não existe muito, pois é mais fácil ser portável em C), pois muitos mecanismos de SOs modernos surgiram depois, como um mutex light ou mutex apenas de read. E como eles olham para o mercado global, o Brasil acaba ficando para trás.
E isso inclui a Boost, o famoso conjunto de bibliotecas usado pelos engenheiros que gostam de complicar seu código. O suporte oficial a XP da Boost acabou na 1.60, mas é possível compilar, se você quiser, versões mais novas, como a 1.68, que usaremos neste artigo. Com ela é possível gerar uma versão compatível com Windows XP usando o builder da Boost e alguns parâmetros mágicos, como toolset e define.
O parâmetro toolset usa no caso a versão compatível para XP do conjunto de compilação do Visual Studio 2015, e o define BOOSTUSEWINAPIVERSION é colocado para suportar pelo menos Windows XP. Já o stagedir seria apenas para separar a compilação padrão para a que suporta XP e é opcional para manter duas compilações distintas. Importante lembrar que, apesar da Microsoft ter extinto o suporte a XP, até o Visual Studio mais novo possui um toolset, compilador e libs para Windows, que suporte o sistema operacional.
Esses mesmos parâmetros usados no build da Boost podem ser usados dentro do vcpkg, o compilador de pacotes multiplataforma da Microsoft. Como esperado, as libs do vcpkg compilam usando tudo do último em sua máquina: Boost, Visual Studio e o suporte ao último Windows (no caso do pacote da Boost, não, se usa o Windows Vista em diante). Mas você pode e deve modificar os ports padrões sempre que necessário. Este artigo explica como fazer partindo do zero sem receita de bolo. Vamos escanear o problema e resolvê-lo. Para isso vamos usar um exemplo bem simples da Boost.Log, que possui dependências mais novas que o Windows XP.
O status inicial e inocente de um projeto que deseja rodar para XP em Visual Studio 2015 (nosso caso de uso, poderia ser o VS mais novo) é criar um projeto que usa Boost.Log pelo wizard, instalar, se ainda não estiver instalado, o Boost.Log no vcpkg, e acabou. Só que não. Eis o código:
Agora eis as configurações:
Esse é um erro que geralmente acontece por dois motivos. O primeiro é quando rodamos um executável de 64 bits em um ambiente 32, mas este não é o caso. O segundo é quando rodamos um executável que possui alguma DLL faltando ou funções específicas de alguma DLL, que é o caso. Para descobrir as dependências de um executável basta rodar o comando dumpbin de dentro de um terminal com as ferramentas do Visual Studio disponíveis.
Dependências de APIs relacionadas com o SRWLock dizem respeito ao Slim Read/Write Lock do Windows, implementado a partir do Windows Vista. A primeira coisa a ser descoberta pelo programador é: quem está usando essas funções? Se não está no seu próprio código, provavelmente está em uma das libs linkadas. E uma dessas libs com certeza é o Boost.Log, pelo include no código.
Note as linhas onde ::InitializeSRWLock é chamado. O escopo global indica que há uma dependência estática entre essa função API e o executável se essa parte do código for compilada, o que pode ser descoberto através da IDE do Visual Studio abrindo os arquivos e verificando se a parte onde há essas chamadas fica &amp;quot;cinza&amp;quot; (há defines que impedem essa parte de compilar), ou depurando e inserindo breakpoints nessa parte, que deverá ser chamada. O dumpbin poderia ser usado de novo caso houvesse símbolos para explorar o uso dessas funções de dentro do executável, mas por padrão a compilação do Boost não gera símbolos, tornando a tarefa ingrata, pois estará tudo em assembly sem tradução para o fonte.
Então, ficamos mesmo na análise do código-fonte e da compilação:
Se analisarmos onde BOOSTUSEWINAPIVERSION é definido descobriremos que ele é um reflexo do famigerado WIN32WINNT, que é o define que o Windows usa para determinar qual a versão mínima que o executável deve rodar. Windows Vista é 0x0600, Windows XP é 0x0501 (com SP 2 em diante 0x0502).
Isso quer dizer que devemos compilar nosso projeto indicando que pretendemos rodar em Windows XP:
E aí começam os problemas de linker.
Aparentemente a própria lib Boost.Log está entrando em contradição com ela mesma, pois há usos dos métodos new e delete, por exemplo, entre vários. A análise da lib compilada irá nos revelar que esses nomes realmente não existem.
Não há nenhum símbolo com esse namespace. Precisamos agora averiguar de onde ele vem.
Então o Boost precisa ser compilado com esse define, também. Do contrário ele deve conter o namespace v2smtnt6 em sua lib. Mudando o define no nosso projeto ele irá apenas mudar a definição nos headers, mas não na lib já compilada.
Mas para isso precisamos descobrir como o Boost é compilado no vcpkg. Sabemos que ele utiliza arquivos cmake dentro de cada subpasta em port, que junto de uma série de scripts já disponíveis pela ferramenta irá executar ações de compilação, instalação, etc. De dentro do Boost.Log encontramos alguns arquivos para analisar.
Não há nada que indique a versão do Windows, mas há um include de boost-modular-build.cmake que parece útil.
Há muito mais coisa nesse cmake, incluindo definição de toolset e os define de WIN32WINNT, que está como 0x602, ou seja, acima do Windows XP. No entanto, esses flags são da compilação do Visual Studio, e não do b2.exe, o compilador do Boost. Como vimos no início do artigo, são os parâmetros para o b2.exe que precisam ser modificados. Ao analisar sua execução de dentro do próprio cmake podemos verificar que há uma variável com essas opções, o bmOPTIONS. O que faz muito sentido.
Me parece que o segredo é inserir ou modificar os argumentos dessa variável e as libs da Boost estarão automagicamente modificadas. Me parece isso hoje, horas e horas depois de analisar o build do vcpkg. Mas vou lhe economizar essas horas. Podemos realizar essa mudança pontualmente no boost-modular-build-helper, mas também devemos recompilá-lo, o que inclui suas dependências e toda a bagaça.
Eu sei, é triste, mas mais uma caneca de café, uma partidinha de xadrez, e está pronta a recompilação. Fun fact: antigamente a compilação do Boost te dava essa dica de ir fazer café.
And voilà! Não há mais dependências das APIs muito novas e conseguimos executar nosso programa em Windows XP. Mas, mais importante que isso, o que aprendemos:
 A verificar os símbolos importados por um executável usando dumpbin, se certificando de que ele poderá rodar em SOs mais antigos. A buscar pelo uso de funções novas pelos fontes compilados pelo vcpkg. A analisar o build do vcpkg para poder modificá-lo e ser compatível com o ambiente que precisamos.  </description>
</item>

     
        <item>
  <title>Vcpkg: Atualizando Lib Asio</title>
  <link>http://www.caloni.com.br/vcpkg-atualizando-lib-asio/</link>
  <pubDate>2019-09-07</pubDate>
  
  <guid>http://www.caloni.com.br/vcpkg-atualizando-lib-asio/</guid>
  <description>Hoje tive que compilar a versão 1.13.0 do Asio para Windows, mas o vcpkg não suporta essa versão ainda, apesar de suportar uma versão (1.12.2.2). Daí entra os problemas que todo programador Windows tem para manter bibliotecas de terceiro compilando em seu ambiente, mas agora com o vcpkg isso nem é tão difícil assim. Vamos lá.
Primeiro de tudo, os pacotes disponíveis no vcpkg podem não ser os disponíveis no branch oficial, que é apenas uma base, que está sendo atualizado e mantido por uma equipe grande que responde os issues, é verdade, mas nem sempre possui as versões que precisamos no dia-a-dia. Para adicionar ou modificar os pacotes deve-se mexer na pasta port do projeto. Dentro dela há uma pasta para cada pacote disponível.
É lá que fica a pasta asio, com seus quatro arquivos: asio-config.cmake, CMakeLists.txt, CONTROL e portfile.cmake. No CONTROL temos o sumário do pacote (nome, descrição, versão), no asio-config.cmake a receita CMake para fazer o build e em CMakeLists.txt como instalar. Isso varia de pacote para pacote, mas no caso de libs como a asio ela fica no GitHub, então em algum lugar nas instruções de instalação (aqui no caso em portfile.cmake) você irá encontrar o uso da função vcpkgfromgithub.
A versão acima é a original. Ela irá obter os fontes baixando pela referência master do git, mas poderia ser outro branch ou tag. Para trocar a versão para a 1.13-0, por exemplo, existe uma tag para isso. Tudo que você precisa é mudar em HEADREF, mas para ficar mais bonito mude em REF também (além de atualizar o CONTROL, que contém informações sobre o pacote que o vcpkg irá exibir para o usuário). De início o SHA512 do download irá falhar, mas assim que você rodar o vcpkg install asio ele irá cuspir qual o hash correto. Daí é só atualizar no arquivo e rodar novamente.
No caso dessa versão é assim que deverá ficar o portfile.cmake:
Feito isso o pacote é baixado, compilado e instalado exatamente como a versão 1.12.
</description>
</item>

     
        <item>
  <title>Do Bit para o Código</title>
  <link>http://www.caloni.com.br/do-bit-para-o-codigo/</link>
  <pubDate>2019-09-03</pubDate>
  
  <guid>http://www.caloni.com.br/do-bit-para-o-codigo/</guid>
  <description>Olá. Esta é uma viagem para dentro do computador. Como funciona um computador? Você sabe? Pois é, nem eu. Mas vamos explorar alguns pontos onde nossa vã metafísica mal encosta na singularidade que é uma arquitetura Von Neumann.
Em primeiro lugar, um bit. O que é um bit? Um bit nada mais é que um dado que se traduz em uma informação com dois, e apenas dois, valores possíveis: ligado ou desligado. Em eletrônica um bit precisa ser extraído de nosso mundo analógico, e quando eu digo analógico eu digo físico, onde existem átomos, prótons e elétrons, mas não existem bits, ou se existem, eles são muito complicados no momento.
Por enquanto, a esmagadora maioria dos computadores utiliza a frequência de uma onda para representar um bit, e dizer se ele está ligado ou desligado. Um filtro de onda consegue detectar se a frequência está alta ou baixa, sendo que alta e baixa também é uma interpretação arbitrária. É estipulado uma determinada frequência e através dela o filtro sensibiliza para o mundo digital se no momento o fio condutor desta frequência está acima ou abaixo dessa frequência, o que para nós, humanos, irá significar se o bit está ligado ou desligado.
Note que tanto faz a maneira com que você traduz a frequência, desde que haja apenas dois valor possíveis, condição sine qua non para definir um bit. Você pode interpretar uma frequência acima do nível estabelecido como ligado ou desligado, mas a partir dessa definição a frequência oposta, abaixo desse nível, deve ser o oposto do que foi definido, para assim termos o ligado/desligado (ou desligado/ligado).
A onda (mais uma intepretação da realidade) gerada pela frequência do sinal elétrico, então, é dividida em dois espaços, delimitados pelo filtro, que funciona como um filtro de linha: apenas a partir de um certo valor da onda ele deixa passar os elétrons, que irão definir do outro lado se o bit está ligado ou desligado.
Isso não quer dizer que o bit desligado (ou ligado, depende de como você definir) não contém eletricidade correndo antes do filtro, apenas que seu valor está abaixo do estabelecido para contar como ligado (ou desligado).
A partir deste ponto podemos trabalhar com o mundo digital. Limpamos as &amp;quot;imperfeições&amp;quot; do mundo físico e transformamos elétrons esquivos em apenas dois valores possíveis: 0 e 1.
Conseguindo usar e armazenar bits, a matemática fica muito mais simples e intuitiva para seres humanos, que só precisam trabalhar com uma base numérica de 2 valores em vez de 10. As mãos dos computadores possuem apenas um dedo cada, somando dois no total.
Como a base é dois convencionamos a dar nomes para as potências de 2 para conseguirmos trabalhar com valores maiores que 0 e 1. 2 elevado a 8, por exemplo, chamamos de byte, embora não no mundo todo, isso também pode mudar de interpretação, dependendo da arquitetura. Porém, na grande maioria do mundo, um byte serão 8 bits, cada um pondendo valer 0 ou 1, e juntando todos, podemos representar os valores de 0 a 255, pois 2 elevado a 8 são 256 combinações (e devemos incluir o zero).
A partir daí não existe muita mágica, pois juntando bytes podemos ter kilobytes (1024 bytes), dos kilobytes podemos ter megabytes, assim por diante até chegarmos no seu &amp;quot;HD de 2 Tera&amp;quot;, o que quer dizer 2 terabytes de informação, ou 35184372088832 bits, todos organizados para serem acessados, ou um a um ou em blocos. O que for mais conveniente para a arquitetura.
Como acessamos esses bits? Bom, informação gera informação na tecnologia da informação. Precisamos dizer, usando bits, quais bits queremos obter do seu &amp;quot;HD de 2 Tera&amp;quot;. O primeiro? O segundo? O vigésimo-quinto? O de número 35184372088832?
Para conseguir acessar precisamos de acesso, e esse acesso precisa conseguir deixar eu falar qual bit/byte que eu quero, ou seja, permitir que eu consiga passar esse valor (primeiro, segundo, etc). Onde está esse bit/byte nós chamamos de endereço, e para passar o endereço de um bit/byte para um HD usamos algo chamado barramento, que é como uma rodovia pode onde passam no máximo X bits.
Porém, como vimos, dependendo do número de bits há um limite da quantidade de valores que podemos representar, e isso irá limitar o nosso acesso aos bits que queremos do &amp;quot;HD de 2 Tera&amp;quot;.
Bom, já deu pra ver que 64 bits é suficiente para pegar muitos e muitos bits. O problema é que endereçar toda essa gente custa tempo, pois cada bit precisa ser interpretado para daí o HD conseguir chegar no bit que ele precisa para daí devolver o seu bit. Imagine que para acessar 1 bit você precisa enviar 64?
Como esse modelo é impraticável criamos uma contraparte: em vez de apenas retornar 1 bit vamos diminuir a resolução e entregar já o bloco mais próximo de bits. Você manda 32 bits, por exemplo, e eu te mando uns 16 bytes, o que dá 65536 bits pela tabelinha acima. É um ótimo negócio, pois enviar bits e bytes para lá e para cá é muito mais barato, computacionalmente falando, do que ter que fazer uma busca de 1 bit em uma imensidão de bits. Essa quantidade de bits que o computador trabalha sempre que pedimos chamamos de palavra (word), o que faz muito sentido: estamos conversando com o computador, e ele responde com palavras geralmente, não com letras. Quem diabos responde um &amp;quot;olá&amp;quot; com &amp;quot;b&amp;quot;?
Já aprendemos muita coisa. Sabemos que os elétrons de um fio condutor pode ser dividido em frequências alta e baixa da onda e que essa divisão transforma o mundo analógico/físico em mundo digital, com bits valendo apenas 0 e 1. Sabemos que 1 bit sozinho não faz muita coisa, então começamos a ajuntá-los com nomes como byte, kilobyte e &amp;quot;HD de 2 Tera&amp;quot;. Sabemos que para conseguir pegar os nossos bits de volta o computador pede bits que dizem onde eles estão, o que chamamos de endereço. E como mandar 32 bits para obter apenas 1 é muito trabalho de busca à toa, sabemos que o computador nos entrega de volta uma palavra, que é um naco de 8, 16, 32 bits ou valores maiores. É assim que nos comunicamos com os computadores: com palavras (words).
Então, agora, o código abaixo não deve ser o menor mistério para nós:
O programa acima verifica se a variável argc contém o valor 2. Argc é um int, o que quer dizer que na minha arquitetura são 4 bytes, ou 32 bits. Se esses 32 bits estão configurados com 0s e 1s de tal maneira que a soma de todos totalizam o valor 2, então meu código entrará dentro do primeiro if. Se não, então o código cairá no else e enviará os caracteres &amp;quot;How to use...&amp;quot; blá blá blá para a saída padrão através da chamada da função da libc puts. Esses caracteres também são formados por bits. Cada caractere possui 8 bits. E estão configurados de tal forma que darão um valor de 0 a 255 que será interpretado de tal maneira: o nth elemento da entrada de uma tabela de caracteres. Essa tabela se chama tabela ascii, e contém os números 0 a 9, as letras de a até z (e maiúculas, A até Z), alguns sinais, etc. Essa é uma nova forma de interpretar os números que conseguimos somando os bits, e só funciona dessa forma porque a linguagem C está especificada dessa maneira.
Essas letras representam o alfabeto romano, usado por boa parte do Ocidente, mas para o computador isso é apenas um comando que depois de passar por várias camadas de interpretação, incluindo o sistema operacional (que controla bits e bytes acima do computador), irá acender determinados leds em seu monitor para que o ser humano que estiver olhando para ele irá entender que aquilo é a letra H, por exemplo. No caso de H, imagine que ele está acendendo uma série de leds da cor da letra que está vendo exatamente na posição que você está olhando, enquanto em volta está acendendo a cor do fundo onde essa letra está sendo &amp;quot;impressa&amp;quot;. Se pudéssemos enxergar com um zoom, poderíamos ver cada um desses leds acesos, mas perderíamos a noção de qual letra no final está sendo desenhada. Na época de monitores de tubo e preto e branco era até possível ver os dois, mas hoje em dia o celular mais vagabundo exibe milhões e milhões de leds em sua cara.
Poderíamos continuar explicando o que é esse FILE e como ele se relaciona com o seu &amp;quot;HD de 2 Tera&amp;quot; para abrir apenas os bits que dizem respeito ao nome do arquivo, que é uma entrada em outra tabela de nomes de arquivos que ele encontra perguntando para o sistema operacional e assim lendo a posição correta dos bits que você precisa e assim por diante até que sua mente estrale e você entenda a miríade de abstrações e interpretações da realidade com que estamos lidando. Daí você veria que eu sou que nem você, dos bits e bytes, dos bauds e sockets, e que me surpreendo a cada dia em como mais e mais interpretações são possíveis de serem criadas a partir de um mundo digital inteiro construído a partir de nosso mundo físico. Bem-vindo ao meu mundo, ao nosso mundo, programador =)
</description>
</item>

     
        <item>
  <title>Some things I learned in a Hacker Rank exercise</title>
  <link>http://www.caloni.com.br/hacker-rank/</link>
  <pubDate>2019-08-08</pubDate>
  
  <guid>http://www.caloni.com.br/hacker-rank/</guid>
  <description>A couple of days ago I subscribed to Hacker Hank, a website specialized in provide interview exercises. The site is as a better version of Code Jam, with the possibility to Compile &amp;amp; Run the code, as well as running several test cases.
Talking with friends about one of them proposed a interesting puzzle called Find the Running Median. This is a good problem because it is easy to understand and tricky to implement.
My first attempt was naive, but worked for test cases where there were no duplicated numbers, a detail I overlooked in the description and happenned the very first test (lucky me it is possible to download the test cases, input and output, giving in return some of the points accumulated solving other problems).
So I started to draw in my window a new solution, based on inplace sort algorithm, using the same vector proposed skeleton by the site. The idea was to just move elements inside the vector, ordering them as calculating the median to evey new number.
I still wasn&#39;t thinking about the sort algorithm until I began to try and fail several times, but this try/error bitch always taught me how to make things faster then embryological bullshit to born from scribbed windows. It only requested a debugger to make the edit, compile, debug triple step.
I was still trying in the window, thought, until in one of these iteractions with the compiler/debugger I achieved a simples, clearer solution, using only offsets from the vector instead of iterators.
This version almost done it, except for timeout error. Hacker Hank has a timeout of 2 seconds to C&#43;&#43; solutions and I was exceding it. After some thought (more try/error) I thought about change the container, but before I made a simples test: instead of using erase/insert methods make the things manually as in good old C.
And it worked. Now what I learned looking the other solutions.
There are incredible tools in C&#43;&#43;, even since 98 or 11, that are frequently overlooked, but it is important to notice that the language has a framework for processing: containers, algorithms and so on. By example, looking for other solutions I learned about the characteristics of multiset and priorityqueue (spoiler: both have a ordering predicate and are logarithmic). There are smart functions in algorithm, too, as lowerbound.
A lot of solutions simply ignored the skeleton provided by the site and began its own code from scratch, eliminating the &amp;quot;request&amp;quot; that the numbers must be stored first in a vector. Sometimes, when there as skeleton in our life, we use them as guidelines, forgetting that &amp;quot;there is no spoon&amp;quot;.
I hope you learned something, too. You can see my Hacker Rank attempts in the site (nickname caloni) or my GitHub repository.
</description>
</item>

     
        <item>
  <title>SLQLocalDB</title>
  <link>http://www.caloni.com.br/sqllocaldb/</link>
  <pubDate>2019-07-21</pubDate>
  
  <guid>http://www.caloni.com.br/sqllocaldb/</guid>
  <description>Hoje foi o dia de redescobrir meu velho ranço com a solução Microsoft para banco de dados. Já perdi horas, dias e semanas com problemas de conexão com algum servidor SQL Server porque a instalação possuía configurações de segurança específicas, a string de conexão não estava exatamente de acordo com a versão instalada ou uma combinação macabra desses e de mais alguns problemas.
Após degladiar novamente com problemas com o SQL Server Express 17 minha esperança para este projeto que requer este banco de dados foi uma versão mínima chamada de LocalDB [1]. Essa versão tem objetivo de servir para desenvolvedores, pois é tão mínima que apenas roda quando você usa, além de permitir isolamento por contas e compartilhamento entre contas e até remoto via named pipe. Parece bom, não?
O marketing da Microsoft sempre será melhor do que as reais soluções entregues. Depois de ver tudo isso funcionar em um banco criado com o LocalDB em pequenos e simples passos, as dores de cabeça começaram na hora de compartilhar ou de criar do zero este mesmo banco em uma conta de sistema, que é como rodam geralmente os serviços do projeto:
O fun fact até aqui é que a primeira versão que tentei, a Express 2017, sequer chegava nesse ponto, dando erros de conexão com named pipe ou timeout no login. Não estou certo de como funcionaria um login em um acesso local em um arquivo, mas essa era uma mensagem extremamente longa e potencialmente inútil. Encontrei uma outra alma sofredora na internet neste mesmo dia de hoje que recomendou fazer o rollback para o Server 2016 [2] (por isso a versão 13.1 no prompt acima), mas os erros apenas mudam de figura ou se repetem indefinidamente.
Aliás, outro fato curioso e revoltante é que a Microsoft sequer mantém a versão anterior dos seus produtos para download. A versão 2016 achei no site de alguém que se dispôs a mantê-los. Do contrário, a solução seria sentar e chorar olhar o código-fonte.
Rá, brincadeira. Não tem o código-fonte.
Um erro frequente e algumas vezes reportado pelas internet é o do login, mesmo. Pesquisando mais a fundo encontrei um artigo no Code Project [3] (quem diria, velhos tempos em que postava nele) de 2014 onde a pessoa explicava que depois de ler muito e testar muito ele descobriu praticamente depurando a instância do SQL Server e descobrindo que o problema estava em um crash que nunca voltava, sendo necessário dropar todas as conexões (ou o conhecido restart que várias pessoas também recomendaram).
Esse não é o meu problema. Meu problema é conseguir rodar a solução na conta de sistema, e desconfio que o modo em que o psexec executa o cmd.exe na conta de sistema pode estar relacionado, pois contas interativas em sistema são fontes clássicas de configuration mismatch (talvez falte ou sobre variáveis de ambiente, alguns handles perdidos, essas coisas).
 [1] https://docs.microsoft.com/en-us/sql/database-engine/configure-windows/sql-server-express-localdb [2] https://feedback.azure.com/forums/908035-sql-server/suggestions/36481279-sql-server-2017-express-localdb-shared-instance-co [3] https://www.codeproject.com/Tips/775607/How-to-fix-LocalDB-Requested-Login-failed  </description>
</item>

     
        <item>
  <title>Como Publicar Seu Blog Em Hugo Para Ebook</title>
  <link>http://www.caloni.com.br/como-publicar-seu-blog-em-hugo-para-ebook/</link>
  <pubDate>2019-07-10</pubDate>
  
  <guid>http://www.caloni.com.br/como-publicar-seu-blog-em-hugo-para-ebook/</guid>
  <description>Eu publico meu blog inteiro de tempos em tempos para um ebook que construo formatando primeiro em html através de um tema do Hugo, o parser de blog que estou usando no momento porque ele suporta 2500 posts sem reclamar. É uma receita simples de sucesso se você precisar ter todo seu conteúdo indexado para rápida referência ou leitura cronológica.
A primeira coisa a ser feita é preparar um tema para formatar seu html. Eu já tenho um linkado no meu blogue e que precisa apenas formatar o index.html, pois todo o conteúdo e índices estarão lá. Segue um exemplo atual que uso. Ele possui índice alfabético, inclusão de um arquivo-diário que mantenho, listagem das categorias (com índices para cada uma delas) e listagem cronológica (e link para pular direto para o conteúdo).
Como eu uso Kindle eu construo a partir desse html um arquivo .mobi, mas creio ser simples de construir qualquer outro formato através desse html final. No caso do Kindle preciso de alguns arquivos para usar o kindlegen (a ferramenta da Amazon) que mantenho na pasta static do hugo, como o .ncx e o .opf (além da capa, cover.jpg). Uso uma batch muito pequena para fazer todos os passos e copiar o .mobi resultante para meu Kindle (conectado por um cabo USB e com um drive montado em K:).
Importante lembrar que a codificação do hugo (utf8) deve bater com a codificação esperada pelo gerador de ebook. Que me lembre não há muito mais segredos. Basta escrever e de vez em quando rodar o script novamente =)
</description>
</item>

     
        <item>
  <title>C Resolve Tudo: goto</title>
  <link>http://www.caloni.com.br/goto/</link>
  <pubDate>2019-05-28</pubDate>
  
  <guid>http://www.caloni.com.br/goto/</guid>
  <description>Para quem decide usar a linguagem C para resolver tudo, a gota da água é o goto. Ele é flexível, cabe em (quase) qualquer ponto do código e tem 1001 utilidades. O goto é o bombril da engenharia de software.
O uso mais simples dessa importante construção da linguagem é pular de um ponto para outro do código em que esses pontos não estão diretamente relacionados, como geralmente ocorre, como sair de um laço, não entrar em um if ou selecionar um case do switch (lembrando que no caso do case do switch ele é no fundo um goto disfarçado).
Claro que esse uso é trivial demais para valer a pena uma troca de fluxo tão desestruturada. Há formas mais úteis de desviar o fluxo padrão. No exemplo acima bastaria colocar todo o código que se segue dentro do grupo pertencente ao if e o goto seria desnecessário.
Mas, por exemplo, imagine que precisamos nos desfazer de recursos na ordem inversa ao qual vão sendo adquiridos. Pode-se aninhar indefinidamente ifs ou usar um bloco de código de unwinding que vai fechando os recursos na ordem inversa e inicia sua chamada dependendo de onde ocorreu o erro. Código é melhor para ilustrar:
Esse estilo de liberação de recursos é muito usado em códigos de kernel e software mais básico, pois simplifica a visualização e aumenta a flexibilidade. Compare com a versão estruturada:
Aliás, esse uso do goto é a maneira de aplicar RAII em C (Resource acquisition is initialization). Implícito em linguagens como C&#43;&#43; e seus destrutores de objetos, em C é você que precisa fazer a faxina. E se a bagunça foi feita da direita pra esquerda a faxina deve ser feita da esquerda pra direita.
Esse uso super-aninhado do código me lembra do exemplo clássico de sair de muitos loops aninhados. Apenas por didática, vamos citá-lo:
Comentei no começo do texto que os cases do switch são labels de goto disfarçados. E são mesmo. Um dos algoritmos mais famosos de transformação de loop chamado Duff&#39;s device junta um do-while com switch e realiza uma cópia de buffer com um número de bytes variável:
O que está acontecendo no código acima: é possível inserir qualquer tipo de mudança de fluxo dentro do switch. Duff aproveitou essa particularidade da linguagem para produzir jumps que poderiam ser feitos em assembly. Dependendo do resto da divisão por oito o salto é realizado para um case diferente, que executará parte do laço até o while comparador final. A vantagem desse tipo de abordagem é que evita-se sair da programação estruturada, e muito menos precisa-se apelar para o assembly.
Esse código também seria possível de ser feito com o goto clássico, mas note que nesse caso ele fica mais verboso, pois é necessário fazer um if diferente para cada condição.
Caso você tenha estranhada a definição inicial da função, ela é como se definia os argumentos em linguagem C antes do padrão ANSI, com os nomes e logo em seguida a declaração das variáveis como se fossem locais (porque de fato elas são, embora sua inicialização seja feita antes da chamada). Como este código data dos anos 80 e como o padrão só foi finalizado em 89, percebe-se que ainda se usava o formato antigo no código.
Passemos para o próximo uso: código infinito. Esse é um uso clássico, e diferente do uso degenerado de laços em que a condição é sempre verdadeira (while(true), for(;;)) usando o goto fica bem-documentado que o objetivo é ficar eternamente nesse loop. Um laço infinito que eu me lembro é quando dá tela azul no Windows. O código-fonte do kernel era algo mais ou menos assim:
Os programadores usaram o apelo clássico do while. Sem motivo, pois goto é usado direto como RAII (já explicado acima). A maneira procedural de fazer seria assim:
Isso lembra outra utilidade do goto que você pode anotar no seu caderninho: ele pode voltar o fluxo, de baixo para cima.
Esse último exemplo é um dos programas C mais lindos do universo. Sua única instrução é o comando rotulado por infinite e referencia ele mesmo. É quase o salto incondicional do assembly, materializado na linguagem mais elegante jamais criada em nossa realidade.
</description>
</item>

     
        <item>
  <title>C Resolve Tudo Clos</title>
  <link>http://www.caloni.com.br/c-resolve-tudo-clos/</link>
  <pubDate>2019-05-17</pubDate>
  
  <guid>http://www.caloni.com.br/c-resolve-tudo-clos/</guid>
  <description>Continuando nossa série, conforme sugerido pelo @colemaker do grupo C/C&#43;&#43;/42/Império do Brasil, a próxima ideia a ser implementada em C é o sistema polimórfico de chamadas do Lisp orientado a objetos. Esse sistema permite realizar a seguinte manobra:
O aspecto-chave aqui, conforme eu descobri, é implementar a estratégia de prioridades entre as sobrecargas dos métodos de acordo com os tipos passados. Analisando bem por cima devemos sempre priorizar os métodos com os tipos mais específicos e ir realizando underpromotion até chegarmos no menos específico (se houver).
A implementação está no GitHub. Para o sistema de tipos em C nada como fazer do zero:
As estruturas estão usando STL. O quê? Mas não era C? Sim, você tem toda razão. Porém, estou usando uma lib mais conhecida. Há milhares de libs containers em C para você escolher para trocar a implementação. Lembre-se que o mais importante não é ser purista, mas atingir os objetivos. Como eventualmente veremos nessa série de artigos, o próprio C&#43;&#43; e toda a sua biblioteca pode ser implementada em C. Este é apenas um atalho para fins didáticos e de produtividade (como eu já falei, produtividade não é o foco aqui, mas enxergar por debaixo dos panos).
Inicialmente feito em STL pela produtividade, a solução atual no GitHub é feita inteiramente em C usando a glib (lib comum em Linux com estrutura de dados, etc). O legal dessa biblioteca é que ela tem 20 anos (desde 1998) e já foi muito usada e testada, além de possuir estruturas e algoritmos simples que fazem parte do pacote básico de qualquer programador, como arrays, strings, hash tables.
O código é bem simples. Mapas e listas com strings e ponteiros para organizar as estruturas por detrás do sistema de tipos que estamos implementando e seus métodos sobrecarregados. Cada método possui um nome, um endereço de ponteiro e o número dos seus argumentos. Todos os argumentos são do tipo polimórfico, seguindo o que provavelmente existe por detrás da própria implementação do Lisp.
O código que utiliza a clos.c é bem direto e enxuto. Como no Lisp.
Futuros posts sobre C Resolve Tudo poderão utilizar a glib ou qualquer outra. Uma outra vantagem da linguagem C é que sua biblioteca padrão é muito enxuta, sendo fácil de ter disponível em seu ambiente um compilador C com a clib, e em cima dela você pode utilizar qualquer biblioteca de sua escolha para estruturas e algoritmos mais complexos. Ou fazer a sua própria.
</description>
</item>

     
        <item>
  <title>C Resolve Tudo: Orientação a Objetos (com Polimorfismo)</title>
  <link>http://www.caloni.com.br/c-resolve-tudo/</link>
  <pubDate>2019-05-17</pubDate>
  
  <guid>http://www.caloni.com.br/c-resolve-tudo/</guid>
  <description>Como programadores há um vício em nossas cabeças que é estar constantemente buscando a bala de prata, ou seja, a solução final e única para todos os nossos problemas de implementação. Com o tempo e alguma experiência descobrimos que tal coisa não existe, mas até lá nos encantamos com esse ou aquele framework, e claro, com essa ou aquela linguagem.
As linguagens que são criadas depois da revolução dos computadores pessoais querem facilitar a vida do programador médio embutindo soluções já testadas por programadores de verdade e evitando a todo custo que o código incorra em erros comuns. Além disso, há movimentos nas comunidades e no mercado que geram tendências que influenciam essas linguagens, o que explica design patterns, orientação a objetos, programação funcional, xp, scrum, devops e qualquer outra bala de prata que vá se solidificando.
Expliquei tudo isso para chegar no tema deste artigo: você pode fazer tudo isso usando linguagem C.
Mas aí você deve estar se perguntando: &amp;quot;supor que uma linguagem resolve tudo não é estar defendendo também uma bala de prata?&amp;quot;. A resposta é sim e não. Sim, é uma bala de prata se você pensar que pode fazer do zero sites e interfaces gráficas modernas em C puro. Mas a resposta também é não porque eu estou trabalhando em uma outra camada, aquela em que as soluções que ficam pra sempre são implementadas. Estou falando de pensar sempre na linguagem C quando estiver interessado no funcionamento das outras soluções.
Esse mindset propost tem como objetivo impedir que você pense que as outras soluções são mágicas porque se você consegue pensar em C ela é real. Se tem algo que a linguagem C não é esse algo é mágica. C é uma simples abstração de uma máquina virtual que se relaciona de maneira muito íntima com as implementações em assembly de várias arquiteturas. Mágica é algo que te impede de enxergar em que momento uma solução se encontra com o hardware. C nunca irá te impedir de fazer isso.
Dito isto, vamos analisar algumas balas de prata e entender como em C isso é implementado para revelar a mágica.
A Orientação a Objetos se divide em algumas features. Algumas não vale a pena falar aqui, como tratar tudo como objeto. C já faz isso através de structs. Você pode montar uma struct que possua métodos, inclusive, através de ponteiros para função. E esses métodos já são sobrecarregáveis e virtuais.
A sobrecarga se torna algo trivial, bem documentada através dos nomes das funções que você está chamando. Tudo fica às claras, nada implícito, nada disse que me disse. Se eu chamo um método NewMyClass2 é óbvio que estou construindo uma segunda versão baseada na primeira, e posso inclusive comparar para ver se os métodos são originais ou sobrescritos com obj.method == &amp;amp;method, por exemplo. Além disso, é possível realizar composições de tipos onde alguns métodos são sobrescritos enquanto outros são compostos por chamadas duplas, triplas. Não há qualquer limitação ao polimorfismo exceto o que você define.
Os métodos são &amp;quot;estáticos&amp;quot; por default (não há contexto), o que aliás facilita programação funcional, mas você pode buscar contexto onde te interessa, passando como parâmetro toda a &amp;quot;classe&amp;quot;, seja por valor ou referência, ou passando até uma versão parcial dela. Há inúmeras maneiras de construir um objeto em C, pois ele não está restrito às regras de sintaxe da definição da linguagem, uma vez que é você que define. Além disso, como você deve ter percebido, para declarar tipos de structs é necessário o uso dessa palavra-chave, mas a linguagem C já possui um sistema de typedef para trocar convenientemente qualquer definição de tipo como um nome único.
Note que podemos ao redefinir a função de soma a de multiplicação também é alterada, mesmo não alterando seu funcionamento (mas alterando uma função que ela usa).
Este é apenas um exemplo besta de polimorfismo, além de um exemplo trivial de como OO em C é infinitamente mais rico e mais complexo. Está nas mãos do programador definir até onde vai a solução proposta. E é bom saber que não existe bala de prata.
</description>
</item>

     
        <item>
  <title>Coroutines Em C: Picoro</title>
  <link>http://www.caloni.com.br/coroutines-em-c-picoro/</link>
  <pubDate>2019-05-08</pubDate>
  
  <guid>http://www.caloni.com.br/coroutines-em-c-picoro/</guid>
  <description>Tantas linguagens hoje em dia tentando implementar a abstração de corrotinas e inserindo mais camadas de abstração (fibras e cereais)... há duas implementações já no Boost, ambas dependendo de uma biblioteca de contexto de stack que é dependente de arquitetura (programada em Assembly).
E aqui está a linguagem C com sua elegância, minimalismo e a filosofia &amp;quot;just works&amp;quot;, por mais ou menos 50 anos.
Estava pesquisando sobre bibliotecas de corrotinas em C e encontrei a Picoro, de Tony Finch. Três coisas me encantaram nela:
 portabilidade (fácil de testar em qualquer arquitetura). simplificade (um header e um .c com menos de 200 linhas, e a maioria são comentários). manutenção (o último commit é de 2010, ou seja, ninguém mais mexeu nela por nove anos).  Ela é uma biblioteca feita para resolver o problema mais básico de toda corrotina: troca de contexto. Isso é feito de maneira descentralizada, embora ela inicie com uma corrotina principal: a primeira que constrói uma corrotina. A partir dessa é possível criar outras e dar resume em qualquer uma delas que não tenha terminado.
A linguagem C já implementa troca de contexto através das funções padrão setjmp e longjmp. Há um tipo dependente de arquitetura, jmpbuf, que é usado para guardar o contexto. O salto é feito no estilo da função fork do Unix, ou seja, não há inclusão de mais nenhuma sintaxe diferente do usual: é um if que retorna 0 (contexto principal) ou não-0 (estamos em outro contexto).
O picoro organiza tudo isso em torno de uma lista ligada. Aliás, de duas listas ligadas: running e idle, onde o head de cada uma delas é usado para verificar se há corrotinas paradas ou em execução. Há algumas regras básicas para que tudo funcione. Por exemplo, uma corrotina que já foi executada até o final ou que está bloqueada pela chamada de resume não pode ser posta para rodar.
Vamos começar com um exemplo simples: apenas um corrotina que recebe um inteiro e incrementa três vezes. A cada vez que ele incrementa ele devolve o controle de execução via yield. O main cria três dessas corrotinas e dá resume em cada uma delas três vezes, finalizando a execução de todas. Ao final, o counter final é de 9.
É importante observar que o uso de troca de contexto pode facilmente consumir a pilha, pois ela está sendo compartilhada com muitas funções em paralelo. Para reservar espaço a coroutinestart aloca um array de 16 KB (fixo). Esses detalhes de implementação podem ser alterados, pois a biblioteca é tão mínima e simples de entender que construir qualquer coisa em cima dela é trivial.
</description>
</item>

     
        <item>
  <title>Visual Studio Unit Test (C&#43;&#43;)</title>
  <link>http://www.caloni.com.br/visual-studio-unit-test/</link>
  <pubDate>2019-05-06</pubDate>
  
  <guid>http://www.caloni.com.br/visual-studio-unit-test/</guid>
  <description>Desde o Visual Studio 2015 há suporte a unit tests em C&#43;&#43; automatizado na IDE. Porém, a partir do VS 2017 15.5 o suporte aumentou drasticamente, vindo embutidos os suportes para as bibliotecas de teste Google Test, Boost.Test e CTest. Além, é claro, do Microsoft Unit Testing Framework for C&#43;&#43;, o caseiro da M$.
Além disso, é possível você mesmo integrar o Visual Studio com outra lib de testes. Mas para que gastar tempo? Várias integrações já estão disponíveis no Visual Studio Marketplace. Ligue já!
OK, parei com o merchan. Até porque não ganho nada com isso. Vamos ao código.
Pelo Wizard do VS podemos criar para um projeto C&#43;&#43; qualquer um projeto de teste. No momento estou vendo os tipos de projeto Native Unit Test e Google Test.
Este é nosso projeto de exemplo:
Para conseguir testar o projeto principal adicione-o como referência.
Após isso basta incluir algum header que contenha os tipos, funções, classes e métodos que deseja testar e vá criando métodos de teste dentro da classe de exemplo:
Agora abrindo o jogo para você, amigo programador C&#43;&#43; que gosta de saber tudo que ocorre debaixo dos panos:
 Um projeto Unit Test é apenas uma DLL com uns códigos de template. Esse código já adiciona a lib de unit test da Microsoft e cria uma classe com exemplo de uso. Adicione todo código do projeto original que ele precisa para compilar.  Por isso eu tirei a tranqueira de precompiled header do projeto de unit test, retirei a referência (sugestão do tutorial da Microsoft) e apenas adicionei o mesmo cpp para ser compilado.
Agora mais mágica: se você abrir a janela Test Explorer ele irá encontrar seus testes e enumerá-los!
Se você já programou um pouco em Windows com C&#43;&#43; já deve saber o truque: como o Unit Test é uma DLL ela simplesmente exporta os símbolos necessários para que o Visual Studio encontre o que precisa. O básico que um plugin dos velhos tempos faz: exportar interfaces com um pouco de reflection.
Se você habilitar Undecorate C&#43;&#43; Functions no Dependency Walker verá que ele exporta justamente uma espécie de reflection, na forma de structs:
E se você prestar atenção na ordem de exportação desse símbolos verá que o primeiro se chama GetTestClassInfo. Acabou a magia, não é mesmo?
Os headers e fontes do CppUnitTest ficam em paths do Visual Studio como VC\Auxiliary\VS\UnitTest, nas pastas include e lib. Nele é possível dar uma olhada no significado das macros e das classes disponibilizadas. Logo abaixo das macros, no arquivo principal, é possível ver como funciona o reflection:
É uma lib pequena e elegante que permite uma interação não apenas com a IDE, como poderia ser automatizada por um script, uma vez que sabe-se o funcionamento interno e algumas interfaces.
</description>
</item>

     
        <item>
  <title>Const Int Pointer Var</title>
  <link>http://www.caloni.com.br/const-int-pointer-var/</link>
  <pubDate>2019-04-29</pubDate>
  
  <guid>http://www.caloni.com.br/const-int-pointer-var/</guid>
  <description>A melhor forma de declarar variáveis ponteiros (constante ou não, mas segue o exemplo) é const int pointer var. Explicação:
Quem diz o asterisco fazer parte do tipo e não da variável tem razão. Pensando dessa forma ele tem que ficar próximo do tipo.
Porém, outra forma de interpretar a variável é que ela equivale a um inteiro quando usado com asterisco, o que também é verdade. Ou seja, int pointer var significa que pointer var equivale a um int (constante ou não, mas preciso dessa variável não-const para o exemplo). É por isso que pointer var igual a dez possui o mesmo valor de atribuição do que int var seguido de var igual a dez, ou seja, pointer var é sinônimo do l-value var (se var fosse um inteiro e não um ponteiro).
Além disso, outro argumento pró-proximidade da variável é que declarações de múltiplas variáveis na mesma linha precisam de múltiplos asteriscos: const int pointer var1, pointer var2, pointer var3.
Portanto, como ambos os lados estão certos, separar o asterisco de ambos não dá prioridade a nenhuma forma que o programador poderá interpretar essa decisão, seja como parte do tipo ou da variável. Cada programador com seu próprio estilo irá enxergar em const int pointer var a proximidade com int ou com var de acordo com seu próprio bias (e estará certo em sua análise).
</description>
</item>

     
        <item>
  <title>OpenSSH no Windows</title>
  <link>http://www.caloni.com.br/openssh-windows/</link>
  <pubDate>2019-04-29</pubDate>
  
  <guid>http://www.caloni.com.br/openssh-windows/</guid>
  <description>O Secure Shell (SSH) é um protocolo de sucesso nos unixes da vida para terminal remoto e seguro por décadas, mas no Windows nunca houve uma forma simples e protegida de abrir um terminal ou copiar arquivos. A opção é instalar um cygwin com esse componente ou tentar compilar um protocolo SSL e em cima dele o SSH. Porém, há detalhes na autenticação que estão relacionadas com o Sistema Operacional e que precisa ser feito. O OpenSSH é uma maneira de compilar tudo isso e ainda funcionar no Windows.
O software WinSCP, um client SFTP para Windows, possui um guia sobre como instalar essa opção no Windows. A partir do Windows Server 2019 e Windows 10 1809 isso não será mais necessário, pois já estará disponível entre as ferramentas opcionais instaláveis do SO (Apps &amp;gt; Apps &amp;amp; features &amp;gt; Manage optional features, &amp;quot;OpenSSH server&amp;quot;). Para os que ainda precisam manter o passado há uma maneira.
Se você preferir não compilar a partir dos fontes você pode baixar um pacote dos binários pelo GitHub. Basta extrair tudo para uma pasta e rodar o script PowerShell de instalação e o serviço sshd estará instalado no modo manual (se você já usou o cygwin sabe que o nome é o mesmo). O local indicado para conter os arquivos é em C:\Program Files\OpenSSH, conforme o tutorial do WinSCP.
Após instalado você deve abrir a porta 22 pelo firewall do Windows (há uma maneira PowerShell de fazer se tiver um Windows novo ou usar a interface mesmo se tiver um antigo). Após esse último passo tudo deverá estar funcionando, e basta criar seu par de chaves pública/privada com o ssh-keygen.exe e adicionar no servidor com ssh-add.exe, além de copiar para um arquivo chamado authorizedkeys... enfim, está tudo no tutorial.
Menos a parte de mudar o sshdconfig.
Como nos informa um post do Stack Overflow, é preciso comentar no arquivo c:\programdata\ssh\sshconfig, próximo do final, essas duas linhas:
Para isso:
Aí, sim. Reiniciar, o serviço e testar a conexão:
Os programas ssh.exe (shell remoto) e scp.exe (cópia remota de arquivos) também estão disponíveis no pacote OpenSSH, mas a versão do Cygwin ou até do Git (que vem com um pacote de ferramentas básicas de Linux) funcionam.
Se seu objetivo é realizar backups remotos silenciosos e para isso você instalar um serviço que irá executar o scp.exe de tempos em tempos é preciso tomar cuidado com as credenciais usadas e onde estarão as chaves de criptografia. O padrão usado pelo OpenSSH no Windows é na pasta C:\Users\Usuário.ssh, mas para um processo na conta de sistema esse valor deve ser diferente. No caso de um terminal executando pelo psexec.exe ele ficou apontando para c:\windows\system32.ssh, mas para serviços rodando como SYSTEM é capaz que seja outro valor. Enfim, é necessário testar e verificar os resultados dos testes.
</description>
</item>

     
        <item>
  <title>Code Jam 2019 Qualification Round</title>
  <link>http://www.caloni.com.br/code-jam-2019-qualification-round/</link>
  <pubDate>2019-04-07</pubDate>
  
  <guid>http://www.caloni.com.br/code-jam-2019-qualification-round/</guid>
  <description>Estou viajando e com poucas horas de acesso a um computador, mas os dois primeiros desafios do Code Jam esse ano foram tão simples que sequer precisaram de meia-hora. Isso para um chinês, campeões em campeonatos de programação, deve ser equivalente a cinco minutos com um código C enxuto. Mas estou apenas aprendendo.
Resuminho: o problema é receber um número e retornar dois números cuja soma seja igual ao primeiro. A única restrição é que nesses números não poderá ter o algarismo quatro.
Solução: copiar como string o número para o primeiro deles e colocar zero no segundo; sempre que houver a incidência do caractere &#39;4&#39; trocar por &#39;3&#39; no primeiro número e &#39;1&#39; no segundo (ou a soma que lhe convier).
Resuminho: tem que atravessar um labirinto formado por quadrados de N x N começando acima à esquerda saindo abaixo na direita. Enviar uma string com os comandos E ou S (East/South) para sair do labirinto. A pegadinha é não repetir nenhum dos comandos de uma garota que resolveu o labirinto antes.
Solução: essa pegadinha é o que ironicamente resolve o problema, pois basta inverter os comandos S e E da string recebida como o caminho da garota e ele nunca se repete e sai do mesmo jeito, pois é o labirinto mais fácil do mundo.
Resuminho: encontrar quais números primos são usados como letras do alfabeto baseado em uma sequência em que o primeiro número é a multiplicação do primo da primeira letra pela segunda, o segundo número é a multiplicação da segunda pela terceira e assim por diante.
Solução: tentei fazer na força bruta criando o dicionário de primos usado procurando o resto zero das divisões dos números e depois já com o alfabeto montado reproduzir as reproduções. Apesar do sample funcionar devo ter perdido pelo tempo ou um erro que não descobri.
Resuminho: descobrir quais bits não estão sendo retornados em um echo (ex: manda-se &#39;1010&#39; e recebe &#39;010&#39;) com um limite de envios para o servidor (este é um problema interativo).
Solução: imaginei dividir o envio pelo número de blocos defeituosos para alternar os 0s e 1s e assim ir dividindo pela metade de acordo com as respostas até ter as posições que não estão retornando. Não cheguei a terminar o código, mas a ideia geral era que como o limite de blocos defeituosos era de 15 ou N-1 (N é o número de bits) e o máximo de chutes é 5, imaginei que a divisão de 2 elevado a 5 fosse o limite da solução.
</description>
</item>

     
        <item>
  <title>Free Pascal e VS Code</title>
  <link>http://www.caloni.com.br/free-pascal-e-vs-code/</link>
  <pubDate>2019-03-09</pubDate>
  
  <guid>http://www.caloni.com.br/free-pascal-e-vs-code/</guid>
  <description>Agora que o VS Code é a ferramenta universal para todas as plataformas e linguagens imagináveis, acreditem ou não, há até plugin para Pascal. Ao instalar a extensão mantida por Alessandro Fragnani você recebe o intelisense e algumas dicas durante erros de programação.
A própria integração com o Free Pascal Compiler, o compilador open source de Pascal multiplataforma, já é mostrada na Home desse plugin. É só seguir os modelos e alterar de acordo com o que pede o VS Code (que está sendo atualizado constantemente).
Após isso o Terminal, Run Build Task exibe a opção de rodar o fpc.exe para seu programa e a compilação sai perfeita ou ele aponta os erros direto no fonte. O programa resultante pode ser executado por fora ou dentro do VS Code e tudo OK.
PS: Se quiser depurar é possível gerar informação de debug para o gdb via a flag -g, ou apenas usar o velho writeln(&#39;passou por aqui&#39;). Alguns dizem que o segundo uso algumas vezes é conveniente. Faz sentido se é um programa de faculdade.
Bons programas verdadeiramente estruturados! (Pascal, diferente de C, permite procedures aninhadas, passando o self durante as chamadas internas; isso, sim, é linguagem bem desenhada).
</description>
</item>

     
        <item>
  <title>Debug Remoto no Visual Studio 2010 ou Superior</title>
  <link>http://www.caloni.com.br/debug-remoto-visual-studio-2010-superior/</link>
  <pubDate>2019-03-06</pubDate>
  
  <guid>http://www.caloni.com.br/debug-remoto-visual-studio-2010-superior/</guid>
  <description>Já escrevi sobre debug remoto no finado C&#43;&#43; Builder, sobre como usar o msvcmon.exe no VS 2003 e o msvsmon.exe no 2010&#43;. Sobre como depurar um serviço quando a máquina está para desligar, e até sobre depurar através de um servidor de símbolos. Está na hora de tornar a depuração mais simples para programadores de serviços Win32.
Resumo dos comandos:
Hoje em dia, às vésperas do Visual Studio 2019, espero que todo mundo use pelo menos o Visual Studio 2010 porque a partir dessa versão tornou-se muito fácil depurar remotamente, pois um pacote feito para isso já é instalado junto do Visual Studo. É uma pasta que basta copiar e colar na máquina-alvo. Para encontrá-la basta digitar &amp;quot;Remote Debugger&amp;quot; dentro do Program Files.
Copie essa pasta para a máquina onde estará os processos que deseja depurar e escolha sua arquitetura (x86, x64, i64), pois cada uma possui uma sub-pasta com os mesmos arquivos. Executa uma vez o msvsmon.exe dentro de uma delas e ele irá configurar para você o firewall do Windows. Feito isso e configurando através da janela que aparece o resto dos parâmetros basta atachar o processo ou iniciá-lo remotamente pela configuração do seu projeto no Visual Studio.
Mas este artigo não é sobre isso, é um pouco mais fundo: depurar serviços. Eles rodam na conta de sistema e muitas vezes é preciso depurá-los antes ou depois do logon na máquina. Às vezes é um teste sob as condições de sistema, o que é igualmente importante. Seja como for a maneira de fazer isso com o msvsmon.exe é transformá-lo também em um serviço. Para isso usaremos o NSSM: o Non-Sucking Service Manager. Copie ele para a mesma máquina e o executa com o comando install nome-do-serviço. Os campos principais são os mais importantes.
Mas este artigo não é sobre isso, é um pouco mais fundo: depurar serviços. Eles rodam na conta de sistema e muitas vezes é preciso depurá-los antes ou depois do logon na máquina. Às vezes é um teste sob as condições de sistema, o que é igualmente importante. Seja como for a maneira de fazer isso com o msvsmon.exe é transformá-lo também em um serviço. Para isso usaremos o NSSM: o Non-Sucking Service Manager. Copie ele para a mesma máquina e o executa com o comando install nome-do-serviço. Os campos principais são os mais importantes.
Se você digitar msvsmon.exe /h ou algo do gênero irá encontrar os parâmetros que precisa.
OBS: Eu costumo executar sem segurança alguma, pois minhas máquinas de teste são VMs locais e o perigo de vulnerabilidade não é menor do que minha própria máquina real.
</description>
</item>

     
        <item>
  <title>Bug no Boost Asio usando função AcceptEx do Winsock</title>
  <link>http://www.caloni.com.br/bug-boost-asio-acceptex-winsock/</link>
  <pubDate>2019-01-06</pubDate>
  
  <guid>http://www.caloni.com.br/bug-boost-asio-acceptex-winsock/</guid>
  <description>Depois de um mês de correção e mais um ou dois meses preparando um compilado do que ocorreu no software que estamos mantendo, foi descoberta uma situação muito peculiar que ocorre tanto em Windows XP quanto no Windows 10, mas que no 10 tem uma correção bem-educada e no XP... bom, nem tanto.
O problema ocorreu em um uso padrão do Boost.Asio de modo assíncrono. Sem querer entrar muito em código nesse momento -- que teve como base nosso projeto de servidor de requisições mais rápido do universo, o motherforker -- se trata apenas de um listening que usa spawn de um lambda para tratar os accepts e dentro dele cria processos, redirecionando sua entrada e saída.
Nas entranhas do Boost.Asio na implementação para Windows o accept utiliza a API AcceptEx, que já cria o socket cliente antes mesmo da conexão ser fechada. Se trata de uma operação de IO assíncrono como os que tem no Windows: faz tudo que é necessário fazer e é responsabilidade do programa verificar se houve IO (de maneira síncrona ou assíncrona). No caso do Asio a maneira de verificar é via checagem do handle de completion durante os momentos de idle do ioservice.
Quando há uma nova conexão o método createProcessGetOutputAndSendBack lê dados do socket cliente como um comando a ser executado e utiliza a API CreateProcess passando esse comando. A saída desse processo criado é capturada via saída-padrão. Para isso é usada a flag de herança de handles e handles de arquivos (poderiam ser pipes) são usados para enviar entrada, capturar saída, etc.
Após o término do processo a saída estará no arquivo aberto em si.hStdOutput. Basta abri-lo para leitura e enviar seu conteúdo via socket para o cliente. O trabalho dessa conexão termina por aí.
O que não estava previsto é que junto da herança dos handles vai também handles indesejados. Como o de &amp;quot;\Device\Afd&amp;quot;, que é um recurso usado na comunicação do winsock. Ao usar as funções síncronas e tradicionais do winsock, que constitui em criar o socket server, dar listen e no accept o socket cliente ter sido criado, o AcceptEx exige já um socket cliente criado, o que é feito no sample da Microsoft com a função socket e no Boost.Asio com a duplicação do socket existente (que também foi criado via socket function).
Esses dois sockets são herdáveis por default (implementação da função socket) e são representados pelos handles listados no Process Explorer como já visto, pelo nome &amp;quot;\Device\Afd&amp;quot;. O contador de handles é aumentado a partir da criação do processo-filho e esses dois handles aparecem em ambos os processos.
Até aí tudo bem. O problema na verdade ocorre no segundo request enviado quando o primeiro request não terminou (e.g. o primeiro request é um notepad.exe que irá demorar e o segundo request um &amp;quot;cmd /c dir&amp;quot;, que executa e já volta com a saída). Nessa situação todos os sockets criados até aqui -- incluindo o cliente do primeiro request -- são herdados para o segundo processo-filho, e por questões que estão além do escopo desse estudo, mas que poderão ser verificados ao se analistar os drivers das camadas de TDI do Windows (kernel mode), o send da saída do segundo request para o socket cliente fica travado até a saída do primeiro processo-filho, onde ocorre dos handles serem fechados.
É uma situação complexa, que depende de várias variáveis, mas ela ocorre, se todas as variáveis ocorrerem ao mesmo tempo. Um resumo:
 Criação do socket cliente com a função socket. Uso do AcceptEx para aceitar conexões. Criação de process-filho com flag de herança de handles habilitada. Processo-filho do primeiro request ainda em execução. Recebimento do segundo request e criação do segundo processo-filho. Escrita no socket cliente do segundo request enquanto o primeiro request ainda não foi finalizado. BUG: Cliente do segundo request não recebe sua resposta. RESULTADO ESPERADO: Que o cliente do primeiro request não interferisse no segundo. Detalhe: Cliente do segundo requeste recebe eventualmente sua resposta após o primeiro request terminar.  A primeira solução para evitar handles herdáveis que não são desejáveis é proposta pelo Raymond Chen em seu blog: usar as API InitializeProcThreadAttributeList e UpdateProcThreadAttribute. Com isso é possível especificar quais handles podem ser herdados pelo processo-filho, e obviamente iremos colocar na lista apenas os arquivos de entrada e saída padrão (obs: não duplicar saída-padrão com erro-padrão quando ambos são o mesmo arquivo/handle).
As API InitializeProcThreadAttributeList e UpdateProcThreadAttribute não existem no Windows XP, o que quer dizer que isso exige uma segunda solução, que eu considerei antes de achar a terceira solução que teria que ser ad hoc: criar um processo-neto, sendo que o filho não receberá os handles herdados, mas irá criar o neto herdando os arquivos de entrada e saída padrão, enviando a saída de volta por um método à parte (ex: usando o nome de um arquivo em comum).
A terceira solução encontrada durante a compilação deste artigo é usar em vez da função socket, que não dá o controle sobre herança de handle, a função WSASocketW, onde existe um argumento dwFlags em que é possível passar o valor WSAFLAGNOHANDLEINHERIT (0x80), onde o handle do socket não será criado com a flag de herdável. Dessa forma apenas o socket cliente não se torna herdável e com isso o primeiro request não trava o segundo. A vantagem dessa correção é que ela é pontual no código e é de uma API já antiga, portanto compatível com todos os Windows.
UPDATE: Na verdade a flag de não-herança do socket só passou a existir no Windows 7 com SP1, o que inviabiliza essa solução para Windows Vista e XP, como previamente foi dito.
Essas correções dizem respeito ao sample de uso do winsock como modelo server/client da própria Microsoft. Ele foi modificado em um repositório que criei para meus testes e poderá ser usado como correção de todos que tiverem o mesmo problema utilizando a API do Windows diretamente.
Já para o Boost.Asio será necessário um estudo de impacto e o envio de uma proposta de correção (ou uso de um patch em que a criação do socket cliente deve ser feita sem herança). Isso pode potencialmente quebrar o funcionamento de outros tipos de programas que dependem direta ou indiretamente da herança de todos os sockets, ou talvez o Boost.Asio tenha uma maneira educada de entregar o controle da criação de sockets dependente de implementação. Eu não sei. Este é um próximo passo da pesquisa.
UPDATE: Embora use a função WSASocketW o Boost.Asio não suporta a parametrização das flags, e sua implementação não é sobrecarregável, fazendo parte do namespace socketopt. Foi criado um issue no GitHub do projeto Boost.Asio para ver os comentários e colocações da equipe. No aguardo.
</description>
</item>

     
        <item>
  <title>A Maneira Errada de Começar um Projeto é com Visual Studio</title>
  <link>http://www.caloni.com.br/a-maneira-errada-de-comecar-um-projeto-e-com-visual-studio/</link>
  <pubDate>2018-12-11</pubDate>
  
  <guid>http://www.caloni.com.br/a-maneira-errada-de-comecar-um-projeto-e-com-visual-studio/</guid>
  <description>Estava eu trabalhando com um sample e resolvi colocar controle de fonte para analisar as mudanças. E a mudança mais inesperada que eu vi quando digitei git diff foi que ele achou que meus arquivos de código-fonte estivessem em binário.
Essa lambança ocorreu com uma versão atual do Visual Studio 2017 após eu resolver ser preguiçoso e deixar o template dele criar o projeto para mim.
Particularmente não sou fã de deixar as IDEs criarem arquivos, porque geralmente elas estão cheias de más intenções disfarçadas de boas envolvendo alguma tecnologia proprietária. No caso da Microsoft há os precompiled headers, que sujam o projeto antes mesmo do tempo de compilação ser um problema. E agora descobri que os arquivos estão sendo gerados em UNICODE Windows.
Se você tiver o mesmo problema e quiser corrigir segue o passo-a-passo: salve os arquivos com um encoding de gente grande como utf8. Fim do passo-a-passo.
Isso pode ser obtido na janela de &amp;quot;Save As&amp;quot; do Visual Studio. Há uma flecha para baixo do lado do botão Save onde você pode abrir a opção &amp;quot;Save with Encoding&amp;quot;.
Na prática, troque possivelmente de &amp;quot;Unicode - Codepage 1200&amp;quot; para &amp;quot;Unicode (UTF-8 without signature) - Codepage 65001&amp;quot;. A partir do segundo commit o git começará a entender que você atingiu a maioridade e vai comparar os arquivos como gente grande para você.
A partir do segundo commit o git começará a entender que você atingiu a maioridade e vai comparar os arquivos como gente grande para você.
</description>
</item>

     
        <item>
  <title>Boost.Bind e os Erros Escrotos</title>
  <link>http://www.caloni.com.br/boost-bind-e-os-erros-escrotos/</link>
  <pubDate>2018-10-01</pubDate>
  
  <guid>http://www.caloni.com.br/boost-bind-e-os-erros-escrotos/</guid>
  <description>Estou voltando a programar algumas coisas no boost. Algo que eu perdi ao me isolar do movimento de modernização do C&#43;&#43; foi a capacidade brilhante da biblioteca boost em encapsular e abstrair conceitos de engenharia de software de maneira portável e mantendo a filosofia por trás da STL, que ainda é a melhor maneira de trabalhar algoritmos já criada em qualquer linguagem de programação séria.
Isso não quer dizer que a linguagem C&#43;&#43; está indo para um bom caminho. Muito pelo contrário. Uma miríade de questões semânticas dividem opiniões e nunca resolvem de fato problemas do mundo real. Verdadeiros arcabouços masturbatórios, o comitê da linguagem se debate em vão quando tenta buscar maneiras de tornar uma linguagem arcaica em um exemplo de expressividade.
Isso às vezes não importa muito para o dia-a-dia, mas outras vezes importa. Veja o caso da biblioteca Boost.Bind, uma das mais antigas a entrar para o projeto. Sua função é simples: expandir o conceito do std::bind para quantos argumentos for necessário. Isso foi criado na época com a ajuda de inúmeros overloads da função (em modo template), mas hoje é possível fazer com variadic templates. Seu uso é simples, intuitivo, direto, e resolve muitos problemas de encaixe de código:
No entanto, o que era para ser um uso simples e direto de uma feature bem-vinda ao cinto de utilidades do programador C&#43;&#43; se transforma em um pesadelo quando as coisas não se encaixam tão bem:
Vou plotar aqui todas as mensagens de erro para sentir o drama:
Este é o erro encontrado usando o último Visual Studio (2017 15.9.0 Preview 2.0) e o Boost 1.68.0. A primeira linha deveria significar alguma coisa (que é para onde todo programador C&#43;&#43; deve olhar):
Mas não. Se olharmos para o código-fonte onde ocorreu o problema, a caixa de encaixe perfeito se quebra:
O que isso quer dizer? O que aconteceu? Onde que eu errei?
Claro que ao final da longa listagem de erros (que se torna ainda mais longa, dependendo de quantos argumentos sua função tem) há alguma luz no fim do túnel:
Mas claro que essa luz pode estar ofuscada quando os tipos dos argumentos são templates de templates de templates... enfim. Deu pra entender onde o caos consegue chegar quando se trata de harmonizar uma biblioteca perfeita com uma linguagem em constante construção.
</description>
</item>

     
        <item>
  <title>Coroutine Internals</title>
  <link>http://www.caloni.com.br/coroutine-internals/</link>
  <pubDate>2018-09-18</pubDate>
  
  <guid>http://www.caloni.com.br/coroutine-internals/</guid>
  <description>Uma corrotinas é um mecanismo de troca de contexto onde apenas uma thread está envolvida. Ela me faz lembrar do Windows 3.0, não exatamente por não existirem threads (e não existiam mesmo), mas pelo caráter cooperativo dos diferentes códigos.
Só que no caso do Windows se a rotina de impressão travasse todo o sistema congelava.
A volta das corrotinas via C&#43;&#43; moderno ocorre, para variar, no Boost. E a arquitetura é simples: mantenha um histórico das stacks das diferentes tasks da thread. Vamos pegar o caso mais simples da Boost.Coroutine para analisar:
Se você já é um programador esperto já deve ter percebido que na saída do prompt será impresso &amp;quot;Hello, world!&amp;quot;, com a vírgula no meio sendo impressa pela função main e as duas palavras da ponta pela função cooperative, ainda que ela seja chamada apenas uma vez.
Note que falei chamada porque se a stack não retornou da função ela não terminou ainda seu trabalho. Não houve o &amp;quot;return&amp;quot;. Outra forma de entender isso é que ela é chamada aos poucos. Enfim, deixo para você a discussão semântica. O fato é que a saída é &amp;quot;Hello, world&amp;quot;.
Depurando encontramos a stack de cooperative, que nos indica que ela não partiu do main, apesar de ter sido chamada através da construção de coroutine pulltype. O método sink chamado logo após imprimir &amp;quot;Hello&amp;quot; deve colocar essa rotina para dormir, voltando o controle para main.
Analisando como isso é feito vemos que o depurador do Visual Studio está fazendo caquinha, pois rodando passo-a-passo voltei para a mesma função cooperative sem passar pelo main. No entanto, a vírgula &amp;quot;, &amp;quot; foi impressa.
Para conseguirmos depurar diferentes rotinas dentro da mesma thread é imperativo entendermos como o mecanismo de troca de contexto funciona por baixo dos panos. Para isso nada como depurar as próprias trocas de contexto.
O tamanho total da stack reservada no Windows é de 1 MB, mas a granuralidade padrão é de 64 KB (&amp;quot;que é suficiente para qualquer um&amp;quot; - Gates, Bill). Então é por isso que quando o Boost aloca uma stack com atributos padrões esse é o tamanho que vemos (65536).
 The default size for the reserved and initially committed stack memory is specified in the executable file header. Thread or fiber creation fails if there is not enough memory to reserve or commit the number of bytes requested. The default stack reservation size used by the linker is 1 MB. To specify a different default stack reservation size for all threads and fibers, use the STACKSIZE statement in the module definition (.def) file. The operating system rounds up the specified size to the nearest multiple of the system&#39;s allocation granularity (typically 64 KB). To retrieve the allocation granularity of the current system, use the GetSystemInfo function.
 Detalhe curioso de arquitetura x86 (32 bits): na hora de alocar, o sp (stack pointer) aponta para o final da pilha. Isso porque no x86 a pilha cresce &amp;quot;para baixo&amp;quot;.
Logo em seguida, no topo da pilha, é empilhado o objeto da corrotina:
Bom, entrando mais a fundo na implementação de corrotinas do Boost, temos o objeto pullcoroutineimpl, que possui flags, ponteiro para exceção e o contexto do chamador e do chamado para se localizar.
O coroutinecontext possui elementos já conhecidos de quem faz hook de função: trampolins. Ou seja, funções usadas para realizar saltos incondicionais de um ponto a outro do código independente de contexto. Na minha época de hooks isso se fazia alocando memória na heap e escrevendo o código assembly necessário para realizar o pulo, geralmente de uma colinha de uma função naked (funções naked não possuem prólogo e epílogo, que são partes do código que montam e desmontam contextos dentro da pilha, responsável pela montagem dos frames com ponto de retorno, variáveis locais, argumentos).
A função que faz a mágica do pulo do gato é a pull, que muda o estado da rotina para running e realiza o salto de contexto. Vamos analisar essa parte com muita calma.
Quem desfaz a mágica, &amp;quot;desempilhando&amp;quot; o contexto para voltar ao chamador da corrotina (através do contexto apenas, não da pilha) é a função push.
Com os dados disponíveis nos objetos de contexto (no exemplo do main, a variável source) é possível pelo Windbg analisar qualquer tipo de stack com o comando k.
A variável de uma coroutine contém o contexto do chamador e do chamado. Quando houver a necessidade de explorar uma pilha não-ativa é preciso obter o valor de sp através dessa variável. Ela fica um pouco escondida, mas está lá. Acredite.
Usando o comando k = BasePtr StackPtr InstructionPtr passando o conteúdo de sp como o stack pointer o Windbg deve mostrar a pilha de todas as formas possíveis (especificar se terá FPO, mostrar código-fonte, argumentos, etc). Para a demonstração live fica bom ter um loop &amp;quot;eterno&amp;quot; para poder repetir a análise quantas vezes forem necessárias:
DICA: É importante detachar do processo, mesmo que estejamos analisando em modo não-invasivo, porque a porta de Debug pode ser ocupada e o Visual Studio vai ficar pra sempre esperando receber eventos de debug que ele não vai mais receber.
Após rodarmos novamente o programa ele pára no main. Podemos atachar com o WinDbg quantas vezes precisarmos:
</description>
</item>

     
        <item>
  <title>Vcpkg Internals: como o gerenciador de pacotes da M$ funciona por dentro (e como fazer seu próprio pacote!)</title>
  <link>http://www.caloni.com.br/vcpkg-internals/</link>
  <pubDate>2018-09-12</pubDate>
  
  <guid>http://www.caloni.com.br/vcpkg-internals/</guid>
  <description>Depois de entender mais ou menos como funciona o vcpkg é hora de realmente entrar no código e entender qual a grande sacada dessa ferramenta da Microsoft.
Uma das formas mais divertidas de entender o funcionamento de um fonte é compilar e sair depurando. E foi o que eu fiz. Através dos step ins e step outs foi possível ter as primeiras impressões de em qual pé está o projeto, além de pegar boas ideias para meu próprio código.
Por exemplo, no começo do programa encontrei uma saída simples e eficaz de como tratar entrada e saída (ou só saída) de dentro de um terminal:
Com tudo UTF-8 a vida fica mais fácil.
Outro ponto interessante é que o fonte é muito C&#43;&#43; moderno, com direito a inclusive usar headers ainda experimentais, como o filesystem (C&#43;&#43; 17). Ele usa também um conjunto de paths sobre onde estão as coisas (instalação, pacotes, etc). Há muito código no vcpkg que são módulos independentes que soam como retrabalho de coisas comuns, como parseamento de argumentos, mas o objetivo do projeto é ser independente de tudo. Do contrário ele não seria um bom gerenciador de pacotes.
O arquivo vcpkg\installed\vcpkg\status contém em formato texto simples o status de todos os pacotes instalados (se foi instalado com sucesso ou não, etc). A pasta vcpkg\ports contém todos os pacotes, instalados ou não. O início de tudo é o executável na pasta-raiz após compilado, vcpkg.exe, feito em C&#43;&#43; e que realiza todas as bruxarias para montar a hierarquia de pastas e arquivos em texto. Tudo é tão simples e baseado em arquivos de texto que vejo que a M$ finalmente se rendeu ao jeito unix de fazer as coisas (mais conhecido como o jeito certo).
No gerenciador de pacotes há um conceito chamado de triplet, que não é uma novidade; é uma forma de especificar um conjunto de elementos do ambiente para cross compiling utilizando um simples nome.
O vcpkg já vem com alguns triplets de fábrica, mas você pode criar os seus próprios na pasta triplets, alterando várias variáveis de controle de compilação:
 VCPKG_TARGET_ARCHITECTURE. A arquitetura alvo (x86, x64, arm, arm64). VCPKG_CRT_LINKAGE. A linkagem do CRT (que é mais conhecida pelo pessoal do Zwindows; valores: dynamic, static). VCPKG_LIBRARY_LINKAGE. O mesmo do CRT, mas para libs (as bibliotecas podem ignorar se elas não suportam isso). VCPKG_CMAKE_SYSTEM_NAME. A plataforma alvo, que pode ser vazio (o Windows desktop padrão), WindowsStore, Darwin (Mac OSX) ou Linux. VCPKG_PLATFORM_TOOLSET. O toolset do Visual Studio (mais uma coisa do Zwindows); v141, v140 são valores válidos (vazio também). VCPKG_VISUAL_STUDIO_PATH. Onde está a instalação do Visual Studio (é, o vcpkg tem uma certa tendência pro Zwindows). VCPKG_CHAINLOAD_TOOLCHAIN_FILE. Esse não é do Zwindows, mas do CMake; a possibilidade de escolher outro toolchain (diferente de scripts/toolchains) para o CMake.  Há diversas flags de compilação que podem ser especificadas direto no triplet:
 VCPKG_CXX_FLAGS_DEBUG VCPKG_CXX_FLAGS_RELEASE VCPKG_C_FLAGS VCPKG_C_FLAGS_DEBUG VCPKG_C_FLAGS_RELEASE  A macro do CMake PORT será interpretada pelo triplet. Isso é uma garantia de mudanças nos settings para portabilidade. Por exemplo:
Que compila qualquer coisa que entre no match &amp;quot;qt5-*&amp;quot; como dinâmico (DLLs), embora todo o resto possa ser estático.
A integração com o Visual Studio ocorre com o uso daqueles pedaços de configuração de projetos que são as abas de propriedades. Você mesmo pode criar abas de propriedade como arquivos separados do seu vcxproj para configurações comuns a mais projetos.
Para realizar a integração o comando é vcpkg integrate install&amp;quot;:
Note que as coisas para quem usa CMake são automáticas e fáceis de usar. Basta acrescentar o toolchain especificado. Já para Visual Studio...
O mecanismo envolve uma pasta do msbuild:
Dentro dessa pasta é colocado um desses pedaços de configuração (propriedades) chamado vcpkg.system.props.
Essa diretiva usa a pasta definida pela variável de ambiente LOCALAPPDATA (geralmente C:\Users&amp;lt;seu-usuario&amp;gt;\AppData\Local) para localizar um outro arquivo, o vcpkg.user.targets.
No exemplo estou usando um vcpkg disponível na pasta c:\libs (que é basicamente um clone do repositório GitHub do vcpkg). Note que ele inclui automaticamente nos projetos do Visual Studio um target dentro dele, o vcpkg\scripts\buildsystems\msbuild\vcpkg.targets. Vejamos o que tem nele:
Note como as pastas de instalação dos pacotes do triplet selecionado são incluídas na configuração de um projeto do Visual Studio. As libs ficam na subpasta installed/triplet/lib, os binários em installed/triplet/bin, os includes em installed/triplet/include e assim por diante. A ramificação dos pacotes está de acordo com o basename de cada um deles.
A mágica ocorre já na hora de dar include. E é mágica desde o autocomplete até o link. Por exemplo, digamos que vamos fazer um embedded de Python usando o exemplo do help:
O programa compila e linka. Para provar que ele usa a lib instalada (versão debug):
Se você prestou atenção ao conteúdo de msbuild\vcpkg.targets lá em cima vai ter visto que há uma condição que adiciona toda e qualquer lib como dependência adicional ao projeto compilando:
É isso que resolve o problema de saber qual o nome da lib resultante de um pacote instalado. Porém, isso não é o ideal, principalmente por dois motivos:
 Os nomes de configuração do projeto tem que ser Debug ou Release (maneiras de melhorar já está sendo discutido no GitHub). O usuário final não tem qualquer controle do que adicionar como dependência; simplesmente vai todos os pacotes instalados (mais uma discussão no GitHub).  Porém, no momento é assim que funciona. Para o problema #1 a solução paliativa é o próprio usuário adicionar em seu msbuild as condições de sua configuração. A sugestão da thread é boa:
Pelo menos tudo que começar com Debug (ou Release) já entraria no filtro.
UPDATE: Essa sugestão já foi adicionada à última versão do vcpkg. É feita uma normalização do nome:
Assim o que seguir é Debug ou Release =).
Um outro potencial problema dos usuários de Visual Studio para compilar e rodar projetos C&#43;&#43; são as dependências de binários (DLLs). É possível que um pacote seja compilado de maneira dinâmica, ou seja, com DLLs de dependência. Essas DLLs na instalação do pacote devem constar na pasta bin, mas por conta dessa pasta não fazer parte dos diretórios de sistema o depurador do Visual Studio irá carregar um executável em sua pasta de geração em que não encontrará as eventuais DLLs que ele precisa para rodar.
Para &amp;quot;corrigir&amp;quot; isso, ou melhor dizendo, contornar a experiência, também foi adicionado um comando Post Build no vcpkg.targets com um comando Power Shell que copia esses binários para a pasta de geração do projeto atual. Dessa forma o projeto pode rodar sem problemas, o usuário fica feliz e consegue terminar sua programação antes de passar para o deploy (e facilita deploys de testes, pois basta copiar a pasta de geração do executável que todas suas dependências estarão lá).
O script executado pelo PowerShell fica em vcpkg\scripts\buildsystems\msbuild e recebe o TargetPath (o binário-alvo) como parâmetro e onde estão os binários instalados pelo vcpkg, e com base na saída da ferramenta dumpbin extrai as dependências do executável e as busca no diretório bin:
Isso é o equivalente ao uso padrão de dumpbin com grep e sed:
A cópia dos binários é feito com um teste simples de &amp;quot;path existe&amp;quot; com deploy:
Fato curioso: no script do PowerShell existem alguns hacks para alguns pacotes, incluindo Qt.
O uso do CMake permite aos usuários do vcpkg ter boas ideias apenas lendo os scripts do projeto. Se você abrir o solution vcpkg.sln dentro de toolsrc vai descobrir todos os scripts listados por lá. Há funções espertinhas como o download e extração de pacotes 7zip do Source Forge.
Essa parte fica em vcpkg/scripts/cmake. Olhe, por exemplo, como retornar a versão do Windows SDK (vcpkggetwindowssdk.cmake):
Assim como o esquema de triplets, tudo pode ser atualizado conforme o gosto do freguês, adicionando funções e configurações úteis em seu clone do repositório, e feitas atualizações com a versão oficial.
O vcpkg não é apenas um ecossistema de libs compiladas e instaladas em uma pasta para serem usadas localmente. Pode ser um caminho simples e rápido para você conseguir compilar libs conhecidas e entregar para um terceiro um zip com todos os includes, libs e dependências do seu projeto.
Para trabalhar em equipe é vital que todos falem a mesma língua. Uma das formas disso acontecer é usar um gerenciamento de pacotes que inclua todos os ambientes que a equipe usa. Como geralmente esses ambiente não são os mesmos, o uso de pacotes próprios do vcpkg é um plus da ferramenta que vem para somar em padronização de fontes e compilação.
Primeiro de tudo é interessante existir um local público de download dos fontes (caso o projeto seja opensource; se bem que é possível que o endereço seja apenas visível para usuários logados ou outro mecanismo de proteção).
Uma estrutura simples de lib que compila com CMake, por exemplo, deverá conter alguns arquivos mínimos:
Um .cpp com a implementação, um .h público para o usuário acessar, uma licença de uso (LICENSE) e um arquivo CMakeLists.txt são o suficiente para demonstar o uso. Dentro do CMakeLists.txt temos as seguintes diretivas:
A partir de um zip na internet da pasta bitforge já é possível começar a montar seu próprio pacote:
Dica: você pode também testar ou implantar isso localmente usando Python:
O arquivo portfile.cmake já possui teoricamente tudo o que precisa para falhar. Há alguns caveats que podem te dar bastante dor de cabeça no começo. Por isso mesmo eu vou economizar algum tempo para você.
Em primeiro lugar, preste atenção no diretório onde estarão os fontes. É costume do template usar o mesmo nome do zip, o que nem sempre é verdade (aqui não é, não existe versão no nome da pasta zipada):
Então em vez de:
Isso:
O erro que deve acontecer na falta dessa mudança é o seguinte:
Em segundo lugar, a cópia do header é feita tanto em release quanto em debug. A compilação via vcpkg irá te avisar que tem alguma coisa errada pois está duplicado, mas já há uma linha mágica que pode ser adicionada:
O erro que deve acontecer na falta dessa mudança é o seguinte:
E por último, é obrigatório ter um arquivo de copyright, no caso o nosso LICENSE do projeto. O portfile.cmake já tem o comando, mas está comentado:
O erro que deve acontecer na falta dessa mudança é o seguinte:
Basicamente isso é o que você precisa para começar a construir seu pacote:
O próximo passo é instalar:
E voilá! Agora o include está disponível, as funções estão disponíveis, o link está funcionando e seu pacote pode ser compartilhado com toda a empresa. Basta copiar a pasta ports/bitforge ou adicioná-la no repositório por um commit.
</description>
</item>

     
        <item>
  <title>GetArg: the ultimate badass argv/argc parser</title>
  <link>http://www.caloni.com.br/getarg/</link>
  <pubDate>2018-08-30</pubDate>
  
  <guid>http://www.caloni.com.br/getarg/</guid>
  <description>Sim, eu acho que já resumi o suficiente meu parseador de argv/argc no meu último artigo sobre o tema. Sim, eu também acho que a versão com STL bonitinha (mas ordinária). A questão agora não são as dependências, mas o uso no dia-a-dia: precisa ter o argc nessa equação?
A resposta é não. Pois, como sabemos, o padrão C/C&#43;&#43; nos informa que o argv é um array de ponteiros de strings C que termina em nulo. Sabemos que ele termina, então o argc é apenas um helper para sabermos de antemão onde ele termina. Mas quando precisamos, por exemplo, passar o argv/argc para uma thread Windows, que aceita apenas um argumento mágico, talvez minha versão antiga não seja tão eficaz, pois isso vai exibir que eu aloque memória de um struct que contenha ambas as variáveis, etc. Por que não simplesmente utilizar apenas o argv?
Nessa versão elminamos a necessidade do argc e de brinde ganhamos a possibilidade de usar um único ponteiro como start de um parseamento de argumentos.
</description>
</item>

     
        <item>
  <title>Meu Novo Parseador de Argc Argv</title>
  <link>http://www.caloni.com.br/meu-novo-parseador-de-argc-argv/</link>
  <pubDate>2018-08-21</pubDate>
  
  <guid>http://www.caloni.com.br/meu-novo-parseador-de-argc-argv/</guid>
  <description>Eis que me deparo com um projeto onde não posso usar STL. Ou seja, nada de map nem string. Isso quer dizer que minha função bonita e completa de parseamento de argumentos argc/argv não pode ser usado. Essa é uma má notícia. A boa notícia é que achei uma forma muito mais simples e à prova de falhas de fazer isso. Ele basicamente percorre o array argv em busca do nome do parâmetro enviado para a função. Uma vez que ele encontre ele retorna o próximo elemento. Na falta de próximo elemento ele simplesmente retorna uma string vazia que não é nulo, mas já indica que há o parâmetro na lista de argumento.
Essa função é tão simples, e tem tão poucas dependências (strcmp) que você pode usá-la em praticamente qualquer programa que use argc/argv e que use os parâmetros dos mais complexos. Ao chamar essa função se passa o argc e o argv recebido no main e o terceiro argumento é apenas o nome de um argumento válido que pode ser recebido via linha de comando. O resultado é um ponteiro (obtido no próprio argv) da próxima string ou uma string C vazia constante (não precisa de alocação) se for o último argv. E caso ele não ache o retorno é NULL. Seu uso comum é uma linha apenas, ou uma linha para cada argumento buscado. Sua complexidade é linear, mas, ei, quem está querendo performance no início do programa?
Uma última observação: dependendo do uso você pode ou não usar o retorno, e ele possui semântica booleana, pois caso o argumento não exista o retorno é NULL e por isso não cai dentro do if (pois NULL traduzido em booleano é false). Eis uma função para copiar e colar abusivamente.
</description>
</item>

     
        <item>
  <title>Vídeo: Visual Studio e seu depurador (comentado)</title>
  <link>http://www.caloni.com.br/video-depuracao-visualstudio-101-comentado/</link>
  <pubDate>2018-07-27</pubDate>
  
  <guid>http://www.caloni.com.br/video-depuracao-visualstudio-101-comentado/</guid>
  <description>Segue meu segundo vídeo curto onde estou apenas demonstrando como é o depurador do Visual Studio. Mas dessa vez com comentários =)
</description>
</item>

     
        <item>
  <title>Vídeo: Depuração Visual Studio 101</title>
  <link>http://www.caloni.com.br/video-depuracao-visualstudio-101/</link>
  <pubDate>2018-07-24</pubDate>
  
  <guid>http://www.caloni.com.br/video-depuracao-visualstudio-101/</guid>
  <description>Redescobrindo meu canal no YouTube me empolguei em publicar mais alguma coisa. Os meu primeiros vídeos, no meu canal pessoal, são longos e possuem narração um pouco confusa, mas explicam bem alguns detalhes do Visual Studio. Agora com meu primeiro vídeo curto estou apenas demonstrando sem voz como é o depurador do Visual Studio. Enjoy =)
</description>
</item>

     
        <item>
  <title>Stanford Encyclopedia of Philosophy Para Kindle</title>
  <link>http://www.caloni.com.br/stanford-encyclopedia-of-philosophy-para-kindle/</link>
  <pubDate>2018-07-15</pubDate>
  
  <guid>http://www.caloni.com.br/stanford-encyclopedia-of-philosophy-para-kindle/</guid>
  <description>A enciclopédia mais completa e de maior respeito da internet não é um enciclopédia geral, mas uma de filosofia. Está hospedada na Universidade de Stanford e possui revisão por pares e toda a autoridade de ser escrita por especialistas nos verbetes em questão. O único problema (até agora) era não ser possível baixá-la para degustar no Kindle. Até agora.
Para realizar esta operação será necessário usar as seguintes ferramentas:
 wget sed sort Calibre  O projeto de conversão (disponível aqui) foi feito pensando em usuários do Windows, mas pode ser adaptado facilmente para qualquer ambiente. Se trata de um conjunto de arquivos batch (script) que realiza vários comandos, a saber:
Este batch baixa todo o conteúdo do site da Stanford em um único diretório. O processo pode demorar mais ou menos, dependendo da sua banda, mas aqui em casa (50MB) demorou cerca de meia-hora pra mais.
Este batch chama dois outros batch, call calibreremovehead.bat e call calibreremovebottom.bat, que limpam das entradas os cabeçalhos e finais em comum que são repetitivos e desnecessários para gerar um ebook, como links úteis de navegação. Como as entradas do site já possuem marcadores, isso facilitou o trabalho.
Esta batch gera os índices das entradas baseado em seus títulos, e os nomes dos arquivos serão usados para links no TOC do Calibre.
Algumas entradas possuem o marcador em, que deve ser retirado antes de ordenar os títulos.
Se não ordenarmos por título o único índice de nosso livro será inútil.
Ao final do processo com o wget percebi que algumas entradas foram baixadas mais de uma vez. Várias delas. Por isso eliminei as duplicatas usando um programa Windows chamado doublekiller.exe, mas basta você usar qualquer ferramenta que encontra os .html da mesma pasta que possuem o mesmo hash e eliminar as duplicadas. Isso deve ser feito nesse passo antes de:
Essa parte do processo precisa converter as entradas no formato Título Link para entradas HTML com a tag a, no formato que o Calibre espera:
Por fim, antes de usar o Calibre é necessário juntar os arquivos de template em um arquivo final de TOC, o calibre.html. Ao final desse processo passaremos ao Calibre em si.
Para realizar este passo basta arrastar ou abrir o arquivo html central que foi criado, e a partir dele iniciar a conversão. Note que após arrastar já será criado um zip com todos os HTMLs relacionados.
Após abrir pelo Calibre ele insere na biblioteca e é só converter para MOBI (Kindle) ou EPUB (outros leitores) ou qualquer outro formato desejado. A nota final aqui é que como se trata de um arquivo gigantesco (50 MB em HTML zipado, 80 MB em MOBI) é melhor baixar a versão 64 bits do Calibre e ter muita memória RAM. Voilà!
E por hoje é só. Se tudo der certo você poderá copiar e colar dentro do seu leitor todas as entradas de uma enciclopédia indispensável para quem está estudando filosofia. Enjoy.
</description>
</item>

     
        <item>
  <title>Python27, protobuf, py2exe e buildexe</title>
  <link>http://www.caloni.com.br/python27-protobuf-py2exe-cx_freeze/</link>
  <pubDate>2018-07-14</pubDate>
  
  <guid>http://www.caloni.com.br/python27-protobuf-py2exe-cx_freeze/</guid>
  <description>Para quem está tentando compilar um executável usando py2exe e protobuf, #ficadica: desista. Ele não vai funcionar ou se funcionar vai dar trabalho. Em vez disso melhor usar buildexe (através do pacote cxfreeze), que é um esquema marotinho que permite configurar tudo e há apenas um patchzinho que precisa ser feito.
Para entender como as coisas dão errado primeiro vamos instalar os requisitos de um pacote fictício em um ambiente virtualizado do Python (para evitar mexer na instalação padrão):
Depois instalamos os requisitos de nosso pacote fictício:
Agora vem a hora do erro. O protobuf que foi instalado possui um pequeno bug que impede que o buildexe obtenha essa dependência corretamente na hora de gerar o executável:
Para fazer funcionar há um pequeno patch: criar um arquivo \init\.py dentro da pasta google onde está instalado o pacote do protobuf:
Após essa pequena operação já será possível gerar o executável com sucesso:
Agora ao listarmos os executáveis gerados encontraremos nosso amigo fictício:
NOTA: conteúdo do arquivo setup.py:
</description>
</item>

     
        <item>
  <title>Vcpkg: gerenciador de libs c&#43;&#43; para Linux, Mac OS... e Windows!</title>
  <link>http://www.caloni.com.br/vcpkg/</link>
  <pubDate>2018-07-14</pubDate>
  
  <guid>http://www.caloni.com.br/vcpkg/</guid>
  <description>O ambiente padronizado de bibliotecas C/C&#43;&#43; dos sistemas UNIX é motivo de inveja dos programadores Windows por séculos. Mas, finalmente, a Microsoft tem acordado diante da ressurreição do C&#43;&#43;, com seus novos bug fixes e new deprecated features.
E com isso uma série de atividades têm permeada a evolução da ferramenta de desenvolvimento da Microsoft, o Visual Studio:
 Updates frequentes Projetos internos lançados como open source no GitHub Compra do GitHub Suporte a mais de um compilador (como clang) Depuração Linux (Ubuntu) dentro do Windows Ambiente Linux (Ubuntu) dentro do Windows Pesado suporte ao CMake Ambiente padronizado de bibliotecas para Windows, Linux e Mac OS (vcpkg) Suporte à compilação de bibliotecas clássicas dos ambientes UNIX via vcpkg Deploy de suas próprias bibliotecas padronizadas via vcpkg  Usar o vcpkg no Windows é tão simples que parece mágica. Ou Linux.
Para instalar você só precisa seguir o passo-a-passo do GitHub deles e usar PowerShell. O prompt PS faz tudo automático. O vcpkg é basicamente um conjunto de CMakes que fazem o serviço direito e conseguem compilar quase 1000 libs, a maioria nascidas no Linux, e integrar diretamente com projetos do VS2017.
Para provar todo o seu poder vamos usar a pior lib de todas: GTK.
O GTK não é apenas uma biblioteca, mas um conjunto de infinitas dependências. Há um tutorial gigantesco para compilar para Windows (defasado) e novos problemas surgem cada vez que alguém tenta utilizá-lo. Eu gastei mais de 40 horas para entender esses problemas compilando todas as dependências (estava em 95%) quando surgiu o vcpkg e jogou todos meus esforços no lixo (ainda bem).
Com o vcpkg tudo que é necessário fazer é rodar o comando de install com o nome da lib e toda a compilação é feita automaticamente. Depois disso, se não houver paths de include nos seus projetos do Visual Studio ele próprio irá levar em conta o path de instalação dessas libs (compilação e link). Parece mágica mesmo para quem passou décadas se matando para compilar alguma coisa que preste no Windows e que veio do Linux.
Vantagens do vcpkg:
 Economia de tempo (de pesquisa, de compilação, de tudo) Uniformidade no uso das libs Flexibilidade para colocar suas próprias libs  Desvantagens do vcpkg:
 Apenas as libs mais novas estão sendo suportadas (e não há suporte para Visual Studio mais antigo, nem SOs mais antigos como XP). Usuário Linux nenhum no mundo vai querer usar (motivo: Microsoft e este já é um problema resolvido neste mundo) Depende de um gerenciador proprietário (se bem que é tudo open source e não há restrições como o Java; qualquer um pode montar seu repositório).  </description>
</item>

     
        <item>
  <title>Manipulando Mouse e Teclado no Windows</title>
  <link>http://www.caloni.com.br/manipulando-mouse-e-teclado-no-windows/</link>
  <pubDate>2018-07-04</pubDate>
  
  <guid>http://www.caloni.com.br/manipulando-mouse-e-teclado-no-windows/</guid>
  <description>Uma forma extremamente bem comportada que o Windows tem para manipular entrada de mouse e teclado são as funções API BlockInput/SendInput [1][2]. Enquanto uma bloqueia todos os eventos de input vindo de todos os lugares do sistema, o outro consegue enviar inputs apenas por software. Imagine a peça que você pode pregar em seus amigos.
No entanto, estas funções não são para amadores. É preciso entender o que são threads, por exemplo, pois apenas a thread que chamou BlockInput pode depois chamar SendInput com sucesso. Além disso, apenas essa thread pode desbloquear novamente os inputs chamando BlockInput novamente, mas dessa vez passando FALSE em seu único parâmetro. E de qualquer forma, uma vez que o programa que chamou BlockInput com TRUE morreu o sistema detecta e tudo volta ao normal.
Essas funções API podem ser úteis para interação remota, por exemplo, quando um usuário não consegue realizar uma operação e ele pode mais atrapalhar do que ajudar você pode bloquear os inputs dele e emular seus próprios cliques de mouse e teclado pela rede.
Nota: usar essas APIs na própria máquina pode ser bem frustrante. Tenha sempre em mãos uma VM de teste.
Funções citadas neste texto:
 [1] https://msdn.microsoft.com/en-us/library/windows/desktop/ms646290(v=vs.85).aspx [2] https://msdn.microsoft.com/en-us/library/windows/desktop/ms646310(v=vs.85).aspx  </description>
</item>

     
        <item>
  <title>SSL e seu limite de pacote</title>
  <link>http://www.caloni.com.br/ssl-limite-de-pacote/</link>
  <pubDate>2018-05-22</pubDate>
  
  <guid>http://www.caloni.com.br/ssl-limite-de-pacote/</guid>
  <description>O protocolo TLS/SSL tem por objetivo criar uma camada de criptografia assimétrica para a aplicação. E quando eu falo em camada não estou me referindo às camadas OSI. Nem às camadas TCP/IP. Isso porque o SSL não se encaixa em nenhuma das duas. Ele interfere com muitas, inclusive a aplicação. E aprendi isso a duras penas: na ponta do depurador.
O pacote SSL tem um limite de 16 KB, ou 16384 bytes. Esse é o limite que será respeitado por qualquer implementação do protocolo, o que inclui o uso de Boost.Asio e seu uso da OpenSSL. O que isso quer dizer na teoria é que você não pode trafegar sentido server=&amp;gt;client nada maior que 16k bytes. O que isso quer dizer na prática é que sua aplicação não pode escrever mais que 16k bytes de uma vez no socket que vai dar pau.
Sim, a camada de aplicação tem que estar ligada que existe SSL abaixo dela.
Isso quer dizer que este snippet de código, por exemplo:
Não é inocente e não funciona sempre. Se sock for um socket cuja comunicação está encriptada por SSL (em outras palavras -- em Boostês -- ele for um sslsocket) você precisa escrever output em pequenas quantidades. Como em outra implementação inocente:
Se isso não for feito e a ponta server escrever, digamos, 512KB, ou 17KB, ou qualquer coisa acima de 16KB, ela irá receber... 16 KB. E acabou. O resto se perder.
Portanto, quando for mexer com SSL, esqueça OSI e esqueça TCP/IP. As coisas funcionam de uma maneira muito mais esotérica que qualquer programador de redes jamais viu, e jamais verá.
</description>
</item>

     
        <item>
  <title>Boost Meta State Machine</title>
  <link>http://www.caloni.com.br/boost-meta-state-machine/</link>
  <pubDate>2018-05-21</pubDate>
  
  <guid>http://www.caloni.com.br/boost-meta-state-machine/</guid>
  <description>O Boost Meta State Machine (MSM for short) é uma das duas bibliotecas mais famosinhas de state machine do Boost. Ela é uma versão estática que permite incluir chamadas para as entradas e saídas de um estado baseado em eventos. A sua principal vantagem é poder visualizar toda a máquina de estado em um só lugar, e sua principal desvantagem é pertecer ao Boost, o que quer dizer que você vai precisar fazer seu terceiro doutorado e ler uma documentação imensa sobre UML antes de conseguir produzir alguma coisa. Ou ler este artigo de 10 minutos tops.
A parte bonitinha de se ver é os eventos e estados completamente ordenados:
Claro que a indentação ajuda. Para cada entrada e saída de um estado é possível utilizar os métodos onentry e onexit de cada struct que define um estado, seja este método um template totalmente genérico ou especificado por evento (e cada evento também é um struct, com direito a dados específicos).
Quando é criada uma nova máquina de estados o estado inicial é chamado pelo evento onentry genérico. Como sabemos qual é o estado inicial? Isso é definido pelo typedef initialstate dentro da classe da máquina de estado (que deve herdar de statemachinedef no estilo WTL, com sobrecarga estática):
O estado final também é definido, mas por herança. O estado final, que também é uma struct, deve herdar de terminatestate:
A partir daí o método processevent serve para enviar eventos à máquina de estado que irá alterar seu estado dependendo do fluxo criado no nome transitiontable dentro da máquina de estado (a tabelinha que vimos acima). A partir daí tudo é possível; a máquina de estado está à solta:
Mas nesse exemplo didático está comportada em uma função apenas. Claro que cada método recebe a própria máquina de estado para ter a chance de alterá-la, ou guardá-la para uso futuro. Ela é recebida como parâmetro assim como o evento. E o evento, por ser uma struct também, pode conter outros dados relevantes para a transição.
</description>
</item>

     
        <item>
  <title>Lista Ligada; tá Ligado?</title>
  <link>http://www.caloni.com.br/lista-ligada/</link>
  <pubDate>2018-04-24</pubDate>
  
  <guid>http://www.caloni.com.br/lista-ligada/</guid>
  <description>Uma lista ligada é uma lista de alguma coisa onde os elementos se ligam um no outro, ou seja, um elemento tem a referência do próximo. O tipo dos elementos de uma lista ligada pode ser inteiros, strings ou estruturas inteiras. Independente do que for, você vai precisar de uma estrutura. Sabe por quê? Porque existe além dos dados em si mais uma informação que você precisará guardar em cada elemento de sua lista: o próximo elemento. E é daí que surge a ligação da lista ligada.
struct Node{int number;struct Node* next;}; Sua estrutura pode ser simples e direta. Digamos uma lista ligada de números vai ter o número que esse elemento armazena e o endereço para o próximo elemento. Em C guardamos o endereço de uma variável usando um ponteiro para o mesmo tipo de elemento (no caso um struct Node).
O elemento mais importante de sua lista ligada é o primeiro elemento, pois sem ele você não consegue mais voltar ao início. Isso pode ser uma variável especial que não é usada para nada exceto indicar qual o primeiro elemento da sua lista. Essa variável não pode mudar, pois precisamos sempre ter uma referência para o início da lista, a não ser que o primeiro elemento seja removido (veremos adiante). Ele pode ser simplesmente um ponteiro para o &amp;quot;próximo&amp;quot; elemento,que no caso o primeiro elemento.
struct Node* head = NULL;
Este ponteiro começa em NULL porque a lista está vazia. Mas assim que inserirmos um item ele deixará de ser nulo.
struct Node* node = (struct Node*) malloc(sizeof(struct Node));node-&amp;gt;number = 10;node-&amp;gt;next = NULL;head = node; Pronto, agora a lista não está mais vazia e a cabeça da lista aponta para o primeiro elemento. Note que você precisa sempre inicializar o membro next com NULL, uma vez que ele é o último elemento da lista e não possui próximo.
Para inserir um novo elemento você pode inseri-lo no começo, no fim ou no meio de sua lista. No começo é o mais fácil, pois já temos o endereço do primeiro elemento.
struct Node* node = (struct Node*) malloc(sizeof(struct Node));node-&amp;gt;number = 10;node-&amp;gt;next = next;head = node; Para inserir um novo elemento no final da lista você terá que percorrê-la até achar o próximo elemento cujo membro next é igual a NULL, o que quer dizer que não há mais próximo. Nesse caso é importante saber se a lista está vazia. Se estiver basta atualizar a cabeça da lista e está pronto (como já visto).
struct Node* lnode = head;if( ! lnode ){head = node;}else{while( lnode-&amp;gt;next )lnode = lnode-&amp;gt;next;lnode-&amp;gt;next = node;} Se formos sempre inserir um novo elemento no final também é interessante termos um ponteiro para o último elemento (o tail), que também pode ser um ponteiro e começa com NULL. Quando for inserido o primeiro elemento ele também será o último, então devem ser atualizados os ponteiros head e tail com o mesmo valor.
struct Node* tail = NULL; É preciso prestar atenção quando temos muitas variáveis com o estado de sua lista sobrando no código. Cada atualização na lista envolve atualizar todos os endereços envolvidos. Preste atenção sempre na hora que estiver escrevendo e depurando seu código ou se arrependerá por horas a fio em um fim-de-semana perdido.
Acho que remover elementos da lista ligada é a parte mais complicada, pois temos que atualizar o elemento anterior, se houver, para que o próximo dele seja o próximo do próximo.
void del(struct Node* node){struct Node* pnode = NULL;struct Node* cnode = head;while( cnode ){if( cnode == element )break;pnode = cnode;cnode = cnode-&amp;gt;next;}if( cnode == element ){if( pnode ){pnode-&amp;gt;next = cnode-&amp;gt;next;}else{head = cnode-&amp;gt;next;}}} Para simplificar programação, depuração e análise de problemas a lista duplamente ligada, apesar de ser uma estrutura mais complexa, acaba nos dando mais controle sobre os elementos de uma lista. Mas este é assunto para próximo post.
</description>
</item>

     
        <item>
  <title>Projeto Aluno</title>
  <link>http://www.caloni.com.br/projetoaluno/</link>
  <pubDate>2018-03-21</pubDate>
  
  <guid>http://www.caloni.com.br/projetoaluno/</guid>
  <description>Observar um estudante de computação (qualquer curso) lutando nos primeiros meses para conseguir fazer seus programas compilarem em C é um misto de emoções. É uma mistura entre risos, risadas e gargalhadas. Há vários motivos para isso, mas o principal, o que vem à minha mente sempre que isso acontece, é a eterna questão: por que a pessoa encontra fórum de programação para perguntar sobre variável mas não consegue ler duas páginas de um livro?
Essa questão está intrinsicamente ligada ao fracasso completo do sistema de ensino (qualquer nível), que no caso de programadores, se proliferou em diversas faculdades caça-níqueis porque &amp;quot;este é o mercado onde se ganha bem&amp;quot;. Ninguém questiona por que se ganha bem neste mercado. É só fazer uma faculdade e o dinheiro começa a fluir. Negócio certo.
Mas quando a primeira variável começa a dar problema, o desespero bate na bunda. &amp;quot;Por que esse programa não está funcionando?&amp;quot;, &amp;quot;Eu só queria resolver isso e voltar pra internet&amp;quot;, &amp;quot;Que droga, chegou a data limite e não sei de quem posso copiar&amp;quot;, &amp;quot;Por que esse exemplo que peguei sei-lá-de-onde está dando esse erro que nunca vi na vida?&amp;quot;.
&amp;quot;O que é UB? Universidade do Brasil?&amp;quot;, &amp;quot;Tá ficando mais complicado ainda; vou pesquisar pra ver se acho o email desse tal de Goku.&amp;quot;, &amp;quot;Já sei, vou mudar de IDE! Isso, sim, vai resolver meu problema.&amp;quot;
&amp;quot;Ah, não. Textão ninguém aguenta!&amp;quot;, &amp;quot;TL;DR&amp;quot;.
</description>
</item>

     
        <item>
  <title>Contra o &#39;Array de 100 bytes é suficiente&#39;</title>
  <link>http://www.caloni.com.br/contra-o-array-de-100-bytes-eh-suficiente/</link>
  <pubDate>2018-03-11</pubDate>
  
  <guid>http://www.caloni.com.br/contra-o-array-de-100-bytes-eh-suficiente/</guid>
  <description>Desde o C&#43;&#43; moderno (pós-03) o uso de arrays de tamanho fixo estão se tornando depreciados. E por um bom motivo: você nunca sabe realmente qual o tamanho que você precisa para um array de bytes até você saber. Daí a próxima grande questão é: &amp;quot;como gerenciar essa memória dinâmica de forma efetiva?&amp;quot;. E a resposta moderna sempre é: &amp;quot;não faça isso você mesmo&amp;quot;. Eis o porquê:
Quando lidamos com funções legadas elas se misturam de tal maneira com código novo que a merda da alocação/desalocação dinâmica manual vai se espalhando também. A não ser que a gente comece a usar o novo modelo RAII e deixe a memória ser gerenciada automaticamente:
Note que estamos obtendo o endereço do primeiro elemento do nosso vector STL porque, desde o padrão C&#43;&#43;0x03, vetores são garantidos que serão contínuos. Essa garantia de leiaute de memória pode facilitar muitos usos de vector que estavam dependentes da implementação. O exemplo acima é apenas o mais simples deles, mas imagine que qualquer tipo de memória contígua cujo tamanho é desconhecido em tempo de compilação pode ser deixado seu gerenciamento para a STL cuidar.
Ah, e a partir do C&#43;&#43;11 podemos usar vector::data() para obter os dados sem deferenciar o primeiro elemento. Particularmente acho mais expressiva a sintaxe dos arrays, mas fica a gosto do freguês.
</description>
</item>

     
        <item>
  <title>Variáveis static local Nunca São Inicializadas Se Você Não Chama Sua Função</title>
  <link>http://www.caloni.com.br/variaveis-static-local-nunca-sao-inicializadas-se-voce-nao-chama-sua-funcao/</link>
  <pubDate>2018-02-20</pubDate>
  
  <guid>http://www.caloni.com.br/variaveis-static-local-nunca-sao-inicializadas-se-voce-nao-chama-sua-funcao/</guid>
  <description>Uma dúvida muito comum dos programadores iniciantes em C/C&#43;&#43; diz respeito às variáveis static que são declaradas dentro de um escopo, como uma função. Sabemos que se ela fosse declarada global, fora de qualquer escopo, ela seria inicializada antes do main ser chamado, como diz este trecho de alguém que pesquisou a respeito:
 &amp;quot;C&#43;&#43; Primer says. Each local static variable is initialized before the first time execution passes through the object&#39;s definition. Local statics are not destroyed when a function ends; they are destroyed when program terminates.&amp;quot; - Someone that google it for but did not get it
 Mas no caso de variáveis static declaradas dentro de uma função isso não acontece, e ela pode ser inicializada a qualquer momento. Basta alguém chamar a função onde ela foi definida.
Note que mesmo trocando static int para static const int a mesma coisa acontece. Apenas conseguimos forçar a inicialização antes do main quando há alguma variável global (static ou não) que chame a função.
O problema disso é que é possível que duas threads chamem func() &amp;quot;ao mesmo tempo&amp;quot;, gerando uma dupla inicialização caso a implementação da libc não seja thread-safe. E a menos que o padrão especifique que essa inicialização deva ser thread safe, melhor fazer as coisas direito.
Mas, a título de curiosidade, é bom saber que o Visual Studio 2017 essa parte da libc já possui um mecanismo de proteção, como o sugestivo nome tlsindex já indica:
</description>
</item>

     
        <item>
  <title>Como Parsear Argc Argv para um map STL</title>
  <link>http://www.caloni.com.br/como-parsear-argc-argv-para-um-map-stl/</link>
  <pubDate>2018-01-26</pubDate>
  
  <guid>http://www.caloni.com.br/como-parsear-argc-argv-para-um-map-stl/</guid>
  <description>Os clássicos argv/argc são úteis quando os parâmetros de um programa são conhecidos e geralmente obrigatórios (até a ordem pode ser obrigatória). Isso funciona muito bem para C. Porém, há a possibilidade de STLzar esses argumentos de forma simples, usando a lógica UNIX de fazer as coisas e transformando tudo em um map de string para string. E tudo isso cabe em uma função pequena que você pode copiar e levar com você em seu cinto de utilidades:
Com a função ParseCommandLine disponível assim que você adicionar este header (eu chamo de args.h) basta no início do seu main chamá-lo passando o argv e o argc recebidos:
O resultado é que a variável args irá conter um mapa entre parâmetros e valores. Se seu programa for chamado com, por exemplo, a seguinte linha de comando:
A variável args irá conter três elementos: &amp;quot;--name&amp;quot;, &amp;quot;--surname&amp;quot; e &amp;quot;--enable-log&amp;quot;. Nos dois primeiros ele irá entregar os valores respectivos &amp;quot;Agatha&amp;quot; e &amp;quot;Christie&amp;quot; se indexado (args[&amp;quot;--name&amp;quot;], por exemplo). No terceiro elemento o valor é uma string vazia. Apenas a existência dele é o flag. Costumo usar isso para conseguir depurar por parâmetro:
De maneira geral argv/argc já estão divididos quando o programa começa. O que o ParseCommandLine faz é apenas entregar os parâmetros formatados da maneira usual para tratarmos rapidamente as opções passadas dinamicamente para o programa.
</description>
</item>

     
        <item>
  <title>Como Achar Erros no Printf via Dump</title>
  <link>http://www.caloni.com.br/como-achar-erros-no-printf-via-dump/</link>
  <pubDate>2018-01-25</pubDate>
  
  <guid>http://www.caloni.com.br/como-achar-erros-no-printf-via-dump/</guid>
  <description>Às vezes, e apenas às vezes, é útil ter um dump do processo que acabou de capotar e ter um singelo backup do pdb (arquivo de símbolos) dos binários envolvidos nessa tragédia. Com alguns cliques pontuais e uma análise simples da stack, da variável e do código envolvido é possível chegar em um veredito sem muitas controversas se foi isso mesmo que gerou o crash. No caso peguei hoje um caso assim.
Abrir um dump (dmp) pode ser feito pelo Visual Studio, Windbg ou sua ferramenta de análise favorita. Mais importante que isso é carregar seus símbolos adequadamente. Com o dump e símbolos abertos é possível analisar a stack de chamadas, o que nos revela que há um problema em uma função de Log. Como se trata de uma versão release não há muita informação da pilha, que pode fazer parte de uma stack modificada (otimização de código). Portanto, tudo que vier é lucro. Como variáveis.
Demos sorte e é possível ver o que tem na variável de format, a mais importante de uma função de log estilo printf, pois geralmente é ela a responsável pelas dores de cabeça infernais.
Através dessa string é possível buscar no código usando grep, vim ou até o Visual Studio. Com isso reduzimos nosso escopo de busca ao mínimo.
E voilà! Temos uma chamada de log que teoricamente teria que passar uma string C, mas não passa nada. Isso quer dizer que a função de printf irá procurar na pilha pelo endereço de uma string, mas irá encontrar um endereço aleatório. Lendo esse endereço, que tem ótimas chances de ser inválido, ele irá capotar. Para dores de cabeças mais intensas, ele irá capotar aleatoriamente (ou na máquina do chefe, o mais provável).
E assim terminamos mais uma sessão simples e rápida de debug. Quer dizer, simples e rápida para quem tem 20 anos de experiência nessas coisas. Os estagiários devem ter ficado de cabelos em pé.
</description>
</item>

     
        <item>
  <title>Como Apagar o Prompt do seu Programa Windows</title>
  <link>http://www.caloni.com.br/como-apagar-o-prompt-do-seu-programa-windows/</link>
  <pubDate>2018-01-23</pubDate>
  
  <guid>http://www.caloni.com.br/como-apagar-o-prompt-do-seu-programa-windows/</guid>
  <description>Geralmente se cria um projeto console/prompt quando há a necessidade de interfacear com o usuário com o uso da tela preta, saída padrão, etc. E no caso do Windows também há a possibilidade de criar um programa Win32 onde não há prompt, pois a função do programa ou é ser invisível ou criar, sabe como é, janelas. Mas nenhum dos dois possibilita ambos ao mesmo tempo. Este snippet permite que você faça isso.
Para isso funcionar você criar um projeto console no Visual Studo. Essa opção está no Linker, System, Heap Reserve Size.
</description>
</item>

     
        <item>
  <title>Cmd e o encoding fake</title>
  <link>http://www.caloni.com.br/cmd-e-o-encoding-fake/</link>
  <pubDate>2017-12-26</pubDate>
  
  <guid>http://www.caloni.com.br/cmd-e-o-encoding-fake/</guid>
  <description>Qualquer um que já tenha mexido no prompt de comandos do Windows sabe que ele permite você escolher qual code page utilizar para enviar e receber comandos. O Windows é todo em UTF-16, mas as saídas podem vir de qualquer programa com qualquer encoding. A missão do cmd.exe é usar o encoding escolhido pelo usuário para exibir os caracteres na tela. Vamos supor que nós criemos uma pasta com acentos no nome (pelo Explorer para não ter erro):
Agora através de um cmd.exe podemos observar como esse nome acentuado aparece:
Note como o &amp;quot;a&amp;quot; acentuado com til aparece perfeitamente. Também note que o codepage utilizado é o 437.
Até aí tudo bem, certo?
Não! Não! Não!
O codepage 437 não possui ã. Nem õ.
Isso, meus amigos, é chamado tecnicamente na área de &amp;quot;muito louco&amp;quot;.
Curioso a respeito disso, resolvi observar a saída padrão do cmd.exe, para ver o que diabos vem como resultado. Para isso desenvolvi um simples output redirector tabajara:
Simples, bonito e prático. Quando executamos Redirector.exe ele executa um cmd.exe, com a diferença que a saída dele vai parar no arquivo cmd.log, que podemos observar com um BareTail da vida.
Opa, opa, opa!
O til sumiu!
Se formos analisar os bytes que vieram de saída, vamos constatar que o byte referente ao ã foi enviado para a saída padrão como o byte 0x61, ou 97 em decimal. No codepage 437 (e em qualquer derivado da tabela ASCII, na verdade) o byte 97 é representado como &amp;quot;a&amp;quot;, simplesmente, sem til.
Isso quer dizer que ao receber um &amp;quot;ã&amp;quot; o cmd.exe o reinterpreta como &amp;quot;a&amp;quot;, mesmo estando sob o encoding 437. Esse é o resultado de um prompt user friendly que quer seu amigo.
Se analisarmos a memória do cmd.exe veremos que ele armazena as coisas em UTF-16, como qualquer programa Windows nativo unicode.
E com isso constatamos que não necessariamente no Windows, What You See Is What You Get. Ou, em termos mais filosóficos, What You See Is Not What I Get.
</description>
</item>

     
        <item>
  <title>Se você não precisa de classe você não precisa de classe</title>
  <link>http://www.caloni.com.br/se-voce-nao-precisa-de-classe-voce-nao-precisa-de-classe/</link>
  <pubDate>2017-12-17</pubDate>
  
  <guid>http://www.caloni.com.br/se-voce-nao-precisa-de-classe-voce-nao-precisa-de-classe/</guid>
  <description>Nos últimos dias me deparei com o seguinte (pseudo-)código:
Dentro de MyClass a seguinte estrutura:
Então eu me pergunto: qual a função da classe em um código desses?
Bjarne Stroustrup desde o começo, em seu livro The C&#43;&#43; Programming Language, sugere que C&#43;&#43; não é uma linguagem unicamente orientada a objetos, mas multi-paradigmas. Hoje, em 2017, ela é uma linguagem genérica e até funcional. Na época poderia ser usada como orientada a objetos, mas também como estruturada e imperativa comum. O goto funciona até hoje.
Então o erro no código acima é supor mecanicamente que como é C&#43;&#43; precisa ter classe. Não. O código não precisa ter uma classe. No entanto, seu código precisa ter classe. Entendeu?
Ter classe é para poucos. É para programadores que se preocupam com a relação entre funcionalidade, estilo, arquitetura e todos os inúmeros elementos que tornam um código perfeito. Para ser perfeito, um código precisa levar em conta tantos elementos que apenas um programador acordado, obsessivo, fora da matrix, conseguiria observar o que deve ser feito.
Uma pequena sugestão:
É a melhor solução? Não. Só uma ideia para tornar o código simples de entender, enxuto para manter, com apenas o modelito básico. Tem até um map para evitar encher de ifs. Mas não precisaria se você tem meia-dúzia de funções.
E note que eu disse funções, não classe. E é possível ter classe sem classes.
</description>
</item>

     
        <item>
  <title>C&#43;&#43; Moderno Arranca os Cabelos por Você (std::move e classes simples).</title>
  <link>http://www.caloni.com.br/cpp-arranca-os-cabelos-por-voce/</link>
  <pubDate>2017-09-26</pubDate>
  
  <guid>http://www.caloni.com.br/cpp-arranca-os-cabelos-por-voce/</guid>
  <description>Um dos últimos posts no grupo CCPPBR do Thiago Adams chama mais uma vez a atenção para a complexidade infinita que linguagens como C&#43;&#43; estão preferindo tomar. Esta é a geração que irá sofrer as dores de compatibilidade com o passado mais que todas as outras que virão.
Isso porque mudanças pontuais que vão sendo aplicadas na linguagem e biblioteca, como move semantics, não cabe mais em exemplos de livrinhos de C&#43;&#43; para iniciantes da década de 90:
Neste singelo exemplo, que está errado by design, a classe X não se preocupa em proteger-se de cópias simples. Mas o programador também não se protege da ignorância e usa std::move como se ele magicamente movesse referências const, o que é absurdo.
A questão, porém, não é sobre qual é o problema no código, mas os aspectos de design de C&#43;&#43; que podem levar futuros programadores a se depararem com o mesmo problema em versões multicamadas de complexidade. Este é um exemplo óbvio, mas até quando será?
Esta crítica pode levar (pelo menos) para dois diferentes caminhos:
 O funcionamento do std::move não é intuitivo e pode levar a erros semânticos (&amp;quot;se usar o move estou movendo referências&amp;quot;); programador não conhece o funcionamento por completo. Em C&#43;&#43; o esforço de manter uma classe é muito maior hoje do que em 98/03 (&amp;quot;tomar cuidado com reference, const reference, rvalue reference...&amp;quot;); isso concordo; as mudanças são bem-intencionadas, mas a linguagem é velha com alguns esqueletos que podem começar a balançar.  C&#43;&#43;, assim como o Brasil, desde o começo nunca foi para amadores. Hoje em dia ele é impossível. Ouço galera falar que está ficando lindo, mas, francamente, está virando é um ninho de cobras. Mantenedores de bibliotecas, se não estão já arrancando os cabelos, deveriam começar.
Mas talvez com C&#43;&#43; 17&#43; os cabelos passem a cair sozinho...
</description>
</item>

     
        <item>
  <title>Migrando Imagens Para Imgur</title>
  <link>http://www.caloni.com.br/migrando-imagens-para-imgur/</link>
  <pubDate>2017-07-28</pubDate>
  
  <guid>http://www.caloni.com.br/migrando-imagens-para-imgur/</guid>
  <description>Depois de migrar meus blogues para o Hugo decidi deixar o repositório mais magro migrando as imagens para um serviço de imagens. O imgur me pareceu uma solução simples com uma interface rápida (e uma API Python). Para realizar essa tarefa você vai precisar das ferramentas de sempre: grep, sed, python, vim. E lá vamos nós.
Meu primeiro passo foi realmente limpar a pasta de imagens, eliminando as que não estavam sendo usadas. A pasta de imagens ficou se acumulando por anos, e muitas imagens foram sendo carregadas através dos Wordpress da vida e plugins que deram resize nas imagens, gerando várias cópias no processo. Tudo inútil e dispendioso.
O principal problema de subir tudo para o imgur é que os nomes dos arquivos irão mudar e perder a referências usadas no texto. Para conseguir renomear os arquivos dentro dos artigos é necessário conectar no serviço do imgur e através dele obter o nome original do arquivo, disponível na propriedade name:
Executando este script será possível gerar um log no formato nome-original-do-arquivo =&amp;gt; id-da-imagem-usado-pelo-imgur. O ID deles também é usado para link direto da imagem, de onde virá o comando sed que vai substituir nos artigos os nomes originais pelo link do imgur:
Lembrar de apagar o all.md. Ele só foi usado para gerar a saída mais simples do grep.
</description>
</item>

     
        <item>
  <title>Forma Mais Simples De Depurar Processos Antes Do Logon</title>
  <link>http://www.caloni.com.br/forma-mais-simples-de-depurar-processos-antes-do-logon/</link>
  <pubDate>2017-07-27</pubDate>
  
  <guid>http://www.caloni.com.br/forma-mais-simples-de-depurar-processos-antes-do-logon/</guid>
  <description>No post anterior sobre debug eu havia me focado mais na depuração de processos remotos no Visual Studio 2003 de maneira convencional. Aqui eu vou abordar o assunto de uma maneira menos convencional: usando o Visual Studio 2017 mais novo e depurando uma DLL (C&#43;&#43;) que é carregada por um serviço antes do logon no Windows 7.
Em primeiro lugar, como vimos anteriormente, a ponta server do depurador é um programa que você executa com alguns parâmetros e ele fica escutando em uma porta. Simples assim. Para que isso funcione antes do logon é necessário instalar esse programa como um serviço. Tanto no caso de depuradores mais antigos (msvCmon) quando nos mais novos (msvSmon) há sempre um executável com alguns parâmetros passados via linha de comando.
O depurador do Visual Studio mais novo fica em sua pasta de instalação Program Files, etc, Microsoft Visual Studio, 2017, Enterprise, Common7, IDE, Remote Debugger ou derivados. Dentro dessa pasta há subpastas para cada arquitetura, x64 ou x86. É essa pasta que deve ser copiada para a máquina que será depurada. Se você estiver depurando um processo 32 bits, use o x86; do contrário, vá de x64.
No caso do msvsmon, se executado com /? (padrão entre programas Windows) ele abre um pequeno help com a ajuda necessária para executar os parâmetros corretos. No caso o comando maroto é o seguinte:
E para transformar em um serviço podemos usar o NSSM, já visto em outros artigos.
Isso cria um serviço de start automático que irá iniciar o debugger na ponta server quietinho, sem janelas, só escutando e esperando o Visual Studio atachar.
Para este exemplo vamos usar um programa console que será convertido, assim como o msvsmon, em serviço, e uma DLL que ele carrega, chamando dois métodos; um de start, outro de stop. Nosso objetivo aqui é começar a depurar a DLL logo em seu início, na chamada do start.
As funções de start e stop não fazem nada, apenas imprimem um passou-por-aqui:
Todo o projeto está no GitHub para baixar e compilar você mesmo.
Depois de copiar Service.exe e DLL.dll para a máquina-alvo (e não se esquecer de instalar as dependências) instalar da mesma forma com que foi instalado o msvsmon:
Agora ache o IP da máquina-alvo e vá em Debug, Attach to Process (Ctrl&#43;Alt&#43;P) no Visual Studio, modo remoto e digite o IP.
Lembre-se de iniciar o serviço.
Após esse teste podemos modificar a DLL para aguardar por um depurador:
Depois que houver o attach você irá continuar a execução. Portanto, coloque um breakpoint logo depois. E depois que isso funcionar já é possível iniciar sua depuração antes da tela de login. Os serviços executarão, e sua DLL estará aguardando um debugger ser atachado. Se houver necessidade é possível deixar esse modo de espera configurável, por timeout, etc.
</description>
</item>

     
        <item>
  <title>CppTests</title>
  <link>http://www.caloni.com.br/cpptests/</link>
  <pubDate>2017-07-25</pubDate>
  
  <guid>http://www.caloni.com.br/cpptests/</guid>
  <description>Iniciei um novo projeto no GitHub que tem por objetivo ser minha prancheta de trabalhos para minha palestra no próximo encontro ccpp. Há uma infinitude de coisinhas novas na linguagem C&#43;&#43;, fora as adições à biblioteca STL, mas que devem passar despercebidas da maioria dos programadores, que está mais é querendo terminar seus próprio projetos. Enquanto alguns conceitos, sintaxes e métodos não se solidificam, vale a pena dar uma espiada no futuro?
Depende.
Dei uma olhada nas últimas modificações adicionadas no Visual Studio 2017 (versão 15.3 preview 1, mas o último lançado é o preview 5), e há muitos elementos IMHO supérfluos, mas que tendem a ser integrados aos poucos (I hope).
A lista que achei interessante (com seu projeto):
 binary_literals_test. Perfumaria muito bem-vinda de uma linguagem feita para trabalhar também baixo nível. constexpr_test. Um teste que alguém fez na nossa lista ccpp do Telegram e que possui uma particularidade interessante (mais abaixo). for_range_generic_test. Ainda em teste, mas me parece a forma definitiva de iterar entre elementos em C&#43;&#43;; completamente genérico. generic_lambdas_test. E por falar em genérico, este lambda tem muito a ver com programação funcional. has_include_test. Uma maneira elegante (apesar do nome feio) de ir migrando projetos/libs aos poucos. initializer_list. Só demonstrando o que já é velho (mas que ainda não comentei no blogue). nodiscard_test. Essa é uma das features mais curiosas para escrita de código robusta. sfinae_test. O SFINAE é um dos pilares do C&#43;&#43;, e ele vem melhorando cada vez mais. static_assert_test. O que estava faltando que no Boost é macaco velho. user_defined_literals_test. Mais uma perfumaria; essa é bonitinha; para uso acadêmico. variable_templates_test. Mais algo já velho, que demonstro aqui com minha superlib de log.  A otimização no if através do uso da palavra-chave constexpr possibilita a criação de diferentes instâncias da chamada que não contém o if, mas um dos dois branches dependendo do tipo ser integral ou não.
Para que a compilação dessa opção funcione no Visual Studio 2017 15.3 é necessário inserir o parâmetro /std:c&#43;&#43;latest nas opções do projeto em C/C&#43;&#43;, Command Line, Additional Options.
Todos (ou a maioria) deles ainda está em teste. Acabei de baixar o preview 5, conforma um dos membros da ML dos MVPs C&#43;&#43; me informou que saiu quentinha do forno. Em breve novidades.
</description>
</item>

     
        <item>
  <title>Debugger remoto do Visual Studio</title>
  <link>http://www.caloni.com.br/debugger-remoto-do-visual-studio/</link>
  <pubDate>2017-06-13</pubDate>
  
  <guid>http://www.caloni.com.br/debugger-remoto-do-visual-studio/</guid>
  <description>Então você está quebrando a cabeça para descobrir por que seu código não faz o que deveria fazer? Então você é desses que acha que é melhor ficar imaginando com um bloquinho de papel na mão do que colocar logo a mão na massa e ver exatamente o código passando pelo processador? Talvez você mude de ideia ao ver como é ridiculamente fácil depurar código em uma máquina remota, seja uma VM ou a máquina do cliente. Neste post vou ensinar a maneira mais antiga e a mais nova que conheço de usar o depurador do Visual Studio. Vamos usar a versão 2003 e a versão 2017 RC.
Há muito tempo atrás eu falei sobre o depurador remoto do C&#43;&#43; Builder, na época a ferramenta que eu mais utilizava para programar. Hoje disparado é o Visual Studio, já faz mais de uma década. Desde o VS2003 tem sido muito simples depurar remotamente. Tão simples que eu realmente esqueci que talvez algumas pessoas não saibam o quanto é útil essa ferramenta no dia-a-dia.
É possível depurar qualquer executável, tendo seu código-fonte ou não. A diferença é que sem código você terá que olhar o assembly e se for compilado como release você pode olhar o código mas ele não fará muito sentido em alguns momentos (onde estão minhas variáveis locais?). O melhor dos mundos, é claro, é depurar um executável que você tenha os símbolos, o código e esteja compilado em debug. Daí o código irá falar com você da maneira mais fácil.
É simples de achar essa opção no projeto em qualquer Visual Studio. Vá nas opções do projeto, Linker e irá encontrar em algum lugar sobre a geração do PDB. Não tenha medo de explorar as opções do projeto. Elas refletem como o XML do projeto muda (sim, é um XML). Se estiver querendo saber exatamente como ele muda, use um controle de fonte e vá experimentando.
Para depurar pelo Visual Studio 2003 há um programa chamado msvcmon.exe que deve ser copiado e executado na máquina-alvo. Ele é um executável que pode ser copiado para qualquer lugar. Junto dele devem estar duas DLLs: a natdbgdm.dll e a natdbgtlnet.dll. Se você tiver o VS2003 instalado deve achar esses arquivos em algum lugar, ou no pior dos casos no CD de instalação. Por via das dúvidas sempre há um link amigo na internet para ajudar alguém a achar o que precisa.
Copiados esses arquivos na máquina-alvo é necessário copiar também o executável. Afinal de contas, ele irá executar remotamente! O arquivo PDB, no entanto, você só precisa guardar com você. Lembre-se que toda recompilação em Debug altera de maneira significativa o PDB, então não recompile seu projeto enquanto estiver depurando. Se for fazê-lo, troque o executável na máquina-alvo.
A primeira execução de toda ferramenta, seu help, irá nos mostrar o seguinte no msvcmon:
Minhas opções favoritas são -tcpip -anyuser -timeout -1, o que libera o acesso a qualquer usuário direto por TCP/IP e o timeout da execução é infinito. All access no limits =)
Agora no Visual Studio 2003 vá em Debug, Processes (ou Ctrl&#43;Alt&#43;P para os íntimos) e escolha a opção de Transport como TCP/IP, digite o IP... explore sua ferramenta, poxa!
Depois de conectar remotamente por essa janela o console do msvcmon irá mostrar que usuário se logou:
Para configurar o início da depuração remota pelo próprio projeto você terá que ir nas opções de debug dele e mexer em Remote Settings. Para começar os problemas é sempre bom lembrar que projetos compilados como debug precisam das DLLs de runtime do Visual Studio que sejam debug. Mas você já sabe disso.
Depois que tudo isso estiver OK é só iniciar seus processos remotamente em modo de depuração ou atachar pela primeira janela que vimos.
Agora você deve estar se perguntando: &amp;quot;mas esse VS é muito velho! e os mais novos?&amp;quot;
Bom, desde o VS 2010 e até o VS2017 RC essa ferramenta está disponível na pasta de instalação, mudou um pouco de cara e você pode encontrar procurando por &amp;quot;remote&amp;quot;. No Caso do VS mais novo que tenho em mãos aqui, o 2017 RC, existe já uma pasta pronta para copiar e colar na máquina-alvo, em Common7, IDE, Remote Debugger. Há duas pastas disponíveis: x86 e x64. Dependendo do tipo de compilação que deseja realizar (e de qual o seu executável) copie uma das duas, rode o executável da pasta e apenas configure.
</description>
</item>

     
        <item>
  <title>Como acessar submódulos no git inacessíveis?</title>
  <link>http://www.caloni.com.br/submodules-locais-no-git/</link>
  <pubDate>2017-05-28</pubDate>
  
  <guid>http://www.caloni.com.br/submodules-locais-no-git/</guid>
  <description>Quando projetos remotos usam submodules é possível que algum deles seja acessível apenas através de chaves criptográficas. Isso exige que os sub-projetos necessários para fazer funcionar seu projeto podem estar fora do seu alcance e acesso, o que irá gerar durante seus comandos pull recursivos erros de ssh (publickey access).
A solução é ler a documentação e descobrir que é possível editar o arquivo .git/config para mudar a url de um submódulo inacessível pela forma do .gitmodules. Eis um exemplo de arquivo config dentro do .git:
Você pode localmente alterar o endereço ssh deste submodule para algo que todos têm acesso ou só você tem acesso, como uma pasta local ou o endereço https:
Note que isso não irá interferir em nada no repositório localizado remotamente do projeto. Dessa forma diferentes membros da equipe podem usar diferentes formas de acessar um submódulo.
</description>
</item>

     
        <item>
  <title>SystemRescueCD: um CD cheio de ferramentas Linux para desenvolvedores e suporte</title>
  <link>http://www.caloni.com.br/systemrescuecd-um-cd-cheio-de-ferramentas/</link>
  <pubDate>2017-05-28</pubDate>
  
  <guid>http://www.caloni.com.br/systemrescuecd-um-cd-cheio-de-ferramentas/</guid>
  <description>Há diversas distros Linux capazes de bootar via CD e com uma penca de ferramentas. Conheci há alguns anos uma delas: a SystemRescueCd: um disco de recuperação de HDs com diversas ferramentas embutidas. Dentro dele pode ser inserido outras ferramentas que achar interessante, e o mais importante, desenvolver através do próprio CD suas ferramentas.
A modificação do CD pode ser feita bootando com ele mesmo, seguinto o tutorial da própria SystemRescueCd. No entanto, para facilitar o uso, é possível utilizá-lo em um ambiente virtualizado (criar uma VMWare que boote pelo CD, por exemplo, e depois instalar no HD virtual).
Outra opção interessante é montar outras partições partindo do próprio CD. Ao bootar com o CD da SystemRescue, após ter acesso ao terminal pela primeira vez, detecte e formate o HD Linux usando a ferramenta fdisk. Dentro da ferramenta use as opções padrão e crie uma particão Linux. Ao final, escreva com &#39;w&#39;, formate a partição (ex: mkfs.ext4) e a partição já deverá estar disponível no próximo boot.
Para formatar uma partição Windows é possível realizar o mesmo procedimento, mas trocar o tipo de partição para Windows FAT32. Com isso a partição estará disponível para ser montada tanto na máquina virtual quanto na real.
Desligue a VM. A partir do Windows, monte o HD Windows e formate a partição criada. Ou, se a partição ainda não foi criada é só criar pelo Gerenciador de Discos do Windows.
Obs.: Apenas a VM ou a máquina real podem utilizar o HD de uma vez. Portanto, para copiar arquivos para o HD virtualizado é necessário desligar a VM antes.
Seguindo o tutorial do SystemRescueCD (&amp;quot;Step-01: Mount the working partition&amp;quot;), vamos montar a partição Linux na pasta /mnt/custom.
Em seguida extraia os arquivos atuais do CD para a pasta custom (essa operação pode demorar alguns minutos):
Após a conclusão dessa operação, os arquivos customizados poderão ser encontrados em /mnt/custom/customcd/files/bin
Para copiar os arquivos novos, monte a partição Windows e copie de uma pasta para outra. Já existe uma pasta em mnt chamada windows que pode ser alvo da montagem. Abaixo os comandos necessários para atualizar um possível script:
Voilá! Agora que os arquivos já foram atualizados é hora de regerar um novo ISO do CD. Para isso, executar o seguinte script do RescueCD (&amp;quot;Step-10: Create the new ISO image&amp;quot;); esse comando pode demorar alguns minutos:
Após a conclusão do comando o novo ISO deverá estar no diretório /mnt/custom/customcd/isofile/ com a data/hora atual. Copie este arquivo para a partição Windows para ter acesso ao ISO na máquina real:
Desligue a máquina virtual e volte a montar o HD na máquina real. O ISO do novo CD estará disponível.
</description>
</item>

     
        <item>
  <title>Forma simples de baixar atualizações remotamente de um cliente para um servidor</title>
  <link>http://www.caloni.com.br/forma-simples-de-baixar-atualizacoes-remotamente-de-um-cliente-para-um-servidor/</link>
  <pubDate>2017-03-23</pubDate>
  
  <guid>http://www.caloni.com.br/forma-simples-de-baixar-atualizacoes-remotamente-de-um-cliente-para-um-servidor/</guid>
  <description>A forma mais simples e rápida para subir um servidor de arquivos é usar o file server embutido do python:
Para que não seja necessário instalar o Python no servidor é possível transformar essa chamada em um executável, com todas suas dependências embutidas:
Esse script pode ser compilado pela ferramenta py2exe, instalável pelo próprio Python. É necessário criar um arquivo setup.py na mesma pasta do script e através desse script gerar uma pasta dist com o script &amp;quot;compilado&amp;quot; e pronto para ser executado.
Pelo prompt de comando executar o seguinte comando que irá gerar a pasta dist:
Uma vez gerada a pasta, renomear para fileserver e copiar no servidor em qualquer lugar (ex: pasta-raiz). Executar de qualquer pasta que se deseja tornar acessível via browser ou qualquer cliente http:
Para testar basta acessar o endereço via browser.
Do lado cliente há ferramentas GNU como curl e wget para conseguir baixar rapidamente qualquer arquivo via HTTP. Para máquinas com Power Shell disponível há um comando que pode ser usado:
Porém, caso não seja possível usar o Power Shell o pacote básico do wget do GnuWin32, de 2MB, já consegue realizar o download.
E assim com poucas linhas de código já é possível iniciar um client/servidor via http que fornece arquivos de atualização. A própria versão do pacote e detalhes podem estar disponíveis na mesma pasta.
</description>
</item>

     
        <item>
  <title>qt5.natvis</title>
  <link>http://www.caloni.com.br/qt5-natvis/</link>
  <pubDate>2017-03-15</pubDate>
  
  <guid>http://www.caloni.com.br/qt5-natvis/</guid>
  <description>A estratégia que utilizei em meu último artigo sobre Qt para expandir o tipo QString no depurador não existe mais no VS2017 RC. O arquivo autoexp.dat foi extirpado e em seu lugar foi deixado os já ativos arquivos natvis, que podem ser usados de forma global ou por usuário.
Existe um arquivo pronto circulando pela net chamado qt5.natvis. Alguns funcionam, outros não. As strings estão funcionando no meu depois que eu adaptei este arquivo com as dicas do help do qt.
Se você é admin de sua máquina, basta copiar este arquivo em %programfiles(x86)%, Microsoft Visual Studio, 2017, Enterprise, Common7, Packages, Debugger, Visualizers. Se for um usuário mané, em %USERPROFILE%, Documents, Visual Studio 2017, Visualizers.
</description>
</item>

     
        <item>
  <title>Entrando na zona com Windows</title>
  <link>http://www.caloni.com.br/entrando-na-zona-com-windows/</link>
  <pubDate>2017-03-14</pubDate>
  
  <guid>http://www.caloni.com.br/entrando-na-zona-com-windows/</guid>
  <description>Update 2019-03-20: Adicionando programa para fazer tela cheia no Windows e retirados detalhes que não uso mais.
Um artigo anterior havia dado umas dicas de como transformar o Vim em uma ferramenta para toda obra, com isso limitando as distrações quando se está em um computador, e com isso facilitando a entrada e a permanência no estado de fluidez de produtividade que conhecemos como &amp;quot;flow&amp;quot;, ou estar na zona. Agora é a vez do Windows.
O Windows 10 já vem com atalhos pré-instalados assim que você loga nele. Tem browser, navegador de arquivos, notícias, e uma caralhada de coisas inúteis que ficam se mexendo na tela, chamando sua atenção, distraindo sobre o que é mais importante.
Mas é possível arrancar tudo isso e deixar na barra de tarefas pinado apenas as coisas realmente vitais para o uso do computador de trabalho, geralmente o terminal, o navegador (pesquisa, emails, etc) e o editor (não necessariamente o Vim).
O terminal do Windows, o Command Prompt, ou cmd para os íntimos, sofreu algumas mudanças ultimamente. Entre elas há a transparência, o que o tornou cool, e a tela cheia (atalho Alt&#43;Enter), o que o tornou ideal como ferramenta de navegação para programadores (melhor do que o explorer, que virou um penduricalho de atalhos inúteis também). Você pode ativá-lo já entrando na tela cheia e com o code page de sua preferência (o meu é 65001, que é o utf8) usando esse pequeno programa:
Os comandos do git são muito verbose. Duas letras já seriam suficiente (o Windbg manipula seu programa com apenas uma...). Para otimizar a digitação no git crie uns aliases em seu HOME.gitconfig:
Agora, através dos atalhos Win&#43;1, 2, 3... pode-se abrir e alternar entre os aplicativos principais do seu dia-a-dia, que devem ficar &amp;quot;pinados&amp;quot; na barra de tarefas. Os meus atualmente são três: terminal (1 cmd), editor (2 vim) e browser (3 chrome). Não é necessário colocar coisas como Visual Studio, já que minha navegação é feita rapidamente pelo terminal para o projeto que irei mexer. Com isso o foco fica restrito a apenas uma coisa: o que você tem que fazer hoje? =)
</description>
</item>

     
        <item>
  <title>Atalhos no terminal do Linux/Unix</title>
  <link>http://www.caloni.com.br/atalhos-no-terminal-do-linux-unix-cygwin/</link>
  <pubDate>2017-02-27</pubDate>
  
  <guid>http://www.caloni.com.br/atalhos-no-terminal-do-linux-unix-cygwin/</guid>
  <description>Há pouca coisa que você pode fazer para manipular a linha de comando que está digitando em um terminal do Windows. Isso faz sentido. O terminal da Microsoft é apenas um resquício do MS-DOS, que foi herdado pelas inúmeras versões do Windows para que desenvolvedores e suporte pudessem executar alguns comandos não disponíveis pelo clique de um mouse. Já no Unix a história é inversa. Durante tantas décadas sendo usado, o sistema Unix, hoje, em sua mais nova reencarnação, Linux, foi acumulando diferentes teclas de atalho para conseguirmos refazer, desfazer e fazer melhor a montagem dos comandos digitados na linha de comando. Um sistema bash padrão já deve ter implementado o mínimo que você precisa para sobreviver na linha de comando. Aparentemente esse é um conhecimento tão bem divulgado pela comunidade que ninguém se dá ao trabalho de escrever um artigo sobre isso. Eu fiz algumas pesquisas uns tempos atrás e cheguei na seguinte lista, que tem muito mais do que eu preciso, e que seria bom aprender, nem que fosse aos poucos.
 Ctrl &#43; r - navigate previous commands Ctrl &#43; a - go to the start of the command line Ctrl &#43; e - go to the end of the command line Ctrl &#43; k - delete from cursor to the end of the command line Ctrl &#43; u - delete from cursor to the start of the command line Ctrl &#43; w - delete from cursor to start of word (i.e. delete backwards one word) Ctrl &#43; y - paste word or text that was cut using one of the deletion shortcuts (such as the one above) after the cursor Ctrl &#43; xx - move between start of command line and current cursor position (and back again) Alt &#43; b - move backward one word (or go to start of word the cursor is currently on) Alt &#43; f - move forward one word (or go to end of word the cursor is currently on) Alt &#43; d - delete to end of word starting at cursor (whole word if cursor is at the beginning of word) Alt &#43; c - capitalize to end of word starting at cursor (whole word if cursor is at the beginning of word) Alt &#43; u - make uppercase from cursor to end of word Alt &#43; l - make lowercase from cursor to end of word Alt &#43; t - swap current word with previous Ctrl &#43; f - move forward one character Ctrl &#43; b - move backward one character Ctrl &#43; d - delete character under the cursor Ctrl &#43; h - delete character before the cursor Ctrl &#43; t - swap character under cursor with the previous one Ctrl &#43; l - clean the screen (history back) Ctrl &#43; z - put in background (fg restores it) Ctrl &#43; c - cancel current command Ctrl &#43; d - exit the current shell  </description>
</item>

     
        <item>
  <title>O velho problema do project out of date do Visual Studio</title>
  <link>http://www.caloni.com.br/o-velho-problema-do-project-out-of-date-do-visual-studio/</link>
  <pubDate>2017-02-20</pubDate>
  
  <guid>http://www.caloni.com.br/o-velho-problema-do-project-out-of-date-do-visual-studio/</guid>
  <description>Acho que todo mundo já passou por isso. Você compila todo o projeto bonitinho e no final, ao depurar, ele faz aquela velha pergunta: &amp;quot;o projeto está desatualizado: deseja compilar novamente?&amp;quot;. Mas como assim? Eu acabei de compilar, não faz nem cinco segundos. Está quentinho, saiu do forno agora.
Quando vem aquela fatídica mensagem do Visual Studio indicando que algo de errado não está certo: &amp;quot;This project is out of date. Would you like to build it?&amp;quot; (again?)
Às vezes o Visual Studio cria umas esquisitices que se perpetuam por todas as versões. Isso tem algum sentido. Funciona mais ou menos assim a lógica do &amp;quot;project out of date&amp;quot;: se existir algum arquivo cuja data/hora eu não consigo verificar eu considero que o projeto está desatualizado. Por que? Pode ser que esse arquivo tenha que ser gerado automaticamente. Pode ser que houve erro de acesso. Pode ser várias coisas, mas ainda assim faz sentido.
Exceto quando o arquivo realmente não existe.
E isso é bem comum de acontecer em um projeto com algum refactory. Você acabou movendo alguns arquivos compartilhados entre projetos, mas em algum desses projetos o arquivo ainda está sendo apontado para o path errado, onde ele não mais existe. No entanto, por se tratar de um arquivo não-necessário para a compilação (ex: um header) não há erros na compilação. Apenas nessa detecção do Visual Studio.
O problema é que não existe nenhuma dica do que está errado em condições normais de temperatura e pressão. Para conseguiu olhar mais detalhes temos que ir em Tools, Options e configurar mais saída para o build. Pelo menos como detailed. Isso fica em Options, Project and Solutions, Build and Run.
A partir daí teremos mais saída na janela de output do build. Logo no começo (talvez pela equipe do VS saber que isso é bem comum) há uma dica de quais arquivos exige o rebuild (você pode fazer isso apenas clicanco em build do projeto que sempre acusa como out of date):
Depois de detectado o arquivo faltante, é só removê-lo ou atualizar o path. Esse erro não deve mais acontecer e agora você só precisa compilar uma vez e sair depurando.
</description>
</item>

     
        <item>
  <title>Visualizando QString no Visual Studio</title>
  <link>http://www.caloni.com.br/visualizando-qstring-no-visual-studio/</link>
  <pubDate>2017-02-20</pubDate>
  
  <guid>http://www.caloni.com.br/visualizando-qstring-no-visual-studio/</guid>
  <description>O Qt não é um framework que pode apenas ser usado no QtCreator. Através de um projeto bem configurado pelo CMake, por exemplo, é possível ter um projeto que pode ser compilado e depurado tanto nas ferramentas do Qt quanto no Visual Studio. No entanto, na hora de depurar algumas coisas são difíceis de fazer. Por exemplo: como olhar o conteúdo de uma QString?
O Visual Studio utiliza um mecanismo que lembra os comandos bizarros que se usa no WinDbg, mexendo com registradores e tal. Através dessa combinação é possível dizer para o depurador como interpretar determinados tipos de objetos. Ele já vem obviamente pronto para std::string, CString (ATL) e deveria vir com QString, de tão famosa que é. Mas a versão do Visual Studio 2015 não vem. O jeito então é editar diretamente o arquivo onde ficam esses padrões.
O nome do arquivo é autoexp.dat e ele fica em uma pasta no estilo Program Files, Microsoft Visual Studio, Common7, Packages, Debugger. É melhor você retirar ele dessa pasta antes de sobrescrevê-lo para não ter erro de acesso. Ao abri-lo verá que no começo há vários comentários que explicam como é o funcionamento desse padrão.
Felizmente (e também obviamente) o pessoal do Qt já fez uma entrada na wiki que explica como fazer para interpretar corretamente uma QString. Eles mesmos admitem que a coisa ficou difícil desde a última versão (Qt 5), mas ainda assim é possível. E, se tudo falhar, ainda é possível usar a janela de Watch:
Mas não foi o caso dessa vez. Tudo funcionou perfeitamente assim que incluí os valores da Wiki logo no começo da sessão Visualizer.
</description>
</item>

     
        <item>
  <title>Palestra: como criar moedas digitais em casa com C&#43;&#43; (kick-off)</title>
  <link>http://www.caloni.com.br/palestra-como-criar-moedas-digitais-em-casa-com-cpp-kick-off/</link>
  <pubDate>2017-02-19</pubDate>
  
  <guid>http://www.caloni.com.br/palestra-como-criar-moedas-digitais-em-casa-com-cpp-kick-off/</guid>
  <description>Esta palestra tem como objetivo ensinar o que são moedas digitais, como o bitcoin, e cada passo necessário o algoritmo e implementação para torná-la real. Será utilizado C&#43;&#43; como a linguagem-base e o foco está mais na implementação do que na matemática ou no algoritmo. Assim como foi criado o bitcoin, o importante a aprender é como unir diferentes tipos de conhecimento e tecnologia em torno de um objetivo único, simples e prático.
A partir da criação da moeda surge a necessidade de facilitar o seu uso, um problema recorrente em todas as mais de 700 moedas digitais existentes no mercado e no laboratório, incluindo o bitcoin. Após a palestra teremos uma discussão de como levar a tecnologia ao usuário comum.
Para nossa moeda digital utilizaremos um sistema simples, rápido e prático para subir informações na memória de um nó (server) e repassar essas informações para outros nós, o tiodb. Este projeto mantém contêineres STL na memória da maneira mais enxuta possível e eles são acessíveis através do protocolo mais simples possível utilizando uma gama de linguagens (C, C&#43;&#43;, Python, .NET).
A primeira coisa é compilar o projeto tiodb, que irá disponibilizar alguns binários em sua saída:
 tio.exe é o executável central cuja instância mantém contêineres na memória; InteliHubExplorer.exe é uma interface simples para navegar por esses contêineres; tioclient.dll é a biblioteca dinâmica que pode ser usada por clientes para acessar o tio.  Podemos rodar o tio deixando ele usar os parâmetros padrão ou alterar número da porta e outros detalhes. Vamos executar da maneira mais simples:
OK, tio rodando e ativo. Podemos navegar já pelos seus contêineres usando o InteliHubExplorer:
Por convenção os contêineres seguem um padrão de nomes que se assemelha a uma hierarquia de diretórios, e os nomes que começam com underline são internos/reservados. O contêiner meta/sessions, por exemplo, contém uma lista simples das conexões ativas deste nó.
A partir do servidor funcionando é possível criar novos contêineres e mantê-los, adicionando, atualizando e removendo itens. A partir dessas modificações outros clientes podem receber notícias dessas modificações e tomar suas próprias decisões.
Vamos criar e popular um contêiner inicial de transações com um GUID zerado, e a partir dele vamos adicionando novas &amp;quot;transações&amp;quot;. Também iremos permitir o monitoramento dessas transações.
Após executar esse código passando o argumento &amp;quot;--build&amp;quot; e atualizarmos o IntelihubExplorer poderemos ver o novo contêiner e seu conteúdo. É possível ler o código rodando o mesmo programa sem passar o argumento &amp;quot;--build&amp;quot;.
Agora imagine que exista um cliente da tiocoin que está monitorando as transações deste servidor para verificar a partir de qual momento uma transação foi aceita (supondo que este contêiner possui as transações aceitas):
Voilà! Agora temos um sistema inicial com um contêiner que irá manter os IDs de supostas transações de nossa moeda digital. Está compilando e está rodando, e em cima disso poderemos ir adicionando as funcionalidades.
</description>
</item>

     
        <item>
  <title>Convertendo Windows de UEFI para MBR</title>
  <link>http://www.caloni.com.br/convertendo-windows-de-uefi-para-mbr/</link>
  <pubDate>2017-02-13</pubDate>
  
  <guid>http://www.caloni.com.br/convertendo-windows-de-uefi-para-mbr/</guid>
  <description>Quando você pesquisa sobre isso no Google o que mais encontra é ferramentas &amp;quot;gratuitas&amp;quot; que prometem fazer a conversão ou algo do gênero. No entanto, há um procedimento simples em que o próprio Windows pode corrigir os problemas oriundos da conversão do boot UEFI/GPT. Depois, é claro, que você usar uma outra ferramenta esperta open-source =)
Entre as diferentes distros do Linux há uma chamada SystemRescueCD que é cheia dos paranauê para manutenção de micros. Entre eles há uma ferramenta chamada testdisk que tem a &amp;quot;proeza&amp;quot; de sair buscando partições perdidas e reescrever o MBR (seja o código ou a tabela de partições). É uma ferramenta simples, interativa e ágil. É ela que deve ser usada para resgatar as partições da máquina após configurar a BIOS para voltar a bootar no modo legacy.
Depois de feita essa manipulação é a vez do CD do Windows, que deverá estar em mãos porque o Windows simplesmente não irá mais bootar. A instalação feita através do modo UEFI não instala o BOOTMGR, o gerenciador de boots do Windows. Isso porque ele não é usado, já que é a partição UEFI que se torna responsável por gerenciar o boot dos SOs presentes.
Mas isso não significa que essa instalação do Windows está perdida. Através de dois boots com o CD, ambos escolhendo o modo de restauração (Repair e Repair at Startup) é possível fazer com que o Windows ache o problema (o bootmgr faltando) e &amp;quot;conserte&amp;quot; a instalação.
No primeiro boot o Windows irá achar um problema inicial na própria instalação, no segundo boot ele já encontra a instalação. E, acreditem só, ele descobre que o BOOTMGR está faltando!
E a partir daí a partição UEFI se torna inútil, embora ainda exista no início do HD, já que o boot legacy usa o velho esquema de usar o código da MBR e a partir daí chamar a partição ativa, que agora será a Windows.
Essa manipulação do boot pode dar algum trabalho, mas é gratuita e com todos os passos devidamente documentados. E não há mágica: reconstrução da MBR seguido de restauração de um SO pré-existente (Windows, no caso).
</description>
</item>

     
        <item>
  <title>UEFI: dê adeus à MBR</title>
  <link>http://www.caloni.com.br/uefi-de-adeus-a-mbr/</link>
  <pubDate>2017-02-09</pubDate>
  
  <guid>http://www.caloni.com.br/uefi-de-adeus-a-mbr/</guid>
  <description>Após depurar a BIOS e a MBR, eis que surge a UEFI: os GUIDs para SOs instalados no seu HD. Quantas siglas, não é mesmo?
A BIOS (Basic Input/Output System, Sistema Básico de Entrada e Saída) é o sistema-base que se comunica com o hardware diretamente e faz a ponte entre várias interrupções e o sistema operacional (se houver um). Uma das funções iniciais da BIOS era encontrar qual a MBR (Master Boot Record, Registro do Boot Mestre) válida para entregar o controle de um pedaço de código de 512 bytes (um pouco menos) cuja função clássica era procurar em uma tabela de quatro entradas dentro dela mesma qual o SO que está ativo. A partir daí o código da MBR passava o controle para a MBR da partição ativa, que deveria conter o bootstrap do sistema operacional (naquela época bootstrap significava outra coisa).
Isso gerava várias confusões em um sistema multi-SO, algo que começou a se tornar constante depois que o Linux e o Windows de verdade (NT) veio à tona, com gerenciadores de boot no próprio SO que possibilitava que o Windows 98 conseguisse pular seu controle para um Windows NT ou 2000 e também para um Conectiva Linux. Quando as coisas davam errado era só pegar o CD de instalação de um desses e começar tudo de novo.
Ou usar o Disk Editor, a famigerada ferramenta do Norton que já salvou a vida de muitos computadores aí afora. Eu me incluo na lista de salvadores durante o tempo que fiz a manutenção de um sistema de criptografia de HD. Usar o Disk Editor era basicamente navegar pelos bytes iniciais do HD principal para encontrar qual lógica do boot estava errada. Poderia ser um erro na tabela de partições ou um modo de endereçamento que não suportava partições muito longe do início (a tabela de partições era bem limitada; abaixo ela está selecionada).
Com a UEFI (Unified Extensible Firmware Interface, Inteface de Firmware Extendido Unificado) a MBR e seus 500 bytes perdem sua vez e no lugar surge uma partição inteira, onde os SOs são organizados não por tipos de entrada, mas por GUIDs únicos (números muito grandes que em teoria não são repetidos nunca). Não há mais a chance de modificar os bytes iniciais do boot para poder realizar alguma manipulação mágica, como gerenciar os diferentes SOs. A UEFI foi feita para isso, e não apenas para SOs locais, mas qualquer tipo de extensão de firmware (o código que reside direto no hardware e manipula correntes e leds). Note como a tabela de partições em um ambiente EFI não possui entradas válidas, e o setor logo em seguida é o início de sua partição.
A UEFI diz que há suporte ao modo antigo MBR. Isso é feito mantendo o primeiro setor disponível para escrita. Uma conversão possível seria editar a tabela de partições inserindo onde está a partição de um SO e inserindo um código padrão do MBR no lugar. A mudança do tipo de boot pode ser feito na BIOS (é o modo legado), mas se for trocada ela usará a MBR para bootar, então é necessário que ela esteja funcionando.
</description>
</item>

     
        <item>
  <title>Pacotes perdidos do NuGet em projetos C&#43;&#43; no Visual Studio</title>
  <link>http://www.caloni.com.br/pacotes-perdidos-nuget-em-projetos-cpp-no-visual-studio/</link>
  <pubDate>2017-02-08</pubDate>
  
  <guid>http://www.caloni.com.br/pacotes-perdidos-nuget-em-projetos-cpp-no-visual-studio/</guid>
  <description>É muito bom (para quem gosta) usar a IDE e viver feliz sem precisar se preocupar em digitar comandos estranhos no prompt. Porém, essa vida acaba quando ocorre o primeiro erro inexplicável, aquele tipo de erro que não importa onde você olhe, não há nada para olhar. Até você apelar para ferramentas de macho.
Que nem hoje de manhã, quando fui inocentemente baixar uma versão limpa do tiodb e após baixar todos os pacotes do NuGet, o gerenciador de pacotes do Visual Studio (inclusive para C&#43;&#43;, agora) acusou a falta do boost, sendo que ele havia acabado de baixá-lo.
Os pacotes do projeto ficam todos na raiz do diretório da solução na sub-pasta packages. Observando o que foi baixado lá, verifiquei que a versão do boost estava ok: ele havia baixado a 1.61 como pedido, mas o erro dizia respeito justamente a um desses pacotes.
O maior problema disso é que não há muitas opções na IDE que resolvam. O arquivo packages.config deveria manter essas dependências, o que de fato ele faz. As opções do projeto (as abinhas do Visual Studio onde ficam as configurações) não possuem nada relacionado ao NuGet.
Então não tem jeito. Há algo de podre dentro desse projeto e o próprio Visual Studio não vai resolver. Grep nele!
Note (e é preciso prestar atenção!) que o projeto server/tio/tioserver.vcxproj referencia a pasta packages como se ela existisse dentro do projeto. Porém, como já sabemos, ela existe na raiz da solution, que fica duas pastas &amp;quot;para trás&amp;quot;. Isso nos indica que talvez o NuGet ainda não esteja tão redondo e que um possível teste é mudar esses valores na mão e ver o que acontece.
Recarregado o projeto no Visual Studio após a intervenção cirúrgica, tudo voltou a funcionar. A lição de hoje é: nunca confie completamente em uma IDE. Às vezes o bom e velho grep e o bom e velho editor de sua escolha podem resolver uma situação.
</description>
</item>

     
        <item>
  <title>Android protobuf, mock configurável</title>
  <link>http://www.caloni.com.br/android-protobuf-mock-configuravel/</link>
  <pubDate>2017-02-06</pubDate>
  
  <guid>http://www.caloni.com.br/android-protobuf-mock-configuravel/</guid>
  <description>A comunicação oferecida pelo Protocol Buffers, uma maneira otimizada de codificar mensagens em alto nível, é uma das formas mais ideais de realizar a ponte entre cliente e servidor quando se fala de aplicativos mobile. A solução já suporta inúmeras linguagens, desde C&#43;&#43; (a linguagem oficial) até Java, passando por Python e .NET. Um mesmo arquivo de definição pode ser usado entre diferentes tipos de tecnologia. Este artigo mostra o caminho das pedras para compilar o protobuf para Android e de quebra mostra como é fácil fazer um mock de servidor local em uma configuração local com o gerenciador de builds do Android.
Antes de tudo é preciso saber que estou usando Windows. Provavelmente as coisas são mais simples no Linux, mas fazer o quê. De qualquer forma, a estrutura mantida pelo projeto do Protobuf para Visual Studio é boa, e compilei sem problemas a solução.
Mas, você deve estar se perguntando: se é para Android, por que C&#43;&#43;? Bom, uma vez que você baixou os fontes do protobuf é necessário gerar o compilador. Você poderia baixar um binário compilado, mas usar direto dos fontes garante que os unit tests estão todos alinhados e que não haverão problemas de versão.
Os guias contidos nos READMEs espalhados pelo fonte, começando pelo primeiro exigido na página do GitHub, são muito bem explicados. Não deve ser nenhum problema segui-los, desde que se atente em colocar os caminhos necessários no path, como a localização do JDK (que pode ser o que vem no Android Studio, mesmo) e abrir um prompt com as variáveis de ambiente para a compilação via Visual Studio. Eu recomendo baixar uma versão estável entre as releases, e pode já baixar a 3 em diante, que contém um monte de features novas e legais.
Depois de compilar o protoc e colocá-lo no devido lugar, há uma questão importante: a versão em Java usa um gerenciador de build do Apache que funciona muito naquelas para Windows, dando erro nos testes e na instalação. Minha solução foi simplesmente usar a segunda opção descrita no README: compilar o Descriptor.proto e com ele gerar todos os .java necessários para sua compilação. Com isso fica até mais simples montar no projeto Android uma solução mais enxuta, apenas com as classes necessárias (no meu caso, pelo menos o JsonFormat e dependências).
A grande vantagem do Android Studio é que ele já escaneia os diretórios do projeto, sendo apenas necessário copiar os fontes e ele já integra no projeto. A partir daí os imports funcionam e ele compila tudo junto. Resolvido.
Para a parte do mock eu recomendo usar o sistema de variáveis do Gradle. Ele mantém uma lista de variáveis em um formato específico no arquivo app/build.gradle:
Você pode jogar direto o valor que deseja, mas há uma solução ainda mais elegante que usa um arquivo apartado chamado local.properties, onde é ideal não jogar no controle de fonte, e de onde todo desenvolvedor pode customizar. No caso de ServerMockData, ele pode ser um json com sua mensagem protobuf já certinha para uso, como se esses fossem os dados do server:
Isso pode estar errado (parênteses demais), mas você entendeu a ideia. É possível jogar um json nesse arquivo e depois o Android e o Gradle irão jogá-lo diretament em uma classe estática, a BuildConfig:
A partir dessa string é possível obter rapidamente a mensagem equivalente:
DICA: O Android Studio tem um botão esperto em sua interface onde, depois de alterado o local.properties, é possível refazer o BuildConfig.
E com isso podemos ter o protocol buffers e um sistema de mock simples e prático para a depuração e testes locais com nosso app que vai revolucionar o mundo =)
</description>
</item>

     
        <item>
  <title>Um commit por feature</title>
  <link>http://www.caloni.com.br/um-commit-por-feature/</link>
  <pubDate>2017-02-04</pubDate>
  
  <guid>http://www.caloni.com.br/um-commit-por-feature/</guid>
  <description>Imagine que você vai começar a trabalhar em algo novo. Daí você baixa a última versão do branch de dev e começa a codar. Então chega um momento em que o primeiro, segundo, terceiro commits são necessários para manter a ordem em sua cabeça. &amp;quot;Fiz isso logo de manhã, testei algo diferente antes do almoço e de tarde fui incrementando a solução final até passar todos os testes.&amp;quot; Tudo bonito. Mas como fica na hora de subir essa bagaça pras pessoas verem?
Vamos visualizar isso em commits. Você baixa a última versão do dev, começa a trabalhar e de duas uma:
 Percebe que dá para resolver tudo em um commit só. Percebe que o buraco é mais embaixo; vou precisar de mais tempo e mais commits.  No caso 1, a solução é simples e direta: faça as modificações, rode os testes locais e aplique o commit já no formato definido pela sua equipe (número do ticket, texto no idioma correto, detalhes nos parágrafos abaixo). Suba e mande para code review.
Se a política de pull request estiver sendo usada, faça isso em um branch à parte, mas já mande para o reviewer aprovar o branch como se fosse um commit apenas e de preferência pronto para o rebase (o que não deve ser nem um problema se for uma mudança pontual).
Quando mais de um commit é necessário é porque vai rolar a festa. Vários commits com texto e modificações temporárias podem ser feitos, e caso o trabalho vire a noite, é recomendado subir tudo para um branch temporário remoto (de preferência que já seja identificado pela equipe como o branch para determinado issue).
Agora nós criamos uma bela duma bagunça, mas em um branch apartado e que ainda não foi enviado para pull requet ou inserido no branch de dev. Agora chega a hora de arrumar a casa. Para isso, como tudo no git, há várias maneiras, mas a mais direta é um rebase interativo (-i), onde você pega os commits e empacota tudo junto.
(Obs.: se sua modificação demorou algum tempo é melhor atualizar o branch de dev para ver se há algo novo e fazer o merge com o branch de feature; o rebase daí não encontrará conflitos.)
Nesse momento o git irá abrir o editor com os commits trabalhados. Você deverá escolher quais operações fazer com cada commit. Se o objetivo é empacotar tudo, geralmente é pick no primeiro e squash em todos os outros:
Ao final da operação mais uma vez o git irá exibir o editor. Agora é hora de você escolher o texto bonitinho, formatadinho, do seu único commit que será usado no branch de dev. Em outras palavras, transformar isso:
Nisso:
Agora na hora de fazer o merge seu histórico estará redondo, sem ramificações e com o resultado final de seu hacking parecendo que foi feito bonito desde o começo (ah, vá):
Esta é uma das inúmeras formas de trabalhar com o git de maneira individual sem atrapalhar seus colegas. Basicamente você pode escolher outras estratégias de commits e branchs locais, mas através do comando rebase -i é possível sempre reorganizar a bagunça em commits comportados, e dar a impressão que esses programadores são enviados divinos que modificam o fonte e acertam de primeira.
</description>
</item>

     
        <item>
  <title>Warning de nível 4</title>
  <link>http://www.caloni.com.br/warning-de-nivel-4/</link>
  <pubDate>2017-01-17</pubDate>
  
  <guid>http://www.caloni.com.br/warning-de-nivel-4/</guid>
  <description>Você já colocou aquele seu projeto favorito em /W4? Por padrão, o Visual Studio cria seus projetos com o nível de warnings e 3, porque o nível 4 é muito, muito chato. No entanto, algumas vezes ele serve para que seu código não fique apenas correto, mas bem documentado e apresentável. Vamos tentar?
OK, este foi o nível 3 do tioserver, o projeto principal do tiodb, uma ferramenta para manter contêineres assináveis na memória e acessíveis via socket. Note que já existe um warning, mas vamos ignorar por enquanto. O objetivo aqui é descobrir quais os warnings mais comuns do projeto que você vai escolher. Vejamos o meu:
Vamos ordenar e capturar apenas o código desses warnings para ver quantos ocorrem e quais os mais comuns:
E a resposta é:
Apenas quatro. Tão comuns que a maioria está até em ordem numérica e diz respeito a repetição de nomes em escopos diferentes, o que esconde os nomes do escopo anterior, mais amplo. O outro, o C4701, pode ser mais problemático, já que ele representa uma variável que potencialmente não foi inicializada, fonte comum daqueles erros de &amp;quot;como é que essa variável virou isso?&amp;quot;.
Felizmente só temos em um ponto do código:
A correção é simples: inicialize a droga das suas variáveis zero (ou determine qual o comportamento no caso else).
Vamos dar uma olhada em um dos outros warnings:
OK, isso é meio feio. A variável handle tinha acabado de ser criada logo antes da entrada do if. A não ser que sejam de fato variáveis distintas no código (apenas analisando a função inteira) elas poderiam ser reaproveitadas em apenas uma (até porque possuem o mesmo tipo). E se forem variáveis distintas... bem, coloque nomes distintos =)
E aqui termina mais uma sessão de &amp;quot;e se eu abrir mais os warnings do meu código&amp;quot;. Espero que tenha aproveitado.
</description>
</item>

     
        <item>
  <title>ReadFile assíncrono pode ser síncrono quando você menos espera</title>
  <link>http://www.caloni.com.br/readfile-assincrono-pode-ser-sincrono-quando-voce-menos-espera/</link>
  <pubDate>2017-01-16</pubDate>
  
  <guid>http://www.caloni.com.br/readfile-assincrono-pode-ser-sincrono-quando-voce-menos-espera/</guid>
  <description>Ano passado tive alguns problemas em um projeto que se comunicava com um dispositivo em firmware pela USB. Estávamos utilizando uma biblioteca open source do GitHub que parecia estar bem testada e mantida. Porém, não exatamente para nossos objetivos.
O problema da lib hidapi era que a comunicação usb era feita de forma assíncrona. Isso no Windows é feito com a mesma função de I/O (ReadFile/WriteFile) só que passando um argumento opcional chamado de overlapped. Esse argumento é um ponteiro para uma estrutura que irá ser preenchida assim que o I/O for concluído. E quando é isso? Deve-se esperar pelo handle ser sinalizado (em outras palavras, dando um Sleep ou WaitForSingleObject neste handle).
O funcionamento padrão via overlapped é bem simples: faça a operação de I/O (passando a estrutura) e verifique o retorno. Ele deve ser FALSE e o retorno do próximo GetLastError deve ser ERRORIOPENDING. Bom, descrevendo a operação ela não parece ser tão intuitiva. Mas funciona:
A questão que nós encontramos nesse projeto apenas aconteceu porque após a operação de I/O assíncrona a thread responsável por retornar o resultado ficava em wait eterno ou dava timeout. Ambas as situações são normais e esperadas. Ficar aguardando para sempre um device acontece quando este simplesmente não responde com nenhum dado. E dar timeout acontece quando não queremos aguardar o device para sempre (WaitForSingleObject(handle, 1000), por exemplo, daria timeout depois de 1 segundo, ou 1000 milissegundos).
O motivo da thread nunca retornar (ou dar timeout), porém, não estava em nenhuma dessas situações. Ao monitorar o tráfego usb se verificou que o device respondia em tempo hábil. O problema estava mais embaixo (ou mais em cima): a hidapi não se comportava conforme o MSDN mandava. Há uma situação não-mapeada nessa lib.
Erros ao chamar a API do Win32 são comuns exatamente porque esta é uma lib arcaica, pouco intuitiva com diferentes tipos de exceções. No caso de uma operação assíncrona com overlapped, se você ler as tantas páginas da função ReadFile, por exemplo, vai acabar encontrando um adendo escondido no meio da documentação:
 Synchronization and File Position If hFile is opened with FILE_FLAG_OVERLAPPED, it is an asynchronous file handle; otherwise it is synchronous. The rules for using the OVERLAPPED structure are slightly different for each, as previously noted. Note If a file or device is opened for asynchronous I/O, subsequent calls to functions such as ReadFile using that handle generally return immediately, but can also behave synchronously with respect to blocked execution. For more information see http://support.microsoft.com/kb/156932.
 Este adendo possui a informação que ninguém ainda sabia porque... porque Microsoft.
 If, on the other hand, an operation is completed immediately, then &amp;amp;NumberOfBytesRead passed into ReadFile is valid for the number of bytes read. In this case, ignore the OVERLAPPED structure passed into ReadFile; do not use it with GetOverlappedResult or WaitForSingleObject.
 Ou seja, em caso da função ReadFile (ou WriteFile) retornar TRUE em uma operação assíncrona/overlapped, isso quer dizer que a operação foi concluída com sucesso de forma síncrona, não sendo necessário aguardar o I/O ser concluído. Na verdade, é um pouco mais específico: o WaitForSingleObject não deve ser chamado. No nosso caso, ao chamá-lo, criávamos uma espera eterna, já que o I/O não seria mais sinalizado (porque deveria? a operação já foi concluída!).
Uma colinha da M$ de como deve ser feito o tratamento:
Após essa correção no projeto as coisas começaram a funcionar normalmente.
A BitForge fez a alteração em um fork próprio da hidapi e enviou o pull request para os mantenedores oficiais da hidapi, a signal11. Esta é mais uma lição de que, em se tratando de I/O, as coisas difíceis que o kernel às vezes faz lá embaixo acabam refletindo aqui em cima. Às vezes até na própria API!
</description>
</item>

     
        <item>
  <title>Vídeo: Usando clang no Visual Studio</title>
  <link>http://www.caloni.com.br/video-usando-clang-no-visual-studio/</link>
  <pubDate>2016-12-27</pubDate>
  
  <guid>http://www.caloni.com.br/video-usando-clang-no-visual-studio/</guid>
  <description>Com o surgimento da infraestrutura LLVM, que possibilita a união entre diferentes ferramentas que suportam diferentes plataformas para o desenvolvimento de software, e o clang, um font-end para C/C&#43;&#43; que roda não só em UNIXes da vida, como também no Windows, como também no Visual Studio, tem sido uma vantagem para projetos que usam as novas features do C&#43;&#43; moderno, muitas ainda não implementadas no compilador da Microsoft, unir o útil (Visual Studio) ao agradável (C&#43;&#43; modernos via clang). Este vídeo tem como objetivo demonstrar como essa união é simples e fácil de ser realizada dentro do próprio Visual Studio. De quebra, vamos descobrir alguns problemas que podem ocorrer nessa união de toolsets e como corrigir.
Este é um guia bem básico, mas atende os requisitos de quem quer começar a mexer com essas duas tecnologias (além de aficionados pelo novo C&#43;&#43; que está em desenvolvimento, mas não abre mão de uma IDE tão poderosa quanto o Visual Studio):
 Criar um novo projeto clang no Visual Studio. Utilizar o projeto com um Console Win32 padrão e toolset Visual Studio. Implementar uma feature ainda não suportada pelo Visual Studio. Utilizar essa feature no Console Win32. Corrigir e entender problemas no meio do caminho.  https://www.youtube.com/embed/dMY91ojS0tw
 CLang LLVM C&#43;&#43; compiler support Fold expression  </description>
</item>

     
        <item>
  <title>A Linguagem de Programação C&#43;&#43;: O Início</title>
  <link>http://www.caloni.com.br/a-linguagem-de-programacao-cpp-o-inicio/</link>
  <pubDate>2016-11-29</pubDate>
  
  <guid>http://www.caloni.com.br/a-linguagem-de-programacao-cpp-o-inicio/</guid>
  <description>O livro-base sobre a linguagem C&#43;&#43; e como programar nela tem o nome pouco criativo &amp;quot;The C&#43;&#43; Programming Language&amp;quot;, e é de Bjarne Stroustrup, o criador da linguagem. Ele começou a desenhar a linguagem em 1979, quando ainda a chamada de &amp;quot;C com Classes&amp;quot;. Havia um problema a ser resolvido na época em que Stroustrup estava fazendo sua tese de doutorado. Havia linguagens muito boas em abstração como Simula -- como o novo conceito de Orientação a Objetos -- que carecia do mais importante na época: velocidade (só na época?). Já linguagens mais antigas como BCPL eram bem rápidas, mas eram tão simples que pareciam mais um Assembly glorificado. Havia, portanto, a necessidade de preencher a área de computação com alguma coisa bem no meio.
Stroustrup não fez tudo do zero, nem fez tudo de uma vez. A primeira necessidade era apenas criar uma abstração já existente na linguagem C, mas que ainda não havia sido integrada à sintaxe: o contexto de uma estrutura, que se assemelha a uma proto-classe, ou para alguns já é até uma classe, pois possui membros e métodos:
A grande sacada é que no meio de toda essa sintaxe de chamada de método havia a passagem de um parâmetro escondido, o this, que se referia à uma instância específica da classe: um objeto.
Isso equivaleria a uma struct em C com funções que recebessem um this adaptado:
Esse tipo de abstração nem é tão complicada assim. O ojetivo eram vários: conseguir proteger os membros de acesso indevido, abstrair o comportamento de um objeto. Com o tempo Stroustrup foi realmente criando algo de novo e muito mais difícil de se manter em C.
Algo para um próximo post =)
</description>
</item>

     
        <item>
  <title>Quantos handles sua aplicação está abrindo?</title>
  <link>http://www.caloni.com.br/quantos-handles/</link>
  <pubDate>2016-11-29</pubDate>
  
  <guid>http://www.caloni.com.br/quantos-handles/</guid>
  <description>Mesmo que você não programe em C/C&#43;&#43;, mas programe para Windows (ex: .NET), sempre há a possibilidade de seu programa estar causando leaks de handles indefinidamente, o que não se traduz em aumento significativo de memória alocada para seu processo, mas é, sim, um problema a ser tratado.
Como isso pode ser causado? Bom, em C/C&#43;&#43; sempre é mais simples de entender esses conceitos. Um código simples que se esquece de fechar o handle usando CloseHandle ou a função equivalente do recurso obtido já seria o suficiente. O último bug que eu encontrei em um código desses comete o clássico erro de sair no meio da função, deixando os recursos alocados:
No exemplo acima quando as coisas dão certo elas também dão errado, já que o retorno do valor no meio da função evita que o HANDLE armazenado em hKey seja desalocado.
E como fazer para descobrir esse tipo de leak?
O HandleLeaker é apenas um exemplo de aplicação que realiza o leak de um handle por segundo. Ele tenta (e consegue) abrir um handle para seu próprio processo, e deixa o handle aberto (programas em Win32 API não são muito bons em RAII).
O Perfmon(.msc) está aí no Windows já faz algumas versões (quase todas). Tudo que você precisa para executá-lo é executar o comando perfmon no diálogo de execução (Start, Run) ou encontrar o atalho para perfmon.msc. Na busca do Windows 8/10 também é possível encontrá-lo pelo nome.
Ao executá-lo a primeira coisa que ele monitora é o processamento da máquina. Podemos eliminar ou esconder esse indicador direto na lista abaixo da ferramenta.
Existem incontáveis contadores no Perfmon. Para o que precisamos vamos em Process e escolhemos o contador de Handles.
Depois de um tempo o Perfmon irá exibir o histórico que determina para onde está indo o seu contador.
Se os valores do seu contador estão fora da faixa do histórico é possível ajustar a escala nas propriedades.
Se a frequência for muito menor do que um handle por segundo (isso acontece, principalmente com serviços que rodam por dias/semanas/meses), é possível mudar também pelas propriedades, mas gerais.
A mudança que fizemos captura o dado monitorado de dez em dez segundos e realiza essa operação por 600 segundos (10 minutos), até repetir o gráfico de histórico.
Outra forma de verificar como andam os handles da máquina é usando a já famosa ferramenta da SysInternals. Através das inúmeras colunas que ela fornece existe o contador de handles de cada processo, através do qual é possível verificar quais são os processos com mais handles abertos.
Se seu programa for um handle hog, vai conseguir até ver esse leak acontecendo em tempo real (como o nosso programa mal-educado).
E como encontrar o código-fonte responsável por esse leak? Mais detalhes em um próximo post.
</description>
</item>

     
        <item>
  <title>Usando GVim com Projetos do Visual Studio</title>
  <link>http://www.caloni.com.br/usando-gvim-com-projetos-do-visual-studio/</link>
  <pubDate>2016-09-18</pubDate>
  
  <guid>http://www.caloni.com.br/usando-gvim-com-projetos-do-visual-studio/</guid>
  <description>A vida dos programadores C/C&#43;&#43; Windows, e que geralmente precisam do Visual Studio, está um abandono total. A configuração de make dos projetos sempre foi baseada no uso de makefiles, assim como no Unix, e por isso mesmo o uso da ferramenta nmake do SDK do Windows era a maneira padrão de se compilar e ver o resultado de dentro do Vim para projetos Windows. Com o advento do .NET, do Visual Studio 2003 e dos XMLs disfarçados como arquivos de projeto e solution o uso do makefile foi paulatinamente abandonado, gerando diferentes versões de ferramentas, todas incompatíveis, para conseguir compilar um ou mais cpps e conseguir ver o resultado.
Por isso mesmo é um assunto pouco explorado nos fóruns do Stack Overflow como configurar decentemente o comando :make do Vim para conseguir realizar o ciclo &amp;quot;program, compile, debug&amp;quot; que já era feito desde a época do Amiga OS (e conhecido no manual do Vim como Quickfix). Ninguém se dá ao trabalho de usar esse modelo torto.
Houve um tempo que eu mesmo pesquisei algumas soluções, e caí no velho problema de tentar conviver com diferentes versões do Visual Studio. Deixei de lado o Vim por uns anos, e passei a usar o VsVim, um plugin que roda em várias versões do Visual Studio e utiliza o vimrc de sua instalação.
Hoje voltei a fuçar esse problema e depois de algumas horas tentando entender qual a dinâmica que deve ser seguida, cheguei a dois usos legítimos do make no Visual Studio: o modo legado, através do devenv, e o modo comportado, que usa a ferramenta MsBuild para encontrar o projeto e a solution que devem ser compilados.
A não ser que você coloque o path das ferramentas direto nos comandos (algo que não recomendo pois as coisas no Vim começam a ficar estranhas com paths com espaços, algo abundante no Windows) é preferível que você escolha qual devenv e qual msbuild deseja utilizar e definir isso na variável de sistema path. No meu exemplo estou usando o msbuild para qualquer Visual Studio acima do 2010 (como o 2015), pois já está padronizado, e como tenho projetos no VS2003 para manter, escolhi deixar o devenv.com com ele.
Note que essa configuração, para ficar persistente, precisa ser definida através do Painel de Controle ou Propriedades do Sistema. Google for it.
Depois de configurado, qualquer projeto deve ser compilável em 2003 pela linha de comando (através do devenv.com). E mesma forma, projetos 2010&#43; devem usar o msbuild. Tirando essa facilidade, as coisas no Vim para msbuild rodam particularmente bem. Basta alterarmos o makeprg da seguinte maneira: &amp;quot;:set makeprg=msbuild\ /nologo\ /v:q\ /property:GenerateFullPaths=true&amp;quot;.
As opções específicas são para gerar o path completo, as barras invertidas são por causa dessa mania do Vim de dar pau quando tem espaço em tudo.
A partir dessa configuração já é possível compilar um projeto estando em sua pasta. Para o Visual Studio 2003 (ou qualquer um usando o devenv.com) é necessário mudar esse comando para o uso do devenv: &amp;quot;:set makeprg=devenv\ %\ /build\ Debug&amp;quot;.
Sim, temos que escolher uma configuração (o msbuild já escolhe por você). E note que ele usa o arquivo atual (%) para compilar. Isso quer dizer que isso irá exigir do usuário de Vim abrir o sln ou o vcproj e executar o :make a partir daí. De qualquer forma, ele funciona também.
Note que em nenhum dos casos erros conseguirão ser capturados para irmos direto no ponto do código-fonte onde ele está. Para isso funcionar, em nosso último passo, é necessário configurar o errorformat para que ele tenha um padrão que funcione com ambas as ferramentas. Depois de testar um pouco, cheguei nesse formato: &amp;quot;set errorformat=%f(%l)%m&amp;quot;. Talvez isso mude no futuro, pois sabe como é a Microsoft com suporte a linha de comando. Este formato pega também os warnings, mas fazer o quê. Você não quer conviver com warnings em seu código pelo resto da vida, né? =)
E para navegar na lista é como o resultado de comandos como :vimgrep. :cnext e :cprevious vão para frente e para trás na lista, sempre pulando para o ponto no código onde está o erro.
Como deu pra perceber, para conseguir usar o msbuild e o devenv ao mesmo tempo você seria obrigado a trocar o makeprg sempre que precisasse. Para facilitar seu uso, nada como fazer um mapeamento de atalhos com o uso do comando map do vim.
</description>
</item>

     
        <item>
  <title>unit-menos-menos</title>
  <link>http://www.caloni.com.br/unitmenosmenos/</link>
  <pubDate>2016-09-05</pubDate>
  
  <guid>http://www.caloni.com.br/unitmenosmenos/</guid>
  <description>Fazer o setup inicial de testes unitários em seu projeto C&#43;&#43; pode ser algo enfadonho se você precisa baixar e compilar uma lib do Google ou do Boost. Há uma alternativa mais leve e bem direta, que um dia apareceu nesses CodeProject da vida, mas que hoje está, até onde eu vi, no GitHub.
E como se faz para começar a montar os testes unitários? Bom, suponha que você tenha um projeto qualque que já compila, roda e faz alguma coisa de útil.
Apenas crie um projeto do lado, console, ou copie e cole o projeto, mas use os arquivos-fonte do projeto original. Dessa forma ele irá compilar com os fontes que estão sendo modificados/compilados.
Apenas se lembra de não incluir o módulo que contém o int main. Esse módulo deve ficar apartado do projeto principal.
Depois basta incluir apenas um arquivo do projeto unit--, que é seu cpp principal.
Com isso existirá um main lá dentro, definido em algum lugar. E tudo o que você precisa fazer é ir criando seus testes em outro arquivo fonte gerado para isso. O corpo e o formato dos unit cases é bem simples. Note que tudo que você fez para já sair testando seu projeto foi copiar um projeto já existente e inserir um módulo de outro projeto. Tudo compilando junto e já podemos fazer os primeiros testes do programa original (desde, claro, que ele seja testável, algo primordial):
E assim por diante. O resultado é que quando você roda o executável de teste, ele execute toda a bateria e já te entregue todos os casos que você deseja testar, sem frescura:
E voilà! Sistema de teste unitário pronto e rodando. Agora cada nova situação de erro ou que você precise validar, basta escrever um novo teste. Se esse projeto ir se tornando algo muito maior, a transição para testes unitários mais parrudos é apenas um regex. No momento, foque em codificar e testar muito bem o que está fazendo.
</description>
</item>

     
        <item>
  <title>Vídeo: Resolvendo problemas em projetos desleixados</title>
  <link>http://www.caloni.com.br/video-resolvendo-problemas-em-projetos-desleixados/</link>
  <pubDate>2016-09-01</pubDate>
  
  <guid>http://www.caloni.com.br/video-resolvendo-problemas-em-projetos-desleixados/</guid>
  <description>Quem nunca teve que mexer em um projeto cheio de bugs de compilação, péssima organização, documentação e nomes de funções, classes e argumentos? Que você acaba de baixar em sua máquina e ele não compila (e você não tem a mínima noção por quê). Que a equipe que trabalha com você ouviu falar do projeto, mas nunca arregaçou as mangas e organizou. Que tal fazer isso agora?
Nesse vídeo eu exploro alguns dos erros mais comuns de projetos desleixados. Esses projetos em que o programador só se preocupa em entregar as coisas, e deixa os problemas de manutenção para o próximo trouxa que irá mexer com ele. Esse rapaz ou moça não usa a metologia PMF, que eu expliquei no artigo anterior. PMF quer dizer entregar as coisas com qualidade. Eles usam uma outra metodologia que também é simples, mas que traz gravíssimos problemas a médio e longo prazo (a despeito de ser divertida):
Pra começar, projetos que não compilam ou cheio de warnings são um sinal de que há algo de pobre no reino do GitHub. Ou é algo feito nas coxas ou é um projeto mal mantido ou é fruto de programação instintiva, que não pensa nas consequências de seus atos.
Depois, o sujeito usa headers com nomes complicados, inclui 2.653 headers diferentes (e duplicados) quando usa apenas dois, inclui headers do boost com nomes estranhos sem dar dica alguma de onde vieram. Cria funções que recebem s1 e s2 (e se chamam func2). Enfim, o pacote completo de desleixadas.
E por último, mas não menos importante: INCLUI BINÁRIOS NO GIT! TEMPORÁRIOS!
Pensando bem, meu exemplo fictício está bonito demais perto do que existe por aí. Bom, ele tem poucas linhas. É tudo questão de tempo e (des)empenho.
</description>
</item>

     
        <item>
  <title>DBAccess</title>
  <link>http://www.caloni.com.br/dbaccess/</link>
  <pubDate>2016-08-16</pubDate>
  
  <guid>http://www.caloni.com.br/dbaccess/</guid>
  <description>Bancos de dados são uma dor de cabeça para o desenvolvedor acessar. Quase tão motivation killer que as configurações do .NET. Se for um programador em C&#43;&#43; para Windows, então, desista.
O DBAccess é mais um dos códigos-fonte desenterrados dos meus backups. Esse eu usei já em vários projetos, porque é simples e rápido de usar.
Sua função é abstrair a abertura de um banco de dados, sua execução e sua saída. Para isso ele cria uma interface simples que usa STL. Por debaixo dos panos, usa OLEDB, que abstrai qualquer coisa, só precisando de instalar o driver e aprender qual das 500 mil combinações é a string de conexão correta. Para não ter que usar outras funções para coisas simples como sqlite, foi incluído seu suporte (que é mais uma tradução entre interfaces), necessitando para seu uso daquele projeto do sqlite que contém um header e um .c (pelo jeito o pessoal desse projeto também gosta de simplificar as coisas).
O código que trata o OLEDB é um pouco grande (umas 300 linhas) por conta da manipulação dos componentes COM. Porém, feito decentemente, faça uma vez e use um milhão (ainda falta fazer alguns unit tests, aliás).
É um bom projeto para entender o uso da minha batidíssima biblioteca de parsear argumentos argv/argc (Args.cpp/h) e a mais batidíssima ainda biblioteca de Log, que utiliza variadic templates para se livrar da maldição dos crashs causados pela falta de tipagem do printf e derivados (em Log.cpp/h).
Além disso, observe como o uso de interface permite que os headers específicos do que tem que ser feito (e.g. oledb.h, atlbase.h, msdasc.h, sqlite.h e até windows.h) não precisa necessariamente estar presente no header da interface (oledb.h), e como o uso de um factory em um método estático da interface permite que a junção das tecnologias envolvidas fique apenas no oledb.cpp. Dessa forma, para retirar ou acrescentar novas formas de comunicação com um banco de dados é muito simples.
PS: A publicação do DBAccess foi inspirada na thread iniciada por Spagiari no nosso grupo C/C&#43;&#43;.
</description>
</item>

     
        <item>
  <title>Vídeo: Depurando código C&#43;&#43; no Visual Studio</title>
  <link>http://www.caloni.com.br/depurando-codigo-c-no-visual-studio/</link>
  <pubDate>2016-08-12</pubDate>
  
  <guid>http://www.caloni.com.br/depurando-codigo-c-no-visual-studio/</guid>
  <description>Olá de novo. Este é o segundo vídeo da série &amp;quot;o que que eu tô fazendo no YouTube?&amp;quot;. Dessa vez abri o Visual Studio para depurar um código de 10 linhas com um bug absurdamente absurdo, mas que pode enganar muita gente. Há quem acredite que esse bug foi proposital, mas não foi. O importante é que ficou muito legal. Vamos ver?
https://www.youtube.com/embed/TpTNMj7ngc
Pra começo de conversa, é importante ressaltar que este é um vídeo introdutório, para quem deseja começar a programar em C&#43;&#43;, ou até para quem quer alguma dica de uso da IDE do Visual Studio. Já trabalhei algumas décadas (uma e meia) com a ferramenta, quando ainda se chamada Visual C&#43;&#43; e foi horrorosamente renomeada para Visual Studio .NET (arght!!!). Com o tempo fui me acostumando com a lerdeza cada vez mais crescente da ferramenta, acreditando piamente que um dia iriam transformar tudo em Java para ficar mais rápido.
Acho que não foi o caso. De qualquer forma, o vídeo acima tem o potencial de funcionar em quase qualquer versão do Visual Studio. Portanto, não se acanhe se ainda está mexendo em projetinhos jurássicos com o .NET 2003 (eu estou, mas só abro em emergência). Tudo deve funcionar exatamente como está no vídeo.
Ou não. Nesse caso, RTFM ou comente aqui =)
</description>
</item>

     
        <item>
  <title>Vídeo: Criando Projeto C&#43;&#43; Console no Visual Studio 2015</title>
  <link>http://www.caloni.com.br/video-criando-projeto-c-console-no-visual-studio-2015/</link>
  <pubDate>2016-08-04</pubDate>
  
  <guid>http://www.caloni.com.br/video-criando-projeto-c-console-no-visual-studio-2015/</guid>
  <description>Esse vídeo é um experimento que estou fazendo para tentar começar a compartilhar conhecimento em vídeo. Para começar, acho que nada mais apropriado que criar um projeto novo no Visual Studio, não? Dúvidas, sugestões, críticas, todas bem-vindas. Compartilhem com aquele amigo que pensa em começar a programar (ainda mais se for em C&#43;&#43;).
Essa primeira tentativa saiu um pouco longa -- 10 minutos -- mas era para ser mais sucinto. Me perdi em alguns detalhes da estrutura do projeto, mas o objetivo era entrar um pouco mais a fundo, mesmo, abrindo os arquivos do Visual Studio &amp;quot;na mão&amp;quot; para ver o que tem dentro, e já dando dicas de como a depuração pode começar já na compilação.
Espero que gostem. Se quiserem vídeos mais específicos, é só comentar logo abaixo. Dependendo do retorno -- ou não -- talvez em breve continuemos o projeto fazendo um básico de depuração.
</description>
</item>

     
        <item>
  <title>Palestra: Stack Overflow</title>
  <link>http://www.caloni.com.br/palestra-stack-overflow/</link>
  <pubDate>2016-06-04</pubDate>
  
  <guid>http://www.caloni.com.br/palestra-stack-overflow/</guid>
  <description>Há umas semanas (sim, estava enrolado para falar sobre isso) ministrei uma nova palestra lá em Sorocaba. Cheguei no meio de uma greve de ônibus, o que atrasou o evento em uma hora e me deu tempo de sobre para pensar nas desgraças que serão cidades próximas da capital crescendo desordenadamente graças às regulações estatais.
Mas divago.
A ideia da palestra foi do meu amigo Alan Silva (a.k.a. jumpi), e era para a SEMANA DA COMPUTAÇÃO E TECNOLOGIA -- mas nada tem a ver com computação, nem tecnologia, mas com oportunidade de emprego de estagiários para empresas corporativistas da área. O foco era sair da mesmisse que os representantes de R.H. fazem em falar de cultura, visão, valores e outras besteiras e falar um pouco mais de bits e bytes, algo que falta a essa geração.
Meu público era muito, muito jovem, e foquei erroneamente em conceitos muito, muito antigos para eles, então não tenho muita certeza se fui útil. De qualquer forma, foi um prazer falar sobre engenharia da computação atrelado a ataque na pilha de execução (sim, um salto enorme para baixo, do R.H. para a placa de memória RAM).
O conteúdo e a palestra está no GitHub e a palestra em si pode ser vista logo abaixo; a apresentação do conteúdo está mais abaixo, e peço desculpas por não ter tido tempo de apresentar todo ele (mesmo com quase duas horas):
http://www.slideshare.net/slideshow/embedcode/key/qRb4TSKjnf8Wx
PS: Ah, esqueci. Também fiz um vídeo para complementar o conteúdo da palestra. Segue:
https://www.youtube.com/embed/kSKQQDTBRXQ?list=PLa0QVTprDkHBz6fjuzy4kU1iTLUnRWkeW
Um StackOverflow é definido pela escrita em uma região não autorizada de memória. Stack overflow, overrun, etc, não interessando a nomenclatura &amp;quot;oficial&amp;quot;, o importante aqui é como um bug de acesso à memória pode permitir acesso exclusivo a regiões de memória que não estariam disponíveis para um atacante se não fosse por esse bug.
No exemplo do código deste projeto, um usuário fictício utiliza um código que possui controle de acesso, mas também possui um bug: ele escreve em uma região da memória inadvertidamente. Dessa forma, é possível explorar essa falha no código para escrever um novo endereço de retorno na pilha (stack), ganhando acesso, dessa forma, a código que não estaria disponível em situações normais de temperatura e pressão.
Para explorar esse tipo de falha, primeiro devemos entender a execução do código na arquitetura que se pretende atacar, além de alguns conceitos específicos do sistema operacional alvo.
  UML: Mundo real aplicado a engenharia.
  Programação: Codificação do mundo real.
  Assembly: Ponte entre ser humano e máquina.
  1&#39;s e 0&#39;s: Codificação lógica do computador.
  Impulsos elétricos: Voltamos para o mundo real.
  Qubit: Voltamos para a Matrix.
  (&amp;quot;IBM disponibiliza computador quântico para público&amp;quot;)
  Mais abstrações: Memória Virtual, Threads, I/O.
  Movimentação de memória (mov, lea)
  Cálculos matemáticos (add, div)
  Meta-comandos (push, pop, ret, jmp)
  Registradores (e[abcd]x, [bs]sp, eip)
  Endereço Virtual ([Kernel|User] Space)
  Endereço Físico (RAM, ROM, Storage, placas)
  Qual o sentido de apontar para a próxima instrução?
  R: Saber onde continuar a execução.
  Demo: Chamada de função.
  Demo: Retorno de função.
  Qual o sentido de existir uma stack?
  R: Conseguir chamar funções.
  Demo: Chamada de função.
  Demo: Passagem de argumentos.
  Demo: Retorno de função.
  Escalonamento de threads
  Virtualização da memória
  Controle de acesso
  Paginação
  Plug and Play
  Windows NT
  Dave Cutler
  xBox One
  Hypervisor
  Thread: Uma ilusão satisfatória.
  Fibers, Co-Routines, Cores, Pipe Line, Branch Prediction.
  Computação Quântica: Hackeando o Universo.
  Python, F#, Lambdas C&#43;&#43;11, Métodos, Função Virtual.
  Bloco de memória chama... Outro bloco de memória
  [[[C]]]]decl e Std(?)call (M$).
  Demo: Função em C sendo chamada.
  Demo: Função da Microsoft sendo chamada.
  Ou: Porque o printf precisa ser cdecl.
  Page Tables, PTEntries, Page Fault, Memory Map.
  Demo: Process Explorer.
  2 bits: Quatro possibilidades.
  Read-Only Memory, Execute Memory.
  Ah, vamos para o BAR: Base Address Randomization.
  Demo: Ver se isso funciona, mesmo.
  ESP Verification.
  Buffer overrun.
  0xCCCCCCCCCCCCCCCCCCCCC
  </description>
</item>

     
        <item>
  <title>Rank and File</title>
  <link>http://www.caloni.com.br/rank-and-file-code-jam/</link>
  <pubDate>2016-04-16</pubDate>
  
  <guid>http://www.caloni.com.br/rank-and-file-code-jam/</guid>
  <description>Passou o Round 1A do Code Jam, e para variar, fui muito mal, só respondendo a primeira questão. A segunda me fez ficar pensando um tempo desproporcional sobre como encaixar as diferentes linhas e colunas para achar a linha restante.
Basicamente, o problema pede que, dado um quadrado de tamanho N, e 2*N-1 linhas fornecidas (que podem ser linhas ou colunas), imprimir a Nésima linha. A regra das linhas é que ela possui números crescentes.
Bom, não consegui chegar numa solução para o problema errado (encaixar as linhas), mas fui, como sempre, dar uma espiada nas respostas dos competidores, em especial a do primeiro colocado. O grande barato de competições como essa é aprender com a inteligência e genialidade dos outros. Para mim, esse é um exemplo de genialidade:
Obs.: O código está higienizado, pois esse pessoal usa bastante macros, etc.
A solução basicamente decide isolar duas questões: achar os números que faltam nas sequência e imprimi-los na ordem. Para o primeiro, varre todas as sequências sinalizando qual deles tem a quantidade ímpar (ou seja, não está representado em todas as linhas e colunas, pois do contrário seria par). Depois ele resolve a segunda questão simplesmente imprimindo os números ímpares encontrados, já na ordem (no array de valores possíveis).
Simples, rápido, eficiente. E correto.
É esse tipo de coisa que faz valer a pena uma competição dessas.
</description>
</item>

     
        <item>
  <title>Testando sistema de postagem</title>
  <link>http://www.caloni.com.br/testando-sistema-de-postagem/</link>
  <pubDate>2016-04-10</pubDate>
  
  <guid>http://www.caloni.com.br/testando-sistema-de-postagem/</guid>
  <description>Bom, depois de criar um script para basicamente apenas escrever o texto dos filmes que assisto e buscar uma imagem agradável para meu finado blogue de Cinema, o próximo passo foi portar esse mesmo método para meus dois outros blogues: o da minha empresa, a BitForge e esse aqui. O processo envolve algo a mais: buscar as imagens usadas (que muitas vezes não é só uma). Porém, nada mais que isso.
O problema mesmo é publicar nas redes sociais. Um detalhe típico do funcionamento dessas redes bem apontou o blogger veterano Hossein Derakhshan, que ficou preso por seis anos e descreveu a mudança que a web sofreu nesse pouquíssimo tempo para a história, mas muitíssimo para a internet. De acordo com ele, postar apenas links não farão muito efeito, mesmo que você seja um escritor conhecido (o caso dele). Para fazer efeito, você precisa de imagens. Pessoas gostam de imagens. De gatinhos, melhor ainda.
Porém, qual imagem que pode ser usada para um blogue técnico e que chame a atenção?
No Cine Tênis Verde fica fácil achar uma imagem, pois filmes são formados por elas (cerca de 170 mil delas, se for um filme de duas horas). Aqui no Blogue do Caloni, tenho que me limitar a abstrações e metáforas.
O que muitas vezes tem funcionado, como minha série Básico do Básico:
 Binário Tipos Ponteiros Assembly Programação Depuração  De qualquer forma, posso continuar utilizando o título do artigo como base para minha pesquisa.
Postar no Twitter é algo relativamente fácil. O script abaixo faz isso com dois pés no joelho:
Já postar no Facebook é mais ou menos uma tortura. As chaves de acesso costumam expirar, e para conseguir uma que não expira este tutorial é femonenal, pois economiza muito, muito tempo de pesquisa.
Curiosamente, o código para postar é muito semelhante ao do Twitter, até mais simples, talvez:
</description>
</item>

     
        <item>
  <title>Crash no Windows Explorer</title>
  <link>http://www.caloni.com.br/crash-no-windows-explorer/</link>
  <pubDate>2016-03-01</pubDate>
  
  <guid>http://www.caloni.com.br/crash-no-windows-explorer/</guid>
  <description>Quem nunca se deparou com um sistema Windows em que o Explorer travasse ou crashasse de vez em quando? O problema com esse tipo de problema (recursividade...) é que ele pode ocorrer por infinitos motivos. Tão infinitos quanto os shell extensions, aquelas DLLs irritantes que são carregadas automaticamente por todo processo explorer.exe, e que portanto podem gerar infinitas maneiras de travar seu shell.
Um que estava me incomodando já há algum tempo era um deadlock que acabava em restart do Explorer (isso é automático no Windows 10). Para verificar o que era, antes configurei a geração de dumps automática para que qualquer novo crash gerasse um arquivo de dump para eu analisá-lo. Só passou algumas horas para ter algo que pudesse trabalhar: um dump pode ser analisado pelo Visual Studio (qualquer versão) ou depuradores como WinDbg (do pacote Debugging Tools for Windows). Como análise exploratório, apenas o Visual Studio é suficiente, pois ele pode exibir coisas como os módulos carregados pelo processo e a pilha de chamadas da thread faltosa.
No caso do dump que eu estava analisando, verifiquei que a thread que gerou o travamento continha uma DLL da NVidia. Essa DLL, de acordo com o AutoRuns, estava cadastrada no registro como um Context Menu Handler para o shell. Depois de desativá-la e iniciar uma nova instância do Explorer foi possível verificar que a DLL não estava mais sendo carregada pelo processo.
E &amp;quot;magicamente&amp;quot; o travamento não aconteceu nos próximos dias =).
</description>
</item>

     
        <item>
  <title>Exportando repositórios antigos do Bazaar para Git</title>
  <link>http://www.caloni.com.br/exportando-repositorios-antigos-do-bazaar-para-git/</link>
  <pubDate>2016-01-27</pubDate>
  
  <guid>http://www.caloni.com.br/exportando-repositorios-antigos-do-bazaar-para-git/</guid>
  <description>Enquanto estudava sobre controle de fontes distribuído, experimentei e usei os projetos Mercurial e Bazaar, precursores desse modelo que funcionavam bem em Windows. Havia o Git, mas por conta da sua evolução assimétrica, o ambiente da Microsoft havia ficado para trás.
Hoje com o Git sendo praticamente o mainstream das conversões do SubVersion, e funcionando razoavelmente bem em ambientes Windows (64 ou 32), sobraram apenas os repositórios do Mercurial e do Bazaar. Na verdade, mais do Bazaar, pois eu havia migrado já do Hg pelo Bazaar possuir algo que hoje o Git emula, mas antes era um diferencial no projeto da Canonical: detecção de rename completo (com histórico e tudo). Isso para refatoração era vital, e suporte à refatoração pesada era o que eu precisava no momento.
Agora é hora de manter esse histórico vivo, mas convertido para o que todos usam.
A primeira coisa a ser feita é converter o repositório. Depois de convertido, como todas as operações estarão no universo Git, há uma de entradas no StackOverflow para nos ajudar a reunir os repositórios em um só, meu objetivo, já que o Git é mais leve e mais versátil nesse quesito.
No Windows, nas últimas versões do Bazaar o comando fast-export não estava mais funcionando. Parado desde 2012, não há previsão de correções. No entanto, para essa operação, a versão 2.4.2 atendeu bem. O comando é um pouco diferente, mas ele é rápido e rodou sem problemas em conjunto com o fast-import do Git.
É óbvio que nem tudo serão mil maravilhas. Eu, por exemplo, encontrei um problema com case-sensitive que me deu algumas dores de cabeça:
O Git gera um arquivo de report onde estão as informações do ocorrido. Uma forma de contornar esse tipo de problema é primeiro exportar para um arquivo e editá-lo (corrigindo o case, por exemplo):
Note que talvez você precise de um editor que suporte arquivos gigantescos (como o Vim) e precise se debruçar sobre merges com arquivos com mesmo nome e diferentes cases. Isso que dá manter projetos com refactoring pesado.
Por fim, faça a conversão para todos os .bzr que tiver e haverá um .git com todo o histórico desses anos usando Bazaar. O próximo passo é montar o histórico de todos eles em apenas um repositório (se assim desejar). Segue uma série de comandos que pode ajudar para usar em uma batch:
Você pode chamar um a um em cima de um repo novo:
Para conseguir ter acesso ao histórico dos arquivos movidos, basta usar a opção -all do log:
Tive alguns problemas em rastrear o histórico utilizando a estratégia de fazer merge no mesmo branch. A solução que encontrei, embora não exatamente direta, foi realizar os merges em branches apartados primeiro, mover os arquivos (de preferência, usando o git, para que ele detecte o rename), aplicar o commit e realizar o merge com o master. Há uma vantagem nessa estratégia, além do log --follow funcionar melhor: mantenha os branches originais, além do ponteiro para remote. Dessa forma, depois de alguns anos, saberá de onde veio esse merge maluco.
Depois de um tempo testando essa técnica, descobri que o Git se perde novamente e não encontra mais todos os logs, mesmo com --follow mesmo movendo os arquivos. O meu problema está relacionado com mesmos paths dos arquivos em repositórios diferentes. Paciência.
</description>
</item>

     
        <item>
  <title>Log de chamadas API direto do WinDbg</title>
  <link>http://www.caloni.com.br/log-de-apis-chamadas-direto-do-windbg/</link>
  <pubDate>2016-01-21</pubDate>
  
  <guid>http://www.caloni.com.br/log-de-apis-chamadas-direto-do-windbg/</guid>
  <description>Há muito tempo atrás eu havia falado sobre como a ferramenta logger.exe, do Debugging Tools for Windows, poderia ser usada para gerar um arquivo de log com centenas de APIs detalhadas em sua chamada, como parâmetros de entrada, retorno e tempo. Bom, testando isso hoje, me veio à lembrança o artigo e também a constatação que o logger é muito instável. Tão instável que não consegui logar as APIs que desejava nas inúmeras tentativas que fiz. Isso em um Windows XP!
Felizmente, as funções do logger também estão em uma DLL estilo plugin do próprio WinDbg, que pode ser chamada facilmente e que -- surpresa! -- internamente ao depurador funciona. Melhor ainda, não é necessário criar um processo para realizar o log, mas pode ser atachado em um processo já em execução, o que facilita bastante seu uso em serviços, por exemplo.
Vamos testar aqui o log da nossa cobaia de plantão, o amigo Notepad (ou Bloco de Notas), exibindo um texto que demonstra com perfeição uma das minhas características mais bizarras: confundir expressões e frases prontas.
Nota: Lembrando que estaremos testando em Windows XP 32 bits com um WinDbg igualmente 32 bits. Inicialmente comecei a testar a versão 64, mas ela também deu xabu. Aparentemente coisas periféricas do Debugging Tools nunca são muito bem testadas.
O texto ainda não foi salvo em nenhum arquivo. Iremos salvá-lo, mas antes, vamos executar o WinDbg e ver como o Notepad realiza essa operação.
A extensão/plugin que me referia é o Logexts.dll. Você pode instalar o log de API em um momento, habilitá-lo em outro, e até desabilitá-lo depois. Ou seja, é um processo ótimo para realizar inspeção pontual de chamadas API. Caso, claro, ele não exploda em um desses momentos.
Depois de gerarmos o que precisamos, podemos desatachar do processo e analisar o resultado: um arquivo LGV. Para abrir esse arquivo existe uma outra ferramenta chamada logviewer. Para evitar procurar em dezenas de milhares de chamadas, há uma opção de filtrar com apenas o que queremos (no caso, CreateFile e WriteFile).
Depois de filtrado, podemos abrir a linha que nos interessa para ver como o programa utilizou a API (quais parâmetros, o retorno, etc). Nesse caso, por exemplo, houve uma falha antes na abertura do mesmo arquivo, mas isso porque houve uma tentativa de abrir um arquivo que já existe (abertura com direito de apenas leitura). Essa chamada foi feita pela DLL do diálogo comum de abertura/salvamento de arquivo do Windows (comdlg32.dll), e não pelo notepad.exe.
Como já havia dito no artigo original sobre o logview, você pode criar seu próprio header com as definições das funções de um módulo e o WinDbg graciosamente irá gerar um log de chamadas, incluindo medidas de performance. Esses dados abertos pelo logviewer podem ser exportados também para modo texto. E temos mais uma maneira de perfcounter chulé para eventualidades.
</description>
</item>

     
        <item>
  <title>Templates em C no lugar de macros</title>
  <link>http://www.caloni.com.br/templates-em-c-no-lugar-de-macros/</link>
  <pubDate>2016-01-14</pubDate>
  
  <guid>http://www.caloni.com.br/templates-em-c-no-lugar-de-macros/</guid>
  <description>A grande vantagem dos templates é manter o tipo de seus argumentos. Infelizmente, eles não existem na linguagem C, mas podem ser usados em construções C feitas com a linguagem C&#43;&#43;, como ocorre com quem desenvolve device drivers para Windows.
Imagine, por exemplo, a estrutura LISTENTRY.aspx), que é uma tentativa de generalizar não só o tipo de uma lista ligada, como seu posicionamento:
A lógica por trás de LISTENTRY é que esse membro pode ser inserido em qualquer lugar da estrutura que representará um elemento. Ele pode estar realmente no meio do elemento, pois isso não importa, desde que você saiba voltar para o começo da estrutura. Isso é útil quando um elemento pode fazer parte de diferentes listas.
OK, temos uma lista ligada cujo head está inicializado. Para inserir um novo item, podemos usar as rotinas InsertHeadList, AppendTailList, RemoveEntryList, PushEntryList, PopEntryList, etc. Enfim, uma infinidade de rotinas já cuidam disso para a gente.
O que não temos é como acessar o elemento. Para isso usamos um truque bem peculiar na linguagem C, já disponível também em kernel:
Basicamente a macro obtém a partir do endereço zero o offset do membro que é a entrada da lista ligada e subtrai esse ofsset do endereço do próprio campo, ganhando de brinde o tipo de sua estrutura. Usando a macro com nossa estrutura:
Note que entry é o nome, literal, do membro na estrutura, e não há maneira possível com templates de obter isso. A solução? Usar um nome padronizado. O resultado final pode ser parecido com este:
Em ação:
&amp;quot;Nossa, tudo isso para substituir uma macro já consagrada no WDK??&amp;quot; Sim, nesse post o objetivo não ficou muito útil. É apenas uma ideia de substituição possível de ser feita em macros em geral. Pode ser bem documentada, usada há 30 anos, mas ainda é uma macro. Meu conselho: se funciona bem, use. Se vai fazer algo novo, tente sempre templates.
</description>
</item>

     
        <item>
  <title>Gabaritos</title>
  <link>http://www.caloni.com.br/gabaritos/</link>
  <pubDate>2016-01-13</pubDate>
  
  <guid>http://www.caloni.com.br/gabaritos/</guid>
  <description>Um template -- ou, como é na tradução da primeira edição de The C&#43;&#43; Programming Language, de Bjarne Stroustrup, aqui no Brasil: gabarito -- é um molde que pode ser usado por diferentes tipos para traduzir o mesmo algoritmo, ou pelo menos a mesma intenção de algoritmo (por pela sobrecarga de operadores é possível que o comportamento de tipos diferentes pode ser diferente).
Em C&#43;&#43;, fazer uma função template é muito simples:
Continuando nosso tema de fazer as mesmas coisas em C, templates não é tão simples, pois não existe de fato na linguagem. Templates são interpretados pelo compilador, que gera um esqueleto de algoritmo que é usado para preencher código de todos os tipos utilizados. Em C isso era feito usando macros. Porém, macros não fazem parte da linguagem C. É apenas uma ferramenta chamada pré-processador que substitui texto antes do programa ser compilado. É através do pré-processador que, por exemplo, os headers são incluídos em um código-fonte. Isso já foi explicado em um artigo bem velhinho, e mais recentemente em uma palestra.
Eu não recomendaria usar macros em C&#43;&#43;, assim como não recomendo em C. Porém, em C é a única opção para reciclar algoritmos de maneira estática. Exceto se você usar ponteiros de função, o que adiciona pouco overhead, mas se perde, assim como a técnica de macro, a informação dos tipos. A própria libc contém uma função, qsort, que é &amp;quot;genérica&amp;quot; através do uso de ponteiros sem tipo (void*) e ponteiro de função. A função ordena elementos de uma lista, mas para isso depende da função de comparação que é passada por parâmetro. Essa função recebe dois void* que deve comparar. Além disso, o leiaute na memória tem que ser fixo, contínuo, pois é assim que a função consegue mover os elementos. Ou seja, bem limitado.
Dessa forma, não pretendo ensinar a usar &amp;quot;templates&amp;quot; em C, mas a usá-los em C&#43;&#43; com foco em C. Um amigo conhecido de vocês, o Fernando/DriverEntry, utilizou essa técnica com maestria em alguns códigos kernel-mode que ele desenvolveu, e é uma maneira válida de se aproveitar de uma linguagem mais &amp;quot;alto nível&amp;quot; como C&#43;&#43; em ambientes limitados como o código que trabalha com o S.O.. Como a API do kernel lida com abstrações em C, seus objetos necessariamente não são objetos no sentido C&#43;&#43;, mas os famigerados &amp;quot;ponteiros opacos&amp;quot;.
Mais sobre isso em um próximo post.
</description>
</item>

     
        <item>
  <title>Classe, objeto, contexto, método, polimorfismo</title>
  <link>http://www.caloni.com.br/classe-objeto-contexto-metodo-polimorfismo/</link>
  <pubDate>2016-01-12</pubDate>
  
  <guid>http://www.caloni.com.br/classe-objeto-contexto-metodo-polimorfismo/</guid>
  <description>No post anterior implementamos &amp;quot;métodos&amp;quot; em C usando ponteiros de função dentro de structs que eram passadas como parâmetro. Tudo isso embutido por um compilador que gera o que chamamos de instância de uma classe, ou objeto, em C&#43;&#43;. Isso é possível graças ao contexto que é passado para uma função (que no caso de C&#43;&#43; é o operador implícito this, que sempre existe dentro de um método não-estático).
Para objetos não-polimórficos, o C&#43;&#43; não precisa mudar essa tabela de funções que os objetos de uma classe contém. No entanto, quando há pelo menos um método virtual, surge a necessidade de se criar a famigerada vtable, ou seja, justamente uma tabela de ponteiros de função, que dependem da classe instanciada (base ou algumas das derivadas). Se uma classe derivada sobrescreve um método de alguma classe base, é o endereço desse método que irá existir na vtable. Já vimos isso há muito tempo atrás escovando os bits da vtable direto no assembly e na pilha.
Como você deve imaginar, é possível também fazer isso em C. Basta mudar os endereços das variáveis do tipo ponteiro de função que estão na struct usada como contexto. Para ficar o mais próximo possível do &amp;quot;modo C&#43;&#43;&amp;quot; de fazer polimorfirmo, podemos escrever hardcoded a tal vtable para os diferentes tipos de &amp;quot;classe&amp;quot;:
A versão C ainda tem a vantagem de não precisar de uma vtable const (embora seja adequado em situações normais de temperatura e pressão). Os &amp;quot;métodos&amp;quot; poderiam mudar caso algum estado mudasse, alguma exceção fosse disparada, mantendo o mesmo contexto, mas um comportamento (vtable) diferente. Quem utiliza muito essa estratégia é o kernel do Windows, que mexe com estruturas que contém não apenas listas ligadas genéricas, mas funções de callback que não apenas o código da Microsoft precisa chamar, mas os próprios drivers de terceiros que se preocupam com bom comportamento e guidelines que tornam o SO rodando perfeitamente.
O importante deste artigo é demonstrar como conceitos aparentemente complicados ou escondidos de uma linguagem como C&#43;&#43; podem ser compreendidos completamente utilizando apenas linguagem de alto nível no bom e velho C. Essa estratégia de descer camadas de abstração, como verá, funciona para linguagens de mais alto nível, como C# ou Java, pois ambas são implementadas em linguagens como C&#43;&#43;. No fundo, engenharia de software é um universo multi-camadas transitando pela última camada que conhecemos -- a física. Pelo menos a última camada que ainda conhecemos.
</description>
</item>

     
        <item>
  <title>Classe, objeto, contexto, método</title>
  <link>http://www.caloni.com.br/classe-objeto-contexto-metodo/</link>
  <pubDate>2016-01-11</pubDate>
  
  <guid>http://www.caloni.com.br/classe-objeto-contexto-metodo/</guid>
  <description>No post anterior falamos como a passagem de um endereço de uma struct consegue nos passar o contexto de um &amp;quot;objeto&amp;quot;, seja em C (manualmente) ou em C&#43;&#43; (automagicamente pelo operador implícito this). Trocamos uma propriedade desse &amp;quot;objeto&amp;quot; em C, mas ainda não chamamos um método.
Hoje faremos isso.
Isso é relativamente simples quando se conhece ponteiros de função, existentes tanto em C quanto em C&#43;&#43;. Ponteiros de função são tipos que contém endereço de uma função com assinatura específica (tipo de retorno e de argumentos). Através de um ponteiro de função é possível chamar uma função e passar alguns argumentos. Como o contexto nada mais é que um argumento, será só passá-lo como parâmetro.
No exemplo anterior não sabíamos como chamar um método de nosso &amp;quot;objeto&amp;quot; em C:
Isso se torna fácil se tivermos uma nova &amp;quot;propriedade&amp;quot; na nossa struct que é um ponteiro para a função que queremos chamar.
Parece muito trabalho para algo que é feito &amp;quot;automagicamente&amp;quot; em C&#43;&#43;, certo? Certo. Porém, agora sabemos o que acontece por baixo dos panos em C&#43;&#43; e que pode ser feito em C (ainda que &amp;quot;na mão&amp;quot;). Você provavelmente nunca fará esse tipo de código em C para emular C&#43;&#43;, mas o objetivo desse código é entender como funciona, por exemplo, a vtable do C&#43;&#43;, que permite polimorfismo.
Mas esse é assunto para outro post.
</description>
</item>

     
        <item>
  <title>Classe, objeto, contexto</title>
  <link>http://www.caloni.com.br/classe-objeto-contexto/</link>
  <pubDate>2016-01-10</pubDate>
  
  <guid>http://www.caloni.com.br/classe-objeto-contexto/</guid>
  <description>Para entender conceitos simples em C&#43;&#43;, como métodos de uma classe, ajuda muito seguir o raciocínio dos programadores C e como eles lidavam com o tipo de problema que C&#43;&#43; resolve elegantemente implementando um novo compilador com uma nova linguagem. Tomemos, por exemplo, métodos. Um método é uma função chamada dentro de um contexto. Qual o contexto? O objeto. Ou seja, uma instância específica de uma classe, que é um molde para se fazer alguma coisa.
Para obter esse contexto, existe uma palavra-chave reservada dentro dos métodos que é o this, que está tão incrustado na linguagem que não precisa ser usado explicitamente: quando referenciamos alguma propriedade (ou um outro método) da classe, só pelo fato de estarmos dentro de um método o compilador já entende que se trata do mesmo objeto, ou mesmo contexto.
E contexto nesse sentido nada mais é que um endereço na memória para alguma coisa que nos interessa. Tal qual uma função API do Windows -- tal qual FindFirstFile.aspx) -- que recebe ou retorna uma struct com o que precisamos, esse geralmente é o contexto procurado.
No caso de nós, que escrevemos uma &amp;quot;classe&amp;quot;, o contexto é recebido &amp;quot;de fora&amp;quot;:
Tal como uma struct que definimos, ela vira o contexto. Da mesma forma, um objeto de uma classe em C&#43;&#43; é esse contexto. Podemos fazer a mesma coisa em C, com o trabalho adicional de especificar o &amp;quot;this&amp;quot; (isto é, o ponteiro para o contexto/struct):
Em um próximo post vamos ver como fazer para chamar MeuOutroMetodo a partir de uma estrutura em C.
</description>
</item>

     
        <item>
  <title>Como ser um hacker</title>
  <link>http://www.caloni.com.br/como-ser-um-hacker/</link>
  <pubDate>2015-11-18</pubDate>
  
  <guid>http://www.caloni.com.br/como-ser-um-hacker/</guid>
  <description>Talvez as pessoas estejam com preguiça de ler. Talvez estejam apenas inundadas por tanta informação que temos hoje. Talvez seja apenas falta de foco pelas interrupções consecutivas de novos &amp;quot;espertofones&amp;quot; ou nossas redes sociais viciantes, pois oferecem muito a troco de nada.
O fato é: se você precisa perguntar para alguém (no caso, eu) o que é preciso fazer para se tornar um hacker, algo como um guia passo-a-passo, eu vou encarar o desafio numa boa, pensar por alguns dias, semanas e talvez meses, e chegar à conclusão que a pessoa que precisa que alguém lhe ensine está percorrendo o caminho errado. Ela nunca vai aprender o suficiente para se tornar algo que possa ser chamado de hacker.
E o que é hacker, que mal lhe pergunte? Há uma definição curta e simplista, há a definição do botão (que eu nunca mais vou me esquecer) e há o Jargon. O que é o Jargon? É um guia dos primórdios da web que contém tudo que você precisa saber sobre o jargão hacker. Duvida? Leia ele primeiro.
Falar em jargão me faz lembrar do nostálgico e muito curioso (e que já falei em outros artigos) Barata Elétrica, o fanzine jurássico de Derneval Ribeiro que consistia em copy&amp;amp;paste de partes interessantes da rede, em inglês e português, e um pouco da cultura hacker na América do Sul (sobretudo Buenos Aires) e sobre a vivência de seu editor no ambiente uspiano. Derneval pode até não ser um &amp;quot;hacker de verdade&amp;quot; (só pra citar a falácia do escocês), mas ler o Barata Elétrica me deu não conhecimentos técnicos, mas muito sobre a nossa era da informação, como informação é vital hoje em dia, além de outros conceitos interessantes que nos fazem ficar atentos para privacidade, governos, política, economia, filosofia, etc. Acho que foi lá a primeira vez que tive contato com 1984, PGP, Mitnick. Enfim, curiosidade, piadas e um pouco do clima social que a web tinha (para mais disso, nada como saudoso mIRC...).
Para quem pretende se tornar um hacker, já deve ficar claro que não existe receita de bolo, nem lista de conhecimentos desejáveis. Isso não e uma vaga para preenchimento de currículo. Isso é a vida real. Se existe uma receita, ela é vaga e de auto-ajuda:
 Primeiro você aprende a gostar de viver de acordo com a definição abaixo. Viver é a busca incessante de conhecimento em todas as suas formas, uma autodescoberta e a busca da felicidade pessoal e instransferível, subjetiva e inalienável. Com base nisso, comece a aprender profundamente sobre tudo o que deseja, em todas as áreas, sobre qualquer assunto, pessoa, lugar. Repita o passo anterior até que a inescapável morte aconteça; o resto é mistério.  Parece meio poético e filosófico, mas não é. Se eu te disser que para ser hacker precisa aprende a crackear programas no Windows, fuçar no WinDbg e esmiuçar a API Win32, disassemblar códigos em binário com o IDA e usar no percurso todas as ferramentas, sistemas operacionais, linguagens de programação e conhecimentos periférios necessários, vai ser apenas uma descrição pessoal que não te levará à satisfação que talvez você deseja nessa jornada. Se sua única satisfação será poder dizer que é um hacker, sinto muito, isso é inútil. Você não está procurando viver por si mesmo, mas se auto-promover sem conhecimento de causa do que realmente a palavra significa. Esqueça o assunto e vá ler um livro. Ou melhor dizendo, vá navegar em sua rede social favorita...
</description>
</item>

     
        <item>
  <title>Indexando símbolos com rapidez</title>
  <link>http://www.caloni.com.br/indexando-simbolos-com-rapidez/</link>
  <pubDate>2015-10-28</pubDate>
  
  <guid>http://www.caloni.com.br/indexando-simbolos-com-rapidez/</guid>
  <description>Trabalhar com inúmeros projetos de diferentes clientes e diferentes binários pode ser uma loucura. Quando o mundo é Windows, algumas medidas precisam ser padronizadas para evitar a perda de informação durante todo o processo de desenvolvimento, testes, deploy e manutenção.
A respeito do deploy e manutenção, um dos principais é manter o código sempre atualizado, limpo e asseado, além de estar dentro de pelo menos um controle de fonte, de preferência distribuído (Mercurial, Git, Bazaar).
Porém, voltando ao mundo Windows, os fontes não são apenas a única fonte de preocupação e zelo. Os binários também são importante. Binários eu digo os EXEs, DLLs geradas, além dos seus símbolos (PDBs), que contém o mapa entre aquele monte de 1s e 0s e o código-fonte de onde ele saiu.
Nós da BitForge costumamos pelo menos indexar binários com fonte, através dos resources do binário. Como isso é feito? Basicamente editando o arquivo RC na parte da versão do binário e inserindo o hash do commit usado para gerar aquele binário. Com isso qualquer binário produzido possui seu pai (&amp;quot;use the source, Luke!&amp;quot;). Usamos um script em Python muito simples e muito eficaz para isso, que indexa .NET e C&#43;&#43; (através do Visual Studio, mas não está com muitas amarras de ambiente):
Quando algum binário parar na máquina de algum cliente em algum lugar do universo, basta olhar para os detalhes pelo Windows Explorer, e ele estará lá.
Através desses códigos em hexa podemos capturar o commit exato de onde saiu o binário. Tudo, é claro, confiando no procedimento de toda a equipe: apenas gerar um binário a partir de um commit publicado. Você também pode exibir a versão dos binários em uma pasta através das colunas do Windows Explorer.
Outro detalhe de binários é que eles vivem sendo sobrescritos. Todo &amp;quot;Project, Build&amp;quot; sobrescreve o binário anterior, que pode ter sido justamente o enviado para o cliente. Se o cliente não possuir nenhum procedimento de armazenamento de versões dos binários gerados (às vezes ele nem precisa, essa é nossa função) não há como obter os símbolos de binários que podem gerar problemas futuros (todo software tem bug).
Para resolver isso, o mínimo que se deve fazer é super-simples e nada difícil: crie uma pasta em algum lugar, nomeie essa pasta seu servidor de símbolos, a cada novo binário que será entregue, indexe o binário e os seus símbolos. Como? Com o &amp;quot;Debugging Tools for Windows&amp;quot;.aspx), como dizia um amigo meu, é mamão com açúcar:
Essa e outra técnicas de indexar fontes e binário você pode ver no meu projeto, artigo, palestra e vídeo de demonstração. Se você for cego, ainda tem a vantagem da áudio-narração do vídeo. Brincadeira, ainda não temos isso.
Com o poder do Windows Explorer, desde o Windows 95 podemos otimizar nossas tarefas nos baseando na extensão dos arquivos que estamos lidando. No caso do indexador de símbolos, eu simplesmente utilizo uma batch que contém exatamente a linha acima (com a diferença de %1 no lugar de MINHA-PASTA-COM-BINÁRIOS) que eu chamo direto do Explorer através de um comando que inseri no registro. Eis o comando:
Você pode seguir o passo-a-passo dessas linhas e gerar seu próprio registro. Após feito isso, surgirá um novo comando para qualquer DLL que você clicar com o outro botão do mouse. Você também pode gerar o mesmo comando para EXEs, bastando realizar o mesmo passo-a-passo na pasta exefile em vez de dllfile.
Procedimentos como esse devem ser uma coisa simples, não difícil. Programadores e pessoas são preguiçosas, e precisam de algum incentivo. E nesse caso, o incentivo é: o que você vai fazer quando der um crash com um binário que você não sabe de onde veio nem qual fonte foi usado para compilá-lo? Pois é.
</description>
</item>

     
        <item>
  <title>É o fonte, idiota!</title>
  <link>http://www.caloni.com.br/e-o-fonte-idiota/</link>
  <pubDate>2015-09-12</pubDate>
  
  <guid>http://www.caloni.com.br/e-o-fonte-idiota/</guid>
  <description>Saiu um artigo recente no The Old New Thing (thanks Strauss pelo tuíte) que fala sobre não misturar runtimes do C de diferentes versões do compilador (especialmente se essas versões estão separadas pelo tempo em nada mais nada menos que dezenove anos!). Concordo. Aliás, a cultura Microsoftiana do uso de binários carece em C/C&#43;&#43; de um fundamento que facilite o reúso e compartilhamento de código exatamente por essa incompatibilidade inerente de uma biblioteca, se não em constante evolução, em constante aprimoramento pontual (como a STL). Como compartilhar código cujo fonte esteja indisponível e cujas bibliotecas sejam incompatíveis porque o projeto não é atualizado há dois pares de anos? Fiz uma vez um artigo explicando como usar a LIBC nativa do sistema operacional (nem sei se isso funciona ainda, provavelmente não). No entanto, essa é uma solução sub-ótima para um problema latente.
É por isso que nesse caso a cultura Linux de compartilhamento do código-fonte acaba por ser a mais flexível e melhor adaptável à mudança dos tempos. Se você encontrou uma LIB que pode te ajudar, baixe e compile usando o último compilador. Se o compilador não consegue mais gerar binário sem gerar erros antes, configure os parâmetros de compilação como eram na época que a LIB foi gerada. A runtime do C (e de qualquer outro framework) que será usado é o da sua máquina. Afinal de contas, é o que faz mais sentido, não? Por que hoje existem diferentes conjuntos de DLLs de runtime de diferentes versões do Visual Studio instalados em sua máquina? Por que os instaladores precisam se preocupar em compartilhar essas DLLs corretamente?
Questões de um passado remoto que voltam a bater à porta sempre que a Microsoft resolve lançar um novo Visual Studio. E isso irá se tornar cada vez mais constante, já que versões com começo e fim bem-definidos são um conceito também antigo, quando comprávamos pela licença de uma versão específica do programa. E hoje, no modelo de assinaturas, como fica?
</description>
</item>

     
        <item>
  <title>O Estranho Caso do PDB Mal-Aformado</title>
  <link>http://www.caloni.com.br/o-estranho-caso-do-pdb-mal-formado/</link>
  <pubDate>2015-08-19</pubDate>
  
  <guid>http://www.caloni.com.br/o-estranho-caso-do-pdb-mal-formado/</guid>
  <description>Era uma vez, há 13 anos atrás, um tal de Visual Studio .NET, que iria trazer a felicidade para nós, meros mortais usuários de programinhas em C com ponteiro pra lá e ponteiro pra cá. Agora a Microsoft traria para o pessoal do &amp;quot;baixo nível&amp;quot; a mais nova novidade do verão: uma IDE lenta, bugada e... bonita?
Bem, para os que estavam acostumados com o Visual C&#43;&#43; 6.0, nada foi mais incômodo do que esperar carregar o programa de manhã para conseguir finalmente compilar. Ajustadas as expectativas, os projetos foram aos poucos migrados para aquela nova forma de configurar EXEs, DLLs, LIBs e OCXs.
E eis que alguém, muito provavelmente eu mesmo, naquele momento de inspiração, criei a seguinte configuração para a geração dos PDBs, os símbolos para depurar programas no Windows. C/C&#43;&#43;, Output File, Program Database File Name = &amp;quot;$(IntDir)/$(ProjectName).pdb&amp;quot;.
Faz sentido, não? Afinal de contas, o PDB costuma ter o nome do projeto, e ele já está setado até em outro lugar para gerar com o mesmo nome. Nada de novo no front. Em Linker, Debugging, Generate Program Database File vemos &amp;quot;$(OutDir&amp;quot;$(ProjectName).pdb&amp;quot;.
Até aí tudo bem. Aliás, tudo ficou muito bem por estranhos 13 anos. Até que alguém decidiu migrar para o já não tão novo Visual Studio 2013, onde tudo correu muito bem por algumas horas... talvez 13. Até que a depuração de repente parou de funcionar.
Será o benedito? Ou o co-piloto?
Pesquisando nos fóruns da vida, antro dos desesperados, achei/lembrei de um comando muito útil no WinDbg que não apenas diz se os símbolos estão &amp;quot;mismatch&amp;quot;, ou seja, os símbolos ou o PDB não está combinando com o EXE, mas também por quê.
Bom, para saber se está mismatch é aquela fórmula de bolo:
Para saber o que está errado, o famigerado !IToldYouSo
Mano, como assim?!?!? Eu acabei de compilar esse binário, eu já apaguei 15 vezes as pastas de Debug e Release, eu já rebootei mais do que o Windows me obriga a rebootar por causa das falhas de segurança.
Pois, então, desesperançado, crio um projeto novo para comparar as configurações, e voltamos 13 anos atrás, naquele fatídico dia, e entendo por que o nome do PDB temporário não é igual. Bom, na verdade não entendo, mas intuo que tenha alguma relação:
E, de fato. Solução? Copie as configurações usuais do &amp;quot;novo&amp;quot; Visual Studio comparando com o velho.
Abaixo a chamada do suporte em inglês, se alguém achar o mesmo problema em algum fórum e quiser &amp;quot;espalhar a palavra&amp;quot;.
 Just got stuck in the same problem, but in a C&#43;&#43; source that has 13 years, where its first solution was in VS 2003. Comparing the Project Properties in C/C&#43;&#43;, Output Files, Program Database File Name, I found out that the project was pointing to the same file path that Linker, Debugging, Generate Program Database File, when the normal situation is to generate a vc120.pdb. Comparing with a new project, the &amp;quot;right&amp;quot; value can&#39;t be $(OutDir)$(TargetName).pdb (ou ProjectName), but $(IntDir)vc$(PlatformToolsetVersion).pdb. That solved the problem. I hope solve another one&#39;s problem as well =) Minha próxima tarefa, aparentemente, é ver como sendo sócio da BitForge e da Intelitrader, e mesmo tendo já atualizado meu perfil MVP há anos, continuo sendo funcionário da UOL Diveo/Broker =/
 </description>
</item>

     
        <item>
  <title>Você sabe o que está usando no seu código?</title>
  <link>http://www.caloni.com.br/voce-sabe-o-que-esta-usando-no-seu-codigo/</link>
  <pubDate>2015-07-28</pubDate>
  
  <guid>http://www.caloni.com.br/voce-sabe-o-que-esta-usando-no-seu-codigo/</guid>
  <description>Quando se mexe com C&#43;&#43; em múltiplos fontes logo vem aquela bagunça do versionamento e do compartilhamento de código. LIBs, DLLs, COMs (de Component Object Model, da Microsoft). É difícil a partir de um binário saber quais os fontes envolvidos em sua construção, a não ser que você os amarre através de um sistema automatizado de build onde todos os binários devem ser obrigatoriamente compilados (e suas dependências, claro).
Porém, há maneiras mais descentralizadas de se trabalhar. Alguém poderia simplesmente colocar a versão em cada CPP e atualizá-la, assim como comentários de histórico, toda vez que alguma mudança for feita:
OK, esse já é um modelo interessante, embora totalmente descartável se você já usa um sistema de build atrelado a um controle de fonte, já que você automaticamente já terá um número mágico para relacionar seus binários: o revno de seu commit (ou seus commits, no caso de mais de um repositório).
Uma versão um pouco mais... &amp;quot;binária&amp;quot;, seria inserir uma string no próprio fonte com essa versão, e talvez até o nome de seu módulo/lib/etc:
static const char* LIBVERSION = &amp;quot;minhalib 0.0.1&amp;quot;;
Dessa forma, por pior que seja a situação do controle de seus binários, sempre haverá a possibilidade de procurar a string lá dentro.
Ops, esqueci que nesses compiladores modernos o que você não usa não será incluído no binário final. Isso quer dizer que se quisermos que essas strings de identificação de dependências apareça no binário compilado precisamos pelo menos dar a impressão de que ele esteja sendo usado:
Agora uma variável estática do módulo deverá ser inicializada como um objeto da classe Using e irá jogar em uma variável estática dentro do construtor. Se ela será usada fica a dúvida do compilador, que deixa tudo como está. Ou seja, ganhamos nossa string no binário:
Uma solução mais genérica pode ser aplicada utilizando as famigeradas macros e...
O quê?!?!?!??! VOCÊ DISSE MACROS?!???!? TÁ MALUCO??!??!
Sim. Macros. São inofensivas se você usar direito.
E se reclamar vai ter goto.
A ideia é que qualquer pedaço de código, seja um conjunto de CPPs que você chama de LIB, ou um CPP que você compila em diferentes projetos (talvez em cópias diferentes ainda sendo usadas), ou até aquela função-chave, ou classe-chave. Na verdade, quando eu digo pedaço de código, é pedaço mesmo. Está livre para você imaginar e rotular o que quiser. Depois você consegue dar uma geral no resultado:
Com esse simples mecanismo que não gasta mais do que algumas chamadas de assembly no início da lib (antes do main) e o espaço ocupado na memória pelas strings somadas (menos de 1KB, provavelmente) você tem em suas mãos uma poderosa ferramenta de análise de como os binários estão sendo gerados pela sua equipe remota, ou por qual configuração foi usada na máquina de build para gerar aquela DLL com aquele problema antigo, ou porque algo que funcionava parou de funcionar e nada foi mexido (isso nunca acontece, não é mesmo?).
O código dessa brincadeira está no meu repositório de samples do GitHub.
</description>
</item>

     
        <item>
  <title>Logs em serviços (e outras coisas)</title>
  <link>http://www.caloni.com.br/logs-em-servicos-e-outras-coisas/</link>
  <pubDate>2015-06-05</pubDate>
  
  <guid>http://www.caloni.com.br/logs-em-servicos-e-outras-coisas/</guid>
  <description>Já uso logs há muito tempo. Me lembro muito bem que quando programava em BASIC o &amp;quot;passou por aqui&amp;quot; já era útil. Depois de fazer muitas bibliotecas super-flexíveis de escrita em saídas diferentes, níveis configuráveis e uso do mais complexo ao mais banal, cheguei à seguinte conclusão:
Vou tentar defender meu ponto de vista.
Esse artigo do Dr. Dobbs explica de uma maneira bem completa como fazer uma lib de log leve e configurável. O que eu peguei desse exemplo foi a forma mais C&#43;&#43; de formatar as linhas, deixando para trás o estilão printf que depois de variadic templates já está datado.
Por que eu acho a minha versão mais legal (não valendo falar que foi porque eu fiz):
 É mais simples ainda, tem poucas linhas e pode ser copiada sem peso na consciência. Pode até estar em um header que o overhead é mínimo. Não requer configuração de arquivo, debug output, named pipe, etc. Isso tem a ver com o uso de cada um. O próximo motivo explica melhor isso. Se for executado em um prompt já exibe as informações para serem filtradas; se for executado como um serviço encapsulo a saída.  Encapsular a saída e o comportamento de um serviço hoje em dia é algo banal. Há diversos programas que fazem isso para você, sendo desnecessário programar toda aquela parte de comunicação com o Windows. O cara do DriverEntry (vulgo o kernel-mode programmer motta-focka Fernando) fez um aplicativo que faz isso, que é simples de usar e continua funcionando no Windows 8.1. Atualmente uso um outro encontrado pelo igualmente fodástico Rodrigo Strauss: o Non Sucking Service Manager (seu nome já explica por que defendo utilizar o mínimo possível das firulas da Microsoft).
Além de ser extremamente flexível e não ter falhado nas vezes que o utilizei, o NSSM consegue redirecionar a saída do aplicativo que encapsula como um serviço para um arquivo e rotacionar o arquivo por tamanho ou data (ou reexecução do serviço). Abaixo uma receitinha básica para configurar seu aplicativo:
(para quem está se perguntando, 10485760 bytes são 10 MB.)
Com essa forma de fazer serviços, há uma dupla vantagem:
 Retirar todo o código para lidar com o Service Manager do Windows das suas mãos. Continuar tendo um aplicativo que roda pelo prompt e já imprime seu comportamento (e pode ser redirecionado também).  E ainda uma vantagem-bônus:
 Você pode executar programas-filho que o redirect para o log vai funcionar do mesmo jeito.  Acho que cada um deve escrever no seu header o que achar melhor para depurar seus programas. No entanto, acho válido compartilhar quais são as informações que tem sido úteis para mim:
</description>
</item>

     
        <item>
  <title>Depurando até o fim do mundo e de volta de novo: source server com GitHub</title>
  <link>http://www.caloni.com.br/depurando-ate-o-fim-do-mundo-e-de-volta-de-novo-source-server-com-github/</link>
  <pubDate>2015-05-26</pubDate>
  
  <guid>http://www.caloni.com.br/depurando-ate-o-fim-do-mundo-e-de-volta-de-novo-source-server-com-github/</guid>
  <description>Semana passada fiquei sabendo que o vídeo da minha palestra &amp;quot;Depurando até o fim do mundo&amp;quot; do TDC 2014 estava disponível online. Resolvi assistir para ver se aprendia alguma coisa. A despeito do palestrante ser muito ruim, ele disse uma coisa interessante: com o Debugging Tools (WinDbg para os íntimos) seria possível além de indexar os símbolos (PDBs para os íntimos) usando o esquema de Symbol Server que a própria Microsoft adota usar algumas ferramentas embutidas para conseguir obter o fonte através de um símbolo indexado.
E de onde viria esse fonte? Bom, a priori é necessário que exista algum controle de fonte para que as versões estivessem já &amp;quot;indexadas&amp;quot; nesse controle e fossem mapeados com strings internas no PDB. Através dessas strings o WinDbg ao analisar um crash dump ou até mesmo depurando um processo com o uso do PDB conseguiria baixar os fontes automagicamente desse controle de fonte, desde que ele estivesse acessível (na internet, na intranet da própria empresa, na rede, em um disco rígido externo ou na própria máquina do desenvolvedor que não quer se matar para conseguir obter a versão exatada dos fontes daquele binário).
O detalhe que o palestrante (Caloni é o nome do sujeito) citou era que já existiam scripts prontos para realizar essa tarefa para os controles de fonte mais comuns, sendo que os mais comuns são: Source Safe (?????), CVS (????????) e, claro, Subversion! (?!?!?!?!??!??!?!).
OK, pelo visto o pessoal da Microsoft mora em uma caverna ou não estão muito interessados em indexar os fontes para alguns controles de fonte que estão surgindo por aí, como Git sendo um exemplo aleatório.
Já que o tal do Caloni disse que ainda não fizeram scripts para controles mais modernos. Nenhum descentralizado ainda está na lista. Os scripts são feitos em Perl, ou seja, estão disponíveis em uma linguagem um pouco mais fácil que .BAT. Ou talvez não. De qualquer forma, não parece muito difícil de entender a dinâmica do WinDbg e simplesmente gerar o que tem que gerar dentro dos PDBs.
Pensando nisso, resolvi fazer uma primeira versão, em Python, de um script em que você passa alguns dados e ele processa seus PDBs. Depois você pode jogá-los em um Symbol Server e quando o WinDbg encontrá-lo através de um binário analisado, este irá conter o endereço no GitHub e um comando do Curl para baixá-lo, passando a exibi-lo imediatamente na tela do WinDbg. E nada mais lógico do que criar um repositório no GitHub para compartilhá-lo, certo?
O funcionamento é muito simples, mas pede muitos parâmetros (recomendo criar um batch para armazená-los). Então vejamos:
 dbgtools é o caminho onde está o Debugging Tools for Windows; pdbpath é o caminho de onde devem ser pegos os PDBs, como um output da vida; projname é porque preciso do nome do projeto com escopo do usuário para compor a URL, e.g. Caloni/GitIndex; repo é o caminho do repositório local, pois o remoto eu já consigo pegar com o projname.  Um detalhe importante: o revno que será usado é o HEAD do repositório local. Sim, futuramente podemos adicionar esse argumento como opcional. Porém, no momento, coisas mais urgentes devem ser feitas. Uma delas é que estou usando a visualização raw do GitHub para conseguir pegar um único arquivo-fonte, e para isso uso a ferramenta curl. Ou seja, quem é de Windows vai precisar baixar uma de suas versões e deixar no path do sistema. Quem não é de Windows... o que você está fazendo com um PDB, rapaz?
Como esse ainda é um projeto muito cru, mas gostaria de compartilhar com vocês (pois algo muito cru é melhor que nada), deixei diversos batchs de teste para ficar mais claro o funcionamento do srcsrv. Há um doc muito bom (er... ou mais ou menos) sobre o seu funcionamento na pasta srcsrv (chama-se srcsrv.doc). Usei algumas informações de lá para conseguir fazer a coisa funcionar. Se quiser me ajudar no projeto, tiver alguma dúvida, sugestão de melhoria/evolução, vamos conversar! Esse projeto será muito útil para mim no futuro, e espero que seja muito útil para outras pessoas, também.
</description>
</item>

     
        <item>
  <title>Analisando erros pelo filtro do File Monitor</title>
  <link>http://www.caloni.com.br/analisando-erros-pelo-filtro-do-file-mon/</link>
  <pubDate>2015-05-06</pubDate>
  
  <guid>http://www.caloni.com.br/analisando-erros-pelo-filtro-do-file-mon/</guid>
  <description>As ferramentas da SysInternals fazem a gente economizar um tempo considerável na resolução de problemas. Não que elas sejam indispensáveis. Tudo que elas fazem é encurtar o caminho entre a análise de um bug e sua resolução, o que acaba sendo muito se considerarmos que programação é 20% codificação e 80% transpiração. Ela é um atalho para muitas coisas, desde achar uma ordem de includes no header errada durante a compilação ou descobrir que por que um processo morreu durante o login.
Curiosamente ambos os exemplos que citei são de uma mesma ferramenta: Process Monitor, ou carinhosamente procmon. Ele é um filho de duas ferramentas hoje extintas, FileMon e RegMon (acho que não preciso explicar o que ambas faziam). Todas são baseadas em drivers que escutam eventos do sistema operacional e um aplicativo que mastiga essa informação e as filtra de diferentes e criativas formas. Vamos utilizá-lo depurando um instalador muito sacana.
A SoSo Company é uma empresa criada na China e que possui programadores muito bons. Eles são altamente especializados em fazer instaladores, e nas horas vagas ainda fritam pastéis de frango (ou &amp;quot;flango&amp;quot;, como os nativos costumam chamar). Porém, alguma coisa está acontecendo com uma nova versão do instalador que está dando erro ao rodar o aplicativo após atualizado.
Isso só acontece em algumas máquinas, na maioria delas tudo funciona perfeitamente. Tanto que esse erro só foi encontrado depois de centenas máquinas terem sido atualizadas. E o primeiro a descobrir esse erro foi um cliente muito importante para a Soso. Entre as máquinas desse cliente muito importante, o erro foi acontecer justamente na máquina do CEO da empresa. (Qualquer semelhança com a vida real não é mera coincidência.)
O analista Juquinha, do suporte técnico terceirizado na Índia sul-americana, foi chamado para dar uma olhada nesse problema. Como os chineses não confiam em um não-comedor de pastel de flango, Juquinha não terá acesso ao código-fonte do produto, mas poderá dar uma espiada no instalador. Ei-lo:
Ahhh, bom. O instalador copia tudo e não verifica erro nenhum. Afinal de contas, o que pode dar errado, não é mesmo?
Vamos agora dar uma olhada no código do aplicativo, coisa que nosso analista não terá a oportunidade.
O produto é constituído de três binários: myapp.exe, myanotherapp.exe e mydll.dll. Os dois executáveis usam a DLL (no bom sentido). Cada um deles chama a DLL para realizar algumas operações.
Na DLL há apenas uma função exportada: Version1. Quer dizer, na versão sendo atualizada foi criada uma nova função, a Version2. Vejamos a versão final:
Como já vimos, o instalador da SoSo não está muito preocupado em capturar erros. Haja o que houver, o mundo continua maravilhoso. Porém, depois da atualização esse erro explodiu na máquina do diretor. E agora?
Sem saber muito bem o que fazer, mas com a possibilidade de testar a situação em uma nova máquina (de outro diretor), Juquinha resolveu rodar novamente o instalador, mas dessa vez com a companhia do ProcMon.
Depois disso, para efeito de comparação, rodou o instalador em uma máquina qualquer onde a atualização funciona.
Dica: Quando for comparar muitos eventos (ex: milhares), em vez de olhar um por um é mais fácil exportar para um CSV e deixar um comparador como o [WinMerge}(http://winmerge.org/) fazer o serviço. No entanto, para comparar muitas informações, algumas colunas precisam ser eliminadas, como o horário de execução dos eventos e o PID dos processos.
E voilà! Parece que alguém está bloqueando a atualização de mydll, embora myapp conseguisse ser atualizado (logo concluímos que não é ele).
Agora, se Juquinha é um analista de nível 1, ele precisará compartilhar suas descobertas com outras pessoas da equipe. Para isso, basta duplo-clicar em um evento e usar o botão de cópia. O resultado será um texto com todas as informações necessárias para uma análise aprofundada.
OK, mas onde está o problema? Bom, aqui começa a pesquisa, mas se você já programou para Windows API já há algum tempo sabe que alguém abriu esse arquivo antes com um modo de compartilhamento incompatível com uma escrita (que é o que o nosso instalador tenta fazer). Para saber quem é o culpado, mais uma ferramenta da SysInternals vem a calhar: Process Explorer (eu ia dizer handle.exe, mas ele não funcionou em meus testes).
Através da opção de menu Find, Find Handle or DLL o culpado se mostrou mais próximo do que imaginávamos. O myanotherapp.exe fica bloqueando a dll no momento da atualização! Na verdade, o grande culpado foi mesmo o programador desse instalador, que sequer tem ideia das centenas de erros que podem ocorrer durante uma instalação/atualização. Azar do suporte técnico desse produto =/
</description>
</item>

     
        <item>
  <title>Convenção de Chamada</title>
  <link>http://www.caloni.com.br/convencao-de-chamada/</link>
  <pubDate>2015-04-20</pubDate>
  
  <guid>http://www.caloni.com.br/convencao-de-chamada/</guid>
  <description>Pergunta de um leitor:
Resposta do Autor: Por que C é zoado :P
OK, a verdade é que não existem (existiam?) muitas regras de sintaxe a serem respeitadas na linguagem pelo compilador. Antigamente, se não fosse colocado nenhum tipo de retorno era como se ele fosse int por default. Da mesma forma, se não colocar parâmetros vale tudo. É como se fossem os três pontinhos do printf. Afinal, você não ia querer ficar repetindo os parâmetros no .c e no .h, não é mesmo :D
Isso me lembra também que havia a declaração &amp;quot;arcaica&amp;quot; da linguagem (já era arcaica antes mesmo do padrão de 1998 sair):
Sim, sua suposição a respeito do vaargs faz todo sentido. E não, os parâmetros não são inutilizados justamente porque a função chamada pode fazer o que quiser que no retorno o chamador limpa a pilha (e o chamador sabe como ele empilhou os parâmetros-extra).
O padrão de chamada da linguagem (lembra disso?) é cdecl. Isso quer dizer que o chamador é que &amp;quot;limpa a sujeira&amp;quot; depois da chamada. Isso é o que permite o &amp;quot;milagre&amp;quot; do printf (oooohhh ooohh oooooohhhh... sons de anjos cantando) receber n argumentos.
Só vai dar problema se definir outro padrão de chamada ou se a função chamada mexer no que não devia (se esperar outros tipos ou número de argumentos, por exemplo).
Agora que sabemos disso, o comportamento do valist nem deve parecer tão mágico assim. Na verdade, apenas saber que a pilha é onde estão todas as variáveis locais e os endereços de retorno das funções é o suficiente para explorar essa área de memória.
Porém, o uso canônico na linguagem C e a forma mais educada de navegar nos parâmetros extras é usando o header stdarg.h. Isso porque C é uma linguagem independente de plataforma, e a priori não temos a mínima ideia de como os dados estão estruturados no computador. Essa visão das variáveis locais e etc é apenas algo que sabemos sobre a arquitetura PC (8086) porque já brincamos demais de assembly e seus registradores.
Uma versão de quem já manja dos internals da arquitetura onde está programando e não se importa com portabilidade poderia simplesmente caminhar pela pilha a partir do endereço de argc.
Repetindo: isso não é bonito, apesar de simpático. No entanto, se o objetivo é explorar a arquitetura, fique à vontade para navegar pela pilha a partir do endereço das variáveis locais.
</description>
</item>

     
        <item>
  <title>Guia de alocação (nos clientes)</title>
  <link>http://www.caloni.com.br/guia-alocacao-nos-clientes/</link>
  <pubDate>2015-03-04</pubDate>
  
  <guid>http://www.caloni.com.br/guia-alocacao-nos-clientes/</guid>
  <description>Se você trabalha com T.I. (nem precisa ser programação) e mora em São Paulo (ou qualquer outro lugar com pessoas paranoicas) então talvez em algum momento da sua carreira teve que ficar alocado (como uma memória que contém um vírus) em algum de seus clientes (ou da empresa onde trabalha/ou). Usando seus apetrechos pessoais dentro de uma mochila para zarpar no final do dia sem deixar rastros.
Não é muito elegante deixar seus logins, seu perfil, seus favoritos e histórico no navegador que está usando, além de ser uma falha de segurança, já que trocar a senha de um perfil no Windows é procedimento natural , além da própria segurança do SO deixar a desejar em alguns momentos. Por isso, segue algumas dicas que tenho usado e recomendo para quem também é essa memória corrompida, nem que seja por pouco tempo.
O TrueCrypt está aposentado graças ao Bit Locker. No entanto, ele ainda pode ser uma mão na roda. E portátil. Basta carregar seu executável e seus drivers em algum lugar e executar e poderá criar um novo volume facilmente.
Dentro desse volume devidamente encriptado com uma senha forte (ou talvez uma chave forte portátil) e algoritmos escolhidos fortes é possível colocar uma miríade de coisas. Eu gosto, por exemplo, de manter meus arquivos do Dropbox/Google Drive/One Drive dentro dele, escolhendo um drive fixo (adicionando aos favoritos). O jeito que meu DropBox se comporta é dar erro quando o volume não está montado, sendo que eu sou obrigado a me lembrar de montar o drive antes de começar a sincronização de arquivos de outros lugares que eu confio (meu notebook, por exemplo). Não que tenha nada muito relevante, mas a ideia é não deixar um rastro sequer, certo?
Por fim, outra possibilidade para o navegador é também usá-lo a partir do drive encriptado. Existem versões portáteis do Firefox e Google Chrome. O Chrome funciona razoavelmente bem, perdendo alguns logins de vez em quando. Mas, ei, perder logins não é exatamente um problema de segurança, certo?
</description>
</item>

     
        <item>
  <title>Origem do tipo char</title>
  <link>http://www.caloni.com.br/origem-do-tipo-char/</link>
  <pubDate>2015-01-26</pubDate>
  
  <guid>http://www.caloni.com.br/origem-do-tipo-char/</guid>
  <description>Programadores C e C&#43;&#43;, preparem-se para explodir as cabeças!
No princípio... não, não, não. Antes do princípio, quando C era considerada a terceira letra do alfabeto e o que tínhamos eram linguagens experimentais para todos os lados, dois famigerados srs. dos Laboratórios Bell, K. Thompson e D. Ritchie, criaram uma linguagem chamada B. E B era bom.
O bom de B estava em sua rica expressividade. Sua gramática extremamente simples. Tão simples que o manual da linguagem consistia de apenas 30 páginas. Isso é menos do que as 32 palavras reservadas de C.
As instruções eram definidas em termos de if&#39;s e goto&#39;s e as variáveis eram definidas em termos de um padrão de bits de tamanho fixo -- geralmente a word da plataforma -- que utilizada em expressões definiam seu tipo; esse padrão de bits era chamado rvalue.
Como esse padrão de bits nunca muda de tamanho, todas as rotinas da biblioteca recebiam e retornavam sempre valores do mesmo tamanho na memória. Isso na linguagem C quer dizer que o char da época ocupava tanto quanto o int. Existia inclusive uma função que retornava o caractere de uma string na posição especificada:
Sim! Char era uma função, um conversor de &amp;quot;tipos&amp;quot;. No entanto a própria variável que armazenava um char tinha o tamanho de qualquer objeto da linguagem. Esse é o motivo pelo qual, tradicionalmente, as seguintes funções recebem e retornam ints em C:
Links interessantes para filólogos de plantão:
 Dennis Ritchie Home Page BCPL Reference Manual by Martin Richards Users&#39; Reference to B by Ken Thompson  </description>
</item>

     
        <item>
  <title>Por que o Visual Studio gera executáveis mutantes</title>
  <link>http://www.caloni.com.br/por-que-o-visual-studio-gera-executaveis-mutantes/</link>
  <pubDate>2015-01-11</pubDate>
  
  <guid>http://www.caloni.com.br/por-que-o-visual-studio-gera-executaveis-mutantes/</guid>
  <description> Esse é um post antigo que encontrei no meio dos meus emails de 2006, mas que contém uma boa dica para quem já entendeu o passo-a-passo da compilação, mas ainda tem sérios problemas quando os projetos ficam gigantes.
 Essa é a segunda vez que encontro esse mesmo problema. Como acredito que outras almas podem estar sofrendo do mesmo mal, coloco aqui uma breve descrição de como o VC8 faz para gerar um executável que, mesmo não dependendo das DLLs de runtime, não são executados em sistemas que suportam a interpretação do &amp;quot;.manifest&amp;quot;. De canja, um pequeno programa que exibe a lista dos programas instalados no sistema.
Primeiro, precisamos de um solution que contenha um projeto console e uma LIB. O projeto console deve usar a LIB para fazer alguma coisa. No exemplo abaixo, estarei listando os programas instalados no Windows (os mostrados no painel de controle através da opção &amp;quot;Adicionar/remover programas&amp;quot;.
Observação importante: para ignorar todas as estripulias da versão Debug, todos os testes foram compilados em Release.
Primeiramente, modifico a configuração padrão dos dois projetos para não depender da DLL de runtime do VC. Isso está em Project, Properties, C/C&#43;&#43;, Code Generation, Runtime Library. Depois executo em uma máquina virtual sem as runtimes do VC8 instaladas:
Perfeito. Exatamente o que eu queria: um executável console que não dependesse de DLL nenhuma exceto as que já estão instaladas em um Windows ordinário.
Agora, vamos imaginar que esse é um daqueles projetos enormes de 5 * 10 ^ 42 de linhas (obs: dramatização) e que meu aplicativo console está linkado com cerca de 3 * 10 ^ 666 de LIBs. E uma delas (a library do exemplo) está com a configuração original, ou seja, com a dependência da DLL de runtime. E ela usa a STL. Provavelmente o aplicativo console não irá compilar, mas isso não é problema, pois estamos acostumados a colocar a msvcrt.lib na lista de LIBs ignoradas, pois em muitos outros casos (que não vale a pena discutir aqui) esse workaround é válido. E tudo volta a funcionar. Quer dizer, linkar:
O sistema no pode executar o programa especificado.
Tudo bem, meu executável não é mutante ainda. Mas agora vamos trocar a chamada da nossa função que usa STL por uma função que não usa:
Agora sim, a mutação fez efeito! Temos um aplicativo que não depende da DLL de runtime, mas que no meio das n LIBs que ele utiliza existe uma configurada com a dependência. Ignorando a msvcrt.lib e um warning na compilação encontramos uma mensagem de erro um tanto exdrúxula.
Até agora, a maneira que eu tenho utilizado para rastrear esse problema é não ignorar a msvcrt e ir tirando as dependências das LIBs pouco a pouco, até que ocorra o erro de símbolo duplicado. Algo assim:
Se você tiver realmente 3 * 10 ^ 666 de LIBs, boa sorte =).
</description>
</item>

     
        <item>
  <title>Entendendo a Compilação</title>
  <link>http://www.caloni.com.br/entendendo-a-compilacao/</link>
  <pubDate>2015-01-04</pubDate>
  
  <guid>http://www.caloni.com.br/entendendo-a-compilacao/</guid>
  <description>Fiz alguns slides a pedido dos organizadores do TDC 2014, já que a palestra que ministrei com esse tema foi para ajudar meu amigo-sócio Rodrigo Strauss que não havia preparado nenhum slide a respeito.Felizmente eu já havia explicado alguns conceitos-chave para quem programa em C/C&#43;&#43; e precisa -- eu disse: PRECISA -- conhecer todo o passo-a-passo que leva o seu código-fonte a gerar um executável com código de máquina pronto para rodar.
Como havia explicado anteriormente, existem três processos principais e clássicos (pode haver mais, dependendo do compilador, ambiente, etc) na formação de um código de máquina a partir de arquivos-fontes escritos em C ou C&#43;&#43; (ou ambos, são intercambiáveis). São eles: preprocessamento, compilação e linkedição.
O preprocessamento é um trocador de textos. No máximo há macros, em que é possível passar argumentos (no formato texto). Exemplos são include, ifdef e define.
A compilação é o núcleo da linguagem. Regras de sintaxe e gramática são validadas aqui pelo compilador. Cada compilação bem-sucedida recebe uma unidade de tradução e cospe um arquivo-objeto, que ainda não é executável, mas que já passou pela validação da linguagem.
Por fim, a linkedição junta todos os arquivos-objeto, procurando ligar os nomes das funções e variáveis referenciadas um pelo outro. Os nomes externos são importantes neste passo para que o linker encontre as lacunas que precisa para consertar os saltos e assim gerar o executável final, que pode ser um programa com uma função main ou uma biblioteca dinâmica carregada por outro programa compilado seguindo esses três passos.
</description>
</item>

     
        <item>
  <title>Houaiss Para *</title>
  <link>http://www.caloni.com.br/houaiss-para/</link>
  <pubDate>2014-10-25</pubDate>
  
  <guid>http://www.caloni.com.br/houaiss-para/</guid>
  <description>O projeto Houaiss2Babylon, iniciado há mais de 6 anos, já devia estar ultrapassado. Porém, cada vez mais pessoas compartilham seus usos e desusos do que foi um dia uma base de dados ofuscada e presa a apenas uma interface Windows. Agora, além de já ter sido convertido para Kindle, em Python e agora através do nodejs para o MySql!
O jornalista e programador Arthur da Paz desenvolveu esta última novidade no programa e gentilmente compartilhou conosco direto no repositório original do HouaissParaBabylon, colaborando felizmente para que esse nome perdesse um pouco mais do sentido (Babylon já está meio ultrapassado, não?). Além disso ele encontrou a solução para um bug que invertia a ordem de apresentação das Rubricas, cujos detalhes ele explica nos comentários do post sobre a última versão.
Muito obrigado ao Da Paz e a todos que colaboram e compartilham melhorias para esse projeto. Um dicionário não é nada sem as pessoas que o utilizam.
</description>
</item>

     
        <item>
  <title>Shareando Ponteiros</title>
  <link>http://www.caloni.com.br/shareando-ponteiros/</link>
  <pubDate>2014-09-03</pubDate>
  
  <guid>http://www.caloni.com.br/shareando-ponteiros/</guid>
  <description>Apesar de ter palestrado algumas vezes sobre Boost e STL nunca escrevi muito sobre esses assuntos aqui. O tamanho dessas bibliotecas assusta um pouco. Mas temos que começar de algum lugar.
E por isso eu gostaria de saber de você, programador miserável, que passou poucas e boas nesses dez anos de padrão 98 brincando com templates quando eles ainda estavam em beta: se fosse para melhorar um aspecto da sua vida de código C&#43;&#43;, qual seria? Qual é aquela coisa que te atormenta como insetos vidrados no seu monitor noite adentro?
Se eu fosse você reponderia: alocação de memória e ponteiros. E portanto vamos matar dois coelhos com um template só usando smart pointers, que desalocam memória quando não precisamos mais dela e mantém os ponteiros gerenciados.
&amp;quot;Ah, mas tem que usar uma biblioteca bizarra com milhões de dependências e que vai quebrar todo o fonte aqui da empresa. Sem contar que vai ter que passar de novo pelos unit tests, vai dar erro de compilação, a LIB XPTO não funciona sem dar três pulinhos virado para a cafeteira e...&amp;quot;
Cada caso é um caso, existe o melhor dos mundos e o pior. Mas (quase) todos têm solução. Mesmo que tudo que você tenha disponível seja um barbante e um clipe, podemos tentar alguma mágica/gambiarra/adaptação técnica. Vamos ver os casos mais comuns:
Um cenário perfeito para começar. A única coisa que você precisa fazer em seus novos projetos e refatorações é incluir um único cabeçalho:
E pronto! Se abriu um mundo mágico onde as alocações serão compartilhadas entre funções sem se perder quem deleta o quê. Não precisa nem checar se o ponteiro é nulo, basta alocar direto e jogar para dentro do nosso mais novo smart pointer da STL:
E pronto: você nunca mais vai precisar se preocupar com quem deleta o ponteiro, nem quantas cópias desse ponteiro andam por aí. O sharedptr da STL, assim como a versão que já tem faz um tempo no boost, mantém um contador de referência para cada cópia do objeto que mantém o mesmo ponteiro &amp;quot;dentro de si&amp;quot;. Só quando esse contador chegar a zero, ou seja, não há mais ninguém referenciando essa região da memória, o ponteiro é deletado.
O std::sharedptr funciona desde o SP1 do Visual Studio 2010. Sem Service Pack ou em versões mais antigas pode haver disponível no namespace tr1, resquício de quando esse novo padrão ainda estava em definição.
Vou imaginar que você usa o Visual Studio 2003, um dos primeiros da safra &amp;quot;.NET&amp;quot;, que, mais uma vez, NÃO TEM QUALQUER RELAÇÃO COM C&#43;&#43; .NET.
Bem, nesse caso, &amp;quot;welcome... to the desert... of the double&amp;quot;:
Pois é, 37 erros. Depois perguntam por que as pessoas ficam com medo de programar em C&#43;&#43;...
Porém, a correção é mais simples do que parece: baixar o boost e trocar o nome do namespace.
ATENÇÃO! Nos meus testes a única versão funcionando com o VS2003 foi a 1.47. Mas já é alguma coisa
Não existe situação difícil que não possa piorar. Porém, mesmo nesse caso ainda há algo a se fazer, já que smart pointer utilizam mecanismos existentes na linguagem C&#43;&#43; desde os primórdios (ou bem próximo disso). Tudo que você precisa para criar seu próprio sharedptr é do construtor padrão, do destrutor padrão, do construtor de cópia e dos operadores de atribuição e ponteiro. E, claro, não se esqueça de usar template se for permitido. Se não for, a coisa complica, mas não se torna impossível.
E é isso. A lição de hoje é: quem quer, arruma um jeito. Quem não quer, uma desculpa.
</description>
</item>

     
        <item>
  <title>O novo &#39;como não dar step into&#39; do Visual Studio 2012/13</title>
  <link>http://www.caloni.com.br/o-novo-como-nao-dar-step-into-do-visual-studio-201213/</link>
  <pubDate>2014-08-01</pubDate>
  
  <guid>http://www.caloni.com.br/o-novo-como-nao-dar-step-into-do-visual-studio-201213/</guid>
  <description>Toda vez que instalo um Visual Studio novo e começo a depurar sempre surge a necessidade de fazê-lo calar a boca nos step intos da STL, Boost, ATL e coisas que sei que não vai dar pau. (Obviamente, quando dá pau, preciso ir no disassembly e cutucar a STL para ela me entregar qual o problema com o meu contêiner.)
Nas edições antigas da IDE (até o 2010) existia uma configuração no registro para isso. Desde o Visual Studio 2012 isso mudou, e agora existe um arquivo em %programfiles(x86)%\Microsoft Visual Studio 11(ou12).0\Common7\Packages\Debugger\Visualizers chamado default.natstepfilter (gostei do detalhe do &amp;quot;nat&amp;quot;: &amp;quot;nat thou step into, little bestard!&amp;quot;). Ele é um XML que já vem preenchido com algumas opções interessante:
Podemos simplesmente adicionar mais duas opções para o parzinho STL/Boost:
A boa nova, pelo menos para o Visual Studio 2013, é que agora é possível, se quisermos, entrar nas funções que serão ignoradas:
Eu não sei qual vai ser a próxima novidade do step into, mas para mim, já está bem ótimo.
(Fonte da informação: Andy Pennell&#39;s Blog).
</description>
</item>

     
        <item>
  <title>Integrando BitBucket/GitHub com Trello</title>
  <link>http://www.caloni.com.br/integrando-bitbucketgithub-com-trello/</link>
  <pubDate>2014-07-22</pubDate>
  
  <guid>http://www.caloni.com.br/integrando-bitbucketgithub-com-trello/</guid>
  <description>Eu nem acredito que estou escrevendo sobre desenvolvimento web, mas como foi algo que me fez dedicar algumas horas do meu fim-de-semana, e não encontrei facilmente uma solução já feita, acredito que pode ser útil para mais alguém que usa Trello e GitHub (ou BitBucket).
Mas o que é Trello? Basicamente é um TodoList feito da maneira mais inteligente possível: uma lista de listas de listas! Os espaços, ou desktops, onde você organiza suas tarefas são chamados de Boards. Em cada board vivem L listas, e em cada lista vivem C cards. Cada card pode conter comentários, histórico de mudanças, labels, checklists, due dates e todas as tranqueiras que geralmente existe em uma lista de tarefas. É um sistema online, desenvolvido pela empresa do Joel Spolsky (o mesmo do excelente blogue de programador Joel on Software (ou em português, e que contém algo que eu adoro em sistemas web: atalhos!
A ideia que tive foi usar os webhooks dos saites de repositórios de fontes para permitir comentar dentro dos cards o commit que foi feito, sua mensagem e o linque para o commit. OK, mas por que não usar o sistema de issues dos já feitos pra isso GitHub e BitBucket? Ele já faz isso muito melhor. De fato. Porém, fica espalhado pelos repositórios, e não é sempre que uma tarefa envolve código (comprar pão, por exemplo). Além do mais, praticamente qualquer serviço desses oferece hooks para a integração de outros projetos/serviços, então se um dia nascer mais um sistema de controle de fonte ou mais um saite que organiza essas tralhas haverá um hook e consequentemente mais uma adaptação do meu código PHP.
E por que PHP? Bom, PHP é uma linguagem fácil de mexer (se parece com C, mas é um script) e praticamente qualquer servidor web do universo, mesmo o mais baratinho, vem com o pacote Apache &#43; PHP (e geralmente uma base MySql). Dessa forma, é uma solução que pode ser implantada fácil e rapidamente.
Vamos começar pelo mais difícil que o resto vai fácil: comentar pela API do Trello. Sua API é beta, assim como sua documentação, então tive arrancar significado inexistente em seu help, mas acabou funcionando. Como qualquer API web, você precisa de uma chave, segredo e a permissão do usuário. Com essa permissão é possível comentar em todas as boards que esse usuário específico tem acesso.
Pelo menos a parte de geração de chave/segredo é simples. Depois disso, mesmo nessa página já é possível conseguir uma chave de acesso para o seu usuário.
Por fim, para fazer o código que irá comentar dentro de um card no Trello, basta usar dois ou três métodos que lidam com enviar coisas pela web (não me pergunte mais que isso):
As informações AQUIVAISUACHAVE e AQUIVAISEUTOKENDEACESSO você já obteve no linque de geração de key/secret. Já o IDDOCARD é algo que depende de em qual lista seu card está, mas felizmente também existe um shortlink único e imutável para cada card no sistema:
Basta usar o ID em Base64-ou-o-que-o-valha no lugar de IDDOCARD que já estamos OK. Depois que este código conseguir ser executado, basta ter acesso à internet que ele irá escrever &amp;quot;Hello, World&amp;quot; no cartão referenciado:
Muito bem. Primeira parte da missão concluída.
Como o GitHub é um dos serviços de repositório de fontes mais famoso, vamos torná-lo nosso caso de sucesso. Basicamente você deve ir no seu repositório do coração (essa é a parte ruim: se você tem mais de um coração, vai ter que repetir esse mesmo procedimento para todos os outros repositórios dos seus outros corações), Settings, Webhooks &amp;amp; Services.
Lembre-se de colocar seu código PHP em um servidor visível na web. Lembre-se também de usar o método de envio urlencoded do payload para simplificar seu tratamento. Para simplificar ainda mais o processo, coloque qualquer coisa no segredo (não validaremos neste post, mas #ficadica de segurança se você não quer que outros acessem seu PHP inadvertidamente).
Pois bem. No código que irá receber o payload do GitHub precisamos de duas coisas: saber qual a estrutura que vai ser recebida e como localizar o id do card onde iremos enviar a informação. Nesse caso, mais uma vez, para simplificar, vamos procurar pelo próprio linque permanente do cartão na mensagem do commit. Aliás, doS commitS (sendo um push, é provável que o evento seja gerado com diversos commits aninhados).
Agora é só testar. Posso pegar esse mesmo artigo e comitá-lo no repositório do blogue usando o linque único do card da tarefa de escrever este artigo. Ou seja, aqui é Inception na veia, mermão!
O que vai deixar você perplexo é entender como esse texto está sendo comitado antes mesmo de eu comitar este texto ;).
E o negócio é rápido, viu?
A única coisa que muda no caso do BitBucket é a tela onde deve ser inserido seu webhook (método POST, sempre) e a estrutura JSon que é enviada. De lambuja, eis o que deve ser feito com esse payload:
</description>
</item>

     
        <item>
  <title>Se iterando com os pseudo-ponteiros: uma breve introdução</title>
  <link>http://www.caloni.com.br/se-iterando-com-os-pseudo-ponteiros-uma-breve-introducao/</link>
  <pubDate>2014-06-24</pubDate>
  
  <guid>http://www.caloni.com.br/se-iterando-com-os-pseudo-ponteiros-uma-breve-introducao/</guid>
  <description>Como já vimos algumas vezes, a STL não prima por interfaces intuitivas, preferindo abstrações que criem um leque de ferramentas genéricas para tratamento uniformizado de coleções de dados através de algoritmos. O problema disso é que novos programadores da linguagem terão que aprender uma maneira nova de lidar com problemas baseada na percepção dos criadores do padrão na época em que foi lançado de como seria a evolução da ciência da computação nos próximos anos. Muitos dos conceitos ali abordados realmente se tornaram padrão de facto, mas na briga pela expansão da linguagem quem perdeu por muito tempo foi o próprio desenvolvedor, que teve que se contentar com uma lista de algoritmos genéricos parcialmente compilado.
Dito isto, a abstração dos iteradores é a coisa mais linda do mundo.
Os dois únicos conceitos que é preciso se lembrar para sempre quando se trata de iteradores é que ele:
  Um iterador se comporta como um ponteiro opaco.
  O final de um contêiner está sempre um elemento além do último.
  Um ponteiro pode ser iterador, mas não o contrário!
Tudo que um ponteiro faz de útil em C/C&#43;&#43; foi emprestado para a STL usar em seus contêiners, e tudo em que ele é prejudicial tentou ficar de fora. E o que um ponteiro faz de útil?
  Um ponteiro pode apontar para elementos sem conhecermos sua posição.
  Podemos incrementar ou decrementar ponteiros para caminhar em listas.
  Dois ponteiros podem ser subtraídos para sabermos a distância entre dois elementos.
  Da mesma forma, operações como cópia, movimentação, ordenação, caotização, pode ser feito usando dois ponteiros/iteradores de dois contêiners distintos, desde que algumas regras básicas sejam seguidas, como um iterador deve sempre apontar para algo válido (ou disponibilizar alguma abstração que insira novos elementos em um contêiner menor). Veremos essas regras em um próximo post sobre o tema. Apontarei para ele aqui.
</description>
</item>

     
        <item>
  <title>Dando cabo do WinDbg</title>
  <link>http://www.caloni.com.br/dando-cabo-do-windbg/</link>
  <pubDate>2014-06-18</pubDate>
  
  <guid>http://www.caloni.com.br/dando-cabo-do-windbg/</guid>
  <description>Na semana passada falei sobre a ideia de comentar algumas mudanças entre o Windows XP e o novo mundo Vista/7/8/ que fizeram com que adaptássemos algum código que obviamente não funcionaria mais. Falamos sobre a famigerada GINA (ou famiGINADA), e agora apenas vou comentar brevemente sobre o sistema de boot, que também mudou.
Na verdade, pouca coisa mudou, mas foi o suficiente para dar problemas na hora de usar o WinDbg. Tradicionalmente, o boot era gerenciado no Windows através de um arquivo localizado na raiz da partição ativa (configuração da MBR) chamado bootini. Dentro dele temos uma estrutura semelhante a um .INI (duh), onde a informação que vemos lá podia ser configurada nas configurações do Computador no Windows XP.
Hoje em dia esse arquivo nem existe mais, o que pode dar um friozinho na barriga (&amp;quot;caramba, não vai mais bootar!!&amp;quot;). Agora, para sistemas baseados em BIOS há uma pasta Boot na raiz e um arquivo chamado bcd. Para os mais moderninhos, baseados em EFI, ele fica na partição EFI. Ah, EFI é Extensible Firmware Interface, e faz parte da especificação da UEFI (Universal blá blá blá), mais ou menos um padrão que define como deve ser feita a comunicação entre hardware e sistema operacional.
Para a edição desse novo arquivo (ou partição) é necessário que seja usada a ferramenta BCDEdit no Windows. É ela que agora configura qual partição está ativa e, mais importante para escovadores de bits, qual pode ser depurada pela porta serial através do WinDbg.
Porta serial? Mas que coisa antiga, hein? Pois é, muita coisa mudou desde o Windows Vista, mas algumas coisas precisam permanecer... compatíveis.
Mas... se você precisar:
</description>
</item>

     
        <item>
  <title>Eles querem que a GINA vá embora: três posts sobre evolução Windows</title>
  <link>http://www.caloni.com.br/eles-querem-que-a-gina-va-embora-tres-posts-sobre-evolucao-windows/</link>
  <pubDate>2014-06-11</pubDate>
  
  <guid>http://www.caloni.com.br/eles-querem-que-a-gina-va-embora-tres-posts-sobre-evolucao-windows/</guid>
  <description>Fui convidado pela Fernanda Saraiva do programa de MVPs da Microsoft Brasil a falar sobre alguma história a respeito da evolução do Windows e como isso impactou minha experiência profissional. Pesquisando em meu próprio blogue fui capaz de lembrar não apenas de uma, mas de três mudanças técnicas que fizeram com que eu e minha &amp;quot;equipe&amp;quot; da época (geralmente mais alguém, no máximo) matássemos alguns neurônios tentando descobrir novas maneiras do sistema fazer o que já fazia no Windows XP. Irei compartilhar uma por vez no que tem sido o meu post semanal que eu apelidei carinhosamente de Post da Terça. Já faz mais de um mês que consigo publicar pelo menos na terça algo de novo, e espero manter esse ritmo.
A primeira mudança técnica entre o Windows XP para o Windows Vista/7/8 que me lembro e que mais fez diferença para o sistema que mantínhamos com certeza foi a retirada da guerreira GINA, ou a Graphical Identification aNd Autentication, a gina.dll da Microsoft que implementava a mundialmente famosa tela de logon do Windows NT/2000/XP:
Seja no formato Home Computer (a telinha de boas vindas) ou no tradicional &amp;quot;Pressione Ctrl&#43;Alt&#43;Del&amp;quot; do Windows NT ¿ quando a máquina está no domínio ¿ quem gerencia essa tela é o processo de sistema iniciado a partir do WinLogon.exe. O WINLOGON carrega a nossa amiga gina.dll que é quem realiza a autenticação dos usuários.
Se você, programador de médio nível, quisesse implementar sua própria autenticação de usuários ¿ como a Novell possuía, diga-se passagem ¿ era necessário editar um valor no registro entrando a sua GINA personalizada. Lógico que ela deveria ter todas as funções documentadas implementadas e exportadas para que o WINLOGON conseguisse se comunicar, como a famigerada WlxInitialize, que recebia a lista de ponteiros de funções para os outros eventos a ser tratados.
Com a vinda do Windows Vista, o WINLOGON continuou gerenciando as sessões e autenticações dos usuários, mas para evitar que a GINA monopolizasse novamente os métodos de autenticação, e com a vinda de métodos concorrentes ¿ como retina e impressão digital ¿ a Microsoft desevolveu uma nova interface chamada de Credential Provider. A implementação dessa interface não sobrescreveria novamente a &amp;quot;GINA&amp;quot; da vez, mas daria apenas uma alternativa para o logon tradicional com login e senha.
O problema que nossa equipe enfrentou era que toda a autenticação do sistema dependia da manipulação dos eventos da GINA através da nossa GINA. Com ela colocada de escanteio, os logins parariam de funcionar.
Depois de uma análise rápida foi constatado que não seria mais possível bloquear o login completamente, uma vez que existiam pelo menos duas alternativas de login que vieram com a instalação do Vista, e o fato de instalar mais uma apenas faria com que essa terceira alternativa não funcionasse, mas o usuário não estaria mais obrigado a &amp;quot;passar por nós&amp;quot;.
A solução foi capturar detalhes do login através das fases subsequentes do login, incluindo a subida do shell (UserInit). Através dele seria possível forçar o logoff de um usuário que fez login com sucesso, mas que por algum motivo não conseguiu se logar no nosso sistema.
Nem sempre o que estava rodando já há anos é a solução mais bonita. Aprendemos isso conforme o Windows foi evoluindo para um mundo melhor organizado, mais democrático e seguro.
</description>
</item>

     
        <item>
  <title>SS</title>
  <link>http://www.caloni.com.br/ss/</link>
  <pubDate>2014-06-03</pubDate>
  
  <guid>http://www.caloni.com.br/ss/</guid>
  <description>Uma das coisas mais cretinas e difíceis para os iniciantes em C&#43;&#43; é conseguir formatar strings de maneira fácil, rápida e indolor. Infelizmente, a biblioteca de printf da linguagem C está fechada para reforma, pois ela é extremamente error-prone e não-intuitiva. Porém, se a printf é não-intuitiva, o que dizer &amp;lt; &amp;lt; daqueles &amp;lt;&amp;lt; sinais &amp;lt;&amp;lt; de &amp;lt;&amp;lt; flechinhas apontando para cout? Bem melhor, não?
A resposta é, pra variar, depende. Se você combinar com seu cérebro que o operador de shift que você aprendeu em C para cout não tem a mesma semântica, OK. No fundo eu acredito que os criadores dessa sobrecarga de operador pensaram sinceramente que hoje em dia quase ninguém conhece os operadores de shift binário, então tudo bem reaproveitá-lo de uma maneira mais miguxa.
Porém, isso depende da maneira com que você usa streams C&#43;&#43;. Vai haver momentos de sua vida que você vai se questionar por que tiraram todo o controle, a elegância e simplicidade de um bom printf, quando os homens eram homens e sabiam configurar jumpers para instalar a nova placa EISA.
A questão dos streams fica mais complicada quando precisamos realizar atividades corriqueiras no código, como retornar uma string formatada, ou até mesmo transformar um inteiro em string.
Já pensou termos que criar uma função dessas sempre que quisermos converter números em string? Ou pior, ter que fazer o que fizemos dentro dessa função: declarar um ostringstream (um cout com buffer interno de string), usá-lo como cout e obter seu buffer interno através do método str. Tudo isso para converter um número para string.
Quando uma tarefa muito comum exige mais de dois passos para ser realizada é de bom tom criarmos algum código reutilizável, certo? Um código que trará de uma vez por todas a solução final!
O código acima serve bem ao nosso propósito de formatar strings em uma linha como um cout, mas retornar uma string no lugar. Ele é simples, ele é direto, ele tem defeitos que não vem ao caso (como não suportar endl), mas pode ser usado de maneira... simples e direta!
OK, o código de exemplo foi idiota, mas você pegou a ideia. Tudo que precisamos fazer para reutilizar essa pequena classe é definí-la (ss() resolve) e usá-la. Seu conversor de string retorna o buffer interno de ostringstream para nós como num passe de mágica.
Obs.: Com certeza deve existir uma centena de bibliotecas que implementam algo do gênero, só que melhor. Essa é a típica fica isolante para continuar trabalhando.
</description>
</item>

     
        <item>
  <title>Desmontando o Aulete Digital</title>
  <link>http://www.caloni.com.br/desmontando-o-aulete-digital/</link>
  <pubDate>2014-05-27</pubDate>
  
  <guid>http://www.caloni.com.br/desmontando-o-aulete-digital/</guid>
  <description>Este post não estará mais disponível devido ao mau uso de pessoas que se aproveitaram das minhas explicações didáticas a respeito do funcionamento da versão Desktop do dicionário e, agindo de má-fé, começaram a baixar a base de dados indiscriminadamente, fazendo com que o serviço que é disponibilizado gratuitamente aos usuários tivesse que ser desligado. É uma lástima que isso tenha ocorrido, e peço desculpas às pessoas que prejudiquei direta ou indiretamente.
É condenável esse tipo de &amp;quot;ataque&amp;quot; a um serviço que é disponibilizado gratuitamente. Meu artigo teve apenas fins didáticos e não tem por objetivo o uso ilegal de uma ferramenta tão útil aos seus usuários.
</description>
</item>

     
        <item>
  <title>Estruturas VS Classes: fight!</title>
  <link>http://www.caloni.com.br/estruturas-vs-classes-fight/</link>
  <pubDate>2014-05-20</pubDate>
  
  <guid>http://www.caloni.com.br/estruturas-vs-classes-fight/</guid>
  <description>Uma dúvida besta e importante ao mesmo tempo que muitos iniciantes em C&#43;&#43; possuem é saber qual a diferença entre um objeto declarado como class e um objeto declarado como struct. A causa dessa dúvida é uma linguagem que se derivou de outra (C) que não possuía classes, e portanto criou a palavra-chave class para &amp;quot;ficar bonito&amp;quot;, pois, na prática, não muda muita coisa. Tomemos como exemplo o código mais simples de todos:
Ele compila e roda sem problemas:
&amp;quot;Estruturalmente&amp;quot; falando, MinhaEstrutura e MinhaClasse são idênticas, pois são os detalhes de sintaxe que diferem, e diferem pouco. Abrindo o jogo, a única diferença que poderá ser sentida em usar um ou outro é que structs possuem seus membros públicos por padrão e classes possuem seus membros privados por padrão. Apenas isso. O resto, nada muda.
Isso pode ser visto quando adicionamos um construtor para nossos tipos de teste:
Antes não havia problemas para MinhaClasse porque o construtor padrão criado para ela é público por default. Porém, explicitando no código um construtor e deixando sua privacidade ligada por padrão temos esse erro que NÃO ocorre em MinhaEstrutura.
Mas, então, posso criar todas minhas classes usando a palavra-chave struct?
Isso mesmo! Nada lhe obriga tecnicamente a usar class. Porém, assim como nada lhe obriga a usar uma linha para cada comando na linguagem ¿ afinal, todos poderiam estar na mesma linha separados por ponto-e-vírgula ¿ o uso da palavra struct para classes no sentido de &amp;quot;objetos que possuem inteligência, métodos, herança, polimorfismo e outras firulas&amp;quot; não se enquadra nas boas práticas dos programadores C&#43;&#43;.
Geralmente uma struct é uma forma de concatenar tipos primitivos e só. Algumas liberdades além disso geralmente são permitidas, mas desencorajadas, como um construtor que inicia os membros da struct com valores-default.
E, por que não, uma sobrecarga do operador de stream para imprimirmos diretamente os valores de MinhaEstrutura para a saída com apenas um comando?
Enfim, não há nenhum limite que se aplica à uma struct além do bom senso. A criação da palavra class não foi por falta do que fazer. Ela diz claramente que estamos definindo um objeto que contém usos mais adequados à orientação a objetos de C&#43;&#43; do que a programação estruturada de C, e vice-versa. É uma forma de tornar o código mais legível, mas nada do outro mundo. Sabemos, no final das contas, que o compilador trata as duas (quase) da mesma maneira.
Qual será a próxima batalha épica? Você escolhe!
https://www.youtube.com/watch?v=zn7-fVtT16k
</description>
</item>

     
        <item>
  <title>50 Anos de BASIC</title>
  <link>http://www.caloni.com.br/50-anos-de-basic/</link>
  <pubDate>2014-05-13</pubDate>
  
  <guid>http://www.caloni.com.br/50-anos-de-basic/</guid>
  <description>Minha primeira linguagem de programação foi o BASIC. Aprendi durante minhas frequentes visitas à biblioteca lendo livros dos anos 80. Na verdade, eu não me lembro muito bem por que diabos resolvi aprender a programar, já que eu estava mais interessado em entender como um computador funciona. Por que? Não sei bem ao certo, parece que já nasci com um chip embutido que foi ativado quando comecei a tender muito para o lado de humanas ao iniciar a faculdade de Letras... um chip salvador!
Enfim, um dos melhores livros que já li na minha vida não foi um cheio de letras, mas muito mais figuras: a Introdução Ilustrada à Computação, de Larry Gonick. Ele foi traduzido e publicado no Brasil pela Itautec e é um clássico absoluto sobre a história da computação, explicada de uma maneira que até um leigo completo conseguiria entender. E quando eu digo &amp;quot;computação&amp;quot; não estou me referindo a noções vagas sobre como o computador processa a entrada e gera saída. O ilustrador Larry Gonick fez um excelente trabalho em capturar a essência de cada inventor da história ¿ como Alan Turing, John Von Newmann, Charles Babbage e Ada Lovelace ¿ e cada conceito básico aplicado à invenção do computador, desde saldos condicionais (Lovelace), lógica booleana (George Boole), codificação binária e, pasmem... flip-flops!
Enfim, depois de explicar tudo isso e mais um pouco, no seu último capítulo ainda há uma pequena introdução ao BASIC que vinha instalado nas máquinas daquela época. Bem rústico, mas capaz de enviar comandos para a máquina e executá-los. Não aprendi todos os comandos nesse livro, mas ele foi minha porta de entrada para leituras mais &amp;quot;densas&amp;quot;, que me fizeram evoluir de uma calculadora capenga (meu primeiro programa!) para um emulador do jogo Genius, com direito a efeitos sonoros, cores configuráveis e gravação de recordes, tudo no próprio executável (na época um .COM, onde isso era possível). Esse foi meu primeiro programa com mais de 1000 linhas que eu me lembro (e com mais de 10 GOTOs e GOSUBs, também).
A modalidade mais popular do BASIC quando me interessei pelo assunto rodava no Windows 95 e se chamada QuickBASIC, ou QBasic, já em sua clássica versão 4.5. Passei longas horas com aquela tela de fundo azul na madrugada corrigindo erros, anotando detalhes no papel, refazendo a lógica mentalmente, até conseguir resolver o problema. Podia ser qualquer problema, pois ele viraria inevitavelmente a diversão da noite. Podia até ser um detalhe de implementação de uma função específica embutida: o F1 funcionava e era bem rápido.
O BASIC é uma linguagem fácil de aprender, não tem muitos limites e seria a minha escolha para ensinar programação para crianças caso ainda não tivessem inventado Python. Ela tem o tipo de sintaxe que você pode literalmente sair programando. Uma linha de código já imprime alguma coisa na tela. A lógica do fluxo de execução é simples, e os GOTOs ajudam a ilustrar como funciona. A depuração é sem frescuras, e os erros de tantos saltos sem nó, para variar, é do programador. Se vira, agora, com tanta SUB!
Os puristas irão dizer que o aprendiz precisa ser educado de acordo com as novas tendências de programação estruturada, orientada a objetos, ou 100% funcional. Porém, eles esquecem que a programação aprendida por autodidatas como eu não era algo que podia-se chamar trabalho. Ninguém imaginava naquela época, naquela idade, fazer algo tão divertido e ser pago para isso. Exatamente, divertido. Uma linguagem precisa ser divertida para que o programador se interesse em conversar através dela com a máquina. É óbvio que, quando amadurecer, enxergará as óbvias limitações de uma linguagem imperativa como BASIC e irá passar para algo mais elaborado, seja Pascal, Java, C, C&#43;&#43;. Não importa. A ambição técnica e perfeccionista do programador, enquanto não o engole, torna qualquer linguagem divertida. E no começo, onde erros de compilação e a falta de ponto-e-vírgula pode desanimar qualquer um, BASIC tinha esse espírito selvagem de &amp;quot;faço tudo o que quiser nessa linguagem até virar homem e programar em C&amp;quot; (ou Assembly).
Por tudo isso, e por muito mais, parabéns pelos seus 50 anos de vida, minha linguagem favorita para me fazer lembrar que programar pode ser divertido e despretensioso. BASIC, você é um amigão!
</description>
</item>

     
        <item>
  <title>Poker Face</title>
  <link>http://www.caloni.com.br/poker-face/</link>
  <pubDate>2014-05-06</pubDate>
  
  <guid>http://www.caloni.com.br/poker-face/</guid>
  <description>O segundo round da segunda fase do Code Jam passou nesse sábado. Disléxico que sou, consegui fazer apenas 8 pontos ¿ como todo mundo ¿ no teste small do problema B, que envolvia apenas dois loops aninhados (a versão large fica para outro post). Na verdade, estou aqui para expressar minha gratidão ao campeonato por ter aprendido mais uma bela lição vendo o código do primeiro colocado do primeiro round, vulgo Kaizero, um coreano que deu uma solução simples, rápida e prática para um problema de probabilidade tão error-prone que até os juízes do Google deram uma lambuja de alguns testes errados (sem contar que houve apenas a categoria small), e me fez pensar em quantas vezes pensamos em demasiado tentando encontrar a solução perfeita para algo que simplesmente... não precisa.
Basta um hack e commit.
O problema reza que existem dois algoritmos para embaralhar uma sequência numérica (de 0 a N): o bom e o ruim. Ambos traçam um loop do iníco ao fim pegando aleatoriamente um elemento da lista e trocando de lugar com o elemento que está sendo varrido no momento.
A diferença entre o bom e o ruim é que o bom pega aleatoriamente apenas os elementos DEPOIS do elemento que está sendo varrido, enquanto o algoritmo ruim pega qualquer um dos elementos SEMPRE. Isso aparentemente e intuitivamente não parece interferir na aleatoriedade do embaralhamento, mas se levarmos ao extremo de embaralhar repetidas vezes somando a lista resultante percebemos uma tendência gritante do algoritmo ruim em manter o ordenamento inicial, ou pelo menos na média sempre tender para números menores no início e números maiores no fim, como pode ser visto nesse teste que fiz, gerado pelo Excel:
O que eu tentei fazer durante meu fim-de-semana retrasado e o feriado foi encontrar um detector de aleatoriedade (aliás, encontrei um bem interessante chamado ent), tanto &amp;quot;na mão&amp;quot; quanto pesquisando. O que eu não imaginava foi que o teste que eu tinha feito no início usando uma simples planilha Excel era a solução óbvia (naquelas de é óbvio só depois que você vê). E foi essa a solução adotada por Kaizero.
O que ele basicamente faz é acumular os resultados de três milhões de embaralhamentos feitos pelo algoritmo ruim e inferir através dos resultados que metade é bom e metade é ruim. O ruim fica do lado desbalanceado da sequência.
Tão óbvio, tão simples, tão elegante.
</description>
</item>

     
        <item>
  <title>Que geleia de mocotó</title>
  <link>http://www.caloni.com.br/que-geleia-de-mocoto/</link>
  <pubDate>2014-04-29</pubDate>
  
  <guid>http://www.caloni.com.br/que-geleia-de-mocoto/</guid>
  <description>A primeira bateria de problemas da segunda fase do Code Jam me mostrou o porquê do seu nome: meu cérebro ficou feito geleia (ha ha ha). Não consegui resolver nenhum problema a tempo, mas não culpo o C&#43;&#43;, que passei a usar para essa fase. É burrice aliada a pressão. Duas horas e meia para entender um problema é o tipo de coisa que me deixa pensando mais no tempo do que no problema. Tenho que melhorar isso.
De qualquer forma, esse final de semana que passou foi dedicado a resolver o primeiro problema e quem sabe escrever um post a respeito. Imagino que todos tenham acesso ao enunciado e aos casos de teste, mas, por via das dúvidas, aqui vai uma descrição adaptada:
Você é um fazendeiro hi-tech com uma vaca que tem um tablet. Não especifica se esse cowblet é um iPad, mas é uma possibilidade, já que como nenhum plugue parece encaixar nas tomadas de sua fazenda, é muito provável que você seja um Applemaníaco com um monte de gadgets que precisam de conversor vindos direto do eBay.
Através do eBay também veio um engenheiro chinês cuja missão é resolver esse gato que o Sr. Fazendeiro fez em sua fazenda. Tudo que ele precisa fazer é girar gigantescos switches (ou disjuntores) que invertem a polaridade binária de cada um dos pino dos conectores das tomadas. Quando um plugue de dispositivo e uma tomada possuem a mesma configuração de bits é possível conectá-los. O objetivo final é que todos os N plugues conectem nas N tomadas depois de virados Y switches, sendo que quanto menos switches melhor (afinal, eles são gigantescos, e o chinês supõe-se que seja pequeno).
O primeiro pensamento do programador preguiçoso (go, horse, go!) manda que usemos a velha força bruta e testemos todas as combinações possíveis de disjuntores, peguemos o com menor número de bits setados (inicialmente, todos estão em 0) e zás! Porém, o caso de teste tamanho large pressupõe que o limite de pinos das tomadas pode chegar a 40, o que seria responsável por nada mais nada menos que 2^40 combinações diferentes, ou 1.099.511.627.776 para ser exato. Isso dá mais de 1 trilhão! Mesmo que nosso código seja extremamente rápido e demore apenas um milissegundo para cada combinação, serão mais de 34 anos desperdiçados, que poderiam estar melhor investidos minerando bitcoins.
Dessa forma, temos que traçar uma solução baseada nas combinações entre as tomadas e plugues, que, pelos limites da versão large dos casos de teste, podem ter a quantidade de 150, o que dá 150 * 150 = 22500 combinações de XOR.
Sim, de XOR. O XOR aqui pode ser usado para detectarmos qual a combinação de switches precisamos para que cada tomada encaixa em cada dispositivo. Esse é o nosso conjunto universo de giros de disjuntores. Com esse conjunto em mãos fica fácil saber quais combinações são possíveis de encaixar todos os dispositivos: basta contar!
Observação: note que retirei o wrapper costumeiro dos exercícios do Code Jam para não poluir demais o exemplo com código. E, na verdade, essa parte do código está compartilhada com todas as soluções (reuse!).
O que aprendi dessa pequena aventura foi: não importa o quanto um problema pareça fácil, anotar em um pedaço de papel é o caminho mais curto entre a mente e o código.
Que venha a segunda bateria de problemas!
</description>
</item>

     
        <item>
  <title>2048 motivos para não programar</title>
  <link>http://www.caloni.com.br/2048-motivos-para-nao-programar/</link>
  <pubDate>2014-04-24</pubDate>
  
  <guid>http://www.caloni.com.br/2048-motivos-para-nao-programar/</guid>
  <description>Pronto, posso programar em paz. O jogo 2048 é uma lástima para todos os trabalhadores intelectuais que dependem de suas mentes para produzir algo que preste. Ele gerou mais posts no Hacker News do que a moda dos bitcoins (talvez não) e mais projetos no GitHub do que a busca para a cura do câncer (talvez não). Obviamente que este post vai gerar mais um gist Python para minha coleção.
Não sou fã de jogos, e dos poucos que participei logo parei (exceções honrosas: Portal e Portal 2, esses malditos). Posso dizer o mesmo de 2048, a versão de uma espécie de jogo já conhecido feita pelo italiano Gabriele Cirulli em um fds para descobrir se seria capaz de fazê-lo. Ele o fez e de brinde também fez o índice de produtividade mundial desabar.
Houve pelo menos dois projetos de I.A. para resolver o problema, que consiste em dobrar números múltiplos de 2 em um quadrado 4 x 4 até que se consiga o quadrado com o valor 2048 (e além). O artigo de Nicola Pezzotti, An Artificial Intelligence for the 2048 game, explica o mais efetivo deles, de autoria de Robert Xiao (eu acho). O programa desenvolvido por Xiao otimiza o tabuleiro do jogo guardando-o em um inteiro de 64 bits, deixando 4 bits para cada casa, mais que o suficiente para que seja armazenada a potência de 2 localizada no quadrado (o limite fica sendo de 2 16, ou 65536). Ao rodar a versão executável console ele imprime cada posição do tabuleiro em um formato &amp;quot;fácil&amp;quot; de ser lido.
Move #69, current score=5841356005100120000 Como pode-se perceber, cada número diferente de zero contém a potência de dois que ocupa a casa (1 é igual a 2, 5 é igual a 2 elevado a 5, que é igual a 32, e assim por diante). Para alinhar corretamente o tabuleiro os números estão impressos em hexadecimal, ou seja, os valores válidos vão de 0 a f (15).
A estratégia do programa de IA é ordenar as casas em um lado e, assim que acumular valores o suficiente, consolidar tudo na última casa. Nem sempre isso é possível, pois uma virada de jogo pode deixar a casa com o maior valor no meio de um dos lados. Nesse caso, é interessante ver como a I.A. se sai, já que com apenas uma execução ela foi até 8192 e mais um 4096. Dá-lhe, computador!
</description>
</item>

     
        <item>
  <title>Geleia de Código</title>
  <link>http://www.caloni.com.br/geleia-de-codigo/</link>
  <pubDate>2014-04-15</pubDate>
  
  <guid>http://www.caloni.com.br/geleia-de-codigo/</guid>
  <description>Não costumo participar de campeonatos de programação por alguns motivos vagos: é perda de tempo (não ganho nada com isso), sou um péssimo programador (ou pasteleiro), dá preguiça (esse é o mais válido) e por aí vai o mimimi. Dessa forma, sempre passei ileso de eventos como o atual Google Code Jam, que pretende levar a categoria de código ofuscado para um novo patamar.
No entanto, esse ano apareceram dois motivos que me levaram a gastar cinco minutos de paciência com as historinhas bestas da equipe do Google. Primeiro o Python, que desde 2013 tem renovado em mim a sensação que programar ainda é divertido (e que o pessoal da Microsoft e do padrão C&#43;&#43; tinham tirado de mim há muito tempo com seus compiladores cada vez mais complexos/lentos e as IDEs que demoram o tempo do cafezinho para abrir). Segundo o que move o mundo: a concorrência. Minha digníssima esposa, levada por alguns pontos-extra na faculdade (uma iniciativa até que louvável do professor), resolveu participar da primeira fase (a classificação desta fase também dava pontos).
O fato é que depois desses cinco minutos eu simplesmente não consegui parar até o minuto final das 23 horas (horário de Brasília) de domingo, quando o tempo-limite esgotou. O aspecto mais divertido do Code Jam é que há liberdade total para a ferramenta que você pretende usar: linguagens de programação, Excel, uma calculadora ou apenas seu cérebro. Você recebe uma &amp;quot;missão&amp;quot; e um arquivo de entrada e precisa cuspir um arquivo de saída de acordo com a missão. Apenas isso. O resto fica por conta da criatividade dos codadores e gambiarreiros de plantão.
Todos os exercícios levam em consideração um arquivo de entrada que possui em sua primeira linha o número de testes que serão feitos e em seguida um número determinado de linhas e parâmetros, geralmente divididos por espaço. O primeiro problema, por exemplo, apenas considerava a suposição de cartas em pequeno truque de mágica e recebia como entrada a disposição dessas cartas junto com a escolha da fileira que o participante dizia onde estava a carta escolhida.
O segundo exercício já envolvia um jogo bem divertido em que o jogador ficava clicando em cookies como se não houvese amanhã. Esse deu um pouco mais de trabalho, mas foi mais divertido que o primeiro.
Já o terceiro... o terceiro passa. Vamos para o quarto, um dos mais instigantes, pois envolve duas regras distintas de um jogo e a otimização das melhores estratégias para ambos. Isso consumiu bem mais tempo que os outros dois iniciais, pois lembro de ter me isolado por uma hora para conseguir colocar tudo na cabeça.
Já o terceiro foi um fracasso total. Tentei de todas as maneiras resolver o impasse de descobrir qual disposição de um jogo de campo minado poderia ser resolvido em apenas um clique (parece o jogo oposto do viciado clicador de cookies), mas falhei miseravelmente. E desconfio o porquê. Primeiro entendo que meu perfeccionismo me impediu de realizar uma checagem padrão para exceções já conhecidas (quando há apenas uma linha ou coluna, quando há apenas um espaço sem minas, etc). Eu pensei: se o Google fez esse problema, ele deve ter bolado alguma solução genérica que independa de ifs. Bom, não que eu saiba. Depois de terminado o tempo dei uma olhada em algumas soluções dos competidores e não achei nenhuma solução que usasse algum algoritmo maluco e genérico (não achei nenhum indiano, contudo).
Eis a solução porca e mal-resolvida (alguns pontos do códido foram feitos depois de ver o código de outrem):
Não, eu não usei o Google para descobrir a lógica por trás do problema. Vai que os caras ficam monitorando quem fica fazendo pesquisas. E, não, tampouco usei o Bing. Não sou masoquista a esse ponto.
PS: Bom, estou na próxima fase. Veremos o que o futuro nos espera. Esse programador foi fisgado pelo campeonato de pastéis.
</description>
</item>

     
        <item>
  <title>Lambda: o Retorno!</title>
  <link>http://www.caloni.com.br/lambda-o-retorno/</link>
  <pubDate>2014-04-08</pubDate>
  
  <guid>http://www.caloni.com.br/lambda-o-retorno/</guid>
  <description>Na última vez que foi abordado o tema &amp;quot;lambda na ferida&amp;quot; falamos brevemente sobre como C&#43;&#43; agora permite criar funções dentro de funções. Hoje vamos apenas falar que aquela construção bizarra que criamos fica ainda mais bizarra se precisarmos retornar alguma coisa dessa função ou usá-la mais de uma vez.
O padrão do lambda é supor que sua função embutida e enlatada não precisa retornar nada, o que torna a sintaxe mais simples: é um void AlgumaCoisa(argumentos). No entanto, para algoritmos como o findif isso não funciona, então é necessário retornar algo. E, no caso de findif, chamá-lo mais de uma vez pode ser feito facilmente criando uma variável lambda:
O tipo de retorno que colocamos através de uma flechinha é obrigatória? De fato, não. Se eu omiti-la vai funcionar do mesmo jeito porque o único ponto de saída da minha função retorna um bool.
Esses compiladores estão ficando cada vez mais espertos.
</description>
</item>

     
        <item>
  <title>A moda agora é levar lambda na função</title>
  <link>http://www.caloni.com.br/a-moda-agora-e-levar-lambda-na-funcao/</link>
  <pubDate>2014-03-28</pubDate>
  
  <guid>http://www.caloni.com.br/a-moda-agora-e-levar-lambda-na-funcao/</guid>
  <description>A nova moda de programar C&#43;&#43; nos últimos anos com certeza é usar lambda. Mas, afinal, o que é lambda? Bom, pra começar, é um nome muito feio.
O que esse nome quer dizer basicamente é que agora é possível criar função dentro de função. Não só isso, mas passar funções inteiras, com protótipo, corpo e retorno, como parâmetro de função.
Isso significa que finalmente os algoritmo da STL vão ser úteis e não um &amp;quot;pain in the ass&amp;quot;.
Por exemplo, antes, tínhamos que fazer o seguinte malabarismo para mexer com arrays/vetores/listas:
Imagine que para cada interação devíamos criar uma função que manipulasse os elementos do vetor.
Uma alternativa que costumava utilizar era a de roubar na brincadeira e criar um tipo dentro da função (permitido) e dentro desse tipo criar uma função (permitido):
Apesar disso gerar INTERNALCOMPILERERROR em muitos builds com o Visual Studio 2003 (e o rápido, mas anos noventa, Visual Studio 6) na maioria das vezes o código compilava e rodava sem problemas. No entanto, deixava um rastro sutil de gambi no ar...
Agora isso não é mais necessário. Desde o Visual Studio 2010 (que eu uso) a Microsoft tem trabalhado essas novidades do padrão no compilador, e aos poucos podemos nos sentir mais confortáveis em usar essas modernices sem medo. Por exemplo:
&amp;quot;Caraca, mas o que é esse código alienígena?&amp;quot;, diria alguém como eu alguns anos atrás (talvez até meses). Bom, nada vem de graça em C&#43;&#43; e dessa vez houve algumas mudanças meio drásticas na sintaxe para acomodar o uso dessa lambida inline.
E não é só isso. Tem muito mais esquisitices de onde veio essa.
</description>
</item>

     
        <item>
  <title>Houaiss para Babylon em Python!</title>
  <link>http://www.caloni.com.br/houaiss-para-babylon-em-python/</link>
  <pubDate>2014-02-27</pubDate>
  
  <guid>http://www.caloni.com.br/houaiss-para-babylon-em-python/</guid>
  <description>O Fabio Montefuscolo expandiu mais ainda o acesso do conversor Houaiss para Babylon implementando uma versão em Python, uma linguagem que estou aprendendo a adorar. Tudo é mais simples, rápido e direto em Python, e o código que ele escreveu utiliza todo esse potencial:
</description>
</item>

     
        <item>
  <title>Real Programmers Don&#39;t Use Java</title>
  <link>http://www.caloni.com.br/real-programmers-dont-use-java/</link>
  <pubDate>2014-02-20</pubDate>
  
  <guid>http://www.caloni.com.br/real-programmers-dont-use-java/</guid>
  <description>When I was a newbie (and a wanna-be) I enjoyed reading &amp;quot;Real Programmers Don&#39;t Use Pascal&amp;quot;, a satiric text that influenced and encouraged me into the path of &amp;quot;C/C&#43;&#43; enlightenment&amp;quot;, most even than K&amp;amp;R&#39;s book. Since then I thought that being a &amp;quot;Real Programmer&amp;quot; was something close to everything one needs to know to get (hard) things done (quickly). Being a &amp;quot;Quiche Eater&amp;quot; was, in couterpart, comparable to nothing. Real Programmers solve real problems! Quiche Eaters are losers who study the academic concepts of computer science and never do a damn useful and/or working program (maybe you know some guy like this).
Jokes apart, the spirit of the text can also be used by those who already find them very good programmers and believe no longer have to grow professionally. The times my ego inflates I still remember that my code use child APIs and an operating system that is a joke. I also remember that there are some people out there designing a starship that will leave the orbit of the Solar System!
On the other hand, many people that just got out of CS course still find programming a difficult matter. This text reminds us that life was difficult 20, 40, 70 years ago, when engineers and programmers were the same person and when you didn&#39;t know that what you were doing could put millions at risk in a project.
Hence, the Real Programmer live in the past. And he always will be worthier than young folks, because he knows how to solve that blue screen problem that nobody else does. As I always say, paraphrasing an illustrious figure in Brazilian television, who is afraid to open Visual Studio and is eternally designing the software instead does not go very far: &amp;quot;who knows to do, do it right way!&amp;quot; .
Here follows a brief summary of the original text adapted to the current times and with my prejucided view of thinking about it. If you wish to use your politically correct piece of mind and criticize me, be my guest!
Languages. Remember: the need to invent more languages/resources to do your job is to remind yourself about your own incompetence to invent such excuse. You are one of those who says &amp;quot;every problem has a specific tool&amp;quot; or something like that. In other words: an inefficient programmer. Don&#39;t you see that everything you need is C. If C won&#39;t do, then assembly will. If none of them, then is isn&#39;t worth doing.
Structured Programming. It is the first and last paradigm to be applied. After all, Object Orientation is another excuse to not program. They are more abstractions that, once you are a dead weight, you are unable to solve a problem using just functions and variables. No, you need classes, inheritance, templates and whatever the hell that will transform your simple and straight code into a magical horn of plenty that will only impress others at the futility and complexity of the solution.
Data structure. Another great concept to fool yourself. Today are many who enslave us to weird SQL layouts and weird frameworks that do all the work. We all know that the only really useful to know the structure is the array. The rest are variants of the same theme: queues and stacks.
Operating system. Mac and Windows are just toys and Linux is a video game that takes more work to set up than playing. The programmer actually uses something like mainframes or other beta operating system, which are too weird and can make a real mess in the hands of those who have not read the WHOLE manual. And knowing all known major kernel bugs and its location by heart at the time of booting is vital.
Tools. If you depend on an IDE that have Code Completion and other fancy stuff or any other editor that depends on your favorite 17,459 plugins installed, then you are not a Real Programmer. A Real Programmer actually use what he have on hand at the time, like notepad, hexdump or even some beeps . The tool is no limit to one that can really code.
Debugging. Are you saying that you need the source code in order to debug? So you do not have a clue of what the program does. Just a few glances at call stack and the registers can make a Real Programmer solve a bug that Quiche Eaters would not get after analyzing those charts with boxes inside UML and use cases for months.
The Real Programmers Work is certainly not doing trivial databases to trivial programs that access SQL with trivial queries. Neither are those horrible websites with PHP/Apache and scripts and more scripts written by kids. No, sir. These are programs that deal with the OS in a more intimate way (HD encryption, file system drivers, critical communication services, etc.), or are programs that do something really useful (compilers, the operating system itself). Or maybe those programs that deal directly with hardware (complex microcontrollers, robots, ships, medical devices, etc.).
The Fun of every Real Programmer is actually chat with friends (about programming), read something (about programming) and watch intelligent movies (about programming or people who have some kind of intellectual challenge to solve &amp;quot;the hard way&amp;quot;). Is there anything more fun than that?
And, finally, in their Natural Habitat, we can find pages and pages of assembly code scattered around the table, a computer locked by a remote kernel debugging serial cable, some notes in hex on a piece of paper, a few dozen browser pages openned about the behavior of functions in BIOS SATA HDDs with 500 GB working on RAID4, coffee (of course), chips, stains on the carpet. When there&#39;s nothing to do the environment is pretty tidy and one cannot notice the presence of Real Programmers in sight.
And the Future of Real Programmer? Well, C may even be dying. But so what? It seems C&#43;&#43; supports pointers as well. The rest of the useless abstractions like classes and inheritance may be totally ignored. The basics will always exist. Forget versions with multiple inheritance and enigmatic concepts. Be a (wo)man!
The real, happy, final truth is: regardless of how much more the world becomes &amp;quot;managed&amp;quot; behind frameworks and programmers who prefer to &amp;quot;do projects&amp;quot; behind their office packages and use cases, when problems pop up, some bug murky life threatening useful for a project, a Real Programmer will be there to save the day, because only a programmer really knows how to do his job well done and have a good night of sleep knowing that everything will just be OK.
If it doesn&#39;t, there will be always a Real Programmer to save the day.
&amp;quot;As long as there are ill-defined goals, bizarre bugs, and unrealistic schedules, there will be Real Programmers willing to jump in and Solve The Problem, saving the documentation for later. Long live FORTRAN!&amp;quot;
</description>
</item>

     
        <item>
  <title>removeif até remove, só que diferente</title>
  <link>http://www.caloni.com.br/remove_if-ate-remove-so-que-diferente/</link>
  <pubDate>2014-01-21</pubDate>
  
  <guid>http://www.caloni.com.br/remove_if-ate-remove-so-que-diferente/</guid>
  <description>A surpresa de hoje foi descobrir (vejam só) que o removeif, como todo algoritmo da STL, deve ser olhado de perto antes de usado. Nesse caso em específico porque, apesar do nome, a função NÃO remove elementos, mas os sobrescreve.
Imagine uma função que usa removeif para remover todas as idades de potenciais lolitas:
Ou até sua contraparte usando um array C:
Um uso trivial pode não cuspir um resultado trivial, ou seja, os elementos não serão removidos como se espera:
Isso ocorre porque o comportamento do removeif é copiar todos os elementos que retornem false (não remova) e pular elementos que retornem true (remova). No entanto, o tamanho do contêiner, e consequentemente seu ponteiro end(), permanecem o mesmo.
De acordo com o saite cplusplus.com, o algoritmo STL é previsível, simples, e por isso mesmo sujeito a otimizações do compilador:
Para obtermos qual seria o &amp;quot;novo end()&amp;quot;, precisamos obter esse valor do retorno de removeif. Com base nisso, podemos alterar o tamanho do contêiner ajustado:
Esse C&#43;&#43;... intuitivo como nunca!
</description>
</item>

     
        <item>
  <title>BovespaBacktesting</title>
  <link>http://www.caloni.com.br/bovespabacktesting/</link>
  <pubDate>2014-01-08</pubDate>
  
  <guid>http://www.caloni.com.br/bovespabacktesting/</guid>
  <description>Eu não sou apenas um programador: sou um especulador. Ou, para quem ficou com medo, um investidor. Ficou bonito, agora? Trocando em miúdos, isso quer dizer que muitas vezes aposto na bolsa de valores, aquela onde as pessoas ganham e perdem dinheiro loucamente. Porém, assim como faço com minha carreira de desenvolvedor, não deixo de estudar e aprimorar minhas habilidades. Tirando alguns anos de estudo com livros de finanças, economia e contabilidade, foi com base nisso que eu fiz uma série de scripts que realiza operações de backtesting nos papéis da Bovespa.
Backtesting é uma maneira dos especuladores terem uma noção de quão bom ou ruim é sua estratégia de compra e venda. É uma maneira profissional de se aproximar do mercado caótico das ações. Basicamente um backtesting simula o que o especulador faria na vida real com um histórico razoável de variação de preços das ações que pretende operar. Se esse monte de palavras novas neste blogue está te deixando com medo, recomendo dar uma passada no Senhor Mercado (lá você irá também aprender mais sobre técnicas de backtesting).
Vamos supor que minha ideia de estratégia seja comprar quando o preço de uma determinada ação estiver na metade do seu topo histórico e vender quando ele estiver no dobro do momento da compra. Uma estratégia bem tosca, mas se fizer dinheiro, quem liga para vaidade? Outra estratégia mais refinada usa médias móveis para estabelecer pontos de compra e venda dependendo da tendência do mercado. Qual das duas dá mais dinheiro? Existem duas maneiras de saber: a dolorosa e a indolor. A dolorosa seria sacar uma grana do banco e começar a operar em sua corretora favorita seguindo ambas as estratégias e ver qual te deixou mais rico e qual te levou à falência. A indolor seria baixar o histórico de preços dos papéis que está interessado em usar essas estratégias e rodar uma simulação que opere seguindo ambas as estratégias e descubra qual é a perdedora. Qual você preferiria?
OK, esse assunto já está ficando bem monótono para quem acompanha um blogue de programação. Vamos ao código!
O projeto que mantenho no GitHub possui algumas ideias que gostaria de compartilhar com todos que estão interessados em realizar um backtesting, independente de sua estratégia. A primeira delas seria de onde baixar o histórico de preços de maneira simples e barata. Eu recomendo e uso o software Grafix, que consegue baixar as informações diretamente do saite da Bovespa e realizar os ajustes necessários para montar e exibir as informações. Com base no banco de dados do Grafix é que o BovespaBacktesting (meu projeto) importa as informações que ele precisa. Ele irá importar apenas os códigos que estiverem em uma lista disponível no arquivo data/filterCodes relativo de onde o script estiver rodando. Esse arquivo é apenas texto com um código por linha.
A partir dessa importação é possível realizar queries com as variações diárias, semanais e mensais dos preços dos ativos conhecidos (a mesma lista de código). A própria lista de ativos conhecidos está disponível através de uma função, tornando a iteração simples e direta.
Com essas informações de preço é possível aplicar qualquer tipo de indicador. O BovespaBackteting possui apenas os mais usuais, mas basta implementar a lógica de tratamento em Python, o que não deve consumir nem muito tempo nem muitos neurônios, pois com o histórico disponível tudo fica mais fácil.
As funções-macro calculam trades (operações) a partir de alguns parâmetros definidos no código ou por parâmetros. As versões do BovespaBacktesting foram variando nesse sentido. Ainda não há uma maneira saudável de comparar diversas estratégias, pois o que eu tenho feito basicamente é alterar alguns parâmetros, rodar o backtesting e exportar para um CSV (função já disponível).
Já existem algumas firulas caso você esteja pensando em uma estratégia em que seja viável viver de operar, como cálculo de salário e a inclusão de variáveis que levem em conta que parte do dinheiro ganho será usado. Ainda é um código bem tosco, mas funciona e pode ser o ponto de entrada de quem deseja conhecer mais sobre o mercado de ações e como os profissionais conseguem tirar dinheiro deste grande cassino.
</description>
</item>

     
        <item>
  <title>Uma nova linguagem</title>
  <link>http://www.caloni.com.br/uma-nova-linguagem/</link>
  <pubDate>2013-12-04</pubDate>
  
  <guid>http://www.caloni.com.br/uma-nova-linguagem/</guid>
  <description>Tenho que me atualizar. Faz um tempo (anos) em que deixei de lado esse mundo &amp;quot;frescurento&amp;quot; de C&#43;&#43;2030 e me foquei única e exclusivamente em resolver problemas da melhor forma possível com o que a linguagem já tinha a oferecer em uma implementação estável de compilador e bibliotecas.
Agora o mundo está mudando. Para quem é do Universo Windows/Microsoft, a empresa do Uncle Bill vem liberando algumas versões interessantes do seu compilador (VS2012, 2013 e agora o CTP), cada vez mais próxima de um C&#43;&#43;11/14 100% compliance. Não acredito que cheguem lá, mas o fato de estarem empenhados indica para a indústria e seus clientes que há uma demanda sendo atendida. Não é mais frescurite de acadêmicos. Algumas features ultra-novas começam a ser usadas e permitidas em projetos.
Estamos falando de uma nova linguagem que se forma com um novo ritmo. O padrão C&#43;&#43;11 demorou &amp;quot;apenas&amp;quot; 2 anos para cair em nossas linhas de comando, há um patch já confirmado para o ano que vem e já existem menções para um novo release em 2017. Para o programador C&#43;&#43; que se acostumou a contar as evoluções em décadas, um novo ritmo se impõe. Não há tempo para cristalização de conceitos. O boost já nos forneceu isso por todos esses anos e hoje ele é reconhecidamente a versão alpha que precisávamos.
Veremos o que o futuro cada vez mais presente nos reserva.
</description>
</item>

     
        <item>
  <title>Ponto Flutuante Afundando</title>
  <link>http://www.caloni.com.br/ponto-flutuante-afundando/</link>
  <pubDate>2013-11-07</pubDate>
  
  <guid>http://www.caloni.com.br/ponto-flutuante-afundando/</guid>
  <description>Quando armazenamos valores monetários em doubles seus cálculos conseguem manter a precisão e na maioria das vezes o ajuste de precisão funciona. Porém, encontrei alguns casos onde a subtração de dois valores fazia &amp;quot;perder&amp;quot; um centavo (ou comparações exatas) justamente pela limitação da precisão do ponto flutuante. Nesse exemplo os valores são 2.358,93 - 1.386,93, que em uma conta de padaria (mas correta) dá 972,00 (até a Calc do Windows e o Excel funcionam), mas pelo Visual Studio 2010 chega perto, mas erra o alvo:
Isso ocorre porque sua representação dentro da variável double é diferente de 272.0 do outro double. Depurando vemos mais claramente:
Ou seja, quando fazemos a subtração de d2 em d1, nossa precisão raspa um pouquinho e escapa pela beirada:
Na comparação com o valor redondo aparece a falha, mas note que isso não ocorre com os outros valores d1 e d2, já que o armazenamento adquire o mesmo formato:
Há uma forma de arredondamento já disponível no C99 (mas não no Visual Studio 2010) que pode ser útil para esses casos. A única coisa que é preciso fazer é arredondar os valores antes do cálculo:
É uma decisão arbitrária essa de arredondar para cima, mas se for adotada em todo o sistema (e já fazendo parte de um padrão, no caso, o C99), não deverão existir problemas de interpretação de cálculos entre os componentes.
O mercado financeiro agradece =).
UPDATE: Não estou de acordo com o armazenamento de valores monetários em doubles em vez de inteiros pelo simples motivo que não há moedas no sistema financeiro com unidades que se dividem ad infinitum. Por consequência, existe sempre uma unidade básica e indivisível (que no caso do Brasil é o centavo de real). Ou seja, como o objetivo é contar o total dessas unidades que não se dividem, o uso de inteiros é brainless.
UPDATE: Existe uma discussão exatamente sobre isso no Grupo C/C&#43;&#43; Brasil, que recomendo a leitura, o que me levou a escrever o post. Particularmente, sigo o raciocínio do Pedro Lamarão.
</description>
</item>

     
        <item>
  <title>Depuração na nuvem com o novo Visual Studio</title>
  <link>http://www.caloni.com.br/depuracao-na-nuvem/</link>
  <pubDate>2013-04-01</pubDate>
  
  <guid>http://www.caloni.com.br/depuracao-na-nuvem/</guid>
  <description>Uma das novidades do futuro Visual Studio pouco comentada ainda em fóruns por seu caráter sigiloso e ainda em testes (mas que pode facilmente ser observada pela engenharia reversa dos binários do Visual C&#43;&#43;) é a possibilidade de depurar trechos de código &amp;quot;na nuvem&amp;quot;, ou seja, dentro dos gigantescos servidores de clusters de serviços de escalabilidade da Amazon, do Google e, claro, da Microsoft.
Já é conhecido que será possível inserir comentários no código-fonte com o formato @nickname e incluir na listagem de bugs o estilo das #hashtags para que programadores vinculados à sua rede social possam enxergar referências a outros programadores e verificar o Developer TrendTopics, como um #blame-joel-on-software. Porém, o que poucos sabem, é que será também possível depurar as APIs de redes sociais em tempo real. Ou seja, caso seja usado o método Twitter::Tweet(), logo após o retorno da chamada será possível aguardar por uma resposta dos usuários envolvidos:
Ou seja, logo será possível além de perder horas navegando em saites de rede social perder também horas depurando os comentários e respostas das pessoas nessas redes direto do Visual Studio. É a Microsoft pensando nos programadores que gostam de perder tempo se envolver com pessoas (ainda que virtuais) e discussões acaloradas sobre tópicos irrelevantes e absurdos (ainda que virtuais).
</description>
</item>

     
        <item>
  <title>eXtreme Go Horse</title>
  <link>http://www.caloni.com.br/extreme-go-horse/</link>
  <pubDate>2012-09-27</pubDate>
  
  <guid>http://www.caloni.com.br/extreme-go-horse/</guid>
  <description>O Go Horse Power (GHP) foi criado por um blogue hoje extinto. As premissas dessa nova metodologia de desenvolvimento era que o projeto fosse feito da maneira mais rápida possível.
Contudo, eles não contavam com a versão turbinada do desleixo humano.
A eXtreme Go Horse (XGP) é o suprassumo das metodologias do mercado brasileiro de desenvolvimento. Quem nunca trabalhou em uma empresa gerida por essas regras? (Bom, pelo menos XGH pelo jeito tem até controle de fonte, algo que era até meio raro uns anos atrás):
1- Pensou, não é XGH
XGH não pensa, faz a primeira coisa que vem à mente. Não existe segunda opção, a única opção é a mais rápida
2- Existem três formas de se resolver um problema
Estas são: a correta, a errada e a XGH, que é igual à errada, só que mais rápida. XGH é mais rápido que qualquer metodologia de desenvolvimento de software que você conhece (Vide Axioma 14).
3- Quanto mais XGH você faz, mais precisará fazer
Para cada problema resolvido usando XGH, mais uns 7 são criados. Mas todos eles serão resolvidos da forma XGH. XGH tende ao infinito.
4- XGH é totalmente reativo
Os erros só existem quando aparecem.
5- XGH vale tudo, só não vale dar o toba
Resolveu o problema? Compilou? Commit e era isso.
6- Commit sempre antes de update
Se der merda, a sua parte estará sempre correta.. E seus colegas que se fodam.
7- XGH não tem prazo
Os prazos passados pelo seu cliente são meros detalhes. Você SEMPRE conseguirá implementar TUDO no tempo necessário (nem que isso implique em acessar o BD por um script malaco)
8- Esteja preparado para pular fora quando o barco começar a afundar¿
Ou coloque a culpa em alguém ou algo. Pra quem usa XGH, um dia o barco afunda. Quanto mais o tempo passa, mais o sistema vira um monstro. O dia que a casa cair, é melhor seu curriculum estar cadastrado na APInfo, ou ter algo pra colocar a culpa
9- Seja autêntico, XGH não respeita padrões
Escreva o código como você bem entender, se resolver o problema, commit e era isso
10- Não existe refactoring, apenas rework
Se der merda, refaça um XGH rápido que solucione o problema. O dia que o rework implicar em reescrever a aplicação toda, pule fora, o barco irá afundar (Vide Axioma 8)
11- XGH é totalmente anárquico
A figura de um gerente de projeto é totalmente descartável. Não tem dono, cada um faz o que quiser na hora que os problemas e requisitos vão surgindo (Vide Axioma 4)
12- Se iluda sempre com promessas de melhorias
Colocar TUDO no código como uma promessa de melhoria ajuda o desenvolvedor XGH a não sentir remorso ou culpa pela cagada que fez. É claro que o refactoring nunca será feito (Vide Axioma 10)
13- XGH é absoluto, não se prende à coisas relativas
Prazo e custo são absolutos, qualidade é totalmente relativa. Jamais pense na qualidade e sim no menor tempo que a solução será implementada, aliás¿ não pense, faça!
14- XGH é atemporal
Scrum, XP¿Tudo isso é modinha. O XGH não se prende às modinhas do momento, isso é coisa de viado. XGH sempre foi e sempre será usado por aqueles que desprezam a qualidade
15- XGH nem sempre é POG
Muitas POG¿s exigem um raciocínio muito elevado, XGH não raciocina (Vide Axioma 1).
16- Não tente remar contra a maré
Caso seus colegas de trabalho usam XGH para programar e você é um coxinha que gosta de fazer as coisas certinhas, esqueça! Pra cada Design Pattern que você usa corretamente, seus colegas gerarão dez vezes mais código podre usando XGH.
17- O XGH não é perigoso até surgir um pouco de ordem
Este axioma é muito complexo, mas sugere que o projeto utilizando XGH está em meio ao caos. Não tente por ordem no XGH (Vide Axioma 16), é inútil e você pode jogar um tempo precioso no lixo. Isto fará com que o projeto afunde mais rápido ainda (Vide Axioma 8). Não tente gerenciar o XGH, ele é auto suficiente (Vide Axioma 11), assim como o caos.
18- O XGH é seu brother, mas é vingativo
Enquanto você quiser, o XGH sempre estará do seu lado. Mas cuidado, não o abandone. Se começar um sistema utilizando XGH e abandoná-lo para utilizar uma metodologia da moda, você estará fudido. O XGH não permite refactoring (vide axioma 10), e seu novo sistema cheio de frescurites entrará em colapso. E nessa hora, somente o XGH poderá salvá-lo.
19- Se tiver funcionando, não rela a mão
Nunca altere, e muito menos questione um código funcionando. Isso é perda de tempo, mesmo porque refactoring não existe (Vide Axioma 10). Tempo é a engrenagem que move o XGH e qualidade é um detalhe desprezível.
20- Teste é para os fracos
Se você meteu a mão num sistema XGH, é melhor saber o que está fazendo. E se você sabe o que está fazendo, vai testar pra que? Testes são desperdício de tempo, se o código compilar, é o suficiente.
21- Acostume-se ao sentimento de fracasso iminente
O fracasso e o sucesso andam sempre de mãos dadas, e no XGH não é diferente. As pessoas costumam achar que as chances do projeto fracassar utilizando XGH são sempre maiores do que ele ser bem sucedido. Mas sucesso e fracasso são uma questão de ponto de vista. O projeto foi por água abaixo mas você aprendeu algo? Então pra você foi um sucesso!
22- O problema só é seu quando seu nome está no Doc da classe
Nunca ponha a mão numa classe cujo autor não é você. Caso um membro da equipe morra ou fique doente por muito tempo, o barco irá afundar! Nesse caso, utilize o Axioma 8.
Este texto foi copiado daqui e daqui. Não existem donos conhecidos do XGH (já devem ter morrido de desgosto). Fiquei com medo de não encontrar mais essa metologia, que é pouco divulgada e muito útil.
</description>
</item>

     
        <item>
  <title>Minha palestra do TDC 2012</title>
  <link>http://www.caloni.com.br/minha-palestra-do-tdc-2012/</link>
  <pubDate>2012-07-21</pubDate>
  
  <guid>http://www.caloni.com.br/minha-palestra-do-tdc-2012/</guid>
  <description>Duas semanas atrás rolou a trilha C&#43;&#43; do TDC 2012, que contou com além da minha presença com a dos já conhecidos Fernando Roberto (DriverEntry), Rodrigo Strauss (1Bit), etc. Uma novidade: meu colega e programador .nerd Gabriel Guilherme também participou em uma palestra sobre um assunto que acredito que deveria ser mais promovido: interop. Afinal de contas, o poder de C&#43;&#43; não seria nada se não houvesse motivos práticos para usá-lo. Entre esses motivos, construir soluções com linguagens mais acessíveis é um deles.
Na minha palestra foquei no conteúdo dos meus dois artigos sobre um fictício Patch de Emergência (parte 1 e parte 2 from Wanderley Caloni
</description>
</item>

     
        <item>
  <title>GetTickCount não é um gerador de IDs únicos</title>
  <link>http://www.caloni.com.br/gettickcount-nao-e-um-gerador-de-ids-unicos/</link>
  <pubDate>2012-06-25</pubDate>
  
  <guid>http://www.caloni.com.br/gettickcount-nao-e-um-gerador-de-ids-unicos/</guid>
  <description>Muitas vezes uma solução intuitiva não é exatamente o que esperamos que seja quando o código está rodando. Gerar IDs únicos, por exemplo. Se você analisar por 5 minutos pode chegar à conclusão que um simples GetTickCount, que tem resolução de clock boa e que se repete apenas depois de 50 dias pode ser um ótimo facilitador para gerar IDs exclusivos durante o dia.
Porém, nada como código para provar que estamos errados:
O motivo do GetTickCount retornar números iguais remete tanto ao fato que o espaço de tempo entre uma execução e outra pode ser muito pequeno quanto ao fato de várias threads podem ser executadas efetivamente ao mesmo tempo em ambientes de dois ou mais cores.
Já o motivo do InterlockedIncrement funcionar sempre é porque aqui estamos usando uma solução de incremento atômico, ou seja, usamos a mesma base contadora e incrementamos ela em uma operação que não pode ocorrer ao mesmo tempo com outra thread.
O que aprendemos aqui? Que por mais que seja intuitiva uma solução, nunca podemos nos basear nas nossas falhas cabeças. Um computador está aí não apenas para ser mais rápido, mas para ser assertivo em nossas elucubrações. Nesse sentido, é o nosso companheiro vulcaniano.
</description>
</item>

     
        <item>
  <title>Meus repositórios no GitHub</title>
  <link>http://www.caloni.com.br/meus-repositorios-no-github/</link>
  <pubDate>2012-06-04</pubDate>
  
  <guid>http://www.caloni.com.br/meus-repositorios-no-github/</guid>
  <description>Depois de vacilar por alguns meses, incentivado pelo meu amigo Chico Pimenta, resolvi experimentar o tal do GitHub, e consequentemente o sistema de controle de fontes distribuído Git, que antes era meio exclusivo do Linux (continua meio sendo, mas com suporte um pouco melhor para Windows).
Com isso, dei uma pequena lida no livro de introdução e comecei a migrar meus fontes perdidos num canto do HD. O que notei de vantagem com relação a outros DRCSs foi que é muito fácil e rápido criar branches e que a comunicação remota e os commits são feitos de uma maneira mais organizada e estruturada, além da própria estrutura interna do repositório ser muito simples de entender: um bando de arquivos compactados cujo nome é o hash do que ele contém.
Meus repositórios estão armazenados em alguns branches que distribuí de acordo com o uso/importância:
 OpenSource. Projetos de fonte aberto que mantenho/ive e que poderiam se perder se alguém não fizesse backup (como o mouse tool ou regmon). Samples. Códigos de exemplo, de palestras e de testes feitos para escrever os artigos do blogue cujo autor vos fala. Caloni. Os códigos que fazem algo de útil, como o Houaiss2Babyulon, CopiaExata e DayToDay. Book. Um projeto em estado de larva sobre escrever um livro de engenharia reversa. Já possui um índice básico. Sugestões são bem-vindas. DriverEntry. Códigos do curso de desenvolvimento de drivers que estou fazendo com o Fernando, da DriverEntry Company. Recomendo!  </description>
</item>

     
        <item>
  <title>Problemas comuns no WinDbg e suas soluções</title>
  <link>http://www.caloni.com.br/problemas-comuns-no-windbg-e-suas-solucoes/</link>
  <pubDate>2012-05-27</pubDate>
  
  <guid>http://www.caloni.com.br/problemas-comuns-no-windbg-e-suas-solucoes/</guid>
  <description>Depois de uma agradável manhã e tarde acompanhando o curso de desenvolvimento de drivers do meu amigo Ferdinando voltei para a casa para brincar um pouco mais com o mundo kernel e voltar a encontrar problemas com o WinDbg &amp;amp; Cia que há mais ou menos 1 ano atrás não tinha.
Pesquisando por um problema específico envolvendo PDBs reencontrei o blogue do Ken Johnson, MVP Microsoft e analista por profissão e diversão, é conhecido por suas excelentes contribuições no mundo da depuração de sistema (notadamente WinDbg). Existe um post específico que ele escreveu para economizar tempo com problemas que ocorrem de vez em quando em uma sessão ou outra de depuração, mas nunca paramos tempo o suficiente para resolver.
Além de outros, ele lista alguns que particularmente já aconteceram comigo ou com colegas de depuração:
O WinDbg demora um tempo absurdo para processar o carregamento dos módulos e está usando tempo máximo de processamento em apenas uma CPU.
Isso ocorre porque existem breakpoints ainda não resolvidos. Resolva deixando apenas esses tipos de breakpoints que são absolutamente necessários, pois cada vez que um módulo é carregado o depurador precisa fazer o parser de cada um deles para verificar se ele já consegue resolve-lo.
Às vezes, porém, existe algum lixo nos workspaces carregados por ele que permanecem mesmo depois de apagarmos todos os breakpoints inúteis ou reiniciar o sistema. Em último caso, sempre podemos apagar o workspace do registro, em HKCU\Software\Microsoft\Windbg\Workspaces.
O WinDbg continua demorando décadas para analisar o carregamento, mas agora nem consome tanta CPU assim.
Isso ocorre porque na cadeia de paths para procurar por símbolos existe algum endereço de rede/internet errado que faz com que ele tenha que caminhar em falso diversas vezes. Esse e outros erros de símbolos sempre poderão ser analisados através do universal !sym noisy, que imprime todo tipo de informação útil do que pode dar errado durante um .reload explícito (eu digitei) ou implícito (lazy reload).
O WinDbg continua recusando carregar um símbolo que eu sei que existe e sei que é válido.
Talvez ele exista, mas por algum motivo foi copiado corrompido para o symbol server. Mais uma vez, !sym noisy nele e deve acontecer algum erro de EPDBCORRUPT. Nesse caso, apague o PDB culpado e tente de novo.
E, como brinde, um grande aliado da produtividade: como evitar que o WinDbg bloqueie seu PDB enquanto você precisa constantemente recompilar seu driver:
Fonte: Blog do Nynaeve.
</description>
</item>

     
        <item>
  <title>Sobrecarga de função às avessas</title>
  <link>http://www.caloni.com.br/sobrecarga-de-funcao-as-avessas/</link>
  <pubDate>2012-05-20</pubDate>
  
  <guid>http://www.caloni.com.br/sobrecarga-de-funcao-as-avessas/</guid>
  <description> Nota do autor: navegando pelo Archive.org, que possibilita viajar no tempo e encontrar coisas enterradas que seria melhor deixar por lá, consegui encontrar um post que se perdeu na dobra espaço-temporal entre o old-fashioned Caloni.com.br (com direito à velha joaninha psicodélica, desenho do meu amigo que uso até hoje no blogue) e um finado outro domínio meu, o CThings. No final, consegui matar a marmota, chegar a 80 milhas por hora e voltar para o presente. Enjoy!
 Alguém já se perguntou se é possível usar sobrecarga de função quando a diferença não está nos parâmetros recebidos, mas no tipo de retorno? Melhor dizendo, imagine que eu tenha o seguinte código:
void CreateNewGUID(wstring&amp;amp;);void CreateNewGUID(GUID&amp;amp;);GUID guid;wstring guidS;CreateNewGUID(guidS);CreateNewGUID(guid); É um uso sensato de sobrecarga. Mas vamos supor que eu queira uma sintaxe mais intuitiva, com o retorno sendo atribuído à variável:
wstring CreateNewGUID();GUID CreateNewGUID();GUID guid;wstring guidS;guid = CreateNewGUID();guidS = CreateNewGUID(); Voltando às teorias de C&#43;&#43; veremos que o código acima NÃO funciona. Ou, pelo menos, não deveria. Só pelo fato das duas funções serem definidas o compilador já reclama com um &amp;quot;error C2556: &#39;GUID CreateNewGUID(void)&#39;: overloaded function differs only by return type from &#39;std::wstring CreateNewGUID(void)&#39;&amp;quot;. E obviamente ele está correto. O tipo de retorno não é uma propriedade da função que exclua a ambiguidade em sua chamada. Apenas a assinatura pode fazer isso (que são os tipos dos parâmetros recebidos pela função).
Como não podemos utilizar funções ordinárias o jeito é criar nosso próprio tipo de função que dê conta do recado usando a sobrecarga do operador de conversão de tipos. O operador de conversão suporta sobrecarga porque é na conversão que o compilador decide qual função chamar.
struct CreateNewGUID{operator wstring ();operator GUID ();}; guid = CreateNewGUID();guidS = CreateNewGUID(); Agora com o novo tipo CreateNewGUID é possível chamá-lo como uma função, o que na prática cria uma nova instância da struct. Ao atribuir o retorno dessa instância a uma variável do tipo wstring ou GUID os operadores de conversão serão requisitados, cada um dependendo do tipo da variável a qual será atribuído o retorno.
Uma vez que criamos um novo tipo, e considerando que este tipo é, portanto, diferente dos tipos wstring e GUID já existentes, devemos simplesmente converter nosso novo tipo para cada um dos tipos de retorno desejados:
struct CreateNewGUID{operator wstring (){wstring ret;// cria guidreturn ret;}operator GUID (){GUID ret;// cria guidreturn ret;}}; E isso conclui a solução meio esquizofrênica de nossa sobrecarga às avessas. E voltando à pergunta original, penso que, com criatividade e C&#43;&#43;, nada é impossível. =)
</description>
</item>

     
        <item>
  <title>Consumo abusivo de memória</title>
  <link>http://www.caloni.com.br/consumo-abusivo-de-memoria/</link>
  <pubDate>2012-05-19</pubDate>
  
  <guid>http://www.caloni.com.br/consumo-abusivo-de-memoria/</guid>
  <description>Era um belo dia em um ambiente de processamento fictício de filas fictícias e threads fictícias. Eis um belo código com filas, threads e processamentos feitos em stop-motion:
Se olharmos de perto o processamento e a memória consumida por esse processo, veremos que no início existe um boom de ambos, mas após um momento de pico, o processamento praticamente pára, mas a memória se mantém:
Depois de pesquisar por meus tweets favoritos, fica fácil ter a receita para verificarmos isso usando nosso depurador favorito: WinDbg!
windbg -pn MemoryConsumption.exe
Achamos onde está a memória consumida. Agora precisamos de dicas do que pode estar consumindo essa memória. Vamos começar por listar os chunks alocados por tamanho de alocação:
O Top 3 é de tamanhos conhecidos pelo código, de 1024 a 1024 &#43; QUEUESSIZE - 1. O de tamanho 1037, por exemplo, possui 0x25e5 blocos alocados. Vamos listar cada um deles:
A listagem do depurador nos dá o endereço onde o chunk foi alocado no heap e o endereço devolvido para o usuário, onde colocamos nossas tralhas. Através de ambos é possível trackear a pilha da chamada que alocou cada pedaço de memória. Isso, claro, se previamente tivermos habilitado essa informação através do GFlags.aspx):
Dessa forma temos onde cada memória foi alocada, o que nos dará uma informação valiosa, dependendo qual o tipo de problema estamos tentando resolver.
Outra informação relevante é o que está gravado na memória, que pode nos dar insights de que tipo de objeto estamos lidando:
Não é o caso, mas vamos supor que fosse um objeto/tipo conhecido. Poderíamos simplesmente &amp;quot;importar&amp;quot; o tipo diretamente do PDB que estamos para modelar a memória que encontramos em volta. Mais detalhes em outro artigo.
  CreateThread.aspx). Cria uma nova linha de execução.
  WaitForMultipleObjects.aspx). Pode aguardar diferentes linhas de execução terminarem.
  std::list. Lista na STL para inserir/remover objetos na frente e atrás (ui).
  Initialize.aspx), Enter.aspx) e LeaveCriticalSection.aspx). Uma maneira simples de criar blocos de entrada atômica (apenas uma thread entra por vez).
  memset. Se você não sabe usar memset, provavelmente não entendeu nada desse artigo.
  </description>
</item>

     
        <item>
  <title>Coletando dumps automaticamente</title>
  <link>http://www.caloni.com.br/coletando-dumps-automaticamente/</link>
  <pubDate>2012-05-17</pubDate>
  
  <guid>http://www.caloni.com.br/coletando-dumps-automaticamente/</guid>
  <description>   Value Description Type Default value     DumpFolder [1] REGEXPANDSZ %LOCALAPPDATA%\CrashDumps   DumpCount [2] REGDWORD 10   DumpType [3] REGDWORD 1   CustomDumpFlags [4] REGDWORD [5]    Chave: HKEYLOCALMACHINE\SOFTWARE\Microsoft\Windows\Windows Error Reporting\LocalDumps.
 [1] The path where the dump files are to be stored. If you do not use the default path, then make sure that the folder contains ACLs that allow the crashing process to write data to the folder.For service crashes, the dump is written to service specific profile folders depending on the service account used. For example, the profile folder for System services is %WINDIR%\System32\Config\SystemProfile. For Network and Local Services, the folder is %WINDIR%\ServiceProfiles. [2] The maximum number of dump files in the folder. When the maximum value is exceeded, the oldest dump file in the folder will be replaced with the new dump file. [3] Specify one of the following dump types: 0 = Custom dump, 1 = Mini dump, 2 = Full dump [4] The custom dump options to be used. This value is used only when DumpType is set to 0.The options are a bitwise combination of the MINIDUMP_TYPE enumeration values. [5] MiniDumpWithDataSegs or MiniDumpWithUnloadedModules or MiniDumpWithProcessThreadData.  Fonte: MSDN (Collecting User-Mode Dumps).
</description>
</item>

     
        <item>
  <title>Header Inútil</title>
  <link>http://www.caloni.com.br/header-inutil/</link>
  <pubDate>2012-03-27</pubDate>
  
  <guid>http://www.caloni.com.br/header-inutil/</guid>
  <description>O Visual Studio é uma ótima ferramenta para depurar rapidamente programas sendo desenvolvidos e para o resto usamos Vim. No entanto, a versão 2010 do ambiente (ainda não testei a 2011 beta) possui um pequeno deslize com sua árvore de dependências que não chega a prejudica o desenvolvedor, mas o deixa com um bug atrás da orelha.
Vamos supor que você crie seu super-projeto ZeroMQ e no meio dele acabe evoluindo uma nova forma de vida inútil e descartável, que aqui iremos chamar de HeaderInutil e seu fiel companheiro CppInutil:
OK. Ele não está fazendo nada, mas e daí? Compilo meu projeto normalmente e depuro ele como se nada estivesse acontecendo.
------ Rebuild All started: Project: ZeroMasQueCoisaProj, Configuration: Debug Win32 ------ Build started 27/03/2012 11:40:32. PrepareForClean: Deleting file &amp;quot;Debug\ZeroMasQueCoisaProj.lastbuildstate&amp;quot;. InitializeBuildStatus: Creating &amp;quot;Debug\ZeroMasQueCoisaProj.unsuccessfulbuild&amp;quot; because &amp;quot;AlwaysCreate&amp;quot; was specified. ClCompile: stdafx.cpp ZeroMasQueCoisaProj.cpp CppInutil.cpp Generating Code... Manifest: Deleting file &amp;quot;Debug\ZeroMasQueCoisaProj.exe.embed.manifest&amp;quot;. LinkEmbedManifest: ZeroMasQueCoisaProj.vcxproj -&amp;gt; c:...\Debug\ZeroMasQueCoisaProj.exe FinalizeBuildStatus: Deleting file &amp;quot;Debug\ZeroMasQueCoisaProj.unsuccessfulbuild&amp;quot;. Touching &amp;quot;Debug\ZeroMasQueCoisaProj.lastbuildstate&amp;quot;.
Build succeeded.
Time Elapsed 00:00:00.73 ========== Rebuild All: 1 succeeded, 0 failed, 0 skipped ==========
&#39;ZeroMasQueCoisaProj.exe&#39;: Loaded &#39;C:...\Debug\ZeroMasQueCoisaProj.exe&#39;, Symbols loaded. &#39;ZeroMasQueCoisaProj.exe&#39;: Loaded &#39;C:\Windows\SysWOW64\ntdll.dll&#39;, Cannot find or open the PDB file &#39;ZeroMasQueCoisaProj.exe&#39;: Loaded &#39;C:\Windows\SysWOW64\kernel32.dll&#39;, Cannot find or open the PDB file &#39;ZeroMasQueCoisaProj.exe&#39;: Loaded &#39;C:\Windows\SysWOW64\KernelBase.dll&#39;, Cannot find or open the PDB file &#39;ZeroMasQueCoisaProj.exe&#39;: Loaded &#39;C:\Windows\SysWOW64\msvcr100d.dll&#39;, Symbols loaded. The program &#39;[5212] ZeroMasQueCoisaProj.exe: Native&#39; has exited with code 0 (0x0).
Show.
Mas o que acontece se eu precisar no momento do refactory (que deve, sim, existir) eu decidir remover meus arquivos inúteis?
Continuo compilando normalmente o projeto, mas na hora de depurar...
Mas o que ocorre? Eu acabei de compilar o projeto! E se eu compilar novamente e pressionar F5, ele continua apresentando o mesmo problema!
OK, não estou admitindo aqui o famigerado Rebuild All. Se você mantém projetos com mais de 200 arquivos, acho que deve repensar seus conceitos ao usar Rebuild All para tudo nessa vida.
Acontece que existe uma árvore de dependências que o Visual Studio mantém para saber se seu projeto foi atualizado com tudo que tem mais de novo no que diz respeito ao File System, mas às vezes se esquece de checar o FS com o que está na solution. Por conta disso, o HeaderInutil e o CppInutil continuam dentro da árvore de dependência como zumbis.
O que pode ser feito nesse caso (além do que os personagens de The Walking Dead costumam fazer) é configurar o arquivo devenv.exe.config (presente em %programfiles(x86)%\Microsoft Visual Studio 10.0\Common7\IDE) e adicionar as seguintes linhas após a seção configSections. (Esses passos estão descritos no blogue da equipe do VC.)
Depois de modificar o arquivo, reinicie o Visual Studio e tente novamente apertar F5 no mesmo projeto, mas com o DebugView aberto.
Como um amigo meu diria: &amp;quot;AHÁ!!&amp;quot;. Descobrimos o culpado.
A solução? Nesse caso não tem jeito: dar um clean no projeto e build novamente para que o VS reconstrua a árvore de dependências. Porém, agora sabemos por que precisamos do Rebuild All. Não é RebuildAllMania.
</description>
</item>

     
        <item>
  <title>RValue é o novo LValue</title>
  <link>http://www.caloni.com.br/rvalue-e-o-novo-lvalue/</link>
  <pubDate>2012-01-11</pubDate>
  
  <guid>http://www.caloni.com.br/rvalue-e-o-novo-lvalue/</guid>
  <description>As grandes discussões filosóficas que participei durante meu estudo da linguagem C, e mais tarde de C&#43;&#43;, muitas vezes convergiam para o significado místico daquela figura que nós da gramática da linguagem conhecemos como lvalue, ou l-value, ou left-value. Enfim, a definição de uma expressão que representa um lugar na memória e, portanto, pode ocupar o lado esquerdo de uma atribuição/cópia/passagem de argumentos qualquer. Porém, os &amp;quot;grandes&amp;quot; embates daquela época hoje parecem brincadeira de criança, como a diferença sutil entre &#43;&#43;x e x&#43;&#43; ou convergência de tipos em templates.
Agora o buraco é mais embaixo. Agora temos referências r-value.
Agora o mundo mudou.
Foi necessário que mudasse. C&#43;&#43;, conhecido internacionalmente como a vanguarda das linguagens, mesmo mantendo sua fama de alta performance, precisava voltar às suas origens performáticas de qualquer forma. O Criador da linguagem e seus seguidores estavam cientes: cópia de strings é uma coisa muito, muito má. Imperfect forwarding (direcionamento imperfeito?) é algo ainda pior, pois é mais sutil.
Todos concordam, então, que a mudança é necessária. Nem todos concordam, contudo, com o preço a ser pago. As coisas começam a ficar cada vez mais difíceis de entender, e agora, com r-values vindo à superfície, o universo de criaturas bizarras volta a mostrar as caras.
Desde o começo de meus estudos em C&#43;&#43; tenho admirado a linguagem com um certo distanciamento. Enquanto a linguagem C continua sendo o supra-sumo das linguagens de médio-nível, C&#43;&#43; continua sendo uma abominação cujos detalhes muitos preferem esquecer. Mas esquecer tem se tornado cada vez mais difícil frente às adaptações técnicas que a linguagem vem sofrendo.
No caso de Rvalues, se antes existia uma discussão interminável sobre sua inclusão no novo padrão, agora existem discussões acerca do que tudo isso significa. Existe até um ótimo guia (thanks to pepperchico) sobre as principais mudanças de conceitos, feito para simplificar o entendimento. Mas ele mesmo é exageradamente complexo para o programador médio. É de forçar a barra, mesmo. É pedir demais.
No próximo dia 28, sábado, nos reuniremos em mais um evento C&#43;&#43; organizado pelo Grupo C/C&#43;&#43; Brasil e pelos agora dois MVPs do Brasil, o veterano Fabio Galuppo e o novato Rodrigo Strauss (meu amigo, mas acima de tudo muito bem-vindo ao cargo). Estou na lista de palestrantes e conversarei com vocês sobre as otimizações que o famigerado RValue deve trazer à mesa. Espero conseguir entender um pouco mais sobre essa criatura fantástica até lá.
Se o Cebolinha for um programador C&#43;&#43;, deve estar se debatendo nesse momento.
 C&#43;&#43; Rvalue References Explained A Brief Introduction to Rvalue References Want Speed? Pass by Value MSDN Community: C&#43;&#43; Renaissance, São Paulo - SP.  Faça sua incrição!
</description>
</item>

     
        <item>
  <title>Depuração de emergência com receita de bolo no WinDbg</title>
  <link>http://www.caloni.com.br/depuracao-de-emergencia-receita-de-bolo/</link>
  <pubDate>2011-10-18</pubDate>
  
  <guid>http://www.caloni.com.br/depuracao-de-emergencia-receita-de-bolo/</guid>
  <description>Continuando o papo sobre o que fazer para analisar rapidamente um crash no servidor com o pacote WinDbg, na maioria das vezes a exceção lançada pelo processo está diretamente relacionada com um acesso indevido à memória, o que tem diversas vantagens sobre problemas mais complexos:
 Possui localização precisa de onde ocorreu a violação, incluindo o nome do arquivo e a linha do código; Não corrompe a pilha ou, se corrompe, não chega a afetá-la a ponto da thread ficar irreconhecível; A thread que contém a janela de crash é a culpada imediata, então basta olhar a pilha.  Resumindo: basta olhar a pilha! Mas, para isso ser efetivo, precisaremos do PDB do executável que gerou o crash, pois através dele é possível puxar a tal localização da violação de acesso. Isso quer dizer que se você mantiver o executável, e DLL também é executável, juntinho com seu PDB, ou pelo menos facilmente localizável, sua vida será muito mais fácil e florida. Também significa que poderá começar a beber cerveja mais cedo.
Mesmo que em alguns momentos-surpresa apareça uma ou outra tela indesejada.
O comando mais útil na maioria desses casos é mostrar a pilha no modo verbose, usando o comando kv seguido de enter. Porém, antes disso, precisamos:
 Ajeitar o path dos símbolos; Recarregar o PDB do executável suspeito; Mostrar a pilha de todas as threads até descobrir a culpada.  Todos esses comandos podem ser vistos abaixo. São, respectivamente, .symfix, .reload e novamente o kv, com a diferença de que para todas threads.
Ops! Um pequeno desvio do curso. Estamos rodando um processo de 32 bits dentro de um SO 64 bits, no exemplo um Windows 7. Isso pode acontecer e é bom saber o que fazer nesse caso. Seguimos com os comandos .load wow64exts e .effmach x86, que irá carregar a extensão de wow64 do depurador e iniciar a tradução da stack para 32 bits.
Nosso depurador favorito acusa uma pilha que contém a função WerpReportFault. Nessa mesma thread a última linha conhecida nossa está no arquivo crashonserver.cpp:13. E essa situação, caro leitor, é dez por cento de tudo o que você precisa saber sobre WinDbg para resolver, mas que já resolve noventa por cento dos casos que irá encontrar em produção. Belo custo-benefício, não?
</description>
</item>

     
        <item>
  <title>Coders at Work: Reflections on the Craft of Programming</title>
  <link>http://www.caloni.com.br/coders-at-work/</link>
  <pubDate>2011-10-14</pubDate>
  
  <guid>http://www.caloni.com.br/coders-at-work/</guid>
  <description> &amp;quot;Personally I have never believed that it is possible to be a good coder without being a good programmer nor a good programmer without being a good designer, communicator, and thinker.&amp;quot; - Jamie Zawinski
 Como Joel e Atwood disseram, a leitura de Coders At Work é tão útil quanto ler o código dos outros, só que em um estilo mais condensado, que se aproveita das décadas de experiência dessa gente para aprimorarmos nossos processos de desenvolvimento e, muitas vezes, a forma de pensarmos sobre software.
No meu estilo de leitura circular, adaptada do brilhante (maluco?) método de Dmitry Vostokov, as coisas vão mais devagar, e estou apenas no início do livro, tendo passado por Jamie Zawinski (desenvolvedor da equipe original do Netscape), Brad Fitzpatrick (criador do Live Journal) e terminado recentemente Douglas Crockford. O artigo de Joel sobre Zawinski demonstra seu apreço pelo codificador pensante, ou aquele que faz as coisas acontecerem e não fica preso eternamente na armadilha da arquitetura. Eu acredito que as seguintes passagens do livro demonstram seu pensamento melhor do que se eu fosse tentar traduzi-los, começando por Jamie Zawinski:
 Personally I have never believed that it is possible to be a good coder without being a good programmer nor a good programmer without being a good designer, communicator, and thinker. (...) Start converting it into the bad one until it stops working. That&#39;s primary tool of reverse engineering. (...) Your competitor&#39;s six-month 1.0 has crap code and they&#39;re going to have to rewrite it in two years but, guess what: they can rewrite it because you don&#39;t have a job anymore. (...) The design process is definitely an ongoing thing; you never know what the design is until the program is done. So I prefer to get my feet wet as early as possible; get something on the screen so I can look at it sideways.(...) I&#39;ve noticed that one thing that separates good programmers from bad programmers is that good programmers are more facile at jumping between layers of abstraction they can keep the layers distinct while making changes and choose the right layer to make changes in. (...) I think one of the most important things, for me anyway, when building something from the ground up like that is, as quickly as possible, getting the program to a state that you, the programmer, can use it. Even a little bit. Because that tells you where to go next in a really visceral way. (...) I don&#39;t want to be a mathematician but I&#39;m not going to criticize someone who is a mathematician. It&#39;s weird that people often confuse those two pursuits. People who are into very theoretical computer science are thought of in this same way as people who are shipping desktop applications. And they don&#39;t really have a lot to do with each other. (...) Then there was another book that everybody thought was the greatest thing ever in that same period&#39;Design Patterns&#39;which I just thought was crap. It was just like, programming via cut and paste. Rather than thinking through your task you looked through the recipe book and found something that maybe, kinda, sorta felt like it, and then just aped it. That&#39;s not programming; that&#39;s a coloring book. (...
 De certa forma, o mesmo pragmatismo pode ser observado em Douglas Crockford, que utiliza o método de leitura de código tanto na entrevista por candidatos (&amp;quot;traga-me o código que tem orgulho de ter escrito e explique-o pra mim&amp;quot;) quanto no dia-a-dia do projeto, para que todos entendam e aproveitem a evolução do projeto como um todo, além de constituir, na minha visão, uma das melhores dicas de auto-management que uma equipe de programadores poderia ter.
 One of the things I&#39;ve been pushing is code reading. I think that is the most useful thing that a community of programmers can do for each other&#39;spend time on a regular basis reading each other&#39;s code. There&#39;s a tendency in project management just to let the programmers go off independently and then we have the big merge and then we have the big merge and if it builds then we ship it and we&#39;re done and we forget about it. One of the consequences of that is that if you have weak or confused programmers you&#39;re not aware of their actual situation until much too late. And so the risks to the project, that you&#39;re that you&#39;re going to have to build with stuff that&#39;s bad and the delays that that causes, that&#39;s unacceptable. The other thing is that you may have brilliant programmers on the project who are not adequately mentoring the other people on the team. Code reading solves both of those problems.
 Can you talk a bit about how you conduct a code reading?
 At each meeting, someone&#39;s responsible for reading their code, and they&#39;ll walk us through everything, and the rest of us will observe. It&#39;s a really good chance for the rest of the team to understand how their stuff is going to have to fit with that stuff. We get everybody around the table; everybody gets a stack of paper. We also blow it up on the screen. And we all read through it together. And we&#39;re all commenting on the code as we go along. People say, &#39;I don&#39;t understand this comment,&#39; or, &#39;This comment doesn&#39;t seem to describe the code.&#39; That kind of stuff can be so valuable because as a programmer you stop reading your own comments and you&#39;re not aware that you&#39;re misdirecting the reader. Having the people you work with helping to keep your code clean is a huge service&#39;you find defects that you never would&#39;ve found on your own. I think an hour of code reading is worth two weeks of QA. It&#39;s just a really effective way of removing errors. If you have someone who is strong reading, then the novices around them are going to learn a lot that they wouldn&#39;t be learning otherwise, and if you have a novice reading, he&#39;s going to get a lot of really good advice.
 So if you don&#39;t clean up every seventh cycle you may be faced with the choice of whether or not to do a big rewrite. How do you know when, if ever, it&#39;s time for a big rewrite?
 Generally the team knows when it&#39;s time. Management finds out a lot later. The team is getting beat up pretty regularly, making too many pretty regularly, making too many bugs; the code&#39;s too big, it&#39;s too slow; we&#39;re falling behind. They know why. It&#39;s not because they became stupider or lazier. It&#39;s because the code base is no longer serving the purpose that it needs to.
 Esse pequeno trecho da entrevista de Brendan Eich, de Coders at Work, revela parte das frustações que os programadores de linha de frente sofrem com os ambientes de depuração, muitas vezes aquém dos desafios atuais. Sinceramente, não sinto isso em meu dia-a-dia, e acho o Visual Studio um excelente depurador com interface (mas que perde feio para o WinDbg em casos mais hardcore). Porém, fica a percepção curiosa do criador do JavaScript.
 Proofs are hard. Most people are lazy. Larry Wall is right. Laziness should be a virtue. So that&#39;s why I prefer automation. Proofs are something that academics love and most programmers hate.&amp;quot; - Brendan Eic
 SGI:
 Diagnosing it was hard because it was timing-sensitive. It had to do with these machines being abused by terminal concentrators. People were hooking up a bunch of PTYs to real terminals. Students in a lab or a bunch of people in a mining software company in Brisbane, Australia in this sort of &#39;70s sea of cubes with a glass wall at &#39;70s sea of cubes with a glass wall at the end, behind which was a bunch of machines including the SGI two-processor machine. That was hard and I&#39;m glad we found it. These bugs generally don&#39;t linger for years but they are really hard to find. And you have to sort of suspend your life and think about them all the time and dream about them and so on. You end up doing very basic stuff, though. It&#39;s like a lot of other bugs. You end up bisecting&#39;you know &#39;wolf fence.&#39; You try to figure out by monitoring execution and the state of memory and try to bound the extent of the bug and control flow and data that can be addressed. If it&#39;s a wild pointer store then you&#39;re kinda screwed and you have to really start looking at harder-to-use tools, which have only come to the fore recently, thanks to those gigahertz processors, like Valgrind and Purify.
 Ferramentas de Depuração Avançadas:
 Instrumenting and having a checked model of the entire memory hierarchy is big. Robert O&#39;Callahan, our big brain in New Zealand, did his own debugger based on the Valgrind framework, which efficiently logs every instruction so he can re-create the entire program state at any point. It&#39;s not just a time-traveling debugger. It&#39;s a full database so you see a data structure and there&#39;s a field with a scrogged value and you can say, &#39;Who wrote to that last?&#39; and you get the full stack. You can reason from effects back to causes. Which is the whole game in debugging. So it&#39;s very slow. It&#39;s like a hundred times slower than real time, but there&#39;s hope. Or you can use one of these faster recording VMs&#39;they checkpoint only at system call and I/O boundaries. They can re-create corrupt program states at any boundary but to go in between those is harder. But if you use that you can probably close in quickly at near real time and then once you get to that stage you can transfer it into Rob&#39;s Chronomancer and run it much slower and get all the program states and find the bug.
 Depuradores da Indústria:
 Debugging technology has been sadly underresearched. That&#39;s another example where there&#39;s a big gulf between industry and academia: the academics are doing proofs, sometimes by hand, more and more mechanized thanks to the POPLmark challenge and things like that. But in the real world we&#39;re all in debuggers and they&#39;re pieces of shit from the &#39;70s like GDB. Yeah. So I use GDB, and I&#39;m glad GDB, at least on the Mac, has a watch-point facility that mostly works. So I can watch an address and I can catch it changing from good bits to bad bits. That&#39;s pretty helpful. Otherwise I&#39;m using printfs to bisect. Once I get close enough usually I can just try things inside GDB or use some amount of command scripting. But it&#39;s incredibly weak. The scripting language itself is weak. I think Van Jacobson added loops and I don&#39;t even know if those made it into the real GDB, past the FSF hall monitors.
 Multithreading:
 But there&#39;s so much more debugging can do for you and these attempts, like Chronomancer and Replay, are good. They certainly changed the game for me recently. But I don&#39;t know about multithreading. There&#39;s The multithreaded stuff, frankly, scares me because before I was married and had kids it took a lot of my life. And not everybody was ready to think about concurrency and all the possible combinations of orders that are out there for even small scenarios. Once you combine code with other people&#39;s code it just gets out of control. You can&#39;t possibly model the state space in your head. Most people aren&#39;t up to it. I could be like one of these chestthumpers on Slashdot&#39;when I blogged about &#39;Threads suck&#39; someone was saying, &#39;Oh he doesn&#39;t know anything. He&#39;s not a real man.&#39; Come on, you idiot. I got a trip to New Zealand and Australia. I got some perks. But it was definitely painful and it takes too long. As Oscar Wilde said of socialism, &#39;It takes too many evenings.
 E isso é tudo que guardarei deste livro. Talvez o revisite daqui a algumas décadas para comparar os novos tempos que viveremos.
 In the real world one big split is between people who use symbolic debuggers and people who use print statements. - Peter Seibe
 </description>
</item>

     
        <item>
  <title>Cuidado com variáveis temporárias</title>
  <link>http://www.caloni.com.br/cuidado-com-variaveis-temporarias/</link>
  <pubDate>2011-07-26</pubDate>
  
  <guid>http://www.caloni.com.br/cuidado-com-variaveis-temporarias/</guid>
  <description>Um dos problemas que a linguagem C&#43;&#43; possui para seus iniciantes é o de não deixar muito explícito partes do seu comportamento, principalmente as partes que lidam com ponteiros/referências e o jogo da vida dos objetos. Às vezes a coisa fica de tal como complexa que fica até difícil explicar o porquê das coisas.
Por exemplo, vejamos o singelo caso de alguém que precisa formatar uma saída de erro e para isso escolheu um stringstream:
Quando chamamos func, ele lança uma exceção que é capturada no main que, por sua vez, formata uma stream e obtém sua string (através do método str) e através dessa string obtém o ponteiro da string em C puro (através do método cstr). Porém, a mensagem resultante na saída-padrão de erro não era o esperado:
Depurando diretamente, vemos que a stream, de fato, contém o que esperávamos. O único elemento errante é justamente o ponteiro obtido através da chamada dupla de métodos.
O porquê isso ocorre só fica óbvio quando vemos a ajuda (ou a assinatura) da função str da classe stringstream:
Ora, a função str retorna uma cópia do objeto string usado internamento pelo buffer de nossa string stream. Duas coisas ocorrem em qualquer cópia de um objeto retornada por uma função:
  A cópia do objeto original e seu desacoplamento (óbvio).
  A construção de um objeto baseado no original e que, após o fim da expressão onde foi chamado o método, é destruído.
  Uma vez que a chamada a str termina, é entregue uma instância de uma string que contém a string original que está sendo usada pela string stream para a expressão da chamada, que geralmente vem seguida de uma cópia:
A variável buf no exemplo acima será, portanto, a terceira string usada aqui até então. Ao final da expressão, a string intermediária retornada por str é automaticamente destruída, por se trata de uma cópia temporária para obedecer a sintaxe de retorno da função.
Agora, o que acontece se, na cópia temporária, é feita uma operação para obter seu ponteiro interno usado para armazenar sua string estilo C?
Obviamente ele fica inválido após o fim da expressão!
Vamos ver em câmera lenta:
Nada como assembly fresquinho para refrescar os conceitos de C&#43;&#43; por baixo dos panos.
Após uma enxurrada de programadores gerenciáveis perguntarem qual seria, então, a solução ideal, segue o snipet mais explicitado:
Outro leitor sugeriu fazer toda a chamada em uma única instrução, economizando em expressividade e ainda evitando a destruição da variável temporária criada ao chamar str.
Particularmente, gosto de instruções simples que me permitam ver claramente o que está acontecendo de forma simples pelo depurador (até porque sei que o compilador irá otimizar tudo no final em versão Release, ainda mais se estiver quebrado em instruções simples). Porém, toda solução que evita o uso da variável temporária após a execução do método str é válida.
</description>
</item>

     
        <item>
  <title>Depuração de emergência</title>
  <link>http://www.caloni.com.br/depuracao-de-emergencia/</link>
  <pubDate>2011-07-26</pubDate>
  
  <guid>http://www.caloni.com.br/depuracao-de-emergencia/</guid>
  <description>O programa está rodando no servidor do cliente, que é acessível por sessão remota do Windows, mas de repente ele capota. Existem aí duas possibilidades fora o debug remoto (que, nesse caso, não é possível):
  Analisar um dump gerado.
  Depurar localmente o problema.
  Para a primeira opção, basta abrir o Gerenciador de Tarefas, localizar o processo e gerar o dump através do menu de contexto.
Com o dump e o Windbg em mãos, basta analisá-lo. Porém, se o seu processo é 32 bits e o servidor é 64 bits (geralmente é), o dump gerado será de 64 bits, EMBORA seja de um process 32. Ou seja, ao abri-lo, o sistema vai mostrar as threads de manipulação do SO para sistemas 32 (todos com o nosso amigo wow64cpu).
Após esse último passo, siga para o último passo desse tutorial. Ou escolha a segunda opção:
Para depurar localmente, supondo que seja um executável simples, você precisa dos seguintes itens:
  Pasta do WinDbg copiado (a Debugging Tools instalada pelo SDK, ou sua pastinha particular guardada no PenDrive).
  Símbolos dos binários envolvidos (em sincronia com os binários que iremos analisar).
  Fontes da compilação dos binários (a versão exata seria ideal; grave o revno do controle de fonte pra facilitar).
  Os fontes, no caso de uma conexão por Terminal Server, podem ser disponibilizados através do mapeamento de drives entre as máquinas. Os símbolos, no entanto, por serem usados extensivamente pelo WinDbg, é recomendável que estejam locais na máquina depurada, pois do contrário você terá que tomar uma quantidade excessiva de cafés para executar meia-dúzia de instruções.
Supondo que temos tudo isso, só precisamos executar alguns passos básicos para o setup:
Por último, execute o seguinte comando na tela de comandos do WinDbg:
E boa sorte =)
</description>
</item>

     
        <item>
  <title>Novo branch para projetos do Caloni.com.br</title>
  <link>http://www.caloni.com.br/novo-branch-para-projetos-do-caloni-com-br/</link>
  <pubDate>2011-05-29</pubDate>
  
  <guid>http://www.caloni.com.br/novo-branch-para-projetos-do-caloni-com-br/</guid>
  <description>Reestruturei meus projetos caseiros e coloquei todos em um branch no repositório do Assembla. A partir dele começarei a reestruturas os códigos de exemplo do saite, o deve facilitar o acesso. Para usuários do Bazaar, como eu, basta puxar o branch usando seu endereço:
Para os usuários do Subversion, ou qualquer outro controle de fonte que consiga ler um branch feito em SVN, google for it.
</description>
</item>

     
        <item>
  <title>Comparando strings no WinDbg</title>
  <link>http://www.caloni.com.br/comparando-strings-no-windbg/</link>
  <pubDate>2011-05-22</pubDate>
  
  <guid>http://www.caloni.com.br/comparando-strings-no-windbg/</guid>
  <description>O WinDbg fornece aos programadores diversos meios (muitos redundantes) de comparar valores inteiros em quaquer lugar da memória, em qualquer tamanho (8, 16, 32, 64 bits). Porém, quando precisamos comparar strings, que todos sabem ser uma sequência de bytes de tamanho arbitrário (se for em C, até o zero terminador).
Uma solução simples e rápida é comparar os 4 primeiros bytes de uma string, ou os 4 primeiros bytes que diferem de uma lista grande.
Por exemplo, imagine o seguinte código que abre todos os arquivos da pasta de sistema:
Queremos colocar um breakpoint no momento em que o arquivo shell32.dll estiver sendo aberto. Para isso, devemos nos atentar para os parâmetros passados para a função CreateFile.
Temos que nos atentar para o padrão de bits após esse path. Vamos dar uma olhada por dentro da string.
O nome do arquivo começa no offset 16&#43;4 = 20, ou 14 em hexa. Dessa forma, podemos capturar o padrão de bits da seguinte maneira:
Para nos certificarmos que é realmente esse o padrão, e para já montarmos nosso próprio padrão para o shell32.dll, vamos alocar um pedaço de memória e verificar se a sequência de bits está correta.
Ótimo. Os padrões bateram, então podemos colocar um breakpoint condicional partindo do padrão de bits do nome do arquivo que precisamos.
</description>
</item>

     
        <item>
  <title>Sem reflection</title>
  <link>http://www.caloni.com.br/sem-reflection/</link>
  <pubDate>2011-05-18</pubDate>
  
  <guid>http://www.caloni.com.br/sem-reflection/</guid>
  <description>Em C&#43;&#43; não temos (ainda) a possibilidade de listarmos, por exemplo, a lista de métodos de um determinado tipo, a fim de chamá-lo pelo nome em tempo de execução. Algo assim:
OK, foi apenas um exemplo tosco de como seria um reflection em C&#43;&#43;.
Porém, existem algumas maneiras de contornar esse problema. A solução, é claro, depende de qual problema você está tentando resolver.
Vamos supor, por exemplo, que você queira cadastrar funções para serem chamadas de maneira uniforme pelo prompt de comando. Vamos chamar nossa classe tratadora de CommandPrompt.
Internamente, para armazenar as funções de acordo com o nome dado, basta criarmos um mapeamento entre esses dois tipos e fazemos a amarração necessária para o método principal de parseamento:
Essa solução não é exatamente um reflection, mas apenas parte do que o verdadeiro reflection possibilita. Existem outras funcionalidades, como traits, que a STL já consegue se virar razoavelmente bem, por exemplo.
</description>
</item>

     
        <item>
  <title>Houaiss 1.3</title>
  <link>http://www.caloni.com.br/houaiss-1-3/</link>
  <pubDate>2011-04-28</pubDate>
  
  <guid>http://www.caloni.com.br/houaiss-1-3/</guid>
  <description>Os problemas relacionados com acesso negado durante a conversão/construção do dicionário foram corrigidos na novíssima versão disponível no GitHub.
Erroneamente imaginando que a falta de acesso tinha alguma coisa a ver com a escrita de arquivos no disco, ou até mesmo com a execução de processos, descobri depurando (o bom e velho depurador) que a origem do acesso negado estava na função AssignProcessToJobObject.aspx). Misteriosamente, no Windows 7, ao chamar essa função ocorre esse erro, independente da execução ser como administrador ou não.
Como já está se tornando tradição de uns tempos pra cá, a solução veio de um artigo do Stack Overflow, cuja melhor solução foi exatamente a que eu segui: inserir o manifesto do UAC e usar a flag CREATEBREAKAWAYFROMJOB.
Agora é só esperar pelo próximo bug =)
</description>
</item>

     
        <item>
  <title>Bazaar com Subversion</title>
  <link>http://www.caloni.com.br/bazaar-com-subversion/</link>
  <pubDate>2011-03-23</pubDate>
  
  <guid>http://www.caloni.com.br/bazaar-com-subversion/</guid>
  <description>Para pessoas que ficaram viciadas em commits curtos e todo o histórico do fonte na própria máquina, foi uma surpresa descobrir que com o uso do plugin bzr-svn (já incluso no pacote de instalação), consigo ainda utilizar o Bazaar, mesmo que agora esteja trabalhando com um branch do Subversion.
Na verdade, melhor ainda: o bzr-svn baixa o SVN trunk com todo o histórico na máquina local, como se fosse um branch do próprio Bazaar, e permite a criação de branches desconectados para pequenos commits e o merge final para o servidor SVN.
E o melhor de tudo: não há segredo. Tudo que precisa fazer é instalar o Bazaar e fazer um get/co com o endereço do branch SVN que o plugin se vira sozinho para detectar que se trata do Subversion. (Se for um branch protegido, o usuário e senha serão pedidos durante o processo).
</description>
</item>

     
        <item>
  <title>Houaiss no Kindle</title>
  <link>http://www.caloni.com.br/houaiss-no-kindle/</link>
  <pubDate>2011-03-22</pubDate>
  
  <guid>http://www.caloni.com.br/houaiss-no-kindle/</guid>
  <description>O blogue de José Ribeiro Pena Neto, aparentemente recém-criado, conseguiu utilizar minha solução de conversão do dicionário Houaiss para Babylon em algo mais incrívei ainda: converter, em alguns passos, a base de dados do Houaiss para o Amazon Kindle.
De uma maneira simples e efetiva, ele cita o passo-a-passo para a conversão da base Houaiss para o formato Babylon e, a partir disso, reconverter para o formato usado pelo gratuito e multiplataforma Stardict.
</description>
</item>

     
        <item>
  <title>Loucuras multithreading</title>
  <link>http://www.caloni.com.br/loucuras-multithreading/</link>
  <pubDate>2011-03-18</pubDate>
  
  <guid>http://www.caloni.com.br/loucuras-multithreading/</guid>
  <description>Estava eu depurando um sistema cliente/servidor com um tantão de threads e me veio à cabeça na volta pra casa como que um programador iniciante entenderia aquela bagunça de dar F10 em uma função e cair no meio de outra, dar outro F10 na outra e voltar pra primeira.
Loucura, não?
Nem tanto. O multithreading de um sistema operacional está aí pra isso. O que ocorre, no caso de depurações em uma única IDE, é que os breakpoints temporários que são definidos ao usar o comando de step into/over podem ser ativados em paralelo, simultaneamente.
Mas confesso que, de vez em quando, depurar múltiplas threads fica parecendo coisa de maluco.
</description>
</item>

     
        <item>
  <title>Base64</title>
  <link>http://www.caloni.com.br/base64/</link>
  <pubDate>2011-03-09</pubDate>
  
  <guid>http://www.caloni.com.br/base64/</guid>
  <description>No meio dos meus artigos pendentes, encontrei esse, de Luiz Rocha, que fala sobre a dificuldade de entender o que seria Base64:
Não é a primeira pessoa que pede informações sobre algo específico demais para explicar (para isso existe a Wikipedia e o Google, não?). No meio da minha escrita, percebi que já havia escrito sobre os fundamentos do conhecimento por trás da criação do Base64, conhecimento esse, acredito eu, todo programador que quer sair do lugar com os próprios pés deve ter.
  Básico do básico: assembly
  Básico do básico: binário &amp;lt;-- Luiz, você está procurando por esse!
  Básico do básico: tipos
  Básico do básico: ponteiros
  Bônus:
  Como ofuscar strings
  Passagem por valor e emails com anexo
  Como funcionam as strings
  REALMENTE para iniciantes:
  Configurando seus projetos no Visual Studio
  Como criar uma LIB no Visual Studio
  Acredito que tudo que um programador precisa saber é o básico. O problema é que esse básico cresce a cada ano, mas, de qualquer forma, continua sendo necessário voltar às raízes de vez em quando, e se existe algo que ele nunca deve esquecer, é isso.
Até porque na programação, 90% não se cria, se copia.
Imaginemos o cenário para a criação do Base64:
Alguns meios de comunicação, notadamente envio de e-mails e a navegação web, por incrível que pareça, trabalham em um protocolo totalmente em modo texto. É até fácil de entender, pois quando essas tecnologias nasceram as limitações de velocidade e estabilidade das conexões permitiam apenas o envio de texto puro de uma ponta a outra.
Isso quer dizer que, na prática, os anexos de um e-mail e as imagens de uma página trafegam, pelo protocolo definido, em modo texto.
Como isso é possível?
A solução não é tão obscura quanto possa parecer. Se um programador médio tivesse esse problema e nenhuma solução existisse ainda, ele faria o que sempre fez para resolver problemas desse tipo: codificar a mensagem na forma permitida. Isso já é feito com o próprio texto, que é apenas uma interpretação de tabelas de caracteres.
Tudo que é necessário fazer é o contrário, mas usando a mesma lógica: montar uma tabela de caracteres válidos e traduzir para um conteúdo binário, sendo que todas as combinações possíveis devem caber nessa tabela.
A forma mais básica binária de comunicação é um byte, constituído por 8 bits, que combinados darão 2^8 entradas em nossa tabela, que precisaria de 256 caracteres diferentes. Como isso ultrapassa o limite dos protocolos que estamos lidando, que em sua maioria utilizam a tabela ascii básica, que possui 128 posições, sendo que algumas posições não possuem caracteres imprimíveis, decidiu-se usar o múltiplo anterior: 64 posições, o que nos dá a chance de codificar 6 bits de cada vez (2^6).
Esse padrão de codificação se chama Base64. Se quiser mais detalhes, basta ler a RFC, que é pequena e muito simples de se ler.
Agora, como codificar essa solução? Só entendendo o básico, é claro.
</description>
</item>

     
        <item>
  <title>Projeto DayToDay</title>
  <link>http://www.caloni.com.br/projeto-daytoday/</link>
  <pubDate>2011-03-03</pubDate>
  
  <guid>http://www.caloni.com.br/projeto-daytoday/</guid>
  <description>O DayToDay é um projetinho que criei para fazer tracking das minhas atividades diárias. Eu o criei há mais de 6 anos, e provavelmente se tivesse pensado em como isso seria útil para as pessoas compartilharem suas ideias e limitasse o número de caracteres para 140, estaria rico hoje.
O &amp;quot;conceito&amp;quot; é bem simples: executo o programa, ele exibe um campo texto para digitar o que estou fazendo, digito enter ou clico no botão de OK e ele fecha. O que eu digitei cai em um arquivo texto com o mesmo nome do programa.
Algumas &amp;quot;features&amp;quot; avançadas que é bom saber:
 Ele gera o arquivo texto em UNICODE. Na época em que eu digitava em russo, isso era importante. Ele já gera suas anotações com data e hora. Você pode gerar um atalho para chamá-lo rapidamente e definir um diretório de trabalho diferente: o arquivo será gerado no diretório de trabalho especificado, e não onde está o executável. Existe uma versão em .NET que fiz na época que estudava C#. Felizmente eu perdi esse projeto.  </description>
</item>

     
        <item>
  <title>VTable</title>
  <link>http://www.caloni.com.br/vtable/</link>
  <pubDate>2011-03-01</pubDate>
  
  <guid>http://www.caloni.com.br/vtable/</guid>
  <description>Acho que na breve história desse blogue nunca contei a história do vtable. No máximo fizemos um hookzinho nos métodos de um componente COM. Mas só.
Não encontro uma analogia simples, assim, de cabeça. Então vou contar no cru, mesmo. Talvez seja até mais divertido.
A vtable foi um mecanismo criado para implementar o polimorfismo em C&#43;&#43; quando falamos de ponteiros para classes base cujos métodos virtuais foram sobrescritos por uma classe derivada.
A coisa fica mais simples quando explicamos que em C&#43;&#43; você só paga pelo que usa. Se você declarar uma classe que não tenha nenhum método virtual, os objetos dessa classe não precisarão de uma vtable. No entanto, você não conseguirá sobrescrever um método dessa classe através de uma derivada:
No exemplo acima, a chamada feita em func irá chamar o método da classe C, mesmo que a classe D tenha sobrescrito esse método. O programador semi-experiente deve pensar &amp;quot;lógico, ela não é virtual!&amp;quot;, e está certo, assim como qualquer pessoa que decora essas formulazinhas de vestibular.
Para criarmos polimorfismo de verdade, precisamos declarar o método em C como virtual:
Agora sim, a chamada em func irá ser para D::method.
Pergunte para o programador semi-experiente em C&#43;&#43; por que as coisas são assim e provavelmente ele irá falar algo sobre vtable, mesmo que não saiba exatamente como ela funciona.
A vtable é uma tabela que guarda o endereço dos métodos virtuais de uma classe. Se uma classe derivada sobrescrever um ou mais métodos de sua classe base, ela terá uma outra vtable com os endereços dos métodos &amp;quot;corrigidos&amp;quot;.
Dessa forma, algo um pouco diferente ocorre na chamada c-&amp;gt;method() quando estamos lidando com classes polimórficas: o início de um objeto dessa classe terá um ponteiro para a vtable de sua classe. Quando um método virtual é chamado, em vez do compilador gerar uma chamada estática para o endereço do método da classe cujo tipo estamos usando, ele irá redirecionar essa chamada para uma posição na vtable para onde esse objeto aponta. No caso de um objeto do tipo D, a entrada para method em sua vtable apontará não para C::method, mas para D::method, uma função com a mesma assinatura contida na classe base C e que, portanto, a sobrescreve.
Façamos um pequeno teste para comprovar o que falamos. Vamos escancarar a chamada feita a partir de uma instância de D e a partir de uma instância de C. Nada que um WinDbg não resolva de braços cruzados:
</description>
</item>

     
        <item>
  <title>Esse ponteiro vai até onde?</title>
  <link>http://www.caloni.com.br/esse-ponteiro-vai-ate-onde/</link>
  <pubDate>2011-01-17</pubDate>
  
  <guid>http://www.caloni.com.br/esse-ponteiro-vai-ate-onde/</guid>
  <description>Brincando com obtenções e conversões de SIDs, tive uma pequena dificuldade de usar a função ConvertStringSidToSid, de Sddl.h. Seu objetivo é receber uma string-SID no formato usado pela ferramenta PsGetSid e retornar uma sequência de bytes de tamanho arbitrário, que é o SID como o sistema o enxerga. Como ela retorna apenas o ponteiro final, do tipo PSID, o que parece fácil pode se tornar tricky se quisermos copiar o SID binário para algum buffer na pilha, já que não sabemos o número de bytes no buffer de origem. Tudo que sabemos é que, após o uso, devemos desalocar essa memória retornada pela API com outra API: LocalFree.
Ora, mesmo que não venhamos a escrever nessa memória de tamanho obscuro, não é de bom tom ler além da conta. Não há garantias que o que estiver após o SID é seguro. Pode até ser o final de uma página de memória, por exemplo, e o seu programa capota por causa de um singelo &amp;quot;Memory could not be read&amp;quot;. Que coisa sem graça!
[](/images/SXf7NsR.png)
Sempre que me vejo com problemas desse tipo procuro informações primeiro no próprio MSDN, segundo na cabeça e terceiro no Google. Nesse caso em específico a cabeça deu um jeito, pois imaginei que houvesse alguma forma de pegar o tamanho da memória alocada através das funções Local (se a API precisa de LocalFree para desalocar sua memória, é óbvio que ela usou LocalAlloc para alocá-la, mesmo que não tenhamos o código-fonte para comprovar).
A partir de LocalHandle posso obter o HANDLE para a memória alocada localmente. Com esse handle a API me dá outra função, LocalSize, de onde posso obter o tamanho da memória previamente alocada através do seu handle. Isso é ótimo, pois em um primeiro momento pensei não haver saída, como nas funções de alocação em C e C&#43;&#43;, por exemplo.
</description>
</item>

     
        <item>
  <title>Dependência pedindo carona</title>
  <link>http://www.caloni.com.br/dependencia-pedindo-carona/</link>
  <pubDate>2011-01-04</pubDate>
  
  <guid>http://www.caloni.com.br/dependencia-pedindo-carona/</guid>
  <description>Mesmo as vezes que você não queira, algumas dependências pedem carona e o compilador deixa entrar. Daí mesmo que você não use uma função API, ela acaba te atazanando a vida.
Foi o caso da ToolHelp32 no Windows NT 4.
Quando compilamos, cada CPP vira uma coleção de funções que serão usadas, mais tarde, pelo linker, para juntar a bagunça. Para mais detalhes dessa fascinante história, recomendo o fantástico artigo sobre Os diferentes erros na linguagem C, seção Linkedição.
Para as dependências localizadas fora do executável final, por exemplo, as DLLs do sistema, o linker cria uma entrada no formato padrão de executável que adiciona essa dependência extra que será resolvida na hora do programa rodar, quando o loader do sistema operacional terá que fazer um linker on-the-fly, catando todas as DLLs e funções necessárias para colocar o bichinho no ar.
Dessa forma, quando existirem unresolved externals fora do executável final, o responsável por dar o erro é o loader do sistema:
Isso significa que o seu processo não poderá ser executado, pois faltam funções no ambiente que ele depende.
Um recurso muito útil para ver essas funções é o Dependency Walker, meu amigo de infância:
&amp;quot;Mas, Caloni, eu nem uso essa função! Como ela pode ser necessária?&amp;quot;
Pois é. As coisas nem sempre acabam sendo como o esperado. Se você possuir uma LIB, por exemplo, e nela existirem duas funções, como abaixo, e você se limitar a usar em seu programa apenas a primeira, todas as dependências da segunda também irão parar no executável final.
Acontece que o nosso amigo linker gera uma lista de dependências por módulo (CPP), e não por função. Dessa forma, tudo que vier é lucro.
Só que às vezes é prejuízo, também. Quando usamos um SO da época do guaraná com rolha, como o Windows NT 4, por exemplo, não conseguimos usar um programa porque este possuía uma função moderninha nunca usada, mas que estava dentro de um CPP junto de uma função comportada, usando apenas APIs documentadas no primeiro papiro da Microsoft.
Sempre existe. Nesse caso, migrarmos as funções moderninhas para um segundo CPP, recompilarmos a LIB e a dependência milagrosamente desaparecerá!
Agora a aplicação poderá rodar em paz naquele que é, como diz meu amigo, um sistema operacional de ponta... da outra ponta!
</description>
</item>

     
        <item>
  <title>Trabalhando em múltiplos ambientes</title>
  <link>http://www.caloni.com.br/trabalhando-em-multiplos-ambientes/</link>
  <pubDate>2010-12-27</pubDate>
  
  <guid>http://www.caloni.com.br/trabalhando-em-multiplos-ambientes/</guid>
  <description>Existem diversas maneiras de se trabalhar com o Bazaar. Eu já havia definido como fazer na máquina de desenvolvedor para modificar o mesmo código-fonte em projetos paralelos, onde basicamente tenho um branch principal conectado no servidor (assim todo commit vai pra lá) e crio branches paralelos e desconectados para fazer quantos commits eu tenho vontade durante o desenvolvimento. Após todas as mudanças e testes básicos, atualizo o branch principal (com mudanças dos meus colegas) e faço o merge com o branch paralelo onde fiz todas as mudanças. Antes de subir com o commit final, ainda realizo um build de teste local, se necessário.
Nos casos em que eu trabalho em casa (ou em outro ambiente), posso fazer basicamente a mesma coisa, só que meu branch paralelo é copiado para outra máquina:
Geralmente o que faço depois é compactar a pasta gerada (se desejar, use uma senha forte nesse passo), fazer uma cópia para um PenDrive e descompactar na máquina que irei trabalhar.
Terminado o trabalho naquela máquina, geralmente gero um branch novo (para limpar o diretório) e recompacto a solução, copio para o Pendrive, e descompacto na máquina da empresa. O resto do caminho é como se eu tivesse feito as modificações na própria máquina:
</description>
</item>

     
        <item>
  <title>Patch de emergência 2</title>
  <link>http://www.caloni.com.br/patch-de-emergencia-2/</link>
  <pubDate>2010-11-09</pubDate>
  
  <guid>http://www.caloni.com.br/patch-de-emergencia-2/</guid>
  <description>No artigo anterior fizemos um patch rapidinho na memória se aproveitando de um Sleep nojento que o código nos forneceu.
E se não houvesse Sleep?
As chances de estarmos escrevendo no momento em que a função está sendo executada são tremendas, de forma que não poderíamos sobrescrevê-la sem correr o risco de um crash.
Uma solução alternativa para isso é alocar um novo pedaço de memória para a versão corrigida e trocar o endereço de chamada na função main.
Antes de trocarmos o endereço dentro do main precisamos &amp;quot;consertar&amp;quot; a função copiada. Ela está usando as funções globais rand e printf, e as chamadas usam offsets relativos. Como agora a função está em outro offset, temos que reconstruir as chamadas:
Agora a função está pronta para ser usada.
É nessa parte que trocaremos o endereço o endereço 00401005 pela memória alocada. Note que essa escrita é muito rápida e o programa lê esse endereço por muito pouco tempo se compararmos com todas as intruções que são executadas. No entanto, essa escrita não é atômica, e mesmo que as chances sejam extremamente remotas, ainda assim pode haver uma colisão no acesso à essa parte.
É salutar rezar por 10 segundos.
E voilà! A partir do momento em que digitei o call seguido de enter, a função nova já começou a operar em cima do processo ainda rodando. Se quisermos voltar a função antiga, sem problemas:
Não façam isso em casa, crianças ;)
</description>
</item>

     
        <item>
  <title>Patch de emergência</title>
  <link>http://www.caloni.com.br/patch-de-emergencia/</link>
  <pubDate>2010-11-08</pubDate>
  
  <guid>http://www.caloni.com.br/patch-de-emergencia/</guid>
  <description>Após um projeto muito bem sucedido, entregue no prazo e homologado em tempo recorde, você e sua equipe estão aproveitando suas devidas férias nas Bahamas, tomando água de coco na sombra de uma palmeira e apreciando a beleza natural da região. Ambas as belezas. =)
Mas eis que liga o seu gerente para o celular vermelho que te entregou no caso de emergências críticas e te avisa que um problema crítico foi detectado em um serviço crítico: o detector de pares. Consegue ver o erro?
Oh, meu Deus!
Com toda a calma do mundo, você saca o seu netbook, baixa a versão homologada do controle de fonte e descobre facilmente o problema, gerando um patch e recompilando o projeto.
Feliz da vida, avisa o seu chefe que a única coisa que precisam trocar é o serviço crítico. Parar, trocar o arquivo, reiniciar o serviço. Simples.
Porém, ele lhe avisa que esse é um serviço crítico, que não pode parar por nenhum segundo sequer. A atualização terá que ser feita sem parar o ciclo ininterrupto de pares/ímpares chegando do gerador de números randômicos.
Mais uma vez calmo da vida, você diz que isso é coisa de criança. Tudo que precisa fazer é atualizar a versão certa na memória. O arquivo poderá ser renomeado e, quando o serviço puder ser reiniciado, a versão nova será executada. Enquanto isso, o patch na memória bastará para corrigir o problema e não causar nenhum momento inoperante.
Tudo que você precisa é abrir o processo pelo WinDbg, encontrar a versão defeituosa e substituir os bytes certos.
Nota: O parâmetro -pv permite depurar um processo de forma não-invasiva, mas as threads serão suspensas. Já com -pvr podemos depurar de forma não-invasiva e ainda conseguir manter as threads do processo rodando.
Analisando o disassembly da função nova e antiga podemos perceber que o tamanho delas não mudou (bom sinal), mas o uso dos registradores e a lógica interna teve uma alteração significativa (mau sinal):
Podemos começar escrevendo a função nova da memória do processo de teste para um arquivo, e lendo em seguida para cima da função antiga. Só que para isso temos que nos certificar que os endereços que referenciam para fora da função sejam os mesmos. Nesse caso, felizmente, são.
Em seguida iremos sobrescrever a função antiga no processo em execução. Para evitar crashes é vital que tenhamos certeza que a função não estará sendo executada nesse momento. No nosso caso basta aguardar a entrada na função Sleep da API, que dorme por 3 segundos, tempo suficiente para a atualização.
Atualizada a função, apenas nos lembramos de renomear o arquivo antigo e atualizar o novo para evitar reativar o problema. Agora podemos voltar para a apreciação das belezas da natureza...
</description>
</item>

     
        <item>
  <title>Suporte técnico</title>
  <link>http://www.caloni.com.br/suporte-tecnico/</link>
  <pubDate>2010-11-05</pubDate>
  
  <guid>http://www.caloni.com.br/suporte-tecnico/</guid>
  <description>Máquina com parte do registro corrompida, notadamente alguma sub-chave de HKEYCLASSESROOT. Resultado: ao rodar um script que abre uma segunda janela e tenta usar seu método focus é exibida a seguinte mensagem:
Erro de automação? (&amp;quot;Mensagem do cliente - A classe não dá suporte para automação&amp;quot;)
Abaixo um exemplo simples para ter uma ideia em JS:
A primeira coisa que se faz nesse caso é pesquisar no Google por pessoas que já tiveram esse problema. A maioria dizia ser necessária registrar novamente as DLLs do navegador/shell, coisa que fizemos à exaustão e não resolveu o problema. Também imaginamos haver relação com a versão da SDocVw.dll que estava alocada na lista de assemblies .NET cacheados, o chamado GAC. Ou seja, já estávamos viajando geral.
No meio dos procedimentos batidos que todos fazem a lista abaixo resume bem:
 Restaurar instalação do Internet Explorer. Atualizar Internet Explorer. Rodar Windows Update. Registrar novamente DLLs do Shell (ShDocVw.dll, etc).  No meio das análises não-tão-batidas que foram feitas estavam os seguintes itens:
 Log de operações pelo Process Monitor da abertura do browser até o erro. Dump gerado no momento da mensagem de erro. Comparação de registro exportado com máquina sadia.  Nada parecia resolver o impasse, a não ser reinstalar o Windows, coisa que o cliente não queria. Dessa forma, A última tentativa não-enlouquecida de tentar descobrir a causa do problema foi usar uma VM e importar o registro exportado da máquina defeituosa.
Que não revelou a anomalia.
Partindo disso, imaginei que o que ocorria era que havia algo faltando no registro danificado, e não algo a mais. Dessa forma, realizei a seguinte operação:
 Exportei o registro da máquina saudável. Transformei a exportação em exclusão total das chaves. Importei ambos os registros no esquema &amp;quot;apaga tudo cria tudo de novo&amp;quot;.  Problema reproduzido.
Agora restava saber qual chave exata estava faltando e o que isso impactava no comportamento do browser.
O registro exportado da VM possuía cerca de 30.000 linhas com chaves e sub-chaves. Se fosse feita a importação por partes, dividindo-se sempre pela metade e testando o acesso à página todas as vezes, teríamos no máximo que fazer uns 15 testes.
Foi esse o procedimento seguido:
 Criar snapshot com o estado inalterado do registro. Apagar metade do registro original exportado (máquina real). Arrastar metade do registro original e importá-lo (apaga chaves). Importar registro danificado do cliente (já na VM). Se deu erro de novo, repassar os passos 2 a 3. Se não deu erro, testar os passos 3 e 4 com a outra metade.  Essa série de passos foi reproduzida em menos de uma hora até chegarmos a apenas uma linha no registro:
Que se revelou pertencer à DLL dispex.dll:
&amp;quot;dispex.dll is a module that contains COM interfaces used by Visual Basic scripts&amp;quot;
Pesquisando soluções de restauração achei esse KB que explica que existe um aplicativo chamado McRepair que teoricamente conserta a bagunça.
Não conserta.
Porém, ao usar o Method 1 (registrar novamente a DLL) o problema foi resolvido. Exportei o registro antes e depois da operação e por algum motivo a máquina do cliente estava com o GUID das interfaces IDispatchEx e IObjectIdentity adulteradas:
Realizei o mesmo teste com nossa DLL que gerou o problema inicial e descobri que não houve mudanças nessa parte do registro por conta dela.
Fica assim indefinida a origem do &amp;quot;corrompimento&amp;quot; dessa parte do registro, apesar de localizada.
Esse artigo é pra mostrar que não é só de ifs e elses que vive um programador =)
</description>
</item>

     
        <item>
  <title>Então você ainda não usa controle de fonte?</title>
  <link>http://www.caloni.com.br/entao-voce-ainda-nao-usa-controle-de-fonte/</link>
  <pubDate>2010-11-02</pubDate>
  
  <guid>http://www.caloni.com.br/entao-voce-ainda-nao-usa-controle-de-fonte/</guid>
  <description>Não há nada de errado nisso. Projetos robustos com uma equipe moderada ¿ 5 a 10 programadores ¿ precisam desse tipo de organização, e tornam a resolução dos problemas do dia-a-dia mais problemática sem esse controle. A questão reside para o programador solitário ou a equipe minúscula ¿ 2 a 4 programadores. Esses geralmente questionam o custo-benefício de terem o trabalho de configurar e manter mais um sistema. Além disso, isso implica em uma mudança de grandes proporções em cada membro da equipe: uma mudança cultural.
Portanto, a primeira decisão que deve ser tomada pelo programador que quer mudar as coisas é instalar um controle de fonte moderno para seus projetos caseiros. Quando digo moderno, digo distribuído.Distribuído porque 1) é possível começar desde já com três comandos simples, 2) quando alguém copia a pasta do projeto está levando todo o histórico junto e 3) pastas duplicadas são branches distintos que podem interagir no futuro.
Os três comandos simples não são nada do outro mundo: criar o repositório, adicionar arquivos e fazer commit.
Dica: Um commit é uma maneira de dizer ao controle de fonte: &amp;quot;já modifiquei o que tinha pra modificar, então mande tudo que tenho de novo para o controle&amp;quot;.
Tanto faz qual controle você pretende usar. No meu exemplo usarei o Bazaar, que é a ferramenta que uso no dia-a-dia com minha pequena equipe e serve bem para programadores solitários também. Basicamente para ter o Bazzar instalado basta baixá-lo, next next e finish.
Marcar para usar o PATH pode ser uma boa pra quem é fã de linha de comando.
Apesar de existirem firulas gráficas, gosto de usar o Bazaar na linha de comando porque faz você pensar direito antes de fazer commits, mas esteja livre para experimentar a maneira que achar melhor.
Isso vale para qualquer projeto que você esteja trabalhando. Pela linha de comando, navegue até o diretório do projeto. Digite os comandos abaixo seguidos de enter:
  bzr init
  bzr add
  bzr commit -m &amp;quot;Primeiro commit no controle de fonte&amp;quot;
  Pronto! Você está oficialmente com seu projeto dentro de um controle de fonte.
Os passos seguintes seguem o mesmo padrão, exceto o passo 1, que é substituído pelo seu trabalho:
  trabalho
  bzr add
  bzr commit -m &amp;quot;Comentário sobre modificação que fiz&amp;quot;
  Basicamente, sim. É claro que um controle de fonte não se baseia apenas em commits. Existem arquivos a serem ignorados (os obj da vida) e eventualmente algum trabalho paralelo ou com mais programadores. No futuro poderá comparar versões diferentes do código. Porém, apenas seguindo essa simples receita acima você já pode se gabar de ter um controle de fontes confiável em seus projetos. Já estará se aproveitando desse controle no futuro, quando aprender mais sobre ele.
</description>
</item>

     
        <item>
  <title>FormatMessage para... dumies?</title>
  <link>http://www.caloni.com.br/formatmessage-para-dumies/</link>
  <pubDate>2010-10-26</pubDate>
  
  <guid>http://www.caloni.com.br/formatmessage-para-dumies/</guid>
  <description>Já foi comentado em alguns círculos de ótimos programadores que a função da Win32 API FormatMessage é uma das criaturas mais bizarras já criadas.
O objetivo da FormatMessage é formatar uma string, assim como sprintf, mas voltado mais a escrever uma descrição de um código de erro. Sendo assim ela é essencial para que o usuário não receba um número no lugar de uma explicação de por que a operação falhou.
Os códigos de erro que ela se propõe a formatar podem ser os erros padrões descritos em winerror.h ou qualquer outro código cuja explicação esteja em algum módulo carregado pelo processo (DLL ou o próprio executável). Isso nos dá a liberdade de, por exemplo, criar uma DLL apenas com códigos e descrições dos erros dos nossos produtos.
Para que seja criada a mensagem final, uma definição de mensagem é requirida como entrada, que pode vir do próprio chamador ou da já mencionada tabela de erros de algum módulo qualquer. No caso de querermos a descrição de um erro de sistema (em winerror.h, retornado por GetLastError ou similares) a definição da mensagem já está embutida no sistema, bastando para nós passarmos o código.
É importante lembrar que, como estamos falando de uma descrição de erro, ou seja, de um texto, este pode vir em diversos idiomas, sendo que é nossa obrigação também definir para qual idioma desejamos traduzir nosso código de erro, sendo também nossa obrigação, no caso de mensagens específicas do nosso programa, fornecer o modelo da mensagem nos idiomas que formos suportar.
O resto da função funciona mais ou menos como o sprintf, cuspindo a mensagem-modelo em uma saída formatada de acordo com os parâmetros de entrada.
As flags do parâmetro dwFlags mudam radicalmente o funcionamento da rotina, o que me lembra de outra figura bizarra: o realloc da biblioteca padrão.
No caso do FormatMessage, a variável dwFlags se divide em dois para especificar dois grupos de opções distintos. A parte maior contém as opções armazenadas tradicionalmente como um mapa de bits, enquanto o byte menos significativo define como será tratada a saída final, com respeito às novas linhas e qual será a largura máxima de uma linha na saída.
O parâmetro mais polêmico é o que possui vários significados. No caso de lpSource, existem dois significados possíveis:
  FORMAT_MESSAGE_FROM_HMODULE. Ele é um HANDLE para um módulo.
  FORMAT_MESSAGE_FROM_STRING. Ele é um ponteiro para string.
  Isso explica por que essas duas flags são exclusivas: ou uma ou outra. Mesmo que a flag FORMATMESSAGEFROMSYSTEM seja usada, a função tentará achar a definição da mensagem no módulo especificado por lpSource primeiro, antes de ir buscar nas tabelas do sistema.
Chamado de dwMessageId, esse é o argumento onde podemos passar um código de GetLastError ou nossos próprios códigos de erro. Se já tivermos uma string em lpSource, no entanto, não faz sentido existir um código de erro.
Para definir o idioma é usado o mesmo sistema de resources: monta-se uma DWORD com MAKELANGID que contém informações do idioma primário e secundário. Se quisermos usar o idioma padrão do sistema (99% dos casos) basta passarmos o retorno de MAKELANGID(LANGNEUTRAL, SUBLANGNEUTRAL).
Mais um argumento polêmico. Se a flag FORMATMESSAGEALLOCATEBUFFER, lpBuffer não é um buffer, mas um ponteiro que será preechido com um endereço de memória alocada usando a função API LocalAlloc. Isso quer dizer que, após usar a mensagem formatada, devemos desalocar essa memória com LocalFree.
Por outro lado, se o buffer for nosso, então seu tamanho deve ser especificado no próximo argumento, nSize.
Só que nem o parâmetro que especifica o tamanho do buffer é simples, assim. Se for especificado a flag FORMATMESSAGEALLOCATEBUFFER, em vez de não fazer sentido esse argumento, ele significa o número MÍNIMO de caracteres que devem ser alocados, independente do tamanho da mensagem.
Obs.: Lembre-se que são caracteres, e não bytes. Se estivermos programando em UNICODE o número de bytes dobra.
Essa seria uma lista simples de argumentos valist que, para quem já fez funções ao estilo printf sabe muito bem usar. A lógica da função determina que os valores &amp;quot;%1&amp;quot;, &amp;quot;%2&amp;quot; e assim por diante dentro da definição de mensagem sejam trocados por estes argumentos.
Se eles são strings terminadas em nulo (interpretação padrão), inteiros ou estruturas específicas, isso vai depender da mensagem que está sendo formatada, o que é outro if a ser lembrado na hora de formatar mensagens do sistema.
Também é importante lembrar que, uma vez chamada a função, o conteúdo de valist não pode ser usado novamente se não for reinicializado com vaend seguido de vastart.
Agora, se todo esse negócio de vasbrubles é muito complicado pra você, é possível passar um array de DWORDPTRs com o uso da flag FORMATMESSAGEARGUMENTARRAY.
Se tudo der certo e você passar todos os argumentos certinhos, o retorno é o número de caracteres armazenados no buffer de saída, independente dele ter sido alocado dinamicamente ou não. Ah, sim, excluindo o nulo terminador.
Se der errado a função retorna zero. É possível obter o erro através de GetLastError, o que muito provavelmente será 87 nas primeiras vezes que você usar essa função.
Pensou que acabaria por aqui? E qual o significado das sequências de escape dentro da mensagem-modelo? O formato básico para inserção de um argumento segue o padrão %n!format-string!.
Onde n é o número que identifica o argumento, como já vimos, e format-string é um espaço reservado para identificarmos o tipo do argumento e como ele aparecerá na mensagem de saída.
Existe uma longa explicação sobre o uso de controladores de largura e precisão da saída formatada e sua localização na lista de argumentos, cujo número irá depender se estamos usando valist ou array de DWORDPTRs, sendo que alguns problemas podem surgir se repetirmos esses números de inserção. Em dois momentos da explicação o artigo seja a sugerir que seja usada a função StringCchPrintf, primeiro por que FormatMessage não suporta formatação de ponto flutuantes, e segundo, porque, mesmo que seja possível formatar valores de 64 bits, seria mais fácil se você usasse outra função.
Ainda existe um uso específico para &amp;quot;%0&amp;quot;, que é evitar quebra de linha durante a formatação da mensagem, inclusive no final. Esse uso entra em conflito com o nosso flag quando este determina um número máximo de caracteres por linha.
Ainda existe &amp;quot;de bônus&amp;quot; outras strings para preencher limitações que o próprio printf possui, como %%, %t, etc.
Como os programadores habituados com ataques de stack overrun devem deduzir, uma mensagem-modelo mal intencionada pode conter sequências de inserção que não existem na formatação habitual, forçando o vazamento de bytes na string final, o que pode forçar ataques planejados. Como o próprio artigo diz, usar um código de erro arbitrário retornado por uma API qualquer e usar FormatMessage sem a flag FORMATMESSAGEIGNOREINSERTS pode levar a resultados desastrosos.
Esse também é um bônus da MSDN, que te presenteia com exemplos de código tão fantasiosos quanto a própria função, veja o primeiro exemplo, por exemplo:
Depois ele chega a reimplementar o exemplo usando valist, o que é muito interessante, mas... bom, deixa pra lá. Vamos fazer nosso próprio teste.
Esse é o uso clássico: precisamos de uma descrição de um código de erro para o usuário; um código Win32. A chamada para esse tipo de uso pode ser encapsulada em uma função mais simples:
Existem milhares de forma de usar essa função, como você deve ter percebido pelos parâmetros. Não seja tímido: se você conhece algum truquezinho esperto e quer compartilhar com os usuários da FormatMessage, essa é a hora!
</description>
</item>

     
        <item>
  <title>Atualizando HouaissParaBabylon no saite</title>
  <link>http://www.caloni.com.br/atualizando-houaissparababylon-no-saite/</link>
  <pubDate>2010-10-22</pubDate>
  
  <guid>http://www.caloni.com.br/atualizando-houaissparababylon-no-saite/</guid>
  <description>O último comentário no meu último artigo sobre o conversor Houaiss para Babylon me fez lembrar de algo muito importante: eu não atualizei o branch do saite com a última versão. Deve ser por isso que as pessoas estão tendo problemas com o uso do código. Resolvo isso já:
Essa é a versão 1.2 descrita no meu último artigo sobre o projeto.
De qualquer forma, qual não foi minha surpresa quando tentei recompilar o projeto e ocorreram erros no atlcom. Depois de uma breve pesquisa descobri que precisava rodar alguns &amp;quot;patches&amp;quot; para o include funcionar direito. Então, provavelmente, Willians, era esse o problema. Tente de novo.
</description>
</item>

     
        <item>
  <title>Três em um</title>
  <link>http://www.caloni.com.br/tres-em-um/</link>
  <pubDate>2010-10-09</pubDate>
  
  <guid>http://www.caloni.com.br/tres-em-um/</guid>
  <description>Que vergonha passar tanto tempo sem postar nada. Parece que não fiz nada que valesse a pena comentar por aqui.
Na verdade, não fiz tanto, mesmo. Muitas mensagens do Outlook, gráficos UML e reuniões de alinhamento depois, sobrou um tempinho pra programar. Aprendi algumas coisas que tinha o desejo de saber há tanto tempo... Agora eu sei, quem diria, criar linques suspensos nas janelas Win32! Que novidade, não? Pois é, isso exige, de acordo com o SDK, algumas artimanhas pra fazer funcionar. Para quem está de Visual Studio 2008/2010 na mão basta seguir os passos seguintes.
Definir que estamos programando para XP ou superior:
Inserir suporte a linques na biblioteca de controles comuns:
Usar o CreateWindow com a classe certa, fazer markup html dentro do título e cuidar das mensagens de click e enter no controle:
Você que não está fazendo subclassing de janelas existe outra técnica que você pode utilizar: arrastar-e-soltar o controle do seu ToolBox. Qual é a graça?
 Outra coisa que aprendi foi como enviar mensagens ao usuário para impedir que este reinicie a máquina em momentos importantes:
A partir do Vista temos uma nova API para fazer isso. E é muito simples:
Quando ao receber a famigerada WMQUERYENDSESSION, basta retornar FALSE. O Windows faz o resto.
PS: E com uma ajudinha do Windows Internals ainda fiquei sabendo que dá pra se colocar na frente da fila para receber essa mensagem.
</description>
</item>

     
        <item>
  <title>Como ofuscar strings</title>
  <link>http://www.caloni.com.br/como-ofuscar-strings/</link>
  <pubDate>2010-08-30</pubDate>
  
  <guid>http://www.caloni.com.br/como-ofuscar-strings/</guid>
  <description>Já fiz ofuscamento e embaralhamento de dados acho que umas três ou quatro vezes. Dessa vez, parti para o batidíssimo esquema de fazer o pré-processamento de um header com defines que irão virar estruturas reaproveitadas por uma função padrão que desofusca e ofusca aquela tripa de bytes em algo legível: a string original.
Vamos ver um exemplo:
Conseguimos capturar os três elementos desse define (um descartável) por um simples scanf:
A função scanf retorna o número de argumentos capturados. Então se a coisa funcionou é só comparar com 2.
Depois de capturado, imprimimos na saída (o arquivo pós-processado) uma estrutura que irá conter nosso amigo embaralhado:
Pronto. Agora o usuário da string precisa abri-la usando uma macro esperta que irá chamar uma função esperta para desofuscar a string e entregar o ponteiro de buffer devidamente &amp;quot;casteado&amp;quot;:
Uma vez que a abertura se faz &amp;quot;inplace&amp;quot;, ou seja, a memória da própria variável da estrutura original é alterada, pode-se fechar a variável novamente, se quiser, após o uso.
A GENERICSTRUCT do exemplo se trata apenas de um esqueleto para que todas as estruturas das 500 strings ofuscadas sejam entendidas a partir de um modelo. Sim, essa é uma solução usando linguagem C apenas, então não posso me dar ao luxo daqueles templates frescurentos.
Como a string é ofuscada? Sei lá, use um XOR:
Dessa forma abrir ou fechar a variável pode ser feito usando a mesma função.
Alguém aí gostaria de uma explicação didática sobre o operador XOR?
PS: Acho que, além das minhas palestras, meus artigos estão também parecendo um brainstorm.
</description>
</item>

     
        <item>
  <title>Gerando dumps automatizados</title>
  <link>http://www.caloni.com.br/gerando-dumps-automatizados/</link>
  <pubDate>2010-08-26</pubDate>
  
  <guid>http://www.caloni.com.br/gerando-dumps-automatizados/</guid>
  <description>Agora que a temporada das telas azuis passou estou às voltas com o nosso sistema de detecção de crashes, além de alguns dumps e logs pra relaxar de vez em quando.
Fiquei impressionado com a simplicidade com que podemos capturar qualquer exceção que ocorra em um programa, independente da thread, e gravar um minidump com o contexto exato em que o problema ocorreu. O uso da função API SetUnhandledExceptionFilter aliado com a já citada na palestra MiniDumpWriteDump pode agilizar muito a correção de crashes triviais como Access Violation.
A mágica é tão bela que resolvi gravar um vídeo do que ocorreu quando compilei e testei o programa abaixo. Note que o tamanho do arquivo de dump ficou em torno dos 10 KB, ridículos nessa era de barateamento de espaço.
Espero com isso aliviar a carga pesada de A.V.s que sempre aparece quando menos se espera. Cuidar de toneladas de código legado exige algumas pitadas de automatização nos lugares certos. Como já dizia meu primeiro chefe: se a mente não pensa...
</description>
</item>

     
        <item>
  <title>Evento C&#43;&#43;</title>
  <link>http://www.caloni.com.br/evento-c/</link>
  <pubDate>2010-08-16</pubDate>
  
  <guid>http://www.caloni.com.br/evento-c/</guid>
  <description>Esse fim-de-semana houve o tão falado evento C&#43;&#43;, com a presença de dezenas de pessoas, algo que eu sinceramente não esperava. O bom desse evento foi saber que existem tantas pessoas interessadas em manter contato com quem gosta e pratica essa linguagem e também em saber que o nível técnico das palestras estão de alto para avançado.
Infelizmente em nenhuma das duas palestras práticas (minha e do Fernando) houve participação interativa, e ninguém que eu saiba abriu meu pacote-surpresa com os dumps a serem analisados. De qualquer forma, minha palestra ficou bagunçada pelo excesso de conteúdo e falta de tempo, o que me fez dar boas risadas ao ouvir no twitter que minha palestra foi mais um brainstorm. A intenção não era essa, claro, mas meu claro despreparo para muito conteúdo gerou essa impressão. Espero que do pouco que consegui explicar alguém tenha achado utilidade.
E, pelo jeito, futuramente irei aplicar essa mesma metodologia brainstorm em um videocast, que ainda não decidi como irei preparar. A ideia é analisarmos alguns dumps em conjunto e, para os que acompanharem online, a interatividade de perguntas &amp;amp; respostas.
Mas enquanto isso não acontece vamos dar uma olhada no que tínhamos no pacote-surpresa.
Como foi visto na palestra, uma pilha nesse estado demonstra claramente alguma variável que estourou e corrompeu o resto da pilha de chamadas. Na hora de voltar para a função chamadora, o endereço usado foi o endereço reescrito por lixo, e daí temos o &amp;quot;crash-pattern&amp;quot; Stack Trash.
A thread ativa no momento do dump aguardava por outra thread. Listando todas as threads do processo temos a primeira e a segunda, que tenta entrar em um critical section. Quando vemos que aquele CS estava sendo bloqueado pela primeira thread vemos claramente se tratar de um dead lock.
O disassemble da instrução inválida tenta escrever claramente em cima do endereço zerado (edx &#43; eax). Dessa forma fica fácil saber que esse tipo de escrita não é permitido, constituindo nosso famosíssimo AV.
Esse foi meio de brinde. Uma exceção de breakpoint (int 3, ntdll!DbgBreakPoint) lançada sem um depurador atachado implica em derrubamento do processo, pois é uma exceção como outra qualquer. O programador deve ter esquecido um DebugBreak ou algo que o valha no código de produção, que acabou sendo executado.
Essa foi a DLL encontrada no cliente quando ocorreu o problema relatado na imagem, também em anexo. Isso foi demonstrado na palestra com a ajuda do meu script que carrega DLLs, além de um pouco de sorte. Podemos analisar esse caso com mais calma em outro artigo. Acho que já falei demais por aqui.
</description>
</item>

     
        <item>
  <title>Foto dos melhores momentos</title>
  <link>http://www.caloni.com.br/foto-dos-melhores-momentos/</link>
  <pubDate>2010-08-12</pubDate>
  
  <guid>http://www.caloni.com.br/foto-dos-melhores-momentos/</guid>
  <description>Mais um quebra-cabeças antes da nossa palestra, esse &amp;quot;baseado em fatos reais&amp;quot;.
A história é a seguinte: o cliente instalou uma versão nova do produto em algumas máquinas que, ato contínuo, começaram a apresentar telas azuis constantemente. Como essas máquinas tinham que ser usadas pelos funcionários, a administradora rapidamente desinstalou essa versão buguenta, e logo em seguida pediu por uma correção.
Até aí tudo bem. O problema maior era que ninguém havia capturado dump de nada.
Por isso pedi encarecidamente por qualquer fragmento de tela azul (minidumps) que pudessem ainda estar nas máquinas afetadas. Dito isso, ela confessou que havia voltado a imagem padrão nesses equipamentos para que os funcionários pudessem voltar ao trabalho rapidamente. Só que sem dump eu não conseguiria trabalhar rapidamente.
Mas eis que no dia seguinte ela me liga, comentando que um funcionário, empolgado (?) pela tela azul em sua máquina, havia tirado uma foto da mesma para &amp;quot;recordação&amp;quot;. Sem nenhuma cerimônia, então, pedi rapidamente que ela conseguisse essa foto para a minha coleção. A foto que ela me manda é exatamente a que está no início desse artigo (clique na foto para ampliá-la), apenas censurado o nome do driver, o que não vem ao caso. Assim que a recebi pude constatar o problema direto no código-fonte, corrigi-lo e enviar uma nova versão, que após alguns dias de testes se revelou bem sucedida.
A questão é: como eu resolvi o problema? Como você teria procedido nessa situação?
A resposta para esse enigma também contará pontos para nossa brincadeira com o livro Windows Internals, como foi explicado no artigo anterior. Vamos lá, Sherlock!
</description>
</item>

     
        <item>
  <title>Não é minha culpa</title>
  <link>http://www.caloni.com.br/nao-e-minha-culpa/</link>
  <pubDate>2010-08-08</pubDate>
  
  <guid>http://www.caloni.com.br/nao-e-minha-culpa/</guid>
  <description>Recebi a dica de meu amigo kernel-mode sobre o aplicativo NotMyFault, escrito como ferramenta do livro Windows Internals e que basicamente gera telas azuis para análise.
Como os problemas gerados pela ferramenta são todos de kernel, resolvi escrever meu próprio conjunto de bugs para o pessoal da userland. E como nada na vida se cria, tudo se copia, tenho o orgulho de apresentar a vocês o NotMyFaultEither!
Seu uso é bem simples. Escolha o problema, aperte a teclar &amp;quot;Fazer Bug&amp;quot; e pronto!
O resultado pode variar dependendo do sistema operacional e da arquitetura (há versões 32 e 64 bits, ambas UNICODE). Um Access Violation no Windows Seven 64 bits, por exemplo, o processo pára de reponder.
Após a análise do SO ele exibe uma tela onde é possível achar onde está o despejo de memória que podemos usar.
Esse é um minidump (mdmp), que possui a pilha da thread faltosa e informações de ambiente. Podemos gerar um dump completo através do Gerenciador de Tarefas.
No caso do Windows XP, podemos executar processo semelhante para gerar o dump através do aplicativo ProcDump, muito útil para preparar o material da minha palestra do próximo fim de semana.
E por falar em palestra, criei um pacote-surpresa de alguns minidumps para análise. Se alguém tiver a curiosidade de já ir mexendo, ou de mexer na hora da apresentação, fique à vontade. Quem montar uma lista relacionando cada dump com o tipo de problema encontrado (não precisa estar completa) irá concorrer, no dia da palestra, à quarta edição do livro Windows Internals, de Mark Russinovich. É minha cópia pessoal, mas está bem novinho, visto que a original pesa pra caramba e consulto sempre o e-book.
Estarei usando estes mesmos minidumps na palestra, junto dos dumps completos. Mas é claro que eu não iria deixar um despejo de memória completo pra vocês. Iria tornar as coisas muito fáceis ;)
Portanto, junte suas grandes dúvidas para o grande dia e nos vemos lá.
</description>
</item>

     
        <item>
  <title>Novas diferenças no Bazaar</title>
  <link>http://www.caloni.com.br/novas-diferencas-no-bazaar/</link>
  <pubDate>2010-08-04</pubDate>
  
  <guid>http://www.caloni.com.br/novas-diferencas-no-bazaar/</guid>
  <description>Novidade incrível nas novas versões do Bazaar. Dando continuidade à sua versão boiola gráfica, agora é possível configurar quantos visualizadores de diferenças você quiser. Na hora de ver a diferença em algum código-fonte, você pode optar pelo enrustido embutido ou, no caso, o meu favorito, WinMerge.
E por que o WinMerge é meu favorito? Porque você pode ignorar toda aquela discussão se devemos usar tabs ou três espaços para indentar o código. Cada um indenta como quer, na hora que mexer no código, que o WinMerge não vai nem ligar para essas diferencinhas (já que o compilador não liga). Ele até detecta blocos de código inteiros que foram movidos dentro do arquivo.
Na hora de ver as diferenças no worktree podemos usar a velha opção de criar um alias para o WinMerge. Mas no meio de um log, podemos ativar tanto o view embutido quanto o de qualquer outra ferramenta que escolhermos.
Vendo essas coisas fico imaginando como ainda tem gente que usa arquivos zip com data para armazenar versões de documentos diferentes. Tsc, tsc.
</description>
</item>

     
        <item>
  <title>Como achar o código-fonte sem símbolos</title>
  <link>http://www.caloni.com.br/como-achar-o-codigo-fonte-sem-simbolos/</link>
  <pubDate>2010-08-03</pubDate>
  
  <guid>http://www.caloni.com.br/como-achar-o-codigo-fonte-sem-simbolos/</guid>
  <description>Continuo escovando bits. Dessa vez de forma mais nervosa. Se trata de um serviço que trava durante seu stop. Um colega muito esperto do suporte gerou um dump para mim, tornando as coisas mais fáceis. O problema era que não havia símbolos nem código-fonte que batessem exatamente com aquela compilação de 2004. Solução? Analisar as pilhas das threads restantes.
É sabido que esse serviço responde requisições de milhares de máquinas em um período curto de tempo, então por isso a primeira coisa que me atentei foi verificar quantas threads haviam:
São muitas.
Analisar essa quantidade absurda de threads seria um saco. Além de inútil. Foi por isso deus inventou a função !uniqstack, que encontra automagicamente quais threads estão com a pilha duplicada.
Muitas threads duplicadas. Isso quer dizer que podemos nos focar na pilha de uma delas. Basta pegar uma.
Através das funções de RPC e OLE32 podemos concluir que se trata de uma chamada direta para uma interface COM. Bom, existem centenas de métodos e dezenas de interfaces nesse serviço, tornando mais fácil tentar desmontar a chamada inicial que o rpcrt4 faz ao nosso módulo.
Nossa função é obtida em ebp&#43;8. Podemos obter esse endereço pelo campo ChildEBP da função em questão.
Note como a função compara algo com zero. Caso não seja zero ela continua. Caso contrário ela vai para um ponto que chama uma função interna e move um código de erro para um ponteiro recebido como parâmetro, o que é muito normal, se lembrarmos que as funções COM de um programa em C devem retornar o código da chamada no retorno (SOK) e o código de erro em um lResult da vida.
O código retornado é 2Fh, e agora temos uma boa pista para encontrar a localização no fonte. A primeira coisa é encontrar o define responsável por esse erro, o que exige um pouco de familiaridade com o sistema, pois não se trata aqui de um código Windows.
Ótimo. 2F, para os leigos (leigos? o que vocês estão fazendo aqui?), é 47 em decimal, exatamente nosso código listado acima. Com esse define podemos agora procurar no código-fonte e analisar todas as funções que retornam esse código em seu início. Para nossa sorte, existe apenas uma.
Para confirmar que não estamos sonhando, podemos dar uma olhada no parâmetro passado para a função Log antes do código retornar. A memória deverá conter uma string idêntica a do código-fonte.
E, agora sim, encontramos o culpado!
Mais para a frente em minha análise consegui encontrar o objeto pelo qual todas as threads esperavam. Não tive tanta sorte, pois se tratava de um mutex, e mutexes não conseguem ser rastreados tão facilmente em user mode. Mas isso não vem ao caso. O que tentei descrever aqui foi mais ou menos o processo que você deverá seguir caso tenha que analisar um binário compilado em outras vidas. Espero que você tenha tanta sorte quanto eu.
</description>
</item>

     
        <item>
  <title>Breakpoints promíscuos</title>
  <link>http://www.caloni.com.br/breakpoints-promiscuos/</link>
  <pubDate>2010-07-26</pubDate>
  
  <guid>http://www.caloni.com.br/breakpoints-promiscuos/</guid>
  <description>Ontem falei sobre como &amp;quot;brincar&amp;quot; com os breakpoints promíscuos, ou seja, aqueles que topam qualquer processo. Isso
é muito simples de se fazer:
 Configure uma VM para bootar em kernel debug. Encontre um processo qualquer (vamos usar o notepad pra variar?). Reabra os símbolos de user mode nele. Defina um breakpoint em alguma DLL de user mode.  Como meus leitores são muito espertos foi partir para o momento após rodarmos um notepad.exe:
O screenshot diz tudo:
Agora a parte mais divertida: experimente com outro notepad, ou com o explorer =)
</description>
</item>

     
        <item>
  <title>Const e Volatile</title>
  <link>http://www.caloni.com.br/const-e-volatile/</link>
  <pubDate>2010-06-04</pubDate>
  
  <guid>http://www.caloni.com.br/const-e-volatile/</guid>
  <description>Padrão C (ISO/IEC 9899:1990)
Chamamos de qualificador de tipo as palavrinhas mágicas const e volatile. Na prática elas definem como uma determinada variável será usada e se comportará durante a vida do programa.
Uma variável const não pode ser alterada pelo programa durante sua execução, apenas durante sua inicialização:
No exemplo acima, o valor de pi não pode mais ser alterado. Só que repare que ele foi, em determinado momento, alterado com um valor constante: na sua inicialização. Isso quer dizer que pi:
 é uma variável no programa representada por um local na memória endereçável pelo programa; não é um define do pré-processador que irá virar uma constante literal (3.14, por exemplo).  Teoricamente a região da memória que contiver uma variável const pode ser qualificada pelo sistema operacional como somente-leitura, mas isso não é uma obrigação. É obrigação do compilador avisar sobre tentativas de alteração da variável no meio do programa, mas nem sempre é possível enxergar que a memória não é alterável. Dessa forma, resultados imprevisíveis podem ocorrer.
Eu costumo usar variáveis const no lugar de defines. Além de ganhar na tipagem as constantes não precisam ser necessariamente globais, nem acessíveis por outros módulos. Um outro uso muito comum é criar variáveis locais que você sabe que não devem ser alteráveis por ninguém, como o tamanho de matrizes primitivas.
O significado do volatile teoricamente muda de implementação para implementação, mas na prática é uma forma de definir uma variável que está sendo acessada por outros programas/threads/entidades espíritas que podem alterar o seu valor sem seu programa notar quando.
O exemplo clássico da API Win32 é o InterlockedIncrement, que realiza operações atômicas em valores inteiros. Para fazer isso é necessário usar um recurso interno disponível pelo processador que irá modificar a memória sem intrusão de outras threads/processadores.
Variáveis volatile geralmente interagem de alguma forma com o sistema em que rodam, e são representadas por ponteiros para memória retornada por esse sistema ou documentada como sendo de uso específico.
É possível que exista uma variável que não pode ser modificada pelo seu programa, mas é modificada pelo sistema, de forma que ela é uma mutante!
A definição de gsystemClock é de uma memória que não pode ser alterada; só que ela é, pelo sistema. Então a variável também é volatile. No entanto, independente de ser const ou volatile, o tipo nunca será alterado, apenas qualificado. São duas coisas diferentes na linguagem.
</description>
</item>

     
        <item>
  <title>Enum</title>
  <link>http://www.caloni.com.br/enum/</link>
  <pubDate>2010-05-31</pubDate>
  
  <guid>http://www.caloni.com.br/enum/</guid>
  <description>Padrão C (ISO/IEC 9899:1990)
Uma enumeração faz duas coisas: define um novo tipo, parecido com um inteiro, e cria uma lista de constantes com nomes significativos. A definição técnica do tipo de um enum é mais complicada, mas basicamente ele é um novo int.
Como funciona: definimos uma lista com cada elemento tendo um valor inteiro, geralmente único. Todos os nomes usados na lista passam a fazer parte do espaço de nomes atual e funcionam como constantes com o seu valor definido no início.
Obs.: Os elementos que não possuem valor definido são definidos automaticamente como o valor do elemento anterior acrescidos de um. Se for o primeiro elemento, seu valor padrão é zero.
Detalhe bizarro: você sabia que, apesar da vírgula ser usada para separar valores de enumeração, ela pode também terminar uma listagem? Por algum motivo exdrúxulo (se alguém quiser explicar), um valor de enumeração foi definido de tal forma que sempre poderá existir uma vírgula terminando ele:
Geralmente usamos enumerações para definir valores únicos (tag) em um argumento de função, ou, mais moderno, como substituto daqueles antigos defines em C para mapas de bits. Nesse último caso não usamos o tipo da enumeração, pois ele pode conter apenas um valor único definido, e não um conjunto deles:
Note que usamos uma enumeração nesse último caso para termos um nome significativo para uma flag, além desse nome fazer de fato parte dos nomes do programa, e não um define que, para o compilador, não existe.
Como os tipos da enumeração passam a pertencer ao namespace atual, eles podem se misturar facilmente com todos os nomes daquele namespace. Dessa forma, é útil e bem organizado definir um prefixo para os nomes, que pode ser formado pelas iniciais do nome da enumeração, como no exemplo acima (fom = FileOpenMode).
O surgimento do enum veio como evolução de uma prática já consagrada pelo uso na linguagem C, que eram as listas de valores constantes criados através de defines com algum prefixo em comum (FILESHARE, SWSHOW, etc). Portanto, sempre que se encontrar em uma situação para criar esse tipo de lista, a enumeração é o caminho atualmente ideal.
Perguntado por um leitor sobre qual a diferença prática do último exemplo, onde temos praticamente o mesmo resultado entre usar defines e enumerações, imaginei que a mesma dúvida pode ter surgido para várias pessoas, porque é uma boa dúvida. Dá a entender que o autor deste artigo está se atentando a preciosismos da linguagem (e está mesmo!), mas à vezes as aparências enganam.
Para ilustrar melhor fiz um mais elaborado. Aqui, estamos lendo pedaços de dados que tiveram que ser alinhados com alguma &amp;quot;gordura&amp;quot;.
Aviso para os programadores mais calejados, eu omiti propositalmente os parênteses obrigatórios para qualquer define que tenha cálculos matemáticos, para ilustrar que muitas vezes o que vemos antes não é o que aparece depois.
</description>
</item>

     
        <item>
  <title>Modificadores e qualificadores de tipo</title>
  <link>http://www.caloni.com.br/modificadores-e-qualificadores-de-tipo/</link>
  <pubDate>2010-05-28</pubDate>
  
  <guid>http://www.caloni.com.br/modificadores-e-qualificadores-de-tipo/</guid>
  <description>@caloni poderia pensar em fazer um artigo sobre os modificadores de tipo em c? os mais complexo, acho eu: volatile, enum, union, extern, etc
Uma coisa de cada vez: existem modificadores (ou qualificadores) de tipo e especificadores de tipo. Volatile e extern se encaixam na primeira categoria, enum e union na segunda. Veremos um pouco desses dois lados da linguagem em doses paliativas.
Um modificador de tipo é opcional na definição de um tipo e deve estar sempre relacionado com a declaração de alguma variável. Ele determina, em termos gerais, qual será a função dessa variável. Ela pode ser modificada? Onde ela se encontra no programa? Como ela será modificada?
Como exemplo rápido, temos abaixo uma variável que é atualizada pelo clock do processador e uma variável que não pode ser alterada após sua primeira atribuição:
Fica meio óbvio que a primeira variável possui seu valor volátil, ou seja, muda conforme o tempo passa, e não depende do próprio código (pode mudar sem sua permissão). A segunda variável também tem um uso explícito, uma vez que o valor de pi nunca será alterado (não nesse Universo).
Os especificadores de tipo possuem cada um sua peculiaridade. Os mais peculiares, que veremos nos próximos artigos, serão as enumerações e as construções bizarras de structs e unions.
Aqui não é um compêndio teórico sobre a linguagem. Vamos falar particularmente da programação Windows, mas esteja livre para dar seus pitacos com respeito a outros sistemas operacionais e suas implementações igualmente exdrúxulas =)
</description>
</item>

     
        <item>
  <title>Analogicamente perfeito</title>
  <link>http://www.caloni.com.br/analogicamente-perfeito/</link>
  <pubDate>2010-05-19</pubDate>
  
  <guid>http://www.caloni.com.br/analogicamente-perfeito/</guid>
  <description>É possível explicar tudo no mundo da informática através de analogias? Pela minha singela experiência de professor informal, eu acredito que sim. Durante esses dois anos, explanei diversos assuntos e, em todos eles, difíceis ou não, consegui um certo grau de sucesso graças ao uso de metáforas e parábolas.
De memória (ou buscando no meu blogue) consigo lembrar alguns tópicos e a forma como os expliquei. Em alguns até fiz um artigo sobre o assunto:
 Ponteiros 16 bits: rua e número de uma casa. Typedefs: apelidos para nomes de pessoas. Depuração: a ciência médica de House. Passagem de argumentos por valor e por referência: e-mails com anexo e com linques. Ponteiros: armário de gavetas. Programadores: programadores de verdade não usam Java (brincadeira). Agendamento de threads: guichê de CPUs. Seções críticas: fila de threads dentro de uma sala. Funções com retorno booleano: o dedo polegar dos romanos. Pilha: uma pilha, só que de pratos e não bytes. Binário: bichos-preguiça contando com seus únicos dois dedos. Tipos: uma forma de bolo que só faz bolos com um único formato. Definições x declarações de variáveis: hardware e software; OK, podemos chamar esse de meta-analogia =) Depuração 2: séries de investigação forense como CSI.  Acredito ser essa a melhor forma de desmistificar esse pequeno mundinho que parece incompreensível aos outros mortais. Até porque tudo que é criado no mundo dos computadores são abstrações do mundo real, que por sua vez são abstrações da mente humana.
É por isso que sempre digo que ciência da computação é uma arte-ciência da área de humanas.
</description>
</item>

     
        <item>
  <title>Por que Long Pointer</title>
  <link>http://www.caloni.com.br/por-que-long-pointer/</link>
  <pubDate>2010-04-21</pubDate>
  
  <guid>http://www.caloni.com.br/por-que-long-pointer/</guid>
  <description>Esse artigo continua a explicação sobre os typedefs arcaicos, já que ainda falta explicar por que diabos os ponteiros da Microsoft começam com LP. Tentei explicar para minha pupila que, por ser código dos anos 80, as pessoas usavam LP para tudo, pois os CDs ainda não estavam tão difundidos.
Não colou. Então vou tentar explicar do jeito certo.
Antigamente, as pessoas mandavam cartas umas para as outras. Carta, para você, caro leitor de quinze anos, era um e-mail implementado em hardware.
Para mandar um e-mail, usamos o nome da pessoa e o domínio em que seu e-mail é endereçado, ex: nome-da-pessoa@dominio.com.br. Para mandar uma carta usamos duas informações básicas: o nome da rua e o número da casa.
Consequentemente enviamos dois comandos ao carteiro: meu amigo, vá para a rua tal. Chegando lá, encontre o número 1065.
Considere que estamos falando do mesmo bairro ou cidade, o que na minha analogia seria um computador e sua memória. Para enviar cartas para outros bairros em outras cidades (outros computadores em outras redes) teríamos que informar também outros dados, como nome da cidade e CEP.
Nesse exemplo também podemos usar o Juquinha do bairro para entregar a carta e economizarmos 10 centavos.
Agora, repare que interessante: em uma rua, cabem no máximo N casas. Se você tentar construir mais casas vai acabar invadindo o espaço de outra rua.
E, já que estamos falando do endereço do destinatário, já podemos relevar que esse endereço constitui um ponteiro em nossa analogia. Se você está usando dois dados para informar o endereço, então estamos falando de um ponteiro longo, long pointer, ou LP!
Na terminologia Intel para as plataformas 16 bits, a memória do computador era acessível através de segmentos (ruas) e offsets (números), que eram pedaços da memória onde cabiam no máximo N bytes. Para conseguir mais bytes é necessário alocar memória em outro segmento (outra rua).
Os ponteiros que conseguiam fazer isso eram chamados de long pointers, pois podiam alcançar uma memória mais &amp;quot;longa&amp;quot;. Os ponteiros que apenas endereçavam o offset (número) eram chamados, em detrimento, short pointers, pois podiam apenas apontar para a memória do seu segmento (rua).
Ora, se seu destinatário está na mesma rua que você, tudo que você tem a dizer ao Juquinha é: &amp;quot;Juquinha, seu moleque, entrega essa carta no número 1065, e vai rápido!&amp;quot;. Nesse caso você está usando um short pointer.
Porém, no exemplo que demos, o destinatário está em outra rua. Se o Juquinha entregar a carta no número 1065, mas na rua errada, estará errando o destinatário. Por isso é que você deve usar um long pointer e falar para o Juquinha do segmento!
&amp;quot;Juquinha, seu moleque safado, entrega essa carta no Segmento 0xAC89, Offset 0x496E. E vê se anda logo!&amp;quot;
Essa frase era muito usada nos anos 80, com seus 16 bits e tudo mais.
Com toda essa analogia, fica fácil perceber que o Windows não cabe em uma rua só. Seus aplicativos precisam de muitas ruas para rodar. Isso exige que todos seus ponteiros sejam long, pois do contrário o Juquinha estará entregando as cartas sempre nos endereços errados. Dessa forma, foi estipulado o typedef arcaico padrão para todos os tipos da API que usasse LP (Long Pointer) como prefixo:
E é por isso que, historicamente, todos os ponteiros para os apelidos da API Win32 possuem sua contraparte LP.
Com a era 32 bits (e mais atualmente 64 bits) os endereços passaram a ser flat, ou seja, apontam para qualquer lugar na memória. Se eu quisesse continuar minha analogia falaria que é o equivalente a uma coordenada GPS, também muito na moda, e que pode apontar para qualquer lugar do planeta. Eu, por exemplo, já trabalhei perto das coordenadas -23.563596,-46.653885, o que eu costumo dizer que fica bem próximo do Paraíso =).
De uns anos pra cá, existem novos typedefs nos headers que permitem o uso dos apelidos Win32 apenas com um P inicial.
A escolha é livre. Assim como com o typedef arcaico.
</description>
</item>

     
        <item>
  <title>Typedef arcaico</title>
  <link>http://www.caloni.com.br/typedef-arcaico/</link>
  <pubDate>2010-04-20</pubDate>
  
  <guid>http://www.caloni.com.br/typedef-arcaico/</guid>
  <description>A API do Windows geralmente prima pela excelência em maus exemplos. A Notação Húngara e o Typedef Arcaico são duas técnicas que, por motivos históricos, são usados a torto e a direito pelos códigos de exemplo.
Já foi escrito muita coisa sobre os prós e contras da notação húngara. Já o typedef arcaico, esse pedacinho imprestável de código, ficou esquecido, e hoje em dia traz mais dúvidas na cabeça dos principiantes em C&#43;&#43; do que deveria. Para tentar desobscurecer os mitos e fatos, vamos tentar explicar o que significa essa construção tão atípica, mas comum no dia-a-dia.
Vejamos um exemplo típico desse pequeno Frankenstein semântico:
Bom, eu nem sei por onde começar. Talvez pelo conceito de typedef.
Um typedef, basicamente, é um apelido. Você informa um tipo e define &amp;quot;outro tipo&amp;quot;.
O tipo é tudo que fica entre o typedef e o novo nome, que deve ser um identificador válido na linguagem. Por exemplo, a empresa onde trabalho fez um typedef informal do meu nome:
Se, futuramente, eu sair da empresa e entrar outro &amp;quot;Wanderley alguma-coisa&amp;quot;, será possível usar o apelido novamente, bastando alterar o typedef:
 Bom, &amp;quot;outro tipo&amp;quot; é forma de dizer. Isso é uma descrição errônea em muitos livros. De fato, o compilador enxerga o mesmo tipo com outro nome, daí chamarmos o typedef de apelido, mesmo.
 Tipos simples são fáceis de entender porque possuem seus símbolos no mesmo lugar:
Já os tipos um pouco mais complicados permite alguma mudança aqui e acolá:
Essa liberdade da linguagem, mesmo sendo um recurso útil, pode ser bem nocivo dependendo de quem olha o código:
Em algumas formas da sintaxe, além de ser inevitável, gera bastante desconfiança:
Antigamente, as structs eram construções em C que definiam um agregado de tipos primitivos (ou outras structs) e que poderiam gerar variáveis desse tipo em qualquer lugar, desde que informado seu nome e que se tratasse de uma struct:
Para evitar toda essa digitação, os programadores usavam um pequeno truque criando um apelido para a estrutura, e usavam o apelido no lugar da struct (apesar de ambas representarem a mesma coisa).
ou
Com a definição da linguagem C&#43;&#43; padrão, e mais moderna, essa antiguidade foi removida, apesar de ainda suportada. Era possível usar apenas o nome do struct como seu tipo:
Porém, isso vai um pouco além de quando a Microsoft começou a fazer código para seu sistema operacional. Naquela época, o padrão ainda estava se formando e existia mais ou menos um consenso de como seria a linguagem C&#43;&#43; (sem muitas alterações do que de fato a linguagem C já era). De qualquer forma, a linguagem C imperava bem mais que C&#43;&#43;. Dessa forma, já era bem formada a ideia de como declarar uma struct: a forma antiga.
Além do uso controverso do sublinhado para nomear entidades (que no padrão foi recomendado que se reservasse aos nomes internos da biblioteca-padrão) e do uso de MAÍUSCULASNONOME (historicamente atribuído a nomes definidos no pré-processador), o uso do typedef atracado a um struct era muito difundido. E ficou ainda mais depois que a API do Windows foi publicada com essas definições.
Ora, do mesmo jeito que é feito há vinte anos: sem typedefs. O próprio paradigma da linguagem, independente de padrões de APIs, de sistemas operacionais ou de projetos específicos já orienta o programador para entender o que o espera na leitura de um código-fonte qualquer. Qualquer pessoa que aprendeu o básico do básico sobre ponteiros e structs consegue ler o código abaixo:
Agora, para entender a forma antiga, ou você se baseou no copy&amp;amp;paste dos modelos Microsoftianos, ou seja, decoreba, ou você é PhD em Linguagem C/C&#43;&#43; e padrões históricos de linguagens legadas. Se não é, deveria começar o curso agora.
Da mesma forma, o uso de uma estrutura simples de tipos mantém a lista de nomes do seu projeto limpa e clara. Compare o visualizador de classes em projetos Windows com algo mais C&#43;&#43; para ter uma ideia.
É claro, essa é apenas uma sugestão. Existem vantagens em sua utilização. Existe alguma vantagem no modo antigo? Existe: a Microsoft usa, e talvez mais pessoas usem. Basta a você decidir qual deve ser o melhor caminho.
De acordo com o leitor Adriano dos Santos Fernandes, a obrigatoriedade do nome struct após seu nome continua valendo para a linguagem C padrão, assim como no compilador GCC ocorre um erro ao tentar omiti-la. Apenas na linguagem C&#43;&#43; essa obrigatoriedade não existe mais.
Eu não fiz meus testes, mas confio no diagnóstico de nosso amigo. A maior falha do artigo, no entanto, é usar a linguagem C como base, quando na verdade ele deveria falar sobre o uso desses typedefs em C&#43;&#43;. Esse erro também foi corrigido no original.
</description>
</item>

     
        <item>
  <title>Using TodoList and Microsoft Project together</title>
  <link>http://www.caloni.com.br/using-todolist-and-microsoft-project-together/</link>
  <pubDate>2010-04-10</pubDate>
  
  <guid>http://www.caloni.com.br/using-todolist-and-microsoft-project-together/</guid>
  <description>The next article about bits is still in the oven. Taking vacation (40 days) had drop me out of ideas! At the moment, I can explain the tips and tricks using TodoList to manage my team and synchronize my tasks in a Microsoft Project timesheet.
The reasons why I am using TodoList are kind of obvious: it does everything I need to organize my day to day tasks and it is portable. Meanwhile, the Project, besides not being portable (I need to carry on with me a 200 MB installer? And do install?) it uses a hard to change format and it was made to project the world, and not to be easily shared.
So, let&#39;s go. Everything we need is a current edition of TodoList and Microsoft Project. The first thing we must to do é to export the tasks we want to a default CSV, using the columns we would like to import to Project:
After that it comes the tricky thing, but not so much. We open the project to where we want to import the tasks and choose the option Open again, but this time we select our friend exported-tasks.CSV.
Before we do import, we got to create a new column that will keep the TodoList tasks IDs, to make sure that in the next imports we make we could merge datum together. So, create this column using a significant name.
Now we can go on the import process. Imagining to be the first one, let&#39;s create a inicial map for this migration:
The time we choose who is who in the columns list, we just need to setup which columns in Project are the counterpart for the columns in TodoList, and remember to allocate our special column ID.
Just more a few Nexts and voilà! We got our tasks properly imported.
But of course all this work would be useless if we had to (sigh) open the Project. To avoid this impure job, we keep on updating the project status in our tiny, tidy TodoList and, when we need, we just import the data again, but this time using a already saved map (follow the screenshots above) and setting our TodoList ID as the key. This way the tasks already present will be just updated, and the unknown tasks will be added. That&#39;s the most important trick in this post.
After I researched all this, I just found out the Project won&#39;t be necessary anymore. Lucky me. Now, if you don&#39;t have such luck, you can use this post =)
</description>
</item>

     
        <item>
  <title>Houaiss Para Babylon!</title>
  <link>http://www.caloni.com.br/houaiss-para-babylon-12/</link>
  <pubDate>2010-04-08</pubDate>
  
  <guid>http://www.caloni.com.br/houaiss-para-babylon-12/</guid>
  <description>Os últimos comentários de Henrique Esteves (quando havia seção de comentários no blogue) sobre o HouaissParaBabylon me fizeram dar mais uma fuçada nele e ver se tento deixá-lo compatível com o Houaiss 3. Foram apenas algumas horas e acho que resolvi os probleminhas relacionados com a troca do registro de instalação e o nome dos arquivos que armazenam os verbetes.
Apenas para constar, segue a lista de artigos sobre este projeto:
 Conversor de Houaiss para Babylon - parte 1 Conversor de Houaiss para Babylon - parte 2 Segunda versão do Houaiss2Babylon HouaissParaBabylon versão beta HouaissParaBabylon versão 1.1  Foi uma odisseia e tanto. E ainda está longe de ser perfeito. Contudo, fico feliz que muitas pessoas já tenham conseguido usá-lo com sucesso e com a qualidade técnica dos meus visitantes. O Henrique, por exemplo, teve que entender o processo interno que o programa faz para renomear os arquivos do dicionário e assim conseguir a conversão. Pessoas como essa faltam na equipe de suporte técnico de programadores de baixaria.
Isso me faz lembrar que uma das motivações do programador, fora programar, é saber que os usuários usam seu programa. E saber que existem melhorias a ser feitas que vão ser úteis para esses usuários é muito legal. Por isso, continuem assim, caros usuários. E bom proveito!
Obs.: Essa versão foi testada em um Windows XP com o Houaiss 3, Babylon 8 e o Babylon Builder mais atual.
</description>
</item>

     
        <item>
  <title>Novidades no Windbg 7</title>
  <link>http://www.caloni.com.br/novidades-no-windbg-7/</link>
  <pubDate>2010-04-01</pubDate>
  
  <guid>http://www.caloni.com.br/novidades-no-windbg-7/</guid>
  <description>Semestre que vem deve sair uma nova versão do nosso depurador favorito. Alguns atrasos e novas definições do projeto fizeram com que tivéssemos mais um ou dois releases da finada versão 6 antes da revolução que será o Depurador 2010.
Entre as mudanças mais esperadas, e entre as mais inesperadas, encontramos essa pequena lista de novidades que, com certeza, deixarão o desenvolvedor de sistemas da Microsoft muito mais feliz:
Hoje em dia é um trabalho um pouco tedioso encontrar qual dos drivers possuía a memória de endereço 0xB8915423, mas agora, juntando o interpretador de símbolos internos e o sistema de tooltips do Windbg, será possível passar o mouse sobre um endereço qualquer e ele mostrará imediatamente quem possui a memória, como ela foi alocada e qual seu conteúdo.
Isso só é possível, é claro, com os símbolos corretamente carregados. Algo não muito difícil se você seguir as recomendações de John Robbins. E é uma mão na roda na hora de dar um feedback instantâneo para o suporte técnico quando der uma tela azul.
Sim! Agora se o ddkbuild estiver no path do WinDbg e você editar o código-fonte do seu driver durante a depuração (na próxima versão a visualização não será apenas read-only) e der um step-into, automaticamente o depurador irá perguntar se deseja recompilar o projeto. Depois de ativar o processo de build, através das conexões serial/firewire/usb-debug, a nova imagem irá parar diretamente na memória kernel da máquina target.
Algumas ressalvas são colocadas pela equipe da Microsoft, no entanto. Se existirem mudanças que dizem respeito a alocação dinâmica de memória em nonpaged-pool, o Edit and Continue não será possível naquele momento, apenas depois do reboot.
O último item, mais esotérico de todos, promete ser lançado a partir da versão 7.1:
Resumidamente, é um !analyze mais esperto com o algoritmo heurístico do Visual Basic .NET. Assim que for aberto um dump de tela azul e carregados os símbolos e o caminho dos fontes, a nova versão do !analyze irá verificar os valores do BugCheck gerado e, caso seja detectado que o problema está em seu driver, irá sugerir uma correção na sua função que estiver na pilha.
Existem um pouco de polêmica em torno dessa funcionalidade. Alguns dizem que ela vai mais atrapalhar do que ajudar os programadores de kernel com a vinda de analistas de sistemas Júnior programando filtros de file system sem a menor discrepância entre o que é um IRP assíncrono e uma ISR. Outros dizem que existirá uma versão paga do WinDbg com essa funcionalidade, nos mesmos moldes do Visual Studio 2010, que virá com a depuração reversa no Enterprise. Essas especulações só o tempo dirá se são verdade ou não. Se eu tiver que pagar mais caro por essas features, o lobby na empresa onde eu trabalho está garantido.
</description>
</item>

     
        <item>
  <title>Convivendo entre TodoList e Microsoft Project</title>
  <link>http://www.caloni.com.br/convivendo-entre-todolist-e-microsoft-project/</link>
  <pubDate>2010-03-15</pubDate>
  
  <guid>http://www.caloni.com.br/convivendo-entre-todolist-e-microsoft-project/</guid>
  <description>O próximo artigo sobre escovação de bits ainda está no forno. Tirar férias (de 40 dias) é uma escassez de ideias! No momento, posso explicar a facilidade que tive para continuar usando o TodoList para gerenciar minha equipe e ainda assim sincronizar nossas tarefas em um cronograma do Microsoft Project.
As razões de eu usar o TodoList são meio óbvias: ele faz tudo que eu preciso para organizar minhas tarefas do dia-a-dia e é portátil. Enquanto isso, o Project, além de não ser portátil (eu preciso levar comigo o instalador de 200 MB? E Instalar?) possui um formato difícil de mudar, já que foi feito para projetar o mundo e não para ser compartilhado facilmente.
Mas vamos lá. Tudo que precisamos é de uma edição atual do TodoList e do Microsoft Project. A primeira coisa que devemos fazer é exportar as tarefas que queremos do TodoList para um CSV padrão, usando as colunas que gostaríamos de importar para o Project:
Depois vem a parte complicada, mas nem tanto. Abrimos o projeto para onde queremos importar essas tarefas e escolhemos a opção Abrir novamente, só que dessa vez selecionando o nosso amigo tarefas-exportadas.CSV.
Só que antes de importarmos, calma lá. Temos que criar uma nova coluna que irá guardar os IDs das tarefas do TodoList, para que nas próximas importações consigamos mesclar os dados já existentes. Portanto, crie uma nova coluna (pode ser qualquer NúmeroX não-alocado ainda) com um nome significativo.
Agora podemos partir para a importação. Imaginando que seja a primeira, vamos criar um mapeamento inicial para essa primeira migração:
Na hora de escolher quem é que, só precisamos definir quais colunas no Project correspondem a quais colunas do TodoList, e lembrar de alocar o ID na nossa coluna especial.
Mais alguns Next da vida e pronto! Temos nossas tarefas devidamente importadas.
Mas é claro que todo esse trabalho não valeria a pena se tivéssemos que (arght) mexer no Project. Para evitar esse trabalho impuro, continuamos atualizando o andamento dos projetos no nosso pequeno, leve e sagaz TodoList e, quando precisarmos, é só importarmos novamente os dados, só que dessa vez usando um mapa já salvo (siga os screenshots acima) e marcando nosso ID do TodoList como chave. Dessa forma as tarefas já importadas são apenas atualizadas, e não criadas novamente. Esse é o famoso &amp;quot;pulo do gato&amp;quot; (que eu ouvia matinalmente na minha época de office-boy).
Depois de eu pesquisar toda essa trama, descobri que o uso do Project não será necessário. Sorte minha. Agora, se você não tiver sorte...
</description>
</item>

     
        <item>
  <title>Bazaar gráfico</title>
  <link>http://www.caloni.com.br/bazaar-grafico/</link>
  <pubDate>2010-02-25</pubDate>
  
  <guid>http://www.caloni.com.br/bazaar-grafico/</guid>
  <description>Bom, já que por enquanto os assuntos de macho estão em falta (acabei de voltar de férias), apresento-lhes o maravilhoso mundo do Bazaar para boiolas user-friendly!
Ele é leve, vem enrustido embutido na última versão e pode economizar alguns page ups/downs no prompt do DOS. Ah, sim, antes que comentem, eu não uso o Tortoise for Bazaar porque instalar shell extensions, só os muito bem feitos. (Do contrário, bem-feito para quem instalou.)
Para exibir a lista de comandos &amp;quot;amigáveis&amp;quot;, digite no prompt os comandos do Bazaar filtrando-os para os que começam com &amp;quot;q&amp;quot;:
Os que eu mais uso no dia-a-dia são:
Diversão garantida. Por meio destes simples comandos podemos ver o histórico de commits e navegar pela árvore de pastas e arquivos com a anotação do último commit para cada elemento. Só para ter uma ideia de quanto uso isso, transformei-os em opções do Explorer.
Além da utilidade básica, de quebra, o qbrowse pode te levar para um qlog filtrado, e o qlog pode te levar a um diff gráfico, que é o próximo comando que eu iria mostrar.
Coisa linda de Deus. Existem dois modos de exibição, mas o padrão já é show de bola, mostrando as mudanças em todos os arquivos de um commit de uma só vez ou do arquivo/pasta especificado pelo comando. É lógico que é possível especificar qualquer faixa de commits que você quiser ver.
Uma desvantagem desse comando é que ele oculta o resto das linhas do fonte e não mostra de jeito nenhum (pelo menos não descobri ainda como fazer isso). Sendo assim, para uma análise mais detalhada das diferenças no código-fonte sempre use um editor externo que consiga comparar arquivos inteiros (eu uso o WinMerge). Você pode colocar esse comando na forma de um diff personalizado, com o uso do qconfig.
</description>
</item>

     
        <item>
  <title>Restaurando o registro</title>
  <link>http://www.caloni.com.br/restauranto-o-registro/</link>
  <pubDate>2010-02-08</pubDate>
  
  <guid>http://www.caloni.com.br/restauranto-o-registro/</guid>
  <description>Algumas ferramentas viram essenciais quando o importante é tempo. As minhas favoritas são: Visual Studio e batch. Com esses dois eu faço virtualmente qualquer coisa que preciso em pouquíssimo tempo. É lógico que, na ausência dessas, alternativas são bem-vindas, como Notepad&#43;&#43;, viM, grep, cygwin.
Ontem tive que resolver uma &amp;quot;situação&amp;quot; no cliente, e graças ao bom Deus (ele também é programador) existia um Notepad&#43;&#43; na bagagem que levávamos. Além, é claro, do Excel e do sistema batch do Windows.
O problema consistia basicamente em usar a saída do RegMon para identificar e restaurar algumas modificações que danificavam a instalação do Internet Explorer. O sistema de reparo do IE não existia no cliente, pois ele estava sem Service Pack (bem-vindo ao mundo real), mas podíamos nos guiar através dele na nossa máquina virtual para saber o que faríamos. O estrago era feito durante o registro e/ou desregistro de um componente COM.
Aliás, não, eu não preciso usar o onipresente e onipotente Process Monitor para resolver um detalhezinho no registro. Você talvez precise, já que a Microsoft já tirou o Reg e o File de circulação.
Para iniciar, filtramos os resultados do RegMon para apenas capturar escritas no registro, não importando se falharam ou deram resultado.
A partir disso executamos o registro e desregistro do componente, além da restauração do IE6, responsável por limpar a bagunça. O processo responsável por registrar componentes é o regsvr32 e o responsável por limpar a bagunça, rundll32.
Tendo a saída do RegMon exportada para formato texto, abrimos no Excel e filtramos o conteúdo pelo nome do processo. Note que existem duas instâncias de regsvr32 para usar, pois não sabemos em qual delas é danificado o registro.
Para cada um dos filtros copiamos apenas o endereço da chave alterada para dois arquivos texto: regsvr32.txt e ierestore.txt. Usaremos esse primeiro para encontrar ocorrências no segundo, provando que um modifica o que o outro consertou.
Existe um comando muito simplório em batch Windows que é o aplicativo find. Através dele podemos encontrar a ocorrência de uma string em um arquivo. Para transformar todas aquelas linhas do registro do arquivo regsvr32 em comandos find poderíamos elaborar algumas colunas no Excel ou usar o Notepad&#43;&#43; e suas macros, mais rápidas.
Para quem não conhece macros, saiba que elas são muito úteis. Às vezes até mais úteis que &amp;quot;regexes&amp;quot;, pois não é necessário pensar muito na expressão a ser usada. Macros apenas repetem os movimentos do teclado que fazemos enquanto as estamos gravando. Por exemplo, eu tenho o meu monte de linhas de registro assim:
Quero transformar cada linha em um comando find. Iniciou a gravação da macro no início da primeira linha e digito o seguinte (em pseudo-alguma-coisa):
find, espaço, abre aspas, end, fecha aspas, espaço, ierestore.txt, linha abaixo, home
Pronto. Parar macro. Terei que repetir isso dois milhões de vezes até o final do arquivo. Ora, então mando o Notepad&#43;&#43; repetir a minha macro até o final do arquivo e adio minha tendinite para os próximos anos.
Só preciso agora renomear meu arquivo para .bat e executar. Posso redirecionar a saída da tela para um terceiro arquivo, de onde irei formatar minha lista de entradas no registro que foram adulteradas por ambos os programas (o registro do componente COM e a restauração do Internet Explorer).
Nesse momento podemos ir tomar café. Bem melhor do que ficar horas e horas dando localizar, copiar, colar em todas as entradas do regsvr.
Terminada a operação, abrimos o terceiro arquivo, retiramos as entradas insignificantes (por exemplo, o gerador de sementes de números randômicos) e os cabeçalhos do comando, algo bem fácil já que se trata do mesmo arquivo.
A próxima tarefa seria analisar cada entrada e ver se ela é relevante. Essa parte foi manual, mas, encontrado um padrão, listamos rapidamente o que poderia estar dando errado e criamos uma lista de entradas para exportar do registro &amp;quot;sadio&amp;quot; a fim de gerar um .REG que corrigiria sistemas danificados.
Algumas passadas no Notepad&#43;&#43; para eliminar linhas duplicadas e algumas passadas pelo cérebro para eliminar chaves redundantes (chave dentro de chave) e tcharam!
O próximo passo para nossa obra-prima é outra macro que irá reproduzir o comando reg, que pode realizar operações no registro do Windows.
E o último passo é juntar toda essa galera em um arquivo só.
Claro, não se esqueça de retirar os cabeçalhos duplicados (Windows Registry Editor Version X.XX). E Voilà! Fácil, não? Não?! Bom, então é por isso que eu sou bem pago =)
</description>
</item>

     
        <item>
  <title>Correção de bugs instantânea</title>
  <link>http://www.caloni.com.br/correcao-de-bugs-instantanea/</link>
  <pubDate>2010-02-01</pubDate>
  
  <guid>http://www.caloni.com.br/correcao-de-bugs-instantanea/</guid>
  <description>Um programador tarimbado sabe que a melhor situação da vida dele para corrigir um bug é quando esse bug acontece em sua máquina de desenvolvimento, na versão Debug e ainda passo-a-passo. Como nessa situação a correção é um verdadeiro &amp;quot;passeio no parque&amp;quot; (ou na mesa do café) ela tende a quase nunca acontecer. Isso é Murphy Aplicado.
Para quem programa para sistemas, então, só o fato de acontecer no mesmo processo toda vez que ele for executado já é o máximo (quem já programou serviços, plugins, GINAs e afins sabe do que eu estou falando).
Porém, saber que uma determinada situação é mel na chupeta (by Thiago) por si só não adianta de muita coisa. É preciso conhecer as verdadeiras técnicas ninjas que conseguem resolver um bug escabroso num instante, coisa de deixar seu gerente de projetos tão feliz ao ponto dele não botar nenhum defeito na solução.
Dentre as mais conhecidas entre os malloqueiros, temos:
  Comenta-descomenta-comenta
  Faz do zero
  Essas duas técnicas são tão úteis e tão fáceis de usar que merecem um artigo a respeito.
Essa técnica milenar corresponde em tirar pedaços do código-fonte que poderiam estar causando o problema até que seja possível criar uma versão em que o problema não ocorra mais. Quando chega-se nesse nível, então volta-se a descomentar o código retirado até que o problema ocorra novamente. O processo é um fluxo de tira-código com volta-código, sendo que é necessário o bom conhecimento do projeto para não gerar outros problemas com a mutilação temporária do projeto.
Se o código começa a ser tão mutilado que chegamos quase em uma versão vazia (sem código), então talvez a melhor forma de atacar o problema seja criar um esqueleto que contenha apenas o código necessário para que ele não faça nada. Isso mesmo. Não fazendo nada, mas instalado. Com isso prova-se que é possível estar lá sem fazer cagadas. A partir daí vai colocando-se o código do projeto real aos poucos no projeto-esqueleto, até que ele apresente o problema. Ou não. Já vi casos em que todo o código foi migrado e o problema sumiu. Ce la vie.
</description>
</item>

     
        <item>
  <title>Passagem por valor e emails com anexo</title>
  <link>http://www.caloni.com.br/passagem-por-valor-e-emails-com-anexo/</link>
  <pubDate>2010-01-18</pubDate>
  
  <guid>http://www.caloni.com.br/passagem-por-valor-e-emails-com-anexo/</guid>
  <description>Mais uma analogia vencedora para ponteiros, chamadas por valor e chamadas por referência: e-mails.
Quando passamos um parâmetro por valor, estamos enviando um e-mail com um arquivo em anexo. Não importa o que o destinatário faça com o arquivo: nós não vamos saber o que foi mudado se ele não enviar uma outra cópia.
Por outro lado, ao passar um parâmetro por referência, estamos enviando um e-mail com um endereço de onde está o arquivo. Se o usuário alterar o arquivo diretamente do endereço que enviamos será possível ver essa alteração imediatamente, pois ambos estão olhando para o mesmo valor na memória.
A analogia pode ser levada mais longe, com ponteiros de ponteiros: enviamos um e-mail com o endereço de um arquivo; dentro desse arquivo existe um endereço para outro arquivo. Dessa forma é possível tanto alterar o arquivo final quanto o endereço de onde ele está; ou ainda &amp;quot;apontar&amp;quot; para outro arquivo, trocando o endereço de dentro do primeiro arquivo.
Assim é fácil de visualizar que os dados estão sempre em um arquivo que ocupa espaço na memória (do disco ou da RAM), mas endereços também podem ocupar espaço, se estiverem salvos em um arquivo.
Dessa forma, um e-mail que contenha um arquivo em anexo vai ser muito maior que um e-mail apenas com o endereço do arquivo, mas é porque todo o conteúdo do arquivo está dentro do e-mail no primeiro caso. No segundo caso, o endereço ocupa apenas alguns caracteres que identificam a localização do arquivo.
</description>
</item>

     
        <item>
  <title>Importando tipos de outros projetos</title>
  <link>http://www.caloni.com.br/importando-tipos-de-outros-projetos/</link>
  <pubDate>2010-01-11</pubDate>
  
  <guid>http://www.caloni.com.br/importando-tipos-de-outros-projetos/</guid>
  <description>A engenharia reversa das entranhas do kernel não tem limites se você sabe o que está fazendo. No entanto, algumas facilidades do depurador podem ajudar a minimizar o tempo que gastamos para analisar uma simples estrutura. Por exemplo, o Process Environment Block de um processo específico.
O comando !peb traz inúmeras informações sobre essa estrutura. Mas talvez estivéssemos interessados em coisas não mostradas por esse comando, mas que existem na estrutura.
Nesse caso, podemos criar um projeto vazio que contenha a definição da estrutura como acreditamos que esteja na versão do kernel que estamos depurando.
Compilamos e geramos um PDB (arquivo de símbolos) que contém a definição desse tipo. Tudo que precisamos fazer agora é carregar esse símbolo na sessão que estivermos depurando.
É claro que nosso executável não vai existir na sessão de kernel local, mas isso não importa. Podemos usar qualquer módulo carregado e usá-lo como host de nosso conjunto de símbolos:
Depois que o símbolo foi carregado em nosso módulo de mentirinha, tudo que temos a fazer é alterar o contexto do processo atual (para que os endereços de user mode façam sentido) e moldar nossa memória com o comando dt, usando o tipo importado do símbolo carregado.
Para que isso funcione, a estrutura definida tem que bater offset por offset com os dados na memória, o que envolve alinhamento (se lembre do pragma pack) e versionamento corretos. Se isso não ocorrer, logo aparecerá algum lixo nos membros da estrutura que não fará sentido. Se isso ocorrer, detecte onde o lixo começa e verifique se o membro existe nessa versão do sistema operacional, ou se o alinhamento está de acordo com o módulo analisado.
Acho que não é preciso dizer que isso não serve apenas para kernel mode =)
</description>
</item>

     
        <item>
  <title>Devaneio nerd rápido sobre profecias</title>
  <link>http://www.caloni.com.br/devaneio-nerd-rapido-sobre-profecias/</link>
  <pubDate>2009-12-30</pubDate>
  
  <guid>http://www.caloni.com.br/devaneio-nerd-rapido-sobre-profecias/</guid>
  <description>Para quem já analisou os dados de uma tela azul sabe que, quando o Windows acha um culpado (vulgo driver) a data de sua compilação é exibida em um formato conhecido como DateStamp ou TimeStamp. Nesse formato o que temos é um número hexadecimal que segue o formato de tempo do Unix, que no caso é o número de segundos desde o dia primeiro de Janeiro de 1970. Isso, por curiosidade, nos dá uma margem de 140 anos antes dos número se repetirem se usarmos 32 bits nessa contagem.
O comando .formats do WinDbg nos consegue trazer desse número a hora exata em que determinado componente foi compilado. Se, por exemplo, um driver faltoso apresentou um DateStamp igual a 49EE9758, podemos concluir que ele foi compilado no dia 22 de abril de 2009, uma linda quarta-feira.
Quando fazemos algo muitas vezes seguidas temos o hábito inconsciente de observar certas idiossincrasias dos dados que sempre vem e vão. No caso dos Date Stamps, sempre me veio o fato deles iniciarem com 4 e estarem prestes a &amp;quot;virar o contador&amp;quot; para 5.
Isso aos poucos - entre uma tela azul e outra - me deixou curioso a respeito de quando seria o dia fatídico em que teríamos o DateStamp 50000000, um número cabalístico em nosso sistema decimal. E, imaginem só:
Pois é, meus amigos. O DateStamp para a virada do contador Unix se fará numa manhã de sexta. Para ser preciso, uma sexta-feira 13.
Curioso, não? Mais curioso que isso, só sabendo que o ano que isso vai ocorrer é o igualmente fatídico 2012. Felizmente antes de dezembro.
</description>
</item>

     
        <item>
  <title>O boot no Windows: Kernel</title>
  <link>http://www.caloni.com.br/o-boot-no-windows-kernel/</link>
  <pubDate>2009-12-04</pubDate>
  
  <guid>http://www.caloni.com.br/o-boot-no-windows-kernel/</guid>
  <description>Finalmente chegamos em um pouco onde podemos usar o WinDbg.
Podemos espetar o depurador e fazê-lo parar assim que conectado. Se estiver rodando antes do próprio sistema operacional, teremos um sistema sem processos e sem threads, pois ele irá parar assim que o executivo puder enviar o sinal de início pela porta serial, após carregar na memória os módulos básicos.
Todos os módulos carregados antes dessa fase são os drivers que tiveram seu Start definido em zero no registro. Todos os programadores que desenvolvem esses drivers gostariam de um dia poder usar o WinDbg. Mas não podem. Quem inicia a comunicação serial com o depurador é o kernel, que só recebe o controle do ntldr depois que os drivers básicos foram carregados.
Brincadeira. É claro que esses programadores usam o WinDbg, usam até demais. Mas só a partir desse ponto. Se algum problema evitar que o sistema chegue nessa fase, o desenvolvedor terá que usar métodos alternativos de depuração, como teste de mesa (risos incontroláveis).
De qualquer forma, estamos aí. Agora podemos depurar a criação de qualquer thread, qualquer processo, o carregamento de qualquer módulo, e a chamada a qualquer função do kernel.
Para depurar a criação de qualquer thread: coloque um breakpoint na função PsCreateSystemThread.
Para depurar a criação de qualquer processo: coloque um breakpoint na função PspCreateProcess, logo no começo. Será possível capturar a criação do processo System, o processo onde roda a primeira thread do kernel, que inicializa o resto dos componentes.
E não é lindo ver que, após a chamada ao Process Manager o processo REALMENTE foi criado e está na lista de processos?
É nesse momento que percebemos que um processo, uma thread, um qualquer-coisa dentro do kernel não é nada mais nada menos que um item em uma lista. Quase tudo no kernel será um item numa lista com um monte de ponteiros referenciando outras estruturas. É isso que mantém a lógica e a coerência no sistema inteiro. Tudo isso é basicamente software, construído como castelos no ar.
O próximo processo a ser criado, logo após carregar todos os drivers, é o nosso amigo SMSS, o Gerenciador de Sessão, o primeiro pedacinho do iceberg que desponta no oceano. É ele que irá iniciar toda a &amp;quot;parte user-mode do kernel&amp;quot;.
Nota: Apesar de parecer contraditório, algumas partes do kernel são de fato implementadas em user mode. Os motivos podem variar, mas geralmente são maior segurança (código que não precisa rodar em um ring privilegiado) e desempenho (código que não precisa de muita prioridade).
Como podemos ver, isso é muito divertido e muito extenso. Poderíamos ir para qualquer lado da evolução do boot. Talvez em artigos futuros daremos uma olhada no processo de logon de um usuário, o que nos obrigaria a ter uma leve noção de como o Windows autentica e autoriza as pessoas. ou talvez daremos uma passadinha no sistema de escalonamento de threads do kernel, um assunto pra lá de complicado e esotérico.
Nota: Eu pessoalmente recomendo acompanhar o processo de boot descrito por Russinovich e depurar passo-a-passo um boot de verdade. Serão horas e mais horas de puro conhecimento empírico catalogado em seu cérebro-depurador.
Então até lá. Com licença que eu preciso ver a criação do System mais uma vez.
</description>
</item>

     
        <item>
  <title>O boot no Windows: NTLDR</title>
  <link>http://www.caloni.com.br/o-boot-no-windows-ntldr/</link>
  <pubDate>2009-11-26</pubDate>
  
  <guid>http://www.caloni.com.br/o-boot-no-windows-ntldr/</guid>
  <description>Minhas análises estão demorando muito para ser feitas. Talvez seja a hora de revelar o pouco que sei (e pesquisei) sobre o próximo processo de boot do Windows: o NTLDR.
O nosso amigo NT Loader pode ser entendido através da leitura do já citado Windows Internals ou através de uma outra leitura que estou fazendo atualmente e que pouquíssimos amigos blogueiros irão se lembrar: o livro da galinha preta; formalmente conhecido como Windows Nt File System Internals.
Para os sabichões de plantão, inclusive os que me criticaram (?) no meu último texto humorístico sobre como Java é podre, eu sei que o bicho da capa não é uma galinha, mas um urubu. A troca de urubu por galinha vem do requisito básico para você fazer trabalhos esotéricos, como macumba e desenvolvimento de drivers: uma galinha preta na encruzilhada. Alguns usam um papel dentro da boca de um sapo, mas vai do gosto de cada um. =)
E, para os que leram o livro, devem entender que para explicar sobre o funcionamento do sistema de arquivos do Windows, parte intrínseca do funcionamento do próprio kernel, foi necessário ao autor explicar várias partes do kernel, inclusive sua inicialização; e é nessa parte que podemos aprender algo mais sobre o NT Loader.
Podemos aprender, por exemplo, que ele é carregado logo depois do NT Detect, que é o executável que dá uma olhada no hardware e ajusta a configuração do boot de acordo com o ambiente encontrado. Após esse ajuste, o nosso amigo NT Loader faz algumas coisas pra lá de interessantes.
O NTLDR é um executável &amp;quot;híbrido&amp;quot; que possui tanto código em modo real quanto código em modo protegido. Com isso podemos supor que é ele o responsável por entrar em modo protegido, uma tarefa que exige alguns conhecimentos da arquitetura.
Além disso, como o próprio nome diz, ele tecnicamente &amp;quot;sobe&amp;quot; o sistema operacional, pois provê a comunicação entre o hardware (processador e periféricos da máquina) e o software (kernel e drivers de boot). O hardware é o que está espetado na máquina e o kernel é o arquivo ntoskrnl.exe; para a comunicação entre eles existe uma camada de abstração, o hal.dll.
Esses dois arquivos, juntos dos drivers de boot, são carregados pelo NTLDR.
Depois de todo aquele trabalhão do setor de boot para analisar o sistema de arquivos, achar o NTLDR, carregá-lo na memória e executá-lo, o controle passa para o nosso amigo híbrido, ainda em modo real. Ele então abre a partição de boot e procura pelo arquivo boot.ini (estamos falando de um boot antes de bcdedit, mas o funcionamento seria aproximado). Como o driver do sistema de arquivos ainda não subiu, isso quer dizer que o NTLDR usa o próprio código embutido para interpretar uma FAT, NTFS ou outros sistemas suportados (um dos motivos por que não é possível instalar o Windows em um ReiserFS).
Nesse ponto o nosso amigo loader faz o que todo mundo já fez na infância (não fez?): trocar o modo de tela fazendo uma chamada para a BIOS para modo texto 80x50 em 16 cores. Ah, ele também faz algo que eu adorava fazer (você não?): encher a memória de vídeo de pixels pretos para limpar a tela!
Como ele leu a lista de kernels bootáveis, é isso que ele exibe naquela famosa tela que qualquer um que depura o kernel vê:
Escolheu seu boot, é a partir daí que ele acha o executável do kernel: ntoskrnl.exe. Ele deve estar na pasta system32 (em ambientes 32 bits). Também é nesse momento que é carregada a HAL (hal.dll) e isola-se o hardware do software a partir daí. As DLLs que esses dois componentes dependem são identificadas e carregadas na memória.
Agora é hora de abrir o registro. Quer dizer, parte dele. Dentro da pasta system32/config deve estar a hive SYSTEM, que é onde ficam os drivers que devem ser carregados a partir daí em vários níveis. Inicialmente são carregados os que possuem o valor Start igual a zero, como o driver Atapi (controlador de disco):
A partir daí vários componentes do kernel serão carregados progressivamente. Só que a partir do momento que é chamada a rotina interna KiInitializeKernel o NTLDR não tem mais nada pra fazer: o kernel, em sua forma básica e primitiva, está carregado.
Veremos nos próximos capítulos como podemos nos aproveitar do ntoskrnl.exe para poder depurar o código a partir daí. Até lá.
</description>
</item>

     
        <item>
  <title>O boot no Windows: pré-NTLDR</title>
  <link>http://www.caloni.com.br/o-boot-no-windows-pre-ntldr/</link>
  <pubDate>2009-09-09</pubDate>
  
  <guid>http://www.caloni.com.br/o-boot-no-windows-pre-ntldr/</guid>
  <description>Conforme fui estudando para recordar os momentos sublimes do boot do Windows me deparei com o artigo mais &amp;quot;espetaculoso&amp;quot; de todos os tempos sobre esse assunto, parte integrante do livro Windows Internals e escrito pelo nada mais nada menos Mark Russinovich: Boot Process, no capítulo 5, &amp;quot;Startup and Shutdown&amp;quot;.
O meu primeiro artigo sobre o boot sem Windows foi 80% escrito com o que eu já sabia de cabeça de tanto mexer na MBR e de tanto depurar o processo de boot em 16 bits. Os artigos posteriores seriam escritos com uma pitada do que sei mais a &amp;quot;inspiração&amp;quot; da minha pesquisa. Apesar de não parecer pouco para os que não sabem inglês, deixa a desejar para os que sabem (boa parte dos meus leitores, imagino).
Nesse caso decidi salpicar a explicação com uma boa dose de reversing para aproveitarmos a caminhada e fuçarmos um pouco no funcionamento interno dos componentes de boot e ver no que dá. Antes de começar, porém, aviso que este não é um tratado sobre o sistema de boot. Eu diria que é apenas o resultado de algumas mexidas inconsequentes pelo disassembly do código de boot. Espero encontrar alguém tão curioso (ou mais) do que eu que compartilhe o que achou de todo esse processo. Antes de mais nada um mapinha para vermos até onde chegamos:
Pelo visto esse foi só o começo. O próximo passo é saber como do setor de boot chegamos ao NTLDR. O que não é nenhum segredo, uma vez que o NTLDR é um arquivo que fica na pasta raiz do sistema de arquivos. Como todos sabemos, qualquer assembly 16 bits de 400 bytes de tamanho consegue ler um arquivo de 250 KB na memória e executá-lo.
Se o NTLDR não conseguir ser encontrado, o seguinte erro será exibido:
Que usuário merece ver isso?
Bom, se ele soubesse analisar o assembly do setor de boot, seria fácil entender essa mensagem. E analisar o assembly é simples demais, quase tão simples quanto entender a mensagem acima. Tudo que precisamos é do programa Debug 16 bits, como o que já vem com o Windows ou aquele mais turbinado do FreeDOS.
Podemos usar o Debug 16 bits para abrir o setor de boot salvo em algum arquivo e analisá-lo. Esse &amp;quot;salvo em algum arquivo&amp;quot; nós podemos obter usando o HxD, um sofware bom demais que eu uso quase todos os dias da minha vida, ou para analisar os primeiros setores do disco ou ler arquivos binários que caem na minha caixa de e-mails.
Eu não vou explicar como salvar um setor do disco em um arquivo. Pelamordedeus, isso é fácil demais. É só fuçar que se acha um jeito.
Se bem que, como esse é um quase-tutorial, vão abaixo apenas algumas dicas:
(1) no primeiro setor do disco de boot, podemos encontrar a tabela de partições;
(2) nessa tabela, a partição ativa é a que começa com 0x80;
(3) existe um campo onde é possível obter o offset de onde está o primeiro setor dessa partição (em setores);
(4) uma simples conversão de Little Endian e de hexadecimal para decimal nos retorna o número do setor que precisamos;
(5) o próprio HxD nos consegue levar para esse setor, de onde podemos selecioná-lo e salvá-lo em um arquivo!
Isso é tudo o que você precisa para fazer engenharia reversa do setor de boot. Bom divertimento!
Existem duas formas que conheço para analisar o disassembly de um setor de boot pelo Debug. Para os que gostam de aventuras radicais (RPG em modo texto?) existe a análise dinâmica, que consiste em digitar no prompt do DOS o comando Debug e o nome do arquivo salvo com o setor de boot. O primeiro comando u irá desmontar os primeiros bytes do setor (e, portanto, as primeiras instruções). Eu costumo fazer isso para uma visão geral de cinco minutos.
A segunda forma de análise que exixte é para os preguiçosos que não conseguem fazer tudo no mesmo dia e optam por salvar o dump do disasssembly em um segundo arquivo. Para realizar essa proeza usando o Debug não é preciso mais que três neurônios:
(1) digite em um arquivo chamado u.bat o seguinte conteúdo:
(2) rode o debug como a linha abaixo:
(3) Pronto! Temos um a.asm com toda a saída do setor de boot. Agora podemos analisá-la e editá-la:
Se fuçarmos por um tempo esse código podemos encontrar várias coisas interessantes, como por exemplo a mensagem que é exibida quando o setor de boot não contém a assinatura padrão 0x55 0xAA em seu final:
Outra coisa interessante é encontrar a sub-rotina que carrega blocos e blocos de conteúdo do disco na memória, utilizando-se para isso da interrupção 0x13 função 0x42: a leitura estendida!
Enfim, todo esse assembly para fazer apenas uma coisa: achar o NTLDR na diretório-raiz da partição onde estamos, carregá-lo na memória e executá-lo. O que se passa a partir daí é o que iremos abordar na futura continuação. Não perca!
</description>
</item>

     
        <item>
  <title>O boot no Windows: sem Windows</title>
  <link>http://www.caloni.com.br/o-boot-no-windows-sem-windows/</link>
  <pubDate>2009-08-18</pubDate>
  
  <guid>http://www.caloni.com.br/o-boot-no-windows-sem-windows/</guid>
  <description>Desde quando o usuário liga o computador até o momento em que ele vê a barra de tarefas e aqueles fundos lindos de papel de parede existem diversas coisas sendo feitas por debaixo do pano. Essa série de artigos irá explicar essas diversas coisas, ou seja, como funciona e quais as fases do boot de uma máquina que possui Windows instalado (plataforma NT).
O que esses artigos não vão fazer muito bem é explicar o lado do kernel mode funcionando, até porque temos artigos melhores explicando esse ponto de vista. Essa é uma abordagem mais &amp;quot;high level&amp;quot;, apesar de &amp;quot;low enough&amp;quot;. No entanto, espero que seja divertido. É esse o mais importante requisito em qualquer aprendizado, certo? Let&#39;s go!
Tudo começa no hardware, que recebe um lampejo de energia que o põe em funcionamento (&amp;quot;levanta-te e anda!&amp;quot;). Isso faz com que um pequeno pedaço de software comece a rodar. Esse pedaço inicial de código é chamado de firmware, que é um meio termo entre hardware e software.
O firmware fica gravado na placa-mãe e normalmente nós ouvimos falar dele pelo nome de BIOS, Basic Input Output System (Sistema Básico de Entrada e Saída). É nele que estão gravadas as rotinas mais básicas para fazer o hardware mais básico funcionar: CPU, memória, vídeo e teclado.
Quando o computador é ligado, o código da BIOS realiza duas operações vitais antes de continuar:
  Ver se todos os componentes de hardware estão bem;
  Ver quem é o dispositivo que inicia o sistema operacional.
  Esse segundo item é o que veremos agora.
Dependendo do computador, podemos iniciá-lo por um disco rígido (HD), por um CD-ROM, por um PenDrive USB e até pela rede. Isso está subordinado ao firmware da máquina, pois é ele que comanda, até segunda ordem, todo o hardware acoplado ao sistema.
Vamos supor que um HD foi configurado para ser o inicializador do sistema operacional. Então será lido um pequeno espaço de 512 bytes, mais conhecido como setor, bem no início desse HD. Esse setor inicial possui código de inicialização (chamado de bootstrapping). Por isso, ele é colocado na memória inicial da máquina e executado. O lugar onde ele fica é fixo e conhecido por todos (lembre-se que estamos rodando em modo real!): 0x7C00.
Agora o próximo passo é com esse setor inicial do disco, que chamamos de MBR: Master Boot Record (ou Registro de Boot Mestre, em tradução livre). Ele contém código 16 bits que não pode depender de runtime nenhuma e faz o que quiser com a memória. Também possui no seu final uma tabela de quatro entradas de partições; é nessa tabela que deve estar a partição ativa, onde está o sistema operacional.
Uma MBR padrão procura por essa partição e lê seu primeiro setor, fazendo um processo bem parecido com o que a BIOS faz inicialmente: carrega na memória o primeiro setor da partição e executa.
Vamos supor que você tenha algum Windows moderno na partição ativa. A MBR irá carregar o primeiro pedaço de código desse sistema operacional moderno, que, até então, estará rodando em modo real desprotegido como o bom e velho MS-DOS.
(Note que, mesmo que se trate de uma MBR escrita por terceiros, se ela se comportar como manda o figurino, irá carregar o primeiro setor da partição ativa descrita na tabela de partições. Isso é o que faz com que MBRs escritas pelo pessoal do Linux (e.g. Lilo) consiga fazer o boot de uma partição Microsoft.)
Agora chegamos em todos os passos iniciais realizados antes de entrar em cena o S.O.:
  O firmware da placa-mãe, conhecida como BIOS, verifica se o hardware básico está funcionando;
  Em seguida, o mesmo código procura pelo dispositivo iniciável que irá dar início ao processo de boot;
  Se for um HD, então o primeiro setor físico desse HD será carregado em memória e executado;
  Esse primeiro setor se chama MBR e contém uma tabela com até quatro entradas de partições no disco;
  O código da MBR procura pela partição ativa onde deve estar o sistema operacional;
  Assim como a BIOS, a MBR carrega na memória o primeiro setor da partição ativa e executa;
  A partir daí temos o código de um possível sistema operacional rodando.
  Todos os componentes principais desse boot podem ser visualizados de uma forma bem macro na figura abaixo.
Alguns detalhes sórdidos que podem fazer alguma diferença para você, desenvolvedor de sistemas operacionais, um dia desses:
  Os setores de que estamos falando (MBR, partição ativa) normalmente devem terminar com uma assinatura de dois bytes (0x55 0xAA), o que &amp;quot;garante&amp;quot; que o código contido nesse setor é válido e pode ser executado.
  No caso do loader do Windows (pré-Vista), existia um arquivo no diretório-raiz da partição ativa chamado boot.ini que continha uma lista de possíveis modos de inicializar o sistema operacional, inclusive com múltiplas versões do Windows, cada um localizado em uma partição/pasta distinta (e.g., multiboot com Windows 98 e XP).
  O limite de quatro partições da MBR pode ser aumentado com o uso de partições estendidas; as partições estendidas apontam para um bloco de setores no HD que inicia com um setor que contém outra tabela de partições exatamente onde fica a tabela da MBR, também com quatro entradas.
  O endereçamento da localização das partições na MBR pode ser feito de duas maneiras distintas: por CHS ou por LBA. A versão CHS é bem antiga, mas ainda usada, e especifica uma localização no HD através de um posicionamento físico de três dimensões, com cilindro/trilha (C - Cylinder), cabeça (H - Head) e setor (S - Sector). Sim, isso é bem old-fashionable. Também existe o LBA (Logical Block Addressing), que é uma forma lógica de endereçar setores no disco, através de deslocamentos (offsets).
  Para detectar problemas de hardware, a BIOS pode ajudar com seus beeps significativos. Isso aparentemente parece ser o fim da picada, mas não é. O DQ sabe muito bem que podemos ter problemas no hardware que exigem análises mais sofisticadas (como comprimento de onda dos sinais).
Se for detectar algum problema no sistema de boot baseado em MBR, então você tem dois caminhos:
  Usar o SoftICE 16 bits e depurar o carregamento da MBR pela BIOS
  Usar o Debug 16 bits do MS-DOS (ou similar) e depurar diretamente o código de boot da MBR, reproduzindo os passos anteriores da BIOS.
  Se o problema for durante o carregamento do próprio sistema operacional, as mensagens de erro do loader são significativas. No entanto, pode-se usar o Debug mais uma vez e depurar essa parte, logo antes, é claro, do sistema entrar em modo protegido de 32 bits, o que daí já é outra história (que pretendo contar em breve).
 Artigo sobre o boot no Linux  </description>
</item>

     
        <item>
  <title>What I&#39;ve been doing in the last 10 years</title>
  <link>http://www.caloni.com.br/what-ive-been-doing-in-the-last-10-years/</link>
  <pubDate>2009-08-17</pubDate>
  
  <guid>http://www.caloni.com.br/what-ive-been-doing-in-the-last-10-years/</guid>
  <description>This week I dedicate myself to update my resumè and I have the brilliant idea of put into it my technical historical, what resuming is a list of things I did or was involved with during my brief ten years stay in the programming world.
So I thought: &amp;quot;this could be useful to the people read me&amp;quot;. Why not? Perhaps you got some doubt waiting to be solved and is unable to find a guy who knows something about this. Perhaps this fork guy even exists and has a blog where he could share some knowledge that is stuck in that empty programmer head.
In this case, it follows bellow a brief description of my professional life, with the things I could remember I did since December 2000. What I haven&#39;t remember probably is not worth of.
 Software and hardware inventory Clipboard and PrintScreen protection using windows hooks and global messages manipulation Driver writing system event log DeviceIoControl user/kernel communication Desktop remote control using VNC technique Remote execution tool PsExec (SysInternals) like Print control using regex (Boost) and shell hook Access policies management during user logon/logoff (register and hooks) Database migration CTree -&amp;gt; SQL (OLE classes) Windows authentication using custom GINA and DCOM; Credential Provider (Vista) CTree database synchronism using custom DCOM service Bootable Linux CD with bash scripts and disk cryptography tools using C language Hard disk encryption and PenDrive (USB) storage control Blue Screen analysis using memory dumps and WinDbg live (Gflags) System account execution using custom COM service MBR (Master Boot Record) customization library Blowfish/SHA-1 encryption library using C&#43;&#43; and 16 bits Assembly Log access driver using shared memory between user and kernel mode Kernel mode API hook for 9X and NT platforms 16 bits Assembly loader; debugging using debug.com tool Executable protection using embedded domain authentication recorded inside files resources Internet Explorer 6/7 and Firefox 1/2 browsing protection using Assembly 32 bits code injection Code, strings and execution protection library (using Win32 interruptions) Centralized log generation library using shared memory and global events Internet Explorer 6/7 BHO (Broser Helper Object) and ActiveX; Mozilla/Firefox XPI plugin Projects management using Source Safe, Bazaar and Batch (Win) scripts Kernel mode debugging using SoftIce and WinDbg for NT platform, SoftIce and WDeb98 for 9X platform Trojans reverse engineering (C&#43;&#43;, Visual Basic, Delphi) using WinDbg and IDA Diagnostic tool listing files, services, drivers, register, disk partitions, processes, etc Jobs monitoring in Win2000&#43; to installation and update control Application use monitoring using noninvasive and invasive windows hooks Houaiss reverse engineering and Babylon importation (dictionaries) Build control with Cruise Control .NET, symbol server with Debugging Tools Projects documentation using Doxygen and Wiki (Trac) Management interfaces using C&#43;&#43; Builder 5/6 and Visual C&#43;&#43; custom libraries E-mails analyzer using regular expressions (ATL classes) Configuration interfaces using Visual C&#43;&#43; (MFC /ATL/WTL) Project and tracing analysis using regular expressions (Vim and Grep) Articles development using technical blog and Code Project community.  Perhaps I update this list frequently. Although I guess the rightest choice would be to update the list with articles about my every day &amp;quot;brushing bits&amp;quot; life . After all, I got a technical blog already!
</description>
</item>

     
        <item>
  <title>AdPlus no cliente, não você!</title>
  <link>http://www.caloni.com.br/adplus-no-cliente-nao-voce/</link>
  <pubDate>2009-08-10</pubDate>
  
  <guid>http://www.caloni.com.br/adplus-no-cliente-nao-voce/</guid>
  <description>O AdPlus é uma das poderosas ferramentas do pacote Debugging Tools for Windows. Se trata basicamente de um script que serve para realizar múltiplas fotografias no estado de um programa em execução usando para isso os depuradores do próprio pacote. Quando alguma coisa estiver errada, principalmente um crash ou travamento, ele paralisa a execução e gera um dump final com toda a história contada desde o começo.
Ele pode ser usado na situação mais comum: o programa trava/quebra em um cliente específico e/ou em um momento específico que pode acontecer em cinco segundos ou daqui a quinze horas. Como você não pode ficar monitorando o tempo todo a execução do programa (haja indexadores no PerfMon!) então você precisa de alguém que monitore por você. Como seres humanos costumam ter deficit de atenção muito facilmente você vai lá no cliente (ou pede para alguém ir) e executa o AdPlus, que dá conta do recado:
Esse notepad, viu! Sempre ele!
Bom, vamos fazer alguma brincadeira de desmontar para ver seu funcionamento. Com o notepad recém-aberto por esse comando, vamos abrir outro depurador em modo de visualização e alterar alguma chamada-chave para quebrar propositadamente:
Após isso só precisamos abrir um arquivo qualquer que não existe:
Depois desse lapso de memória o AdPlus irá gerar dois &amp;quot;dumpões&amp;quot; e um &amp;quot;dumpinho&amp;quot; para você:
O dumpinho é a exceção de first chance, que ele iria gerar de qualquer forma se houvesse uma exceção capturada pelo programa. É apenas um minidump.
Os outros dois dumpões são o momento da exceção second chance, o que quer dizer que é antes da casa cair, e o segundo é quando a casa já caiu e o processo pegou suas coisas e já tá indo embora.
A partir do second chance podemos visualizar a cagada feita pelo nosso WinDbg de passagem.
Se você não é desenvolvedor apenas empacote essa pasta com os dumps e envie para o culpado (ou quem você gostar menos).
Existem alguns outros parâmetros bem comuns e que podem ser muito úteis para outras situações:
  Quando o programa já está rodando e não pode ser parado senão tudo está perdido (adplus -crash -pn processo.exe).
  Quando o programa não vai capotar, mas vai travar/parar de responder (adplus -hang -sc processo.exe).
  Quando existem muitos outros processos com o mesmo nome (adplus -crash -p [PID]).
  Existem outros mais, mas apenas decorando esses e guardando a pasta do Debugging Tools no PenDrive já garante sucesso em 90% dos casos em que o cliente xingar o suporte.
</description>
</item>

     
        <item>
  <title>Cuidado com a cópia de arquivos na VMWare</title>
  <link>http://www.caloni.com.br/cuidado-com-a-copia-de-arquivos-na-vmware/</link>
  <pubDate>2009-07-27</pubDate>
  
  <guid>http://www.caloni.com.br/cuidado-com-a-copia-de-arquivos-na-vmware/</guid>
  <description>Quebrei a cabeça com uma DLL de hook que não estava funcionando para usuários comuns. No entanto, para qualquer administrador funcionava.
Isso acontece porque quando se arrasta uma DLL recém-compilada para a VMWare ela possui um mecanismo que primeiro cria esse arquivo no temporário do usuário atual e depois move esse arquivo para o lugar onde você de fato arrastou.
Como sabemos, a pasta temporária de um usuário fica em seu perfil, que possui direitos de uso apenas do usuário e dos administradores do sistema. Se eu copio um arquivo de uma pasta restrita para outra pasta os direitos do arquivo permanecem. Isso quer dizer que apenas o usuário atual e os administradores terão acesso ao arquivo, mesmo que se trate de um arquivo para uso de todos.
Resultado: arrastava a nova DLL de hook compilada da pasta de saída direto para a pasta de sistema da máquina virtual e esse caminho através do temporário era seguido, tornando a DLL inacessível para os usuários que eu estava testando.
Solução: após arrastar o arquivo, mude suas permissões. Ou copie-o através do bom e velho copiar/colar. Diferente do arrastar, o Ctrl&#43;C Ctrl&#43;V não gera arquivos temporários.
</description>
</item>

     
        <item>
  <title>Name mangling</title>
  <link>http://www.caloni.com.br/name-mangling/</link>
  <pubDate>2009-07-13</pubDate>
  
  <guid>http://www.caloni.com.br/name-mangling/</guid>
  <description>A sobrecarga estática possui algumas desvantagens em relação ao sistema de nomes da boa e velha linguagem C: ela não foi padronizada entre compiladores. O que isso quer dizer na prática é que funções exportadas de bibliotecas dinâmicas (DLLs) vão possuir nomes diferentes dependendo do compilador utilizado (e sua versão). Isso é o que chamamos name mangling.
Em dois projetos usando Visual C&#43;&#43; 2008 e Borland C&#43;&#43; Builder 5 (última versão que funciona direito) eu fiz uma exportação da função soma em linguagem C (o fonte é um .c). Veja o resultado:
Já usando a linguagem C&#43;&#43; (o fonte é um .cpp) temos outro resultado totalmente diferente para nossas duas funções soma descritas no artigo anterior:
Se quiser tentar entender essas letrinhas bizarras, recomendo baixar projetos de exemplo. Se apenas entender que você não conseguirá juntar classes VC&#43;&#43; e Builder usando dllexport.aspx) para tudo quanto é lado, então terminamos por aqui.
</description>
</item>

     
        <item>
  <title>Polimorfismo estático</title>
  <link>http://www.caloni.com.br/polimorfismo-estatico/</link>
  <pubDate>2009-07-10</pubDate>
  
  <guid>http://www.caloni.com.br/polimorfismo-estatico/</guid>
  <description>Para explicar polimorfismo, nada como ver as coisas como elas eram. Se você fosse um programador C de vinte anos atrás e criasse as seguintes funções:
Imediatamente o compilador iria acusar os seguintes erros:
Isso acontece porque em C os identificadores são únicos por escopo. Esse é o motivo por que o seguinte código também está errado:
De volta aos anos 90, isso também está errado em C&#43;&#43;. Até por uma questão de lógica: como o compilador pode saber a qual variável estamos nos referindo se usarmos o mesmo nome para duas delas?
Só que existe um truquezinho para impedir essa ambiguidade quando falamos de funções: os parâmetros que ela recebe.
Isso permitiu que em C&#43;&#43; fosse criada a sobrecarga estática, que é exatamente isso: chamar a função não apenas de acordo com seu nome, mas também de acordo com sua assinatura, ou seja, o número e o tipo dos parâmetros recebidos. Chamamos de sobrecarga estática porque isso é feito apenas pelo compilador, não pesando em nada durante a execução do programa.
Entre seus usos mais comuns estão os seguintes:
  Ter funções com o mesmo nome mas que tratam de diferentes parâmetros;
  Versões novas da mesma função que recebem parâmetros adicionais;
  Mesmo nome de método para setar e obter o valor de uma propriedade;
  Bom, o que mais sua imaginação mandar =)
  </description>
</item>

     
        <item>
  <title>Static Polymorphism</title>
  <link>http://www.caloni.com.br/static-polymorphism/</link>
  <pubDate>2009-07-10</pubDate>
  
  <guid>http://www.caloni.com.br/static-polymorphism/</guid>
  <description>To explain the polymorphism nothing is better than see how stuff used to be. If you were a twenty old C programmer in the past and created the following functions:
Immediately the compiler would blame you about the following errors:
This happens because in C the identifiers are unique into the scope. This is the reason why the following code is wrong also:
Back to the 90&#39;s, this is also wrong in C&#43;&#43;. Even for a logic issue: how the compiler can pick a variable if we&#39;re using the same name for both of them?
Even though, there&#39;s a little trick to stop the ambiguity when we talk about functions: the parameters that they receives.
This allowed in C&#43;&#43; the creation of static overload, that is exactly this: to call a function not just by its name, but also to match its signature, the number and the type of the received parameters. We call static because this is done just by the compiler, not creating any overhead during the execution.
Among the most common uses some are as it follows:
  Functions with the same name treating different parameters;
  New version of the same fuction with addictional parameters;
  Same method name to set and get the value of a class property;
  Well, whatever your imagination and needs demand =)
  </description>
</item>

     
        <item>
  <title>Strings</title>
  <link>http://www.caloni.com.br/strings/</link>
  <pubDate>2009-07-07</pubDate>
  
  <guid>http://www.caloni.com.br/strings/</guid>
  <description>Como já vimos centenas e centenas de vezes, memória é apenas memória até que alguém diga que isso vale alguma coisa. Em seu estado latente é o que chamamos formalmente de dados. E dados são bytes armazenados na memória.
No entanto, quando esses dados viram algo de útil em um determinado contexto, não necessariamente alterando-se seu conteúdo na memória, passamos a lidar com informação. Ou seja, é um dado com significado. E informação é a interpretação desses mesmos dados.
A conclusão óbvia para isso, falando de strings, é: uma série de bytes enfileirados na memória pode ser uma string.
Para tanto precisamos apenas de dados (os bytes enfileirados) e significado (uma tabela de símbolos que traduza esses bytes para caracteres e a definição de como a string se organiza).
Por exemplo, uma série de bytes diferentes de zero com valores que representam índices de uma tabela de tradução de caracteres e que termina sua sequência em um byte com o valor zero nele é considerada uma string C, ou string terminada em nulo.
Já uma mesma sequência de bytes no mesmo molde só que sem o byte final com o valor zero, mas com um byte inicial que tem como valor não um índice de caractere, mas o número de bytes subsequentes, isso é uma string Pascal, ou uma string com contador de tamanho.
Agora note por que tanto uma string vazia em Pascal e em C possuem os mesmos dados, mas informação diferente.
Outras strings que não necessariamente possuem terminador nulo: std::string, UNICODESTRING.aspx), strings no kernel.
</description>
</item>

     
        <item>
  <title>Bugs Difíceis de Achar</title>
  <link>http://www.caloni.com.br/bugs-dificeis-de-achar/</link>
  <pubDate>2009-06-18</pubDate>
  
  <guid>http://www.caloni.com.br/bugs-dificeis-de-achar/</guid>
  <description>Saiu um artigo na Wired News sobre os piores bugs da história. Entre eles estão a explosão de um oleoduto soviético em plena guerra-fria (como se não bastasse chernobyl), o primeiro worm da Internet (que se aproveita de um buffer overflow da função gets) e o famoso erro de divisão em ponto flutuante do Pentium; um erro de cálculo de cerca de 0,006% que causou um prejuízo de 457 milhões de dólares para a Intel.
Mas o que achei mais legal, apesar de não estar na lista, estava relacionado com o Mariner 1, primeira espaçonave de um programa da NASA para pesquisar Marte, Vênus e Mercúrio em voos automatizados. Mariner 1 não chegou a sair de órbita, pois houve uma falha na antena de comunicação entre módulos e um bug no programa do computador de bordo.
Falava-se que o bug havia sido gerado ao trocar uma vírgula por um ponto em um loop escrito em FORTRAN. Apesar de não ter sido esse o causador da falha do computador da nave do projeto Mariner, ele existiu de fato em outro projeto da NASA, o Mercury. A linha fatal no caso era essa:
É óbvio que a intenção do programador foi fazer um loop até o label 17 dez vezes, pois a instrução para isso é:
Mas pela troca da vírgula pelo ponto, e como em FORTRAN os caracteres de espaço não são significativos, a linha com o bug não representa mais um loop, mas uma atribuição à uma variável chamada &amp;quot;DO17I&amp;quot;:
Esse detalhe esdrúxulo de uma das linguagens mais famosas da época nos leva a crer que antigamente os programadores deveriam estar muito mais atentos durante a digitação de código do que os programadores de hoje em dia, com seus ambientes com verificação sintática embutida. Existe inclusive um texto humorístico de longa data comparando programadores de verdade e programadores de linguagens estruturadas como PASCAL recém-saídos da faculdade, carinhosamente citados no texto como &amp;quot;Quiche Eaters&amp;quot; (comedores de pastelão).
O tipo de erro de falta de atenção do programa da NASA lembra uma das mais duras críticas às linguagem C e C&#43;&#43;: é fácil escrever um código errado do ponto de vista lógico mas sintaticamente correto (compilável). Alguns exemplos famosos:
Dessa coleção de problemas, o compilador nos brinda com dois warnings:
Agora imagine o número de horas noturnas em frente ao micro que você não poderia ter economizado em sua vida se aumentasse o nível de warning e lêsse-os de vez em quando? =)
Colaborando com a lista de bugs difíceis de achar do artigo ai vai código/piadinha:
Esse não é pego pelos alertas dos compiladores (pelo menos não pelos que eu uso)... É um bom motivo para usar const no lugar de define em alguns casos, ou no mínimo cercar o define por parênteses &amp;quot;(&amp;quot; e &amp;quot;)&amp;quot;
Outro bug muito comum entre iniciantes é o de templates aninhados, apesar de que compiladores mais novos lidam melhor com o bug e trazem mensagens de erro mais claras:
</description>
</item>

     
        <item>
  <title>Programadores de verdade não usam Java</title>
  <link>http://www.caloni.com.br/programadores-de-verdade-nao-usam-java/</link>
  <pubDate>2009-06-18</pubDate>
  
  <guid>http://www.caloni.com.br/programadores-de-verdade-nao-usam-java/</guid>
  <description>Quando era um newbie (e um wanna-be) gostava de ler o &amp;quot;Real Programmers Don&#39;t Use Pascal&amp;quot;, um texto humorístico que mais me influenciou e encorajou a caminho da iluminação C/C&#43;&#43; do que o livro de K&amp;amp;R. A partir dele, supunha eu, ser um &amp;quot;programador de verdade&amp;quot; era ser tudo. Ser um Quiche Eater (Comedor de Torta) não era nada. Programadores de verdade é que resolvem os problemas de verdade! Quiche Eaters são os losers que estudam os conceitos acadêmicos da ciência da computação e nunca fazem um maldito programa que preste (conhece alguém assim?).
Piadas à parte, para mim o humor do texto ainda pode ser aproveitado por aqueles que já se acham muito bons e acreditam não terem mais como crescer profissionalmente. Quando meu ego infla demais, ainda me lembro que enquanto programo com APIs de brincadeirinha e um sistema operacional que é uma piada tem gente projetando uma nave que vai sair da órbita do Sistema Solar!
Por outro lado, muitas pessoas recém-saídas da faculdade de computação ainda acham programação uma matéria difícil. Esse texto nos lembra que difícil era a vida 20, 40, 70 anos atrás, quando engenheiros e programadores eram a mesma pessoa, e quando se você não soubesse o que estava fazendo colocaria projetos de milhões em risco.
Por consequência, o programador de verdade vive no passado. E ele sempre se valoriza frente ao povão jovem, porque ele sabe resolver aquele problema de tela azul que mais ninguém sabe. E como eu costumo dizer, parafraseando uma figura ilustre da televisão brasileira, quem tem medo de abrir o Visual Studio e em vez disso fica projetando eternamente o software não vai muito longe: &amp;quot;quem sabe faz na hora!&amp;quot;.
Aqui segue um breve resumo do texto original adaptado para os tempos atuais e com a minha visão preconceituosa de pensar sobre o assunto. Se quiser, use sua parte politicamente correta da mente e critique à vontade!
Linguagens. Lembre-se: inventar que você precisa de mais linguagens/recursos para fazer seu trabalho é lembrar que você é incompetente o suficiente para inventar esse tipo de desculpinha. Você é daqueles que diz &amp;quot;cada problema tem sua ferramenta específica&amp;quot; ou algo do tipo. Ou seja, um programador politicamente correto e ineficiente. Não vê que tudo o que você precisa está na linguagem C. Se não estiver, então está no assembly. Se não estiver nem no C nem no assembly não vale a pena ser pensado a respeito.
Programação Estruturada. É o primeiro e último paradigma a ser aplicado. Afinal de contas, Orientação a Objetos é mais uma desculpinha para não programar. São abstrações e mais abstrações para inventar que, uma vez que você é um peso morto que não consegue resolver um problema com funções e variáveis, precisa de classes, herança, templates e outras tranqueiras que vão transformar seu código simples e reto em uma cornucópia mágica que só vai impressionar os outros pela inutilidade e complexidade da solução!
Estrutura de dados. Outro ótimo conceito para enganar a si mesmo. Hoje são muitos os que se escravizam nos leiautes SQL e classes estranhas de frameworks estranhos que fazem todo o trabalho. Todos sabemos que a única estrutura realmente útil de saber é o array. O resto são variantes do mesmo tema: filas e pilhas.
Sistema operacional. Mac e Windows são brinquedinhos e Linux é um vídeo-game que dá mais trabalho de configurar do que de jogar. O programador de verdade usa algo como mainframes ou qualquer outro sistema operacional beta, que são bem esquisitos de mexer e que podem fazer um verdadeiro estrago nas mãos de quem não tiver lido TODO o manual. E saber todos os bugs conhecidos e importantes do kernel e sua localização de cor na hora de bootar é vital.
Ferramentas. Se você depende de uma IDE que tem Code Completion e outros penduricalhos do tipo, ou depende de algum outro editor seu favorito com seus 17459 plugins instalados, então você não é um programador de verdade. um programador de verdade usa o que tiver à mão na hora que precisar, seja um notepad, um hexdump ou até mesmo alguns beeps. A ferramenta não é limite para quem sabe programar de verdade.
Depuração. Vai dizer que precisa do código-fonte para depurar? Então você não faz a mínima ideia do que o programa faz. Apenas algumas olhadas na call stack e nos registradores podem fazer um programador de verdade solucionar um bug que os comedores de torta não conseguiriam depois de analisar aqueles gráficos UML com caixinhas dentro e casos de uso por meses a fio.
O Trabalho de programadores de verdade com certeza não é fazer programinhas que acessam basezinhas de SQL com opção de consulta e cadastro. Nem são aqueles saitezinhos com PHP/Apache, scripts e mais scripts. Não, senhor. São programas que lidam com o Sistema Operacional de uma forma mais íntima (criptografia de HD, drivers de File System, serviços de comunicação crítica, etc), ou são programas que fazem algo de verdadeiramente útil (compiladores, o próprio sistema operacional). Ou tavez que mexam diretamente com hardware (microcontroladores complexos, robôs, naves, aparelhagem médica, etc).
A Diversão de todo programador de verdade é conversar com os amigos (sobre programação), ler alguma coisa (sobre programação) e assistir filmes inteligentes (sobre programação ou pessoas que fizeram algum tipo de desafio intelectual &amp;quot;na marra&amp;quot;). Existe algo mais divertido que isso?
E, por fim, em seu Habitat Natural, poderemos encontrar páginas de código assembly espalhadas em volta da mesa, um computador travado por uma depuração remota de kernel por cabo serial, algumas anotações em hexa em um pedaço de papel, algumas dezenas de páginas abertas no navegador sobre comportamento das funções BIOS em HDs SATA com mais de 500 GB trabalhando em RAID4, café, salgadinhos, manchas no carpete. Quando não há nada para fazer, o ambiente está arrumadíssimo e não se nota a presença de programadores de verdade à vista.
E o Futuro do programador de verdade? Bom, a linguagem C pode até estar morrendo. Mas, e daí? Essa tal de C&#43;&#43; ainda suporta ponteiros. O resto das abstrações afeminadas como classes e herança podem ser totalmente ignoradas. O básico sempre existirá. Esqueça as versões com herança múltipla e o enigmático concepts. Seja homem!
O fato é que, independente de quanto mais o mundo se tornar &amp;quot;gerenciado&amp;quot; por trás de frameworks e programadores que preferem &amp;quot;fazer projetos&amp;quot; atrás de seus pacotes de escritório e casos de uso, quando algum problema pipocar, algum bug tenebroso ameaçar a vida útil de um projeto, um programador de verdade estará lá para salvar o dia, pois só um programador de verdade sabe fazer o seu trabalho. E bem feito.
PS: Na verdade, me lembrei. Eu peguei esse cacoete de falar &amp;quot;quem sabe faz na hora&amp;quot; do meu amigo Thiago. Ele também dizia &amp;quot;se vira nos 30!&amp;quot;. Bom, se eu citar todas as frases brilhantes que ele usava quando trabalhávamos juntos o texto vai ficar bem longo =)
Se você gostou desse texto, talvez goste de eXtreme Go Horse!
</description>
</item>

     
        <item>
  <title>Como compilar em somente um passo</title>
  <link>http://www.caloni.com.br/como-compilar-em-somente-um-passo/</link>
  <pubDate>2009-05-25</pubDate>
  
  <guid>http://www.caloni.com.br/como-compilar-em-somente-um-passo/</guid>
  <description>Uma das primeiras perguntas do teste do Joel é saber se você pode compilar todo o projeto em apenas um passo. Essa é uma questão essencial e um desafio para muitas equipes. Perdem-se horas sagradas para gerar um novo Release.
Compilação automática geralmente está disponível nas ferramentas de desenvolvimento. Se você estiver usando o Visual Studio, por exemplo, é possível fazer isso com uma linha:
Se não for exatamente o que você precisa, basta fazer uma pesquisa de quinze minutos e encontrar os parâmetros corretos. O objetivo é: eu rodo esse comando em cima do projeto inteiro em uma máquina zerada e ele simplesmente compila.
É lógico que ter apenas um solution/workspace para guardar projetos médios e grandes é inviável. Demora para carregar no ambiente e possuem dezenas de dependências. Isso já foi tentado duas vezes nas duas empresas em que trabalhei e não funcionou. Talvez por isso seja necessário criar um script que rode o comando acima para todas as soluções do projeto, o que não muda muito o modus operandi da coisa:
Note que meu script usa a estrutura padronizada dos diretórios de um projeto, onde cada tipo de componente tem sua pasta e solução.
Aos poucos você pode ir colocando &amp;quot;frescurinhas&amp;quot; em seu build (executa Debug e Release, roda automatizado no servidor, faz testes unitários, incrementa o número da versão, ...), mas algumas premissas sempre se mantêm:
  Deve ser possível compilar o projeto inteiro em um passo
  Deve ser possível usar qualquer máquina de desenvolvimento para isso
  Regras simples de ser seguidas se você usar sempre a máxima do KISS.
</description>
</item>

     
        <item>
  <title>Meu roteiro C&#43;&#43;</title>
  <link>http://www.caloni.com.br/meu-roteiro-c/</link>
  <pubDate>2009-05-20</pubDate>
  
  <guid>http://www.caloni.com.br/meu-roteiro-c/</guid>
  <description>Como não consigo mais ter ideias para artigos, resolvi catalogar todas as coisas que já falei nesse blogue e, o mais importante, todas as coisas que ainda não falei nesse blogue (e espero um dia falar ou talvez nunca fale), começando por C&#43;&#43;, que era o intuito original (só que não é mais, porque eu uso mais a Win32 API que a STL):
  História
  Conceitos
  Linguagem
  Biblioteca
  Dicas
  Espero que isso me ajude a continuar completando as lacunas do saite. Se não der certo, pelo menos já sei o que fiz.
Sugestões?
</description>
</item>

     
        <item>
  <title>A sala da fila das threads</title>
  <link>http://www.caloni.com.br/a-sala-da-fila-das-threads/</link>
  <pubDate>2009-04-17</pubDate>
  
  <guid>http://www.caloni.com.br/a-sala-da-fila-das-threads/</guid>
  <description>Quando falei sobre a fila das threads, e como cada thread espera pacientemente em uma fila até chegar sua vez de ser atendida no guichê das CPUs, também vimos como é fácil fazer caquinhas em um programa que roda paralelamente duas threads ou mais.
Também falei que iríamos resolver esse problema, afinal de contas, temos que salvar todos aqueles programas que usam dezenas de threads trabalhando ao mesmo tempo para contar números de um até dez.
A boa notícia é que o salvamento é mais simples do que parece: coloque todas as suas threads em uma sala trancada e deixe apenas uma chave. As threads terão que brigar para sair da sala e, depois que a vencedora sair, as outras terão que ficar esperando ela voltar.
Confuso? Se estiver, ainda bem. Isso quer dizer que estamos novamente em um daqueles artigos com &amp;quot;pseudo-parábolas&amp;quot;, a maneira mais ilustrada de explicar as coisas.
Os SOs modernos possuem inúmeras maneiras de controlar e monitorar o acesso a recursos do sistema. Neste breve artigo irei falar apenas de um: o critical section, ou, em tradução livre, &amp;quot;seção crítica&amp;quot;. O &amp;quot;seção&amp;quot; desse nome diz respeito a uma seção do programa, ou seja, um pedaço de código mesmo. Um pedaço de código crítico.
Resumidamente, um critical section é um recurso que apenas uma thread por vez pode obter. Para que outra thread tenha acesso ao mesmo critical section, a primeira thread que o obteve deve soltá-lo. Enquanto ela não solta, as outras threads ficam paradas, esperando pela chave, na sala trancada.
Do ponto de vista do programador, o critical secton é apenas uma estrutura que é usada na chamada de quatro funções básicas: para inicializar o recurso, para entrar na seção crítica.aspx), para sair da seção crítica.aspx) e para liberar o recurso.aspx) (quando aquele critical section não mais será usado).
Falando assim, parece simples. Bom, na verdade é simples, mesmo. Tudo que você precisa para corrigir o programa do artigo anterior é criar um critical section e fazer com que as threads obtenham-no antes de mexer com o contador compartilhado.
Para finalizar, algo para pensar: se uma thread só consegue um critical section depois que outra thread soltá-lo, o que acontece se essa outra thread estiver esperando por outro critical section que uma thread que aguarda estiver segurando?
Acabamos de ilustrar um procedimento muito simples para cagar completamente no código e gerar um travamento que pode demorar de horas a semanas para ser detectado e resolvido. É o conhecido deadlock. Se você não entendeu ainda, imagine que, para voltar à sala das threads, a primeira thread que saiu precisa de duas chaves; só que ela só pegou a primeira, e a segunda está dentro da sala. Para pegar a segunda chave, ela precisa entrar na sala, só que a sala está trancada pelas duas chaves!
Deadlocks são sempre indesejáveis, e é por isso que existem diversas técnicas para tentar evitá-los. A mais conhecida é sempre obter os critical sections na mesma ordem. Dessa forma a obtenção de recursos é hierarquizada, o que impede que dois CSs estejam no mesmo nível de obtenção, evitando que duas threads distintas os obtenham.
Espero que tenha ficado claro nossa breve explanação de como podemos controlar programas multithreading. Espero, pois a próxima tarefa é entender outros conceitos mais abstratos e virtuais, como funções virtuais e classes abstratas.
</description>
</item>

     
        <item>
  <title>A fila das threads</title>
  <link>http://www.caloni.com.br/a-fila-das-threads/</link>
  <pubDate>2009-04-07</pubDate>
  
  <guid>http://www.caloni.com.br/a-fila-das-threads/</guid>
  <description>Em um ambiente multithreading diversas threads disputam &amp;quot;a tapas&amp;quot; a atenção do processador (CPU). Certo? Podemos dizer que, em um ambiente com muito processamento a realizar, de certa forma é isso que acontece. São threads e mais threads rodando um pedacinho de código cada vez que passam pelo processador.
Um ambiente complexo como um sistema operacional executando dezenas (às vezes centenas) de programas é repleto de pequenos detalhes que podem fazer o iniciante logo desanimar quando tentar depurar um programa com mais de uma thread. De fato, eu já percebi que muitos não vão saber nem como começar a pensar sobre o problema.
Uma forma de visualizar o cenário multithread começa na fila das threads. Elas estão indo em direção ao guichê das CPUs onde vão conseguir tempo de processamento para rodar seu código. Depois que elas esgotam seu tempo elas se dirigem para o final da fila esperando por mais tempo para executar mais código.
Para simplificar este cenário vamos imaginar duas threads iniciando com o mesmo código. Esse código incrementa um contador global até ele chegar a dez, quando a função retorna e as threads terminam.
int count = 0;increment() {while( count &amp;lt; 10 ) {count&#43;&#43;;print(tid, count);}}main() {thread t1(increment);thread t2(increment);} O tid no pseudo-código acima é sinônimo para Thread ID, o identificador único de uma thread, que costuma ser um número. Para simplificar vamos dar ao id os apelidos de t1 e t2. Esta é uma possível saída do código acima, dependendo de quantos processadores e cores possui a máquina:
t1 1t1 2t1 3t1 4t1 5t1 6t1 7t1 8t1 9t1 10 Pelo jeito a primeira thread não deu chance para a outra executar. Isso acontece por causa do pequeno espaço de tempo que é necessário para realizar a tarefa de incrementar uma variável. É tão pequena a tarefa que nem foi suficiente para a primeira thread ficar sem tempo e a CPU mandar ela para o fim da fila. Por isso a segunda thread nunca chegou a incrementar o contador.
Quando uma thread quer realizar algum processamento, ela precisa entrar na fila das threads ativas, que aguardam pela CPU que irá atendê-las. Nessa fila ela pega uma senha e aguarda a sua vez. Só que cada vez que uma thread é atendida ela ganha um tempo limitado de atendimento, que na arquitetura do sistema operacional é chamado de quantum ou time slice. Se o quantum de uma thread estoura, ou a thread não tem mais nada pra fazer, ela sai do guichê de atendimento e volta a ficar inativa, ou volta para o final da fila, aguardando por mais processamento.
Uma thread pode opcionalmente ir para o final da fila por conta própria. Para isso, basta que ela chame uma função do sistema operacional pedindo para dormir. Por isso geralmente essa função é chamada de sleep na API do sistema operacional. Nessa função costuma haver um parâmetro de quanto tempo a thread deseja dormir. Se for maior que zero ela vai para a fila de threads dormindo até passar esse tempo, para depois se dirigir à fila de threads ativas, aguardar para ser processada. Se o tempo passado for exatamente zero ela vai direto para essa última fila, mas ficará sem executar do mesmo jeito, pois esta é a fila de quem está aguardando pela sua próxima fatia de tempo de processamento.
Se chamarmos a função para dormir no código da thread antes de voltar a incrementar o contador é possível que a segunda thread tenha chance de executar.
increment() {while( count &amp;lt; 10 ) {count&#43;&#43;;print(tid, count);sleep();}} Agora cada thread, depois de incrementar uma vez o contador, volta para o final da fila. Dessa forma vemos uma thread de cada vez incrementando o mesmo contador.
t1 1t2 2t1 2t2 3t1 4t2 4t2 6t2 7t1 5t1 8t2 8t2 9t2 10 Peraí, o mesmo contador? Isso pode gerar problemas. Se duas threads tentarem incrementar o mesmo contador ao mesmo tempo, quem garante que elas não irão incrementar o mesmo valor? Bom, se você é bom observador já deve ter reparado que na execução acima ocorreu exatamente isso, com mais de uma thread incrementando o contador com o mesmo valor.
Para forçar isso acontecer mais rápido e de maneira mais gritante podemos fazer a thread ir para o final da fila antes de incrementarmos e após pegarmos o valor atual do contador. Note que nesses testes a saída muda completamente dependendo de quantos processadores sua máquina tem. O resultado às vezes pode ser bem bizarro do que o visto nesse artigo. 1
increment() {while( count &amp;lt; 10 ) {int c = count;sleep();c&#43;&#43;;print(tid, c);count = c;}} O código acima pode gerar a seguinte saída:
t1 1t2 1t1 2t2 2t1 3t2 3t1 4t2 4t1 5t2 5t2 6t1 6t2 7t1 7t1 8t2 8t2 9t1 9t2 10t1 10 Explicando mais uma vez com mais detalhes: quando uma thread guarda o valor do contador na variável local e volta para o final da fila, ela deixa de armazenar o contador atualizado para apenas depois que todas as outras threads passarem na sua frente. Só que as outras threads também pegam o mesmo valor do contador, pois ele ainda não foi alterado. Quando chega a hora da segunda passada no guichê das CPUs, todas as threads incrementaram o mesmo valor do contador. Se houvesse apenas um processador em uma máquina o fluxo de execução do ponto de vista do processamento único para duas threads ficaria mais ou menos o seguinte (zzz é quando uma thread dorme):
t1 c = count (0)t1 zzzt2 c = count (0)t2 zzzt1 c&#43;&#43; (1)t2 c&#43;&#43; (1)t1 print c (1)t2 print c (1)t1 count = c (1)t2 count = c (1)t1 c = count (1)t1 zzzt2 c = count (1)t2 zzz... O exemplo acima forçou essa situação, mas é preciso lembrar que isso pode acontecer mesmo sem a thread dormir. É possível que o tempo da thread se esgote e ela pare de ser atendida justo na hora que iria salvar a variável c no contador global. Dessa forma, ela vai para o final da fila à força e, quando voltar a ser atendida, uma outra thread já terá lido o valor anterior para ela própria incrementar.
O que gostaríamos que acontecesse para corrigir o problema é forçar a segunda thread a esperar antes que a primeira termine todo o processo de incrementar e salvar no contador global, o que resolveria o nosso problema (o wait no exemplo abaixo é uma thread aguardando e não fazendo nada):
t1 c = count (0)t1 zzzt2 waitt1 c&#43;&#43; (1)t2 waitt1 print c (1)t2 waitt1 count = c (1)t2 waitt1 readyt2 c = count (1)t1 waitt2 c&#43;&#43; (2)t1 waitt2 print c (2)t1 waitt2 count = c (2)t2 readyt1 c = count (2)t2 wait... Esse wait do fluxo, ou seja, deixar a próxima thread aguardando a que chegou primeiro incrementar, pode ser obtido se utilizarmos um mecanismo de acesso exclusivo fornecido pelo sistema operacional. Uma outra história para contar, que chamarei de &amp;quot;A sala da fila das threads&amp;quot;.
  Eu mesmo em meus testes não pude usar sleep passando zero como o tempo para dormir porque meu número de processadores não permite que eu faça esse experimento, já que sempre vão existir processadores dispostos a reprocessar a thread que acabou de ir para o final de sua fila. &amp;#x21a9;&amp;#xfe0e;
   </description>
</item>

     
        <item>
  <title>Depurando até o último segundo</title>
  <link>http://www.caloni.com.br/depurando-ate-o-ultimo-segundo/</link>
  <pubDate>2009-03-31</pubDate>
  
  <guid>http://www.caloni.com.br/depurando-ate-o-ultimo-segundo/</guid>
  <description>Como depurar um programa que dá pau logo no final do desligamento de uma máquina?
No cenário em que isso se passa não existem usuários logados no momento, o que significa a impossibilidade de rodar qualquer programa em uma sessão prévia e mantê-lo no ar após o logoff. A não ser que se trate de um serviço.
O nosso programa é justamente um serviço, e por isso ele continua rodando até o final, ou bem perto dele. A primeira ideia que vem à mente é instalar o Msvcmon - depurador remoto do Visual Studio - como um serviço, como aliás já foi demonstrado neste blogue.
Essa é uma boa ideia, de fato. Contudo, não podemos esquecer que a ordem de descarregamento dos serviços pode não favorecer o nosso depurador remoto e ele ir embora antes que consigamos &amp;quot;atachar&amp;quot; nosso VC no programa faltoso. Além do mais, a própria rede, que é disponibilizada com a ajuda de serviços, pode não estar no ar, mesmo que o Msvcmon esteja.
Tudo bem, vamos dizer que você é um expert em configuração de dependências de serviços e conseguiu fazer com que a rede, o Msvcmon e o programa faltoso sejam os últimos serviços - com exceção dos drivers - a serem descarregados. Bravo!
Contudo, isso não vai adiantar de muita coisa se for necessário parar a execução por um breve momento e analisar a pilha por, digamos, cinco segundos. Esse é o tempo que o sistema - que continua rodando - precisa para desligar a máquina.
Agora o problema é outro: não há tempo para análise durante a depuração, pois o sistema continua rodando. Nesse caso, teremos que ser mais radicais e parar o próprio sistema para que possamos depurar calmamente o problema. Isso implica em termos que utilizar um depurador de kernel (WinDbg), pois só ele tem poderes de congelar o sistema inteiro.
Mas, ainda assim, precisamos de um depurador de user para fazer análises mais profundas ou, pelo menos, mais simples, com a ajuda de símbolos e tudo mais. Nesse caso é necessário usar um depurador de user que redireciona o controle para o depurador de kernel. A transição user mode &amp;gt;&amp;gt; kernel mode pode ser feita com apenas algumas configurações antes do reboot.
E, após toda essa bagunça, podemos depurar, no conforto de uma VM, o bendito programa matador.
</description>
</item>

     
        <item>
  <title>Os problemas mais cabeludos</title>
  <link>http://www.caloni.com.br/os-problemas-mais-cabeludos/</link>
  <pubDate>2009-03-05</pubDate>
  
  <guid>http://www.caloni.com.br/os-problemas-mais-cabeludos/</guid>
  <description>Quase todos os problemas do Universo são resolvidos depois de um belo dia de depuração, código comentado, descomentado, recomentado e umas muitas e boas doses de café. Alguns outros problemas mais cabeludos precisam de uma boa noitada na frente do computador, e mais café. E, finalmente, existem aqueles que nem tomando o estoque inteiro de café a coisa anda.
Um exemplo: um hook global do Windows que quando ativado em determinados eventos envia mensagens para uma única janela que cataloga informações sobre diversas janelas e processos no sistema. Esse procedimento é uma subfunção do programa principal, que já possui seus próprios problemas e idiossincrasias. Em momentos aparentemente aleatórios algumas funcionalidades não parecem estar de acordo com o que se espera.
Para esse tipo de situação que envolve 1. o sistema como um todo, 2. processos de terceiros e 3. comportamento obscuro por parte do resto do código, vale a pena seguir um checklist mais rigoroso, colocar seu bonezinho de CSI e partir para desmembrar o funcionamento do código problemático:
  Como o programa deveria funcionar?
  O que exatamente não funciona?
  O que pode ser? O que NÃO pode ser?
  Existe uma maneira de provar?
  Cada uma dessas perguntas deve ser respondida com a maior sinceridade e disciplina, custe o que custar.
Esse deve ser o primeiro e mais importante indício do que pode estar acontecendo. Sem entender o funcionamento do programa, dificilmente conseguiremos passar para os passos seguintes. Na maioria das vezes, sem saber onde a coisa começa e termina, o problema vai ficar rindo da nossa cara até entendermos de fato que aquele if não merece estar naquela linha.
Para facilitar esse entendimento, nada como elaborar uma pequena explicação para si mesmo no estilo How Stuff Works. Não precisa exagerar e fazer uma tese a respeito e criar vídeos explicativos. Só precisa descrever o fluxo com os detalhes aparentemente importantes para a resolução do problema.
Continuando nosso exemplo:
  O programa inicia e cria uma _thread _específica.
  Essa _thread _específica cria uma janela que monitora e carrega uma DLL.
  Essa DLL é chamada pela _thread _e instala um _hook _global no sistema.
  O _hook _recebe eventos de todos os processos que possuem janelas.
  Quando eventos específicos são disparados, o processo atual envia uma mensagem para a janela que monitora.
  A janela que monitora monta uma tabela estatística dos eventos.
  De tempos em tempos, essa tabela é escrita em disco em um arquivo encriptado.
  A lista acima é longa o suficiente para podermos elaborar perguntas interessantes e pequena o suficiente para podermos ter em mente o seu funcionamento como um todo, o que é vital para o sucesso das observações durante a depuração.
Note que a pergunta nos direciona para o sintoma do problema, não o problema em si, que provavelmente ainda não é conhecido. E nunca é demais lembrar que podemos estar lidando com uma série de problemas trabalhando em conjunto para nos deixar acordados por dias a fio.
Exemplos de respostas possíveis: a tabela estatística perde a lógica em determinado momento, o hook algumas vezes não funciona, aleatoriamente um dos processos &amp;quot;hookados&amp;quot; capota.
Essa pergunta deve ser respondida com uma análise das respostas das duas primeiras perguntas. Batendo os sintomas do problema com o seu funcionamento macro, uma ou mais cabeças aos poucos irão elaborando teorias a respeito de onde pode estar falhando.
Ex: talvez por algum motivo a DLL esteja sendo descarregada (que lugares podem ser estes?), alguém está desinstalando o hook (quais as partes do código que fazem isso?), alguma ferramenta de análise está atrapalhando nossos resultados (o que acontece se rodarmos sem o DebugView?).
Ao mesmo tempo que os sintomas do problema acusam que algo está errado, existem os sintomas de que alguma coisa, afinal de contas, está funcionando nessa porcaria de código. Através dos sintomas positivos é possível chegar a algumas conclusões sobre o que está funcionando bem.
Ex: o arquivo de log está sendo atualizado, a thread da janela que monitora recebe mensagens continuamente, algumas informações da tabela não estão corrompidas.
Esse é o pulo do gato, a parte que diferencia meninos e meninas de homens e mulheres. Se conseguirmos, através de código de teste e/ou observação, aos poucos provar nossas conclusões a respeito do problema e conseguir elaborar, passo a passo, uma &amp;quot;maquete mental&amp;quot; de todo o código funcional, será possível aos poucos ir descartando teorias e reforçando nossa confiança sobre o caminho que estamos trilhando.
Às vezes uma pequena mudança no código pode provar inúmeras coisas, como inocentar algumas partes e proteger-se de acusações infundadas feitas anteriormente. É uma briga contra o próprio ego, especialmente se o código foi feito por você mesmo.
Ex: Desabilitei o tratamento dos eventos e o hook continua funcionando.
O importante é nunca parar de pensar sobre o problema, evitando ao máximo agir mecanicamente e por impulso, a não ser que exista um bom motivo para isso. Às vezes apenas pensando de novo sobre o mesmo assunto comprova-se algo. É uma fase muito rica e próspera na resolução de problemas e deve ser aproveitada.
Ex: Quando estava habilitado o tratamento de eventos, o hook parava de funcionar em menos de cinco minutos. Agora, rodando os testes por três horas, o hook continua ativo.
Ex: Desabilitei um dos eventos que possui comunicação remota com o servidor. O hook continuou funcionando, apesar do resto dos eventos.
Por fim, com uma pequena dose de sorte e muitas doses de força de vontade (e café), o problema cansa de se esconder e mostra a cara.
Ex: Quando há falha na comunicação com o servidor com o erro 666 uma exceção é lançada, e quando capturada tenta gerar um logue, só que esse logue está mal formatado e causa com que a thread inteira vá para o espaço.
Essa é a hora em que todos se esquecem do esforço que custou chegar até ali e não documentam nada do que foi feito. Desse jeito perde-se todo esse tempo não apenas uma vez, mas todas as vezes que alguém diferente do time mexer com a mesma situação. Por isso deve-se, com a cuca fresca, escrever algumas dicas de como reproduzir o problema e elaborar um pequeno relatório ou algo que o valha do que foi feito, como foi feito e por que funcionou. Mais uma vez, não exagere. Deixe as apresentações sofisticadas de PowerPoint para os outros departamentos da empresa.
Como deve ter parecido, esse tipo de abordagem leva tempo e não é fácil de ser levado adiante sem disciplina e muita persistência. Por esse motivo é que só deve ser usado naqueles problemas em que já se perdeu uma imensidade de tempo e esperança, uma situação irremediável e que ainda não conseguiu vislumbrar o dia em que finalmente poderemos dedicar nossas vidas profissionais para uma outra tarefa mais interessante.
</description>
</item>

     
        <item>
  <title>WinDbg.info</title>
  <link>http://www.caloni.com.br/windbginfo/</link>
  <pubDate>2009-02-10</pubDate>
  
  <guid>http://www.caloni.com.br/windbginfo/</guid>
  <description>Para os perdidos e desatualizados como eu, notei hoje que Robert Kuster possui um saite onde mantém diversas informações sobre o WinDbg; uma espécie de continuação de sua famosa transparência &amp;quot;WinDbg. From A to Z&amp;quot;.
Como eu descobri? Bom, ele me mandou um e-mail perguntando se poderia deixar sua tradução para inglês do meu artigo como Foreword para os slides =)
</description>
</item>

     
        <item>
  <title>As funções-polegar</title>
  <link>http://www.caloni.com.br/as-funcoes-polegar/</link>
  <pubDate>2009-01-30</pubDate>
  
  <guid>http://www.caloni.com.br/as-funcoes-polegar/</guid>
  <description>Como já havia dito, não há nada mais prazeroso do que ensinar a alguém os velhos truques da profissão e relembrar o porquê de tantas coisas que guardamos na cabeça sobre programação. Hoje tive a oportunidade de explicar como funcionam as funções-polegar.
A função-polegar, uma categoria de função muito peculiar em várias APIs, possui um comportamento padrão de retorno de erros. Entre as diversas funções-polegar que conheço e uso, eis algumas que lembro de cor:
 read, write (C) connect.aspx), send.aspx) (Sockets) ReadFile.aspx), WriteFile.aspx), CreateProcess (Win32)  O que todas essas funções têm em comum? Bom, ignorando seu funcionamento interno ou seu objetivo, todas elas possuem um valor de retorno no estilo sim ou não, ou seja, deu certo ou não deu. Nessas funções o código de erro, o motivo da função não ter dado certo, não é retornado diretamente. É o que chamo de esquema do polegar pra cima ou polegar pra baixo. O retorno da função especifica o ângulo giratório do dedão:
 ssize_t pread, ssize_t write. Retorno de -1 significa que deu algo errado. int connect, int send. Se retornar SOCKET_ERROR BOOL ReadFile, BOOL WriteFile, BOOL CreateProcess. TRUE sucesso, FALSE erro.  Por exemplo, chamamos a função ReadFile para ler um arquivo. Ela retorna FALSE. Isso significa que não deu certo nossa leitura. Por quê? Ora, não sabemos ainda. Apenas sabemos que o polegar está virado para baixo!
Em funções nessas condições, geralmente existe uma segunda função (ou variável) que retorna o último erro que ocorreu na API, ou seja, o erro que fez com que última função chamada retornasse que algo não deu certo. Nas funções de exemplo, são usados três métodos distintos, pois estamos falando de três APIs distintas:
  Variável errno
  Função WSAGetLastError.aspx)
  Função GetLastError.aspx)
  São esses métodos que realmente retornam o porquê da função ter dado errado. E é elas que devemos chamar, eu disse devemos chamar, sempre que a função der errado. Até porque, já que o polegar está virado para baixo, temos que fazer alguma coisa para que nosso programa não morra.
Como bem observado pelo Fernando no comentário abaixo, nem todas as funções-polegar possuem uma função para obter a causa do erro. Vide SysAllocString, ou mesmo malloc. Nesse caso, não há muito o que determinar a não ser que não foi possível alocar o recurso pedido pelo sistema. Paciência.
</description>
</item>

     
        <item>
  <title>Básico do básico: assembly</title>
  <link>http://www.caloni.com.br/basico-do-basico-assembly/</link>
  <pubDate>2009-01-26</pubDate>
  
  <guid>http://www.caloni.com.br/basico-do-basico-assembly/</guid>
  <description>É lógico que não poderia faltar no cinto de utilidades de todo bom programador C conhecimentos básicos da linguagem assembly, sua mãe espiritual. São tantos conceitos em comum que, uma vez aprendido seu funcionamento, fica difícil não pensar no código-assembly gerado pelo compilador C. E é nesse ponto que as coisas começam a ficar mais claras.
Antes de tudo, é importantíssimo lembrar que o foco aqui é apenas a arquitetura 8086, um dos marcos na invenção de computadores de massa, mas que existem trocentros outros modelos de processadores e computadores funcionando mundo afora. Não deixe sua mente fechar para os outros tipos de modelos.
A CPU trabalha em conjunto com a memória RAM. Só que o acesso à essa memória, apesar de rápida, não é comparável à velocidade em que as coisas ocorrem dentro da própria CPU. Esse é apenas um dos motivos para a existência de um conjunto bem menor de memória que vive nas entranhas do processador, bem ao lado dele. São os chamados registradores.
Os registradores são memória do tipo ultra-rápida que funciona no mesmo ritmo do processador. A maioria das instruções executadas pela CPU faz referência a pelo menos um registrador. E por um motivo muito simples: é o modelo de entrada-e-saída funcionando!
No modelo de entrada-e-saída, ultrassimplificado por mim nesse artigo, o processador executa microinstruções muito básicas, que juntas fazem alguma coisa de útil, por exemplo, somar dois números:
x = y &#43; z;
A operação acima é realizada através de microinstruções bem sucintas:
 Leia memória y para registrador 1 Leia memória z para registrador 2 Some valor de registrador 1 e 2 e coloque resultado no registrador 1 Carregue memória x com valor do registrador 1  É lógico que o sistema não se baseia apenas em movimentações simples de memória. Existem algumas abstrações que estão incrustadas no funcionamento da arquitetura. Uma das mais importantes é o conceito de pilha, vital tanto em arquitetura, quanto assembly, quanto linguagem C e muitas outras linguagens, também.
Pilha é uma forma de armazenar memória em blocos empilhados um-a-um. Esses blocos são empilhados na ordem a, b, c e desempilhados na ordem c, b, a. Ou seja, quem foi empilhado por último será o primeiro a ser desempilhado. A analogia com uma pilha de pratos é óbvia e simples de imaginar.
Para isso funcionar em termos de memória computacional, o programa reserva um espaço de memória com começo e fim que irá guardar os blocos empilhados. Além de ter começo e fim é necessário ter um marcador de onde estamos para empilhar o próximo item ou desempilhar o último.
Se você pensou rápido, a resposta é sim, existem registradores para guardar a posição na pilha em que estamos. Aliás, quando mudamos de função, o valor desses registradores é salvo na própria pilha, já que voltaremos à mesma posição após a chamada.
Antigamente eram muito usados os chamados registradores de segmento. Eles representavam o endereçamento da arquitetura de 16 bits do 8086. Cada endereço de memória estava localizado em um segmento, que era uma abstração para multiplicar a memória e assim alcançar a quantidade de RAM que estava disponível no sistema. Com a chegada do 32 bits, isso não é mais usado diretamente pelos programadores, que não têm que se preocupar mais tanto com esses detalhes internos da memória.
Resumidamente, temos no PC os seguintes tipos de registradores e seu uso geral na programação C:
Registradores de uso geral. EAX, EBX, ECX, EDX. Registradores de código e dados. ESP, EBP, EIP.
Você os verá em 90% das ocasiões em que desassemblar seu código C, pois a rotina do código não muda muito: soma, divide, multiplica, muda endereço do código (saltos), compara valores (flags).
Ah, sim, as flags! Elas são importantíssimas para o funcionamento sadio de nossos programas. Sem as flags, não teríamos coisas maravilhosas e fundamentais na programação moderna, tais como o salto condicional.
As flags são bits que mudam de acordo com algumas instruções, principalmente as de comparação (vide cmp). Após a execução de comparação, o estado de determinadas flags junto da próxima instrução (que deverá ser um salto condicional) irá dizer para onde o programa irá pular sua execução. É assim que temos o if:
O código acima seria representado em assembly mais ou menos como abaixo:
 carrega valor de x no registrador 1 2. compara registrador 1 com 10 3. pula para 6 se for diferente 4. chama XEhIgualA105. pula para 76. chama XEhDiferenteDe107. próxima instrução  Uma curiosidade interessante é a flag de comparação. Se o resultado da comparação disser que os dois elementos são iguais, a flag fica igual a zero, o que significa que os comparandos são idênticos. Se você reparar, a mesma semântica é utilizada na conhecida função strcmp, que retorna zero caso duas strings sejam idênticas. Isso faz sentido em ambos os lados, já que o resultado computacional geralmente deixa um rastro de diferença que é usado como retorno. Se esse rastro não existir, quer dizer que o que foi comparado é idêntico.
  mov
  cmp
  jmp
  jne, jle, jnz, etc
  push e pop
  call e ret
  push ebp mov epb, esp
  push eax mov ecx, dword ptr[variavel] push 10 call funcao
  cmp something jne | jne | jae | ...
  Desmonte programas, chamadas API. Veja que funções internas elas chamam para realizar determinada tarefa. Tente mudar o comportamento do programa para provar que suas observações sobre o funcionamento estavam corretas.
PS.: Ia me esquecendo. Enquanto estava escrevendo este artigo, um conjunto bem mais detalhado de artigos estava sendo publicado pelo DQ. Recomendo veementemente sua leitura.
</description>
</item>

     
        <item>
  <title>HouaissParaBabylon versão 1.1</title>
  <link>http://www.caloni.com.br/houaissparababylon-versao-11/</link>
  <pubDate>2008-12-30</pubDate>
  
  <guid>http://www.caloni.com.br/houaissparababylon-versao-11/</guid>
  <description>Saindo mais um do forno.
Essa nova versão do conversor do dicionário Houaiss para Babylon corrige o problema de não encontrar o Houaiss 1.0. O problema ocorria porque o conversor se baseava na localização do desinstalador para encontrar o dicionário. Na primeira versão do dicionário o desinstalador fica na pasta c:\Windows, onde obviamente não estava o dicionário.
Nessa nova versão, além de procurar o caminho do dicionário no registro (desinstalador) e antes de pedir para o usuário o caminho correto é tentado o caminho padrão de instalação, %programfiles%\Houaiss. Se mesmo assim o dicionário não existir continuamos perguntando para o usuário, que tem a opção de dizer onde está instalado o dicionário no disco rígido ou apontar diretamente para o CD de instalação.
</description>
</item>

     
        <item>
  <title>Básico do básico: binário</title>
  <link>http://www.caloni.com.br/basico-do-basico-binario/</link>
  <pubDate>2008-12-18</pubDate>
  
  <guid>http://www.caloni.com.br/basico-do-basico-binario/</guid>
  <description>Apesar do tema binário, o assunto de hoje no fundo remete-nos a todo e qualquer tipo de representação. É o faz-de-conta um pouco mais intenso, vindo das profundezas da matemática e dominado com maestria pela nossa mente e sua capacidade lógica de abstrair.
Como todos sabemos, nós, seres humanos, somos dotados de dez dedos: cinco em cada mão. Isso influenciou fortemente nosso sistema de contagem de coisas, e, como consequência, nossa forma de representar números.
No entanto, números serão sempre números, independente de seres humanos e de dedos. Outros seres inteligentes de outras galáxias poderiam representar os mesmo números, sendo um conceito lógico independente de raça, usando qualquer outra forma e quantidade de símbolos. Por falar em símbolos, nós temos dez, a saber:
Outros seres poderiam usar, sei lá, dois:
É lógico que esse &#39;0&#39; e esse &#39;1&#39; podem ser representados por outros sinais, como pedra e pau, cara e coroa, tico e teco, e por aí vai a valsa.
O importante é que seriam na quantidade de dois.
O nosso sistema de representação ainda possui algumas características singulares, como o valor posicional. Os mesmos dez símbolos, quando colocados em posições diversas, assumem valores diversos.
Dessa forma, quando esgotamos todos os símbolos e chegamos a nove, para irmos ao dez começamos a repetir os símbolos, mas em outra posição:
A nova posição do símbolo &#39;1&#39; possui o próximo valor após o nove. O zero, como sabemos, apenas marca posições e não possui valor algum. Se valesse algo, seria somado, como no número 111, que é uma soma de três valores distintos posicionados de acordo:
Pronto! Eis toda a base de nosso sistema numérico. O resto é historinha pra boi dormir. Com isso é possível até mudarmos de base, ou seja, o número de símbolos usados, conforme nos convier.
Para nos comunicarmos com a raça alienígena que usa dois símbolos poderíamos contar seguindo o mesmo princípio:
O valor do número, como sabemos, depende de sua posição. Mas, calma lá! O 111 logo acima não é idêntico ao 111 que vimos anteriormente, pois mudamos a base! Agora só temos dois símbolos para representar números, quando antes tínhamos dez.
O &amp;quot;segredo&amp;quot; do valor posicional também está na base, pois o zero, apesar de não possuir valor, marca a quantidade de símbolos que foram utilizados para se esgotar uma posição qualquer. Dessa forma, enquanto o nosso conhecido 10 (dez) vale todos os símbolos não-nulos (nove) mais um (nove &#43; um = dez), o outro 10 (um-zero) da raça alienígena de dois dedos também vale todos os símbolos deles nã-nulos (um) mais um (um &#43; um = dois).
Como não faz parte do tema, não vou explicar como o sistema binário foi importante para a definição de uma arquitetura simples o suficiente para ser expandida a níveis nunca antes imaginados de processamento e comprimida em espaços que muitos diriam não caber qualquer coisa de útil que fosse. No entanto, apesar de brilhante, o binário no dia-a-dia do programador gera alguns problemas. Principalmente se o programador escreve seus cálculos de ponteiros em binário.
Para entender isso, basta lembrar que, atualmente, a quantidade de memória RAM que é contada e, portanto, valor dos ponteiros que apontam para ela, é muito grande até para nosso sistema decimal, que possui, relembrando, dez símbolos. O que dirá, então, um sistema que possui meros dois símbolos para representar, digamos, três gigabytes:
São tantos zeros que aqueles bugs de leak de memória, famosos por levar tempo para ser corrigidos, seriam mais famosos ainda, pois o tempo gasto para se entender alguma coisa no meio de ponteiros dessa magnitude seria astronômico!
E, claro, ainda poderia ficar pior, se fosse depurado um desses novíssimos sistemas de 64 bits:
Eu sei que não vou conseguir explicar tudo sobre bases numéricas em apenas um miniartigo. Porém, vamos dar uma rápida olhada no famoso hexadecimal, que foi o que nos salvou de lidar com os numerozinhos acima.
Nesse sistema, a representação dos número ocupa menos espaço ainda que o sistema decimal, pois usa dezesseis símbolos distintos, usando as letras de A a F após os já conhecidos símbolos decimais:
A grande vantagem de contar as coisas em dezesseis é que sua representação será sempre um múltiplo de dois, o que facilita a conversão para o sistema binário: em um único número hexadecimal cabem quatro números binários, ou quatro bits.
Tabelinha básica, fácil de achar em qualquer lugar da internet, mas colocada aqui apenas para relembrar a relação entre as três bases.
Bom, acho que é isso. Já ultrapassei o limite do teórico, porque na verdade o que importa aqui, para captar de fato o binário dos fatos, é praticar:
  Conte em binário quando não estiver fazendo nada. É simples e ajuda a fixar. Dessa forma: um, um-zero, um-um, um-zero-zero, um-um-zero, um-um-um, ...
  Decore a relação entre os números hexadecimal e binário. Você pode até esquecer isso depois, mas o esforço para decorar será útil para fixar. E nunca se sabe quando você terá que reaver a MBR de um cliente seu.
  Estude a lógica por trás da tabela ASCII e seus valores binários. Irá descobrir que existem relações muito óbvias entre letras, números (maíusculos e minúsculos) e sinais. Tente decorar.
  </description>
</item>

     
        <item>
  <title>Básico do básico: tipos</title>
  <link>http://www.caloni.com.br/basico-do-basico-tipos/</link>
  <pubDate>2008-12-12</pubDate>
  
  <guid>http://www.caloni.com.br/basico-do-basico-tipos/</guid>
  <description>Um tipo nada mais é que do que uma forma (ô) de bolo, que molda a memória como acharmos melhor moldá-la. Bom, para isso fazer sentido é necessário explicar memória, que é um conceito mais básico ainda.
A memória é qualquer lugar onde eu possa guardar alguma coisa. No artigo anterior era um punhado de gavetas. Mas poderiam muito bem ser caixas de presente. Ou um caderno. Ou até uma placa de memória RAM. O que sua criatividade quiser.
O importante no conceito de memória, computacionalmente falando, é saber que ela pode guardar qualquer tipo de informação, mas ela não sabe o que você está guardando. E eis que surge o segredo do tipo: ele conta para você, e seu programa, o que de fato está guardado na memória.
Vamos exemplificar.
Computadores trabalham muito bem com números. A própria memória só guarda valores numéricos. Porém, se é dessa forma, como conseguimos abrir o Bloco de Notas e digitar algum texto?
Para entender essa &amp;quot;mágica&amp;quot; é necessário vir à tona o conceito de representação, um tema que ainda pode dar muito pano pra manga quando estudarmos base numérica. Por enquanto, basta saber que uma representação é um faz-de-conta em que todos concordam com o que for dito. Por exemplo: Faz de conta que a letra &#39;A&#39; é o número 65. Dessa forma, sempre que for visto o número 65, de agora em diante, será vista a letra &#39;A&#39; no lugar.
Existem alguns faz-de-conta que são muito difundidos entre e humanidade informática. Um deles é chamado tabela ASCII (se pronuncia &amp;quot;ásqui&amp;quot;). É uma forma de todos conseguirem entender os textos de todo mundo. Abaixo podemos ver a representação de todas as letras maiúsculas na codificação ASCII:
Agora, imagine que você digitou o seguinte texto no bloco de notas:
Como esse texto é guardado na memória de um computador, se ele só entende números?
Através da nossa já conhecida tabela ASCII! Na verdade, números são armazenados na memória, mas por representarem as letras &#39;C&#39;, &#39;A&#39;, &#39;S&#39; e &#39;A&#39;, são traduzidos de volta para o formato texto pelo Bloco de Notas, que conhece o que guardou na memória.
A técnica de representação pode guardar qualquer coisa na memória como números que serão traduzidos por algum programa que consiga abrir aqueles dados. Dessa forma podemos não só armazenar texto, como imagens, vídeos, páginas web e até mesmo os próprios programas que os abrem!
Na programação do dia-a-dia, as coisas funcionam da mesma forma. As tão faladas variáveis reservam um espaço de memória para guardar alguma coisa, mas só sabemos o que essa alguma coisa é através do tipo da variável:
Esses elementos, na memória, são um bando de número que, sem os tipos, não possuem significado algum, como podemos ver na depuração do programa abaixo:
Note que os números não estão aqui representados em decimal, onde se esperaria 35 e 42, pois a representação formal da memória geralmente está no formato hexadecimal, transformando esses números em 0x23 e 0x2a, respectivamente. Para entender essa diferença cabe estudar um pouco sobre base numérica, outro tema básico do programador sólido.
Nada é bem aprendido se não for apreendido. Algumas tarefas programáticas que podem fixar o conceito de tipo estão listadas abaixo:
  Usar printf especificando tipos diversos (%d, %s, %f, %p, ...) para a mesma variável, inclusive correndo o risco de gerar algumas exceções.
  Usar scanf especificando diversas variáveis para o mesmo tipo (%d, %s, %f, %p, ...), vendo o resultado da leitura da entrada do usuário na memória.
  Tentar copiar o conteúdo de uma variável para outra variável de tipo diferente. Sempre analise a memória para ver o resultado.
  Ordenação de extremidades): O problema Little Endian e Big Endian.
  UNICODE: Por um conjunto de letras universal.
  Base numérica: O que são binário e hexadecimal e como eles afetam nossa vida.
  </description>
</item>

     
        <item>
  <title>Básico do básico: ponteiros</title>
  <link>http://www.caloni.com.br/basico-do-basico-ponteiros/</link>
  <pubDate>2008-12-06</pubDate>
  
  <guid>http://www.caloni.com.br/basico-do-basico-ponteiros/</guid>
  <description>Nessas últimas semanas tenho gastado meu tempo junto da mais nova pupila da SCUA, aspirante a programadora em C e Install Shield Script. Minha tarefa? Explicar tudo, desde o mais simples, como variáveis, até as coisas não tão triviais, como símbolos de depuração.
Posso afirmar que tem sido muito compensador ativar algumas partes do meu cérebro que acreditava nem mais existirem. Rever velhos conceitos, apesar de manjados, nos dá a oportunidade de lembrar que as coisas mais complexas que construímos no dia-a-dia se baseiam em um punhado de preceitos básicos que é essencial ter na cabeça. E nunca esquecê-los.
Meu amigo costuma chamar esses preceitos básicos de fundamentais. Isso por um bom motivo lógico e semântico: tudo que aprendemos de básico sobre qualquer área de conhecimento serve-nos de base para suportar as outras coisas que virão a ser entendidas na mesma área de conhecimento. Ou seja: é a parte mais importante a ser aprendida. Sem ela, a base, não nos é possível construir nada sólido e duradouro. Sem ela, toda a estrutura construída a posteriori se rompe e vai abaixo.
Foi partindo desse princípio que me preocupei com esmero para explicar as peças mais fundamentais do conhecimento em jogo, formadoras da cabeça de um programador para sempre, seja em C como em qualquer outra linguagem. E como nada é bem explicado sem formar imagens na cabeça, aproveitei para desenhar alguns esboços no papel. O resultado desses esboços é esse artigo.
Não tenho a presunção de conseguir explicar 100% para alguém iniciante o que são ponteiros em C, como usá-los e como se proteger deles. Definitivamente ponteiro não é um conceito simples, apesar de básico, e posso dizer sem vergonha que demorei cerca de seis meses no meu aprendizado em C pra entender completamente tudo relacionado com ponteiros. Demorou, quebrei a cabeça, mas depois nunca mais esqueci.
De acordo com o meu amigo Rafael, a melhor definição que usei até hoje para explicar esse conceito envolvia um armário repleto de gavetas, todas numeradas em ordem de posição (1, 2, 3...). Cada gaveta podia guardar qualquer coisa, inclusive o número de outra gaveta em um pedaço de papel. Com isso, eu poderia guardar em uma gaveta aleatória o que eu precisava guardar e escrever o &amp;quot;endereço&amp;quot; dessa gaveta em um pedaço de papel e guardá-lo na gaveta número 1, por exemplo. Com isso poderia até esquecer a posição onde está o que eu guardei, pois bastava abrir a gaveta número 1 e ler a posição em que estava essa gaveta.
Deve ter ficado óbvio, mas se não ficou: o armário é a memória RAM, as gavetas são váriáveis e as gavetas onde guardamos pedaços de papel são ponteiros, que não deixam de ser variáveis, e apontam para outras gavetas que são... adivinha? Outras variáveis!
Outros conceitos que costumo utilizar é relacionar a memória RAM com a memória do programa e contar a memória como se contam carneirinhos. Dessa forma fica fácil pelo menos entender dois conceitos fundamentais na arte dos ponteiros: memória e endereço.
O segundo passo, acredito eu, é entender como a memória é dimensionada através do programa, e como o tipo molda a representação dos bits e bytes através das ligações de silício, mas isso fica pra mais tarde. Temos que programar, e é isso que vai de fato fazer a diferença no aprendizado de uma linguagem como C. Nada como uma boa mistura de teoria e prática para gerar um concreto armado que irá suportar um Empire State de conhecimento.
Por isso, segue uma lista de tarefas interessantes para exercitar o conceito de ponteiros:
  Criar funções que modificam números passados como parâmetro.
  Criar funções que modificam texto passado como parâmetro.
  Alocar e desalocar memória dinamicamente.
  Tarefas mais específicas da minha área e que uso o tempo todo:
  Escrever e ler texto em arquivos.
  Escrever e ler no registro do Windows.
  Obter o endereço de uma função do Windows dinamicamente. E chamá-la.
  Este vídeo é o mais didático do universo sobre como funcionam ponteiros em C. Veja e mostre pros seus filhos:
https://www.youtube.com/embed/mnXkiAKbUPg
</description>
</item>

     
        <item>
  <title>HouaissParaBabylon versão beta</title>
  <link>http://www.caloni.com.br/houaissparababylon-versao-beta/</link>
  <pubDate>2008-11-15</pubDate>
  
  <guid>http://www.caloni.com.br/houaissparababylon-versao-beta/</guid>
  <description>Depois de muitos fins-de-semana divididos em horas picadinhas de programação de lazer, está disponível em vosso saite a primeira versão para usuários do conversor do dicionário Houaiss para o aplicativo Babylon.
Foi uma longa jornada, sim, mas espero que valha a pena para quem esperou. Também espero poder receber inúmeras respostas com dúvidas, sugestões e até mesmo mais problemas que vierem a acontecer.
Segue um pequeno roteiro do funcionamento do programa, que é bem simples, aliás. Para que tudo dê certo, no entanto, é necessário que o computador onde será feita a conversão possua os três programas abaixo instalados e funcionamento corretamente:
 Dicionário Houaiss. Testado na versão 2, deve ser instalado com opção de cópia dos arquivos no disco rígido. Babylon. Testado nas versões 6 e 7. Pode ser registrado ou não. Babylon Builder. O construtor dos dicionários Babylon. Apesar de ser possível construir dicionários personalizados para o Babylon, é necessário que se use esse aplicativo conversor. O HouaissParaBabylon o usa, e por isso precisa que ele esteja instalado corretamente.  Tudo isso verificado, basta então clicar no botão de Iniciar Conversão, sentar e esperar. A primeira fase envolve três passos:
 Desencriptação do dicionário original. Isso é feito baseando-se em nossa análise de engenharia reversa. Montagem do projeto de dicionário Babylon. Para isso existe um processo de interpretação do formato Houaiss, agora desencriptado, e sucessivas traduções para um projeto que o Babylon Builder irá entender. Construção do dicionário Babylon. Essa parte é feita pelo Babylon Builder. Por ser o maior dicionário de português da atualidade, esse processo pode demorar bastante, e com certeza irá se tornar o maior dicionário já instalado na sua lista de dicionários do Babylon.  Na segunda fase, após toda essa movimentação de HD, existe apenas uma coisa a fazer: instalar o dicionário no Babylon.
Quem faz isso é o próprio Babylon, se devidamente instalado. Se tudo deu certo, o HouaissParaBabylon sai de fininho e deixa o usuário com o progresso da instalação do dicionário Houaiss-Babylon.
Se não for encontrado o dicionário Houaiss devidamente instalado no disco rígido, será exibida uma mensagem de erro pedindo que a instalação seja feita dessa maneira. Se, contudo, não for possível localizar a instalação do dicionário, será pedido ao usuário que diga onde ela se encontra, ou aponte para a pasta &amp;quot;Houaiss&amp;quot; em seu CD de instalação, uma dica suficiente para que a operação seja bem-sucedida.
Outros erros comuns, como o Babylon Builder não instalado, serão obviamente avisados ao usuário. Erros mais raros terão um tratamento mais genérico. No entanto, nem por isso ele está livre de solução. Ao sair de uma conversão mal-sucedida, o usuário tem a opção de exportar o log de operações que foram realizadas durante a malfadada operação. Dessa forma, ele próprio conseguirá diagnosticar o problema ou, em casos mais sérios, me enviar o resultado de suas tentativas.
E é isso. Para uma versão inicial, talvez esteja razoável. Quem confirmará serão os ansiosos usuário que, espero sinceramente, consigam seus objetivos há tempos aguardados.
</description>
</item>

     
        <item>
  <title>Como funciona o PsExec</title>
  <link>http://www.caloni.com.br/como-funciona-o-psexec/</link>
  <pubDate>2008-10-29</pubDate>
  
  <guid>http://www.caloni.com.br/como-funciona-o-psexec/</guid>
  <description>Semana passada precisei reproduzir o comportamento da ferramenta PsExec em um projeto, o que me fez sentir alguma nostalgia dos tempos em que eu fazia engenharia reversa todo dia. Este breve relato (espero) reproduz os passos que segui para descobrir o que esse programa tão útil quanto perigoso faz.
Sabe-se que o PsExec consegue executar um programa remotamente, ou seja, de uma máquina para outra, outra essa que chamaremos de máquina-alvo. O programa a ser executado geralmente deve estar disponível na própria máquina-alvo (condição ideal). Além da simples execução, para aplicativos console ele permite ainda a interação como se estivéssemos executando o programa remoto em nossa própria máquina local. Ele consegue isso redirecionando sua entrada e saída, o que o torna, como nos descreve o próprio autor, um &amp;quot;telnet light&amp;quot;:
Além desse comportamento já muito útil ainda existe um bônus que se trata de especificar um executável local que será copiado remotamente para a máquina-alvo e executado. Esse é o comportamento que espero imitar:
No teste acima o myprogram.exe é somente o cmd.exe renomeado. Um teste básico =)
Já fizemos isso logo acima. Se trata apenas de observar o programa funcionando. Ao mesmo tempo em que entendemos seu modus operandi coletamos pistas sobre suas entranhas. No caso do PsExec, que faz coisas além-mar, como redirecionar os pipes de entrada/saída de um programa console, iremos checar a existência de algum serviço novo na máquina-alvo e arquivos novos que foram copiados, além de opcionalmente dar uma olhada no registro. Ferramentas da própria SysInternals como Process Explorer e Process Monitor também são úteis nessa análise inicial.
Como podemos ver, um serviço com o nome de PsExec foi criado na máquina-alvo. Se procurarmos saber o caminho do arquivo que corresponde a esse serviço, tanto pelo Process Explorer ou o Service Manager, descobriremos que se trata de um arquivo no diretório do windows chamado psexecsvc.exe.
Se o arquivo existe nessa pasta, então é óbvio que alguém o copiou. Resta saber como.
Nessa segunda fase, podemos refazer o comportamento esperado inúmeras vezes, coletando dados e pensando a partir dos dados obtidos. Para esse caso, como quase todos que analiso, vou usar o nosso amigo WinDbg. Para isso, como tenho sempre minhas ferramentas disponíveis no ambiente onde trabalho, basta digitar &amp;quot;windbg&amp;quot; antes do comando anterior e dar uma olhada em algumas APIs-chave, como a criação/abertura de arquivos e a criação de serviços. Note que é importante fazer isso em um escopo limitado para não perdermos horas de análise. Descobrir coisas como, por exemplo, que as ações do PsExec só começam a ser executadas após a digitação da senha do usuário, pode ajudar, pois daí só começo minha análise a partir desse ponto.
Uma rápida busca no Google nos informa que o pipe querendo ser aberto pertence à lista de pipes que estão sempre disponíveis nas máquinas para responder às requisições do sistema. São importantes para a comunicação entre processos (IRP, Inter Process Communication). No entanto, quem usa esse pipe é o sistema, e ele foi chamado, como pudemos ver, pela função WNetAddConnection2W.aspx).
Se analisarmos mais a fundo a pilha de chamadas conseguiremos dar um olhada nos parâmetros passados. Para isso existe a opção de mostrar os argumentos passados para as funções ao exibir a pilha:
Ele tenta abrir uma conexão com a máquina-alvo em seu compartilhamento de IPC, que como já vimos serve para comunicação entre processos, até entre máquinas distintas. Dessa forma, descobrimos um dos pontos importantes no funcionamento do PsExec: ele usa o nome e senha fornecidos para abrir uma comunicação remota no compartilhamento IPC$.
Depois sugem várias paradas ao CreateFile, de maneira que a melhor forma de acompanhar isso é colocando um &amp;quot;dumpezinho&amp;quot; de memória na sua parada:
Muito bem! Chegamos a mais um ponto importante de nossa análise: o psexecsvc.exe é copiado através do compartilhamento ADMIN$ remotamente (diretório c:\windows). Esse compartilhamento se torna acessível, uma vez que uma conexão autenticada já foi aberta. Se listarmos as conexões existentes, veremos o compartilhamento IPC$ aberto:
Também podemos notar que, enquanto estamos parados depurando o processo psexec.exe, temos acesso ao compartilhamento admin$:
A análise desses fatos demonstra como é importante fazer as coisas, pelo menos na fase &amp;quot;iniciante&amp;quot;, bem lentamente, e entender a mudança de estado durante o processo. Nem sempre isso é possível, é verdade, ainda mais quando estamos falando de análise de kernel. Mas, quando as condições permitem, vale a pena pensar antes de fazer.
Voltando à analise: temos direitos remotos nessa máquina. Dessa forma, fica fácil criar um serviço.aspx) remotamente, que é o que faz o nosso amigo PsExec:
Pronto. Isso era tudo que precisava para conseguir reproduzir seu comportamento. Agora posso fazer isso programando ou até manualmente:
O resto do comportamento, como o redirecionamento de entrada e saída e execução do processo na conta especificada, embora muito interessante, não me interessa de imediato. Quem sabe interesse a você, e não tenhamos uma continuação dessa análise em um outro blogue de &amp;quot;desmontagem&amp;quot; por aí =)
</description>
</item>

     
        <item>
  <title>Como usar WTL com o ATL do DDK</title>
  <link>http://www.caloni.com.br/como-usar-wtl-com-o-atl-do-ddk/</link>
  <pubDate>2008-10-15</pubDate>
  
  <guid>http://www.caloni.com.br/como-usar-wtl-com-o-atl-do-ddk/</guid>
  <description>No entanto, num belo dia, qual não foi minha surpresa ao notar umas pastinhas chamadas atl21, atl30 e atl71 dentro da distribuição do WDK (o finado DDK, renomeado sabe-se-lá-por-quê)? Pelo visto, tem alguém arrastando coisa errada pra onde não devia nos instaladores de Seattle. Esses estagiários!
O fato é que eles fizeram isso, e agora é possível ter o WTL mais novo compilado com o WDK. E nem é tão difícil assim.
A primeira coisa a fazer é obter o tal doWDK. Para variar um pouco, agora existe um processo de registro antes de obter acesso ao download, mais ou menos nos termos da Borland para baixar o Builder / Turbo / Developer Studio.
Aliás, para os que baixaram esses produtos gratuitos da Borland versão C&#43;&#43; e não funcionou em algumas máquinas, como foi o meu caso, está disponível para baixar uma versão mais nova; dessa vez não vi nenhum problema na compilação e depuração. Ainda.
Após instalado, em qualquer lugar da sua escolha, configure no seu Visual Studio Express o caminho de onde se encontra a pasta atl71 (ou a 30, ou a 21). Aproveite também para colocar a pasta do WTL e o diretório de LIBs:
Isso vai fazer com que pelo menos os exemplos que vêem com o WTL compilem.
No entanto, você verá o seguinte erro durante a compilação dos recursos:
Para resolver esse problema, remova a inclusão do arquivo de manifesto no arquivo RC:
Depois dessa alteração, deve ainda existir o seguinte erro de linquedição:
Esse problema ocorre porque as funções de alocação e desalocação de memória da ATL estão em outra LIB que os exemplos da WTL desconhecem. Para resolver, basta incluir essa nova dependência:
E pronto! Agora temos todo o poder das 500 milhões de classes da ATL aliadas à ilimitada flexibilidade das classes de janelas da WTL.
  Explicando a sopa de letrinhas da programação C/C&#43;&#43; para Windows: WTL
  WTL for MFC Programmers
  </description>
</item>

     
        <item>
  <title>Windows Jobs com Completion Port</title>
  <link>http://www.caloni.com.br/windows-jobs-com-completion-port/</link>
  <pubDate>2008-09-23</pubDate>
  
  <guid>http://www.caloni.com.br/windows-jobs-com-completion-port/</guid>
  <description>Ou &amp;quot;Como esperar o término de todos os processos-filho criados a partir de um conjunto de processos&amp;quot;.
Dessa vez confesso que esperava um pouco mais de documentação do MSDN, ou pelo menos um sistema de referências cruzadas eficiente. Outro dia demorei cerca de duas horas para conseguir criar um job.aspx), anexar o processo desejado e, a pior parte, esperar que todos os processos (o principal e seus filhos e netos) terminassem.
Além da pouca documentação.aspx), parece que não são muitas as pessoas que fazem isso e publicam na web, ou eu não sei procurar direito.
Mas, pra início de conversa, o que é um job mesmo?
Um job é um objeto &amp;quot;novo&amp;quot; no kernel do Windows 2000 em diante, e se prontifica a suprir a carência que havia anteriormente de controle sobre o que os processos podem fazer e por quanto tempo.
A abstração mais coerente que eu consigo tirar de um job é como um trabalho a ser executada por um ou mais processos. O objeto job controla a criação, o término e as exceções que ocorrem dentro dele mesmo.
Entre as funções mais úteis de um job estão limitar o tempo de execução do conjunto de processos, o número de handles/arquivos/outros objetos abertos, limite de memória RAM ocupada e a possibilidade de terminar todos os processos de uma só vez.
Para informações básicas de como criar um job e anexar processos recomendo o ótimo artigo de Jeffrey Richter.
No final desse artigo ele chega a citar o controle mais refinado dos processos através de uma completion port.aspx), que permitirá receber eventos que ocorrem dentro de um job durante sua vida útil. Apesar de citar, não há código de exemplo que faça isso.
Bom, agora há:
O exemplo acima cria um processo baseado em uma linha de comando e espera pelo término do processo criado e de todos os subprocessos criados a partir do primeiro processo. Note que mesmo que o primeiro processo termine, a Completion Port só receberá o evento que todos os processos acabaram depois que o último subprocesso terminar.
Dessa forma, ao compilarmos o código:
E rodarmos mais um prompt de comando através de nosso programa (o texto em azul significa nossa nova janela de prompt):
Microsoft Windows XP [versão 5.1.2600] (C) Copyright 1985-2001 Microsoft Corp. C:\Tests\CreateJob&amp;gt;notepad C:\Tests\CreateJob&amp;gt;exit
Mesmo ao fecharmos o prompt criado, o programa só será finalizado ao fecharmos o Bloco de Notas iniciado pelo segundo prompt.
Além desse evento, que era o que eu estava procurando, esse método permite obter outros eventos bem interessantes:
 JOB_OBJECT_MSG_NEW_PROCESS. Um novo processo foi criado dentro do job. JOB_OBJECT_MSG_EXIT_PROCESS. Um processo existente dentro do job foi terminado. JOB_OBJECT_MSG_PROCESS_MEMORY_LIMIT. O limite de memória de um processo já foi alcançado. JOB_OBJECT_MSG_END_OF_PROCESS_TIME. O limite de tempo de processamento de um processo já foi alcançado.  Enfim, jobs não terminam por aí. Dê mais uma olhada no MSDN e veja se encontra mais alguma utilidade interessante para o nosso amigo job. Eu encontrei e fiquei feliz.
</description>
</item>

     
        <item>
  <title>Reúna seus comandos mais usados no WinDbg com .cmdtree</title>
  <link>http://www.caloni.com.br/reuna-seus-comandos-mais-usados-no-windbg-com-cmdtree/</link>
  <pubDate>2008-09-19</pubDate>
  
  <guid>http://www.caloni.com.br/reuna-seus-comandos-mais-usados-no-windbg-com-cmdtree/</guid>
  <description>Tudo começou com o artigo de Roberto Farah sobre o comando &amp;quot;escondido&amp;quot; do WinDbg .cmdtree. Logo depois meus outros colegas do fã-clube do WinDbg Volker von Einem e Dmitry Vostokov comentaram sobre a imensa utilidade desse comando.
E não é pra menos. É de longe o melhor comando não-documentado do ano. Tão bom que sou obrigado a comentar em português sobre ele, apesar dos três artigos já citados.
E eu estava justamente falando sobre essa mania dos programadores sempre acharem soluções para tarefas repetitivas e monótonas que o computador possa fazer sozinho.O comando .cmdtree é uma dessas soluções, pois possibilita ao depurador profissional juntar em uma só guia o conjunto de comandos mais usados por ele no dia-a-dia, por mais bizarros e com mais parâmetros que eles sejam, já que é possível representá-los por um alias (apelido):
O resultado:
E podemos usar essa janela no nosso WinDbg, cada vez mais bonitinho e cada vez mais WYSIWYG:
Realmente não há segredos em seu uso. Esse artigo foi apenas um patrocínio do clube do WinDbg.
PS: Interessantemente o suficiente, durante minha navegação em busca das referências encontrei mais dois artigos de duas figurinhas carimbadas no mundo de debugging: John Robbins e a Tess. Pois é, se o mundo de informática já é pequeno, imagine o mundo de WinDbg =)
</description>
</item>

     
        <item>
  <title>Retorno do PathIsDirectory</title>
  <link>http://www.caloni.com.br/retorno-do-pathisdirectory/</link>
  <pubDate>2008-09-10</pubDate>
  
  <guid>http://www.caloni.com.br/retorno-do-pathisdirectory/</guid>
  <description>Estava eu outro dia programando aquele código esperto &amp;quot;para ontem&amp;quot; quando me deparei com uma situação no mínimo inusitada. Ao testar se um caminho recebido era de fato um diretório.aspx) me foi retornado pela API um valor diferente de TRUE. E diferente de FALSE!
De acordo com a documentação, o retorno deveria ser TRUE caso o caminho enviado à função fosse de fato um diretório. Caso contrário, o retorno deveria ser FALSE.
Note que existem apenas dois valores possíveis para essa função. Porém, o valor retornado não é 1, o equivalente ao define TRUE, mas sim 0x10 (16 em hexadecimal). O simples exemplo abaixo deve conseguir reproduzir a situação (Windows XP Service Pack 3):
Isso quer dizer apenas que o código abaixo vai funcionar,
o código abaixo vai funcionar
e o código abaixo não vai funcionar:
E, pior, o código abaixo também não vai funcionar!
Pesquisando um pouco descobri uma boa discussão sobre o tema, e inclusive que outras pessoas descobriram o interessante detalhe que para pastas normais o retorno é 0x10, mas para compartilhamentos o retorno é 0x1.
O problema ocorre por causa da maneira que a função determina se o caminho é um diretório ou não. Uma simples vistoria sobre a função nos revela o detalhe crucial:
Ou seja, para pastas locais a função simplesmente usa a conhecidíssima GetFileAttributes.aspx), que retorna o flag 0x10 setado caso se trate de uma pasta, de acordo com a documentação:
&amp;quot;The attributes can be one or more of the following values.
Aqui termina nossa dúvida sobre o pequenino bug na documentação. E isso nos lembra também que é sempre bom comparar as coisas da melhor maneira possível. E essa melhor maneira em se tratando de ifs é supor apenas dois valores binário: ou é zero ou é não-zero.
</description>
</item>

     
        <item>
  <title>ProcessLeaker</title>
  <link>http://www.caloni.com.br/processleaker/</link>
  <pubDate>2008-08-21</pubDate>
  
  <guid>http://www.caloni.com.br/processleaker/</guid>
  <description>O artigo anterior mostrava como detectar o leak de um processo gerado pela retenção e não-liberação de handles para o Windows Explorer. O problema fora causado por um serviço malcriado. No entanto, a título de demonstração, criei um pequeno programinha sem-vergonha para fazer as coisas parecerem difíceis. No entanto o programa é bem fácil:
Para usá-lo, basta abrir um Gerenciador de Tarefas com opção de exibir o PID dos processos.
A partir daí, é só criar e matar várias instâncias do explorer.exe. Antes de matar um, digite o PID do novo processo no ProcessLeaker.
Para listar os processos perdidos, basta usar o comando &amp;quot;!process 0 0&amp;quot; no WinDbg depurando em kernel. O resto você já sabe.
</description>
</item>

     
        <item>
  <title>Os processos-fantasma</title>
  <link>http://www.caloni.com.br/os-processos-fantasma/</link>
  <pubDate>2008-08-20</pubDate>
  
  <guid>http://www.caloni.com.br/os-processos-fantasma/</guid>
  <description>Estava eu outro belo dia tentando achar um problema em um driver que controla criação de processos quando, por acaso, listo os processos na máquina pelo depurador de kernel, após ter dado alguns logons e logoffs, quando me vem a seguinte lista de processos do Windows Explorer:
Analisando pelo Gerenciador de Tarefas, podemos detectar que o único processo de pé possui o PID (Process ID) do último elemento de nossa lista, curiosamente o único com um contador de handles diferente de zero.
Lembrando que 1940 em hexadecimal é 0x794, exatamente o valor deixado em destaque na lista acima, e reproduzido abaixo:
Sendo ele o único processo a rodar, a única explicação válida para as outras instâncias do explorer.exe estarem de pé seria o fato de haver algum outro processo (inclusive o sistema operacional) com um handle aberto para ele. Felizmente isso pode ser facilmente verificado pelo uso do comando !object do WinDbg, no caso abaixo com o primeiro explorer.exe da lista, utilizando-se a sua estrutura EPROCESS (em vermelho na lista acima).
Muito bem. Temos dois handles e dois ponteiros ainda abertos para o objeto processo-fantasma explorer.exe. O fato de haver um handle aberto indica que é muito provável que se trate de um outro processo rodando em user mode, já que normalmente as referências para objetos dentro do kernel são feitas com o uso de ponteiros.
Para descobrirmos quem detém esse handle, existe o comando !handle, que pode exibir informações sobre todos os handles de um determinado tipo no processo atual. Como queremos procurar por todos os handles do tipo Process em todos os processos existentes, é necessário usá-lo em conjunto com o comando mais esperto !foreachprocess, que pode fazer coisas incríveis para o programador de user/kernel:
Uma simples busca pelo EPROCESS do processo-fantasma nos retorna dois processos que o estão referenciando: um svchost.exe e um outro processo com um nome muito suspeito, provavelmente feito sob encomenda para a confecção desse artigo:
Se lembrarmos o ponteiro dos outros processos, podemos notar que ele está bloqueando todas as outras instâncias dos antigos explorer.exe, executados em outras sessões do usuário:
Esse ProcessLeaker se tratava de um serviço do mesmo produto que contém de fato um leak de recurso: em um dado momento ele abre um handle para o processo explorer.exe, só que por alguns motivos obscuros ele não é fechado nunca, gerando uma lista interminável de processos-fantasma. E é lógico que ele originalmente não chama ProcessLeaker.exe =)
Essa análise mostra duas coisas: que com um pouco de conhecimento e atitude é possível encontrar bugs em outras partes do programa, mesmo quando resolvendo outros problemas e que, nem sempre o problema está onde parece estar, que seria no nosso querido driver de controle de processos do começo da história.
</description>
</item>

     
        <item>
  <title>Quando o navegador não quer largar um arquivo</title>
  <link>http://www.caloni.com.br/quando-o-navegador-nao-quer-largar-um-arquivo/</link>
  <pubDate>2008-08-13</pubDate>
  
  <guid>http://www.caloni.com.br/quando-o-navegador-nao-quer-largar-um-arquivo/</guid>
  <description>De vez em quando gosto muito de um vídeo que estou assistindo. Gosto tanto que faço questão de guardar para assistir mais vezes depois. O problema é que o meu Firefox ou, para ser mais técnico, o plugin de vídeo que roda em cima do meu navegador, não permite isso. Ele simplesmente cria um arquivo temporário para exibir o vídeo e logo depois o apaga, utilizando uma técnica muito útil da função CreateFile, que bloqueia o acesso do arquivo temporário e apaga-o logo após o uso:
Muito bem. Isso quer dizer que é possível abrir um arquivo que mais ninguém pode abrir (nem para copiar para outro arquivo), e ao mesmo tempo garante que quando ele for fechado será apagado. Isso parece uma ótima proteção de cópia não-autorizada para a maioria das pessoas.
Infelizmente, tudo isso roda sob limites muito restritos: um navegador, rodando em user mode, usando APIs bem definidas e facilmente depuráveis.
Antes de iniciar a reprodução do vídeo, e conseqüentemente a criação do arquivo temporário, podemos atachar uma instância do nosso depurador do coração e colocar um breakpoint onde interessa:
Nesse momento podemos dar uma boa olhada nos parâmetros 4 e 6 da função para ver se trata-se realmente da proteção prevista (na verdade, prevista, nada; esse é um artigo baseado em uma experiência passada; vamos imaginar, contudo, que estamos descobrindo essas coisas como na primeira vez).
Como podemos ver, o modo de compartilhamento do arquivo é nenhum. Entre os flags definidos no sexto parâmetro, está o de apagar o arquivo ao fechar o handle, como pude constatar no header do SDK:
Nesse caso, a solução mais óbvia e simples foi deixar esse bit desabilitado, não importando se o modo de compartilhamento está desativado. Tudo que temos que fazer é assistir o vídeo mais uma vez e fechar a aba do navegador. O arquivo será fechado, o compartilhamento aberto, e o arquivo, não apagado.
E agora posso voltar a armazenar meus vídeos favoritos.
</description>
</item>

     
        <item>
  <title>Guia para iniciantes no DriverEntry</title>
  <link>http://www.caloni.com.br/guia-para-iniciantes-no-driverentry/</link>
  <pubDate>2008-08-11</pubDate>
  
  <guid>http://www.caloni.com.br/guia-para-iniciantes-no-driverentry/</guid>
  <description>A mensagem anterior deixou bem claro que tenho um roteiro de leituras bem hardcore a fazer nos próximos 20 anos. Pretendo, enquanto isso, programar alguma coisinha rodando em ring0, porque nem só de teoria vive o programador-escovador-de-bits. Pensando nisso, esse fim-de-semana comecei a me aventurar nos ótimos exemplos e explicações do DriverEntry.com.br, nossa referência kernel mode tupiniquim.
A exemplo do que Dmitry fez com os livros de drivers, acredito que a mesma coisa pode ser feita com os blogues. A maneira de esmiuçá-los vai depender, principalmente, da quantidade de material a ser estudado e das práticas necessárias para que o conhecimento entre na cabeça de uma vez por todas.
No momento, minha prática se resume a isso:
  Debug or not debug. Aqui resolvi dar uma olhada de perto nas macros e funções usadas para tracing no DDK, e descobri que, assim como a runtime do C, podemos ter mensagens formatadas no estilo do printf e vprintf, o que economiza uma porção de código repetitivo. Dessa forma pude usar minha estratégia de ter a macro LOG usada para mandar linhas de depuração na saída padrão. Ainda tenho que estudar, contudo, o uso da variável va_list em kernel.
  ExAllocatePool (WithoutTag). Precisei fazer alguns testes no Dependency Walker e anexar o fonte que faz a vez do GetProcAddress para drivers em meu miniprojeto do Bazaar para aprendizado de programação em kernel (linque para download no final do artigo).
  Getting Started. Esse foi o artigo mais interessante de todos, pois foi a base de todo o código que ando repetindo em meus exercícios. Além desse, é vital o uso do Visual Studio no processo de desenvolvimento, pois muitas (quase todas) das funções do DDK são alienígenas para mim, assim como os seus 497 parâmetros cada.
  Driver plus plus. Tive que perder algum tempo codificando uma segunda versão do Useless e baixando o framework da Hollis para testar as peculiaridades do C&#43;&#43; em kernel mode. Não que eu vá usar alguma coisa avançada nesse estágio, mas preciso conhecer algumas limitações e alguns macetes que farão uma grande diferença no futuro, quando as linhas de código ultrapassarem 10.000.
  Pulei alguns tópicos que pretendo explorar quando estiver mais à vontade com alguns conceitos básicos, como a explicação de como obter o processo dono de uma IRP, a explicação do que é uma IRP (apesar de eu ter baixado e brincado com o monitor da OSR) e a aparentemente simples explanação sobre como funcionam as listas ligadas do DDK. Tudo isso virá com o tempo, e algumas coisas estarão sempre martelando na cabeça. É só dar tempo ao tempo e codificar.
  Nós queremos exemplos. Esse foi o artigo que mais me deu trabalho, mas que mais valeu a pena. Codifiquei tudo do zero, olhando aos poucos no código do Fernando para pegar o jeito de usar funções com nomes enormes e auto-explicativas e parâmetros com os nomes a, b, c. Também dediquei um tempinho considerável com a aplicação de user mode, para (re)aprender a depurar dos dois lados da moeda.
  Próximos passos?
Pelo que eu vi, no geral, acredito que aos poucos irei voltar para os tópicos que pulei, além de olhar em outros artigos que chamaram minha atenção:
  Como criar um driver de boot
  Usando o DSF para interagir com dispositivos USB de mentirinha
  A continuação emocionante de nosso driver que recebe reads e writes
  Usar o que existe de bom e melhor para garantir a qualidade de um driver
  Mais alguns detalhes que começam a fazer sentido em nosso KernelEcho
  Criando e usando IOCTLs. Essa vai ser ótima!
  A necessidade inevitável de mexer com o registro do sistema
  Tudo isso aliado aos exemplos e à teoria latente do Windows 2000 Device Driver Book (minha primeira leitura) irá dar um upgrade forçado aos meus neurônios. Espero sobreviver para contar o final da história.
</description>
</item>

     
        <item>
  <title>Antidebugging during the process attach</title>
  <link>http://www.caloni.com.br/antidebugging-during-the-process-attach/</link>
  <pubDate>2008-08-05</pubDate>
  
  <guid>http://www.caloni.com.br/antidebugging-during-the-process-attach/</guid>
  <description>Today was a great day for reverse engineering and protection analysis. I&#39;ve found two great programs to to these things: a API call monitor and a COM call monitor. Besides that, in the first program site - from a enthusiastic of the good for all Win32 Assembly - I&#39;ve found the source code for one more antidebugging technique, what bring us back to our series of antidebugging techniques.
The purpose of this protection is to detect if some debugger tries to attach into our running process. The attach to process operation is pretty common in all known debugger, as WinDbg and Visual Studio. Different from the DebugPort protection, this solution avoids the attach action from the debuggee program. In this case the protection can make choices about what to do on the event of attach (terminate the process, send an e-mail, etc).
The code I&#39;ve found does nothing more than to make use of the attach process function that&#39;s always called: the ntdll!DbgUiRemoteBreakin. Being always called, we can just to put our code there, what is relatively easy to do:
To compile the code above, just call the compiler and linker normally. Obs.: We need the user32.lib in order to call MessageBox API:
After the program has been running, every try to attach will show a detection message and program termination.
Yes, I know. Sometimes we have to use &amp;quot;brute force codding&amp;quot; and make obscure codes, like this:
There are a lot of ways to do the same thing. The example above is what is normally called in the crackers community as a shellcode, what is a pretty name for &amp;quot;byte array that is really the assembly code that does interesting things&amp;quot;. Shellcode for short =).
Alternative ways to do this are:
  To declare a naked function in Visual Studio, to create an empty function just after, do some math to calculate the size of the function to be copied into another place (aware of Edit and Continue option).
  To create a structure whose members are masked opcodes. This way, is possible in the constructor to receive the values and use it as a &amp;quot;mobile function&amp;quot;.
  Both have pros and cons. The cons are related with the environment dependency. In the first alternative is necessary to configure the project to disable &amp;quot;Edit and Continue&amp;quot; option, whilst in the second one is necessary to align 1 byte the structure.
Anyway, given the implementation, the main advantage is to isolate the code in only two functions - AntiAttachAbort and InstallAntiAttach - an API local hook (in the same process) that should never be called in production code. Besides, there are C&#43;&#43; ways to do such thing like &amp;quot;live assembly&amp;quot;. But this is matter for other future and exciting articles.
</description>
</item>

     
        <item>
  <title>Antidebugging using the DebugPort</title>
  <link>http://www.caloni.com.br/antidebugging-using-the-debugport/</link>
  <pubDate>2008-08-01</pubDate>
  
  <guid>http://www.caloni.com.br/antidebugging-using-the-debugport/</guid>
  <description>When a debugger starts a process to be debugged or, the article case, connects to a already created process, the communication between these processes is made through an internal resource inside Windows called LPC (Local Procedure Call). The system creates a &amp;quot;magic&amp;quot; communication port for debugging and the debugging events pass throw it.
Among these events we can tell the most frequent:
  Activated breakpoints
  Thrown exceptions
  Threads creation/termination
  DLLs load/unload
  Process exit
  In the case of connecting into a existent process, the API DebugActiveProcess is called. Since this call, if successful, the caller program is free now to call the API DebugActiveProcess looking for debugging events. The main loop for a debugger is, so, pretty simple:
The interesting detail about this communication process is that a program can be debugged actively only for ONE debugger. In other words, while there&#39;s a process A debugging process B, no one besides A can debug and break B.Using this principle, we can imagine a debugging protection based on this exclusivity, creating a protector process that connects to the protected process and &amp;quot;debugs&amp;quot; it:
The needed steps to test the code above are:
  Compile the code
  Run notepad (or another victim)
  Get its PID (Process ID)
  Run the protector process passing the notepad PID as the argument
  Try to attach to the notepad using a debugger (e.g. Visual C&#43;&#43;)
  After the attach process, the debug port is occupied, and the communication between the debugger and debuggee is made throug LPC. Bellow we can see a little illustration of how things work:
Basically the process stay receiving debugging events (through the LPC message queue) until the final event, the process exit. Notice that if someone try to terminate the protector process the debuggee process will be terminated, too.
The strength in this protection is that it doesn&#39;t affect the code understanding and readability. In fact the code that protects is in another process. The weakness, I would say, it is your visibility. Everyone that will try to attack the solution will se two processes being created, what gives him/her something to think about...
That&#39;s why thinking about the implementation is vital. Particularly the main point to be thought is the debugger/debuggee union. As much as better these two pieces were packed, harder to the attacker will be to separate them. An additional idea is to use the same technique in the opposite way, in other words, the debuggee process to attach into the debugger.
This time I&#39;m not going to say that there&#39;s a easy solution. Maybe because I haven&#39;t though enough about the problem. Ideas?
</description>
</item>

     
        <item>
  <title>Antidebugging using exceptions (part two)</title>
  <link>http://www.caloni.com.br/antidebugging-using-exceptions-part-two/</link>
  <pubDate>2008-07-30</pubDate>
  
  <guid>http://www.caloni.com.br/antidebugging-using-exceptions-part-two/</guid>
  <description>In the first article we saw how it&#39;s possible to spoof the debugger through exceptions and let the attacker lose some considerable time trying to unbind the program from the fake breakpoints. However, we saw also that this is a difficult solution to keep in the source code, besides its main weakness to be easily bypassed if discovered. Now it&#39;s time to put things easier to support and at the same time to guarantee tough times even if the attacker discover what is going on.
The upgrade showed here still uses the exception throwing intrinsically, but now it doesn&#39;t depends on the code division in minifunctions and minicalls. Instead, we just need to get code traces and put them inside a miraculous macro that will do everything we want. This, of course, after some &amp;quot;hammer work&amp;quot; that will be explained here.
The solution above is explained in pseudocode to make things clearer. Notice that exist some kind of invisible return, not stack based. To handle it, however, we can use the good for all C ANSI standard, using the setjmp (step one) and longjmp (step 3). To understand the implementation for theses functions running on the 8086 platform we need to get the basic vision of the function calls in a stack based environment (the C and Pascal way).
Registers are reserved variables in the processor that can be used by the assembly code. Stack frame is the function calling hierarchy, the &amp;quot;who called who&amp;quot; in a given execution state. Call and ret are assembly instructions to call and return from a function, respectively. Both change the stack frame.
Imagine you have a function, CallFunc, and another function, Func, and one calls the other. In order to analyse just the function call, and just that, let&#39;s consider Func doesn&#39;t receive any argument and doesn&#39;t return any value. The C code, would be like bellow:
Simple, huh? Being simple, the generated assembly will be simple as well. In CallFunc it should have the function call, and inside Func the return from the call. The rest of the code is related with Debug version stuff.
From the assembly above we can conclude two things: 1. The stack grows down, since its value decremented four bytes (0012FD3C minus 0012FD38 equal four) and 2. The return value from the calling is the address of the very next instruction after the call instruction, in the case 00411FA3.
Well, in the same way we can follow this simple execution, the attacker will do as well. That&#39;s why in the middle of this call we will throw an exception and, in the return, we will not do the return in the conventional way, but using another technique that, instead using the ret instruction, sets manually the esp value (stack state) and jumps to the next instruction in CallFunc.
All this assembly stuff doesn&#39;t need to be written in assembly level. It was just a way I found to illustrate the differences between the stack return and the jump return. As it was said, to the luck and well being for all, this same technique can be implemented using ANSI C functions:
That was the new trick for the trowing of exceptions. The final code is clearer, now:
At first sight, it seems a waste the if being directly in the code (remember we gonna use the same conditional structure in several parts in the code). To turn things clearer, resume the protected call and allows the protection to be disabled in debug version code, let&#39;s create a macro:
Now we allow the antidebugging selection by call, what turns things much easier than to choose the protected points inside the code.
</description>
</item>

     
        <item>
  <title>Antidebugging using exceptions (part one)</title>
  <link>http://www.caloni.com.br/antidebugging-using-exceptions-part-one/</link>
  <pubDate>2008-07-28</pubDate>
  
  <guid>http://www.caloni.com.br/antidebugging-using-exceptions-part-one/</guid>
  <description>A debugger puts breakpoints to stop for a moment the debuggee execution. In order to do this it makes use of a well known instruction: int 3. This instruction throws an exception - the breakpoint exception - that is caught by the operating system and bypassed to the handling code for this exception. For debuggee processes this code is inside the debugger. For free processes this code normally doesn&#39;t exist and the application simply crashs.
The main idea in this protection is to take care these exceptions during the application execution. Doing this, we can make use of this fact and, in the handling code, run the protected code. The solution here looks like a script interpreter. It consists basically of two threads: The first one read an instructions sequence and tells the second thread to run it step to step. In order to do this the second thread uses a small functions set with well defined code blocks. Here&#39;s the example in pseudocode:
The protection isn&#39;t there yet. But it will as intrinsic part of the execution thread. All we need to do is to add a exception handling and to throw lots of int 3. The thrown exceptions are caught by a second function that runs the instruction before to returning:
The execution thread algorithm is the same. Just the point where each instruction is executed depends to the exception throw system. Note that this exception has to be thrown in order to the next instruction run. This is fundamental, since this way nobody can just rip of the int 3 code to avoid the exception. If one does that, so no instruction will be executed at all.
In practice, if one tries to debug such a program one will have to deal with tons of exceptions until find out what&#39;s happening. Of course, as in every software protection, is&#39;s not definitive; it has as a purpose to make hard the reverse engineering understanding. That&#39;s not going to stop those who are really good doing that stuff.
The price paid for this protection stays on the source code visibility and understanding, compromised by the use of this technique. The programming is state machine based, and the functions are limited to some kind of behavior standard. So much smaller the code blocks inside the minifunctions, so much hard the code understanding will be.
The example bellow receives input through a command prompt and maps the first word typed to the function that must be called. The rest of the typed line is passed as arguments to the functions. The interpreter thread reads the user input and writes into a global string variable, at the same time the executor thread waits the string to be completed to starts the action. It was used the variable pool to let the code simpler, but the ideal would be some kind of synchronise, just like events, by example.
The strength in this protection is to confound the attacker easily in the first steps (days, months...). Its weakness is the simplicity for the solution, since the attacker eventually realize what is going on. It is so easy that I will let it as an exercise for my readers.
In the next part we will se an alternative to make the code clearer and easy to use in the every day by a security software developer.
</description>
</item>

     
        <item>
  <title>Aprenda a usar sua API</title>
  <link>http://www.caloni.com.br/aprenda-a-usar-sua-api/</link>
  <pubDate>2008-07-22</pubDate>
  
  <guid>http://www.caloni.com.br/aprenda-a-usar-sua-api/</guid>
  <description>É conhecido que uma das desvantagens de se programar diretamente em Win32 API é a dificuldade de se entender os parâmetros e o retorno das funções. Concordo em parte. Constituída de boa documentação, parte da culpa dos programas mal-feitos reside na preguiça do programador em olhar a documentação por completo.
A Win32 API está longe de ser perfeita, mas pelo menos está razoavelmente documentada, e é na leitura atenta da documentação que iremos encontrar as respostas que precisamos para que o programa funcione.
Vejamos alguns exemplos.
O código abaixo parece bem razoável:
No entanto, está errado.
É fato que a maioria das funções que retornam handles retornam NULL para indicar o erro na tentativa de obter o recurso. Ao comparar o retorno com NULL, o programador geralmente faz uma chamada a GetLastError.aspx) para saber o que aconteceu. No entanto, uma das funções mais usadas, a CreateFile, não retorna NULL, mas INVALIDHANDLEVALUE.
Sendo assim, o código acima deveria ser:
Taí uma função que muitos erraram. Erraram tanto que eles fizeram uma nova versão menos complicada. Como está escrito no MSDN.aspx):
&amp;quot;The GetVersionEx function was developed because many existing applications err when examining the packed DWORD value returned by GetVersion, transposing the major and minor version numbers.&amp;quot;
O motivo de tantos erro pode ter sido o fato que o valor retornado é uma estrutura de bits dentro de um DWORD, coisa que nem todos programadores C sabem lidar muito bem, e o fato de ser uma função muito utilizada por todos (pegar a versão do sistema operacional).
Eis a tabela de campos do retorno de GetVersion:
Mesmo que não seja tão difícil, pode ser ambíguo. Por exemplo, como saber se o Windows é 95, 98 ou ME?
O código abaixo, muito usado por todos que suportam ainda o Windows mais velhinhos, verifica se estamos rodando em plataforma NT ou 9x.
Nem sempre o handle que obtemos é fechado com CloseHandle. As funções abaixo retornam handles que devem ser desalocados com as funções à direita:
Sempre tem. Algumas dicas úteis para o dia-a-dia de um programador Win32 API são:
  Leia a documentação
  Se atente aos valores de retorno em caso de sucesso e erro
  Leia sempre a seção remarks pelo menos uma vez; ela explica como desalocar recursos
  Releia a documentação
  Às vezes uma singela chamada de uma função de autenticação pode nos fazer preencher uma estrutura de 20 membros, sendo que seis deles são obtidos com mais sete chamadas de funções, todas com direito a desalocar recursos no final. O importante é sempre manter a calma, o espírito de aprendizado e aventura. Afinal, quem mandou não fazer software de telinha?
</description>
</item>

     
        <item>
  <title>O conhecido unresolved external</title>
  <link>http://www.caloni.com.br/o-conhecido-unresolved-external/</link>
  <pubDate>2008-07-18</pubDate>
  
  <guid>http://www.caloni.com.br/o-conhecido-unresolved-external/</guid>
  <description>O artigo anterior mostrou que nem sempre as coisas são simples de resolver, mas que sempre existe um caminho a seguir e que, eventualmente, todos os problemas se solucionarão.
Porém, resolver um problema por si só não basta: é preciso rapidez. E como conseguimos rapidez para resolver problemas? Um jeito que eu, meu cérebro e o Dmitry Vostokov conhecem é montando padrões.
Um padrão nos ajuda a não pensar novamente em coisas que sabemos a resposta, de tantas vezes que já fizemos. Só precisamos saber o caminho para resolver determinado problema.
Mesmo assim, existem diversos caminhos a percorrer. Até mesmo para um singelo e batidíssimo &amp;quot;unresolved external&amp;quot;.
O erro mais comum é usar uma LIB onde não está a função que estamos usando, ou usar uma versão diferente da mesma LIB que não contém a função, ou contém, mas com assinatura (parâmetros da função) diferentes. Isso pode ser verificado no código-fonte da LIB, se disponível, ou então pelo uso do dumpbin, como já vimos anteriormente.
Dica extra: às vezes você pensa que está usando uma LIB em um determinado caminho, mas o linker achou a LIB primeiro em outro lugar. Para se certificar que está verificando a mesma LIB que o linker achou, use o Process Monitor.
Às vezes, porém, não estamos usando a função diretamente e não conhecemos quem a usaria. Para isso que hoje em dia os compiladores mais espertos nos dizem em que parte do código foi referenciado a tal função:
É sábio primeiro inspecionar a função que referencia, para depois entender porque ela não foi encontrada. Mesmo parecendo diferente, essa operação faz parte do primeiro passo, que é identificar a origem.
Parece estúpido, mas às vezes é esse o caso. Essa é a segunda coisa a fazer porque não é tão comum quanto a primeira, visto que hoje em dia é rotina colocarmos as funções em um header e incluirmos esse cabeçalho em nosso código-fonte (em C&#43;&#43;, praticamente obrigatório). Se houvesse discrepância entre o nome da função chamada e o nome da função existente, provavelmente teríamos um erro de compilação (&amp;quot;função não encontrada&amp;quot;) antes do erro de linking.
Se a LIB não está cooperando, e der pouco trabalho, experimente incluir a função inteira (ou o cpp) dentro do seu projeto, para linkar diretamente. Se funcionar, então existe alguma diferença de compilação entre os dois projetos (o seu e o da LIB) para que haja uma divergência no nome procurado. Procure nas opções de projeto.
Sempre que nos deparamos com um problema que aos poucos vai consumindo o nosso tempo, tendemos a gastar mais tempo fazendo coisas inúteis que sabemos que não irá adiantar de nada. Às vezes fazer brute force pode dar certo. Outras vezes, seria melhor recomeçar a pesquisa e tentar entender de fato o que está acontecendo na compilação. Em outras palavras: gastar o seu tempo pensando pode ser mais produtivo do que agir instintivamente.
</description>
</item>

     
        <item>
  <title>O caso da função de Delay Load desaparecida</title>
  <link>http://www.caloni.com.br/o-caso-da-funcao-de-delay-load-desaparecida/</link>
  <pubDate>2008-07-16</pubDate>
  
  <guid>http://www.caloni.com.br/o-caso-da-funcao-de-delay-load-desaparecida/</guid>
  <description>Todos os projetos do Visual Studio 6 estavam compilando normalmente com a nova modificação do código-fonte, uma singela chamada a uma função.aspx) da DLL iphlpapi.dll. No entanto, ainda restava a compilação para Windows 95, um legado que não era permitido esquecer devido ao parque antigo de máquinas e sistemas operacionais de nossos clientes.
Ora, acontece que a função em questão não existe em Windows 95! O que fazer?
Essa é uma situação comum e controlada, que chega a ser quase um padrão de projeto: funções novas demais. A saída? Não chamar a função quando o sistema não for novo o suficiente. Isso pode ser resolvido facilmente com uma chamada a GetVersion.aspx).
Porém, um outro problema decorrente dessa situação é que a função chamada estaticamente cria um link de importação da DLL para o executável. Ou seja, uma dependência estática. Dependências estáticas necessitam ser resolvidas antes que o programa execute, e o carregador (loader) de programas do sistema é responsável por essa verificação.
Para verificar a existência de todas as DLLs e funções necessárias para nosso programa podemos utilizar o mundialmente conhecido Dependency Walker:
Se a função ou DLL não existe no sistema, o seguinte erro costuma ocorrer (isso depende da versão do Sistema Operacional):
Mas nem tudo está perdido!
Existe uma LIB no Visual Studio que serve para substituir a dependência estática de uma DLL pela verificação dinâmica da existência de suas funções quando, e se, for executada a função no programa.
Essa LIB contém algumas funções-chave que o Visual Studio utiliza ser for usado o seguinte parâmetro de compilação:
A função principal se chama &amp;quot;delayLoadHelper@8&amp;quot;, ou seja, é uma função com convenção de chamada WINAPI (stdcall) que recebe dois parâmetros.
Isso costuma sempre funcionar, sendo que tive uma grande surpresa com os seguintes erros de compilação na versão do programa que deve ser executada em Windows 95:
Isso, é claro, depois de ter checado e rechecado a existência da LIB de Delay Load na lista de LIBs a serem lincadas:
Acontece que eu conheço algumas ferramentas que podem sempre me ajudar em situações de compilação e linque: Process Monitor e dumpbin.
O Process Monitor pode ser usado para obter exatamente a localização da LIB que estamos tentando verificar:
Após localizar o local, podemos listar seus símbolos, mais precisamente a função &amp;quot;delayLoadHelper&amp;quot;:
A análise mostra que a função possui um &amp;quot;2&amp;quot; no final de seu nome, causando o erro de linque.
Essa função, pelo visto, tem mudado de nome desde o Visual C&#43;&#43; 6, o que fez com que LIBs mais novas não funcionassem com essa versão do Visual Studio.
Para sanar o problema, existem duas coisas que podem ser feitas:
  Usar a delayimp.lib antiga. Isso não exige nenhuma mudança no código.
  Criar uma função delayLoadHelper como wrapper. Isso exige a escrita de código. O código-fonte dessa função está disponível no diretório Include do Visual Studio, e pode ser adaptada para versões antigas.
  Nessa sessão de depuração você aprendeu como usar o Process Monitor para rastrear arquivos usados na compilação e como listar símbolos de LIBs que são usadas para lincar o programa.
</description>
</item>

     
        <item>
  <title>Segunda versão do Houaiss2Babylon</title>
  <link>http://www.caloni.com.br/segunda-versao-do-houaiss2babylon/</link>
  <pubDate>2008-07-14</pubDate>
  
  <guid>http://www.caloni.com.br/segunda-versao-do-houaiss2babylon/</guid>
  <description>Depois de vários comentários (na época que o saite tinha comentários) de pessoas tendo problemas em converter seus dicionários Houaiss para o formato Babylon, resolvi criar vergonha na cara e dar uma pequena melhora na versão beta do conversor.
Agora a maioria dos erros que houver será descrita por uma mensagem no seguinte formato:
O primeiro erro acima ocorre principalmente se não houver algum Houaiss instalado que o programa possa detectar. Resolva este problema fazendo uma busca no Buscapé.
Abaixo segue a função criada para exibir essas mensagens:
Se você notou, a função acima pode receber um número de argumentos variáveis para formatar a string da mensagem principal do erro, além de exibir seu código. Essa mágica pode ser feita usando-se o cabeçalho padrão &amp;quot;stdarg.h&amp;quot;. Através dele temos acesso ao tipo valist, que representa uma lista de argumentos variáveis.
Pela convenção de chamada da linguagem C (e C&#43;&#43;), quem desmonta a pilha é o chamador. Sendo assim, a função chamada não precisa conhecer o número de argumentos com que foi chamado.
A função de formatação de string é uma variante do conhecidíssimo printf, na versão que recebe um tipo valist. Muito útil para formatação de logs.
A versão beta do Houaiss2Babylon está para sair. Não estarei mais atualizando o saite do projeto no LaunchPad. Aguardem por mais novidades no próprio blogue.
</description>
</item>

     
        <item>
  <title>Primeiros passos no VMware Workstation</title>
  <link>http://www.caloni.com.br/primeiros-passos-no-vmware-workstation/</link>
  <pubDate>2008-07-10</pubDate>
  
  <guid>http://www.caloni.com.br/primeiros-passos-no-vmware-workstation/</guid>
  <description>Como uma ferramenta essencial que uso todos os dias da minha vida de programador, sou obrigado a falar neste blogue sobre a VMware, ferramenta que tem me salvado algumas centenas de horas de depuração, testes e alguns cabelos brancos (a mais).
Para os que não sabem, o VMware é um software de virtualização que permite rodar diversos sistemas operacionais secundários (chamados de convidados, ou guests) em cima do sistema operacional primário (chamado de hospedeiro, ou host). Para isso ele utiliza uma técnica muito interessante conhecida como virtualização, onde o desempenho da máquina virtual chega bem próximo da máquina nativa em que estamos rodando, ainda mais se instalados os apetrechos de otimização (vide VMware Tools) dentro dos sistemas operacionais convidados.
O VMware, diferente de alguns outros programas de virtualização, não é gratuito. No entanto, o tempo despendido pela equipe da VMware em tornar esta a solução a de melhor qualidade (opinião pessoal de quem já mexeu com Virtual PC e pouco de VirtualBox) está bem cotado, sendo que seu preço é acessível pelo desenvolvedor médio. Pior que o preço da VMware com certeza será o dos sistemas operacionais convidados, se estes forem da Microsoft, que obriga cada instância do Windows, seja hospedeiro ou convidado, a possuir uma licença separada. Se rodar um Windows XP como hospedeiro e um Vista e 2000 como convidados vai desembolsar pelo menos o quíntuplo da licença da VMware.
No entanto, não entremos em mais detalhes financeiros. Os detalhes técnicos são mais interessantes.
A instalação é simples e indolor, sendo constituída de cinco ou seis botões de next. O resto, e mais importante, é a instalação de um sistema operacional dentro de sua primeira máquina virtual. Outro assistente existe nessa fase para guiá-lo através de suas escolhas que irão configurar sua futura máquina.
Um pouco sobre redes
Use bridged networking. É criada uma conexão real através de uma ponte feita em cima de uma placa de rede da máquina real. É usado um IP diferente da máquina real e se comporta como uma outra máquina qualquer na rede.
Use NAT. As conexões são criadas usando o IP do sistema operacional hospedeiro. Para isto acontecer é usado o conhecido esquema de NAT, onde um único IP externo pode representar n IPs internos de uma rede (nesse caso, a rede virtual formada pelas máquinas virtuais de uma mesma máquina real).
Use host-only networking. O IP usado nessa conexão é diferente da máquina real, mas só é enxergada por ela e por outras VMs localizadas na mesma máquina hospedeira. Muito útil para isolar um teste de vírus, quando se precisa de uma rede mas não podemos usar a rede da empresa inteira.
Imagine uma VM (Virtual Machine) como uma máquina de verdade, onde podemos dar boot, formatar HDs (virtuais ou reais), colocar e remover dispositivos. Tendo isso em mente, fica simples entender o que funciona por dentro de sua console, ou seja, a tela onde vemos a saída da virtualização.
Um pouco sobre discos virtuais
Os HDs que criamos para nossas VMs são arquivos lógicos localizados em nosso HD real. A mágica em que o sistema operacional virtual acessa o disco virtual como se fosse de verdade é feita pela VMware, inclusive a doce ilusão que ele cotém 80 GB, enquanto seu arquivo-repositório ocupa meros 5 GB no disco. Nas edições novas do software, é possível mapear um HD virtual e exibi-lo na máquina real.
Se você dispõe do CD de instalação de um sistema operacional, por exemplo, Windows XP, basta inseri-lo no CD virtual de sua VM. Ela aceita também imagens ISO, se for o caso. Lembre-se apenas que ele terá que ser &amp;quot;bootável&amp;quot;, do contrário é necessário um disquete de boot.
Um pouco sobre BIOS
A sua VM emula todo o comportamento de uma máquina real. Ela, portanto, contém uma BIOS, feita pela VMware. Essa BIOS possui as mesmas opções interessantes de ordem de boot (primeiro o disquete, depois o HD, etc) e escolha de dispositivo de boot (tecla ESC).
A instalação do sistema operacional segue os mesmos passos que a instalação do sistema operacional de qualquer máquina de verdade.
As teclas mágicas
Entrar o foco na VM. Digite Ctrl &#43; G. Todos seus movimentos de teclado e mouse só irão funcionar dentro da máquina virtual, exceto o Ctrl &#43; Alt &#43; Del, exclusividade do sistema de autenticação do Windows.
Tirar o foco da VM. Digite Ctrl &#43; Alt. Todos seus movimentos de teclado e mouse passam a ser do SO hospedeiro.
Ctrl &#43; Alt &#43; Del dentro da VM. Use Ctrl &#43; Alt &#43; Insert. Ele terá o mesmo efeito que um CAD, independente em que tela estiver em sua VM.
Após feita a instalação, você terá um sistema operacional rodando dentro de um sistema operacional. Isso não é legal?
Snapshots
A primeira coisa a fazer em sua VM com SO recém-instalado é criar um snapshot, ou seja, salvar o estado atual de sua máquina virtual. Ao fazer isso, se fizer alguma coisa dentro da VM que possa se arrepender depois, basta voltar para o estado que salvou anteriormente. A VMware permite criar quantos snapshots precisar (basta ter espaço em disco). Ela permite que você crie novas máquinas virtuais a partir de um estado de uma VM já criada, o que pode economizar todo o tempo de montar do zero outra VM ou copiar o disco virtual.
  Abrir os seus e-mails suspeitos. Não tenha mais medo de sujar seu computador com e-mails de conteúdo duvidoso. Crie um estado seguro em sua VM através de um snapshot (fotografia de estado da máquina virtual) e execute os anexos mais absurdos. Depois basta voltar para o estado seguro.
  Testes que costumam alterar o estado da máquina. Driver, GINA ou serviço novo? Que tal usar uma VM para fazer os testes iniciais e parar de reformatar o Windows?
  As VMs possibilitam um mundo de utilidades que o mundo ainda está descobrindo. Para nós, desenvolvedores, a maior vantagem de tudo isso é termos nossos ambientes de testes mais bizarros facilmente configurados no conforto de uma caixinha de areia.
</description>
</item>

     
        <item>
  <title>Projeto-modelo</title>
  <link>http://www.caloni.com.br/projeto-modelo/</link>
  <pubDate>2008-07-08</pubDate>
  
  <guid>http://www.caloni.com.br/projeto-modelo/</guid>
  <description>É muito difícil construir um modelo de pastas que sirva para a maioria dos projetos que tivermos que colocar na fôrma. Ainda mais se esses projetos tiverem que futuramente fazer parte da mesma ramificação. Foi pensando em várias coisas que chegamos a uma versão beta que pode ajudar aqueles que ficam pensando durantes dias antes mesmo de colocar as mãos no código.
Antes de começar a pensar em como as pastas estarão alinhadas, é importante saber como funcionará o controle de código do seu projeto. Como eu disse sobre o Bazaar, a estrutura inicial permitirá a junção de dois projetos distintos se estes compartilharem do mesmo commit no começo de suas vidas.
Portanto, trate de iniciar a estruturação em um projeto-modelo que já contenha pelo menos um commit: o das pastas vazias já estruturadas.
Build. Essa pasta contém tudo que é necessário para compilar e testar o projeto como um todo. Idealmente a execução da batch build.bat deve executar todo o processo. Após a compilação, é de competência dos componentes na subpasta Tests fazer os testes básicos do projeto para se certificar de que tudo está funcionando como deveria.
Common. Aqui devem ser colocados aqueles includes que servem para vários pontos do projeto. Está exemplificado pelo arquivo de versão (Version.h), pois todos os arquivos devem referenciar uma única versão do produto. Podem existir Outras definições básicas, como nome do produto, dos arquivos, etc. É aqui que são gravadas as interfaces que permitem dependência circular entre os componentes (e.g. Interface de componentes COM).
Docs. Aqui deve ser colocada toda a documentação que diz respeito ao projeto. A organização interna ainda não foi definida, pois imagina-se ser possível usar diversas fontes, como doxygen, casos de uso, bugs, arquivos de projeto e UML. Foi exemplificado com o arquivo todo.txt e changes.txt, que deve ter sempre a lista de coisas a fazer e a lista de coisas já feitas, respectivamente, tendo, portanto, que ser sempre atualizados.
Drivers. Essa é a parte onde ficam todos os componentes que rodam em kernel mode. Por se tratar de um domínio específico e muitas vezes compartilhar código-fonte de maneira não-heterodoxa (e.g. sem uso de LIBs), faz sentido existir uma pasta que agrupe esses elementos. Dentro da pasta existem subpastas para cada driver, exemplificados em Driver1 e Driver2.
Install. Todas as coisas relacionadas com instalação, desinstalação e atualização do software deve vir nessa pasta. Foi reservada uma subpasta para cada item, não sendo obrigatória sua divisão. Também existe uma pasta de DLLs, onde possivelmente existam telas personalizadas e biblioteca de uso comum pelos instaladores (o desinstalador conversa com o instalador e assim por diante).
Interface. Todas as telas de um programa devem ser colocadas nessa pasta. Essa é uma divisão que deve ser seguida conceitualmente. Por exemplo, se existir um gerenciador de alguma coisa no produto, as telas do gerenciador e o comportamento da interface ficam nessa pasta, mas o comportamento intrínseco do sistema (regras de negócio) devem ficar em Libraries. Para exemplificar o uso, foram criadas as Interface1 e Interface2.
Libraries. O ponto central do projeto, deve conter o código mais importante. Imagine a pasta Libraries como a inteligência de um projeto, de onde todos os outros componentes se utilizam para que a lógica do software seja sempre a mesma. As outras partes do projeto lidam com aspectos técnicos, enquanto o Libraries contém as regras abstratas de funcionamento. Opcionalmente ela pode ser estática ou dinâmica, caso onde foi criada a subpasta DLLs. Porém, elas devem ser divididas por função em bibliotecas estáticas, como foi exemplificado em Library1 e Library2.
Resources. A origem de todas as imagens, sons, cursores, etc de um projeto devem residir primeiramente na pasta Resources. A divisão interna desse item fica a critério do designer responsável, pois ele pode dividir tanto por função (Install, Interface) quanto por elementos (Images, Sounds).
Services. Além dos drivers e das interfaces alguns projetos necessitam de processos &amp;quot;invisíveis&amp;quot; que devem fazer algo no sistema. Isso inclui serviços do Windows, GINAs, componentes COM e coisas do gênero. Devem ser colocados nessa pasta e distribuídos como no exemplo, em Service1 e Service2.
Tools. Além dos componentes essenciais para o funcionamento do software também existem aqueles componentes que fornecem mais poder ao usuário, ao pessoal do suporte ou ao próprio time de desenvolvimento. Essas são as ferramentas de suporte que permitem a fácil identificação de erros no programa ou a configuração mais avançada de um item que a Interface não cobre. Adicionalmente foi colocada a subpasta Develop, que deve conter ferramentas usadas estritamente durante a fase de desenvolvimento.
Todos os componentes que disponibilizarem unidades de testes devem conter uma pasta Tests dentro de si. Essa padronização permite facilmente a localização de testes internos aos componentes. Além disso, os arquivos executáveis de testes devem sempre terminar seu nome com Test, o que permite a automatização do processo de teste durante o build.
Acredito que este esboço esteja muito bom. É o modelo inicial que estou utilizando nos projetos da empresa e de casa.
</description>
</item>

     
        <item>
  <title>VirtualBox</title>
  <link>http://www.caloni.com.br/virtualbox/</link>
  <pubDate>2008-07-04</pubDate>
  
  <guid>http://www.caloni.com.br/virtualbox/</guid>
  <description>O VirtualBox parece ser o concorrente mais próximo atualmente da VMWare. Descobrimos ele essa semana e resolvemos fazer alguns testes. O resultado foi bem animador.
Desenvolvido pela Sun Microsystems, as características do VirtualBox impressionam pelo cuidado que houve em torná-lo muito parecido com sua concorrente paga. Apenas para começar, ela suporta dispositivos USB, possui múltiplos snapshots e já suporta o modo do VMWare Fusion - chamado de &amp;quot;seamless mode&amp;quot; - , que estará integrado na versão 7 da VMWare.
No entanto, entre as coisas que testamos (instalado em um Windows Vista SP1 como host), o que não funcionou já não agradou tanto. A lista de prós e contras ainda confirma a liderança da VMWare, pelo menos em qualidade:
Além da tabela de testes acima, é necessário notar que por mas três vezes a VM simplesmente parou de responder, sendo necessário reiniciar o programa Host.
Em suma, o VirtualBox tem tudo para arrasar em futuras versões. Se, é claro, conseguir competir em qualidade com a VMWare que, no momento, é a líder em soluções de virtualização. Talvez por isso sua solução não seja tão barata.
</description>
</item>

     
        <item>
  <title>Pesquisas sobre a GINA</title>
  <link>http://www.caloni.com.br/pesquisas-sobre-a-gina/</link>
  <pubDate>2008-07-02</pubDate>
  
  <guid>http://www.caloni.com.br/pesquisas-sobre-a-gina/</guid>
  <description>Já sabemos o que é uma GINA. Afinal, todo mundo já viu uma antes. E sabemos que hoje em dia ela está morta.
No entanto, algumas pequenas mudanças foram feitas nela no Windows XP que ainda almaldiçoam o código de quem tenta reproduzir a famosa GINA da Microsoft. Nem todos chegam no final e morrem tentando.
Eu sou um deles.
Uma explicação sobre como funciona o processo de logon (local e remoto) e os componentes envolvidos está no artigo &amp;quot;How Interactive Logon Works&amp;quot; da Technet. Esse artigo irá abrir os olhos para mais detalhes que você gostaria de saber sobre nossa velha e querida amiga. Os desenhos explicativos estão ótimos!
Após essa leitura picante, podemos voltar ao feijão com arroz e começar de novo lendo a descrição de como funciona a GINA na Wikipedia, que nos remete a vários linques interessantes, entre os quais:
  A explicação documentada do MSDN de como funciona a interação entre Winlogon e GINA.
  Um ótimo artigo dividido em duas partes que explica como fazer sua própria customização de GINA. Foi nele que encontrei o retorno que precisava para emular a execução do Gerenciador de Tarefas baseado na digitação do Ctrl &#43; Alt &#43; Del. De brinde ainda vem uma GINA de exemplo para download.
  A partir de mais algumas buscas e execuções do Process Monitor podemos encontrar os valores no registro que habilitam o Fast User Switching e a Tela de Boas Vindas do Windows XP. O valor da Tela de Boas Vindas é que habilita e desabilita a execução do Gerenciador de Tarefas baseado em Ctrl &#43; Alt &#43; Del. Esses itens são essenciais para os que quiserem criar uma réplica perfeita da GINA da Microsoft no Windows XP. Isso finaliza a minha busca.
Sempre tem mais. Se a máquina estiver no domínio essa opção não funciona. Porém, o WinLogon verifica se existe um valor chamado ForceFriendlyUi, que descobri graças ao Process Monitor. Aliado ao LogonType, sendo igual a 1, a Tela de Boas-Vindas é habilitada, mesmo em um ambiente com servidor de domínio.
Por último, claro, salvo se não existir o valor GinaDll dentro da chave do WinLogon. Se esse for o caso, o ForceFriendlyUi também não funciona. E é exatamente aí que uma GINA é instalada.
E eis que surge uma nova GINA.
</description>
</item>

     
        <item>
  <title>Reflexão em C&#43;&#43;</title>
  <link>http://www.caloni.com.br/reflexao-em-c/</link>
  <pubDate>2008-06-30</pubDate>
  
  <guid>http://www.caloni.com.br/reflexao-em-c/</guid>
  <description>O termo e conceito de &amp;quot;reflection)&amp;quot; (reflexão), muito usado em linguagens modernas, é a capacidade de um programa de observar e até de alterar sua própria estrutura. Bom, isso você pode ler na Wikipédia. O interessante é o que podemos usar desse conceito na linguagem C&#43;&#43;.
Infelizmente não muito.
O sistema de RTTI (Run Time Type Identification), a identificação de tipos em tempo de execução, seria o começo do reflection em C&#43;&#43;. Foi um começo que não teve meio nem fim, mas existe na linguagem. Dessa forma podemos tirar algum proveito disso.
Um leitor pediu para que eu falasse um pouco sobre essas coisas, especificamente como se faz para obter o nome da classe de onde estamos executando um determinado método. Para esse tipo de construção podemos usar o operado typeid, que retorna informações básicas sobre um tipo de acordo com um tipo, instância ou expressão:
Dessa forma, podemos nos aproveitar do fato que todo método não-estático possui a variável implícita this, do tipo &amp;quot;ponteiro constante para T&amp;quot;, onde T é o tipo da classe que contém o método sendo chamado.
class MyClass::MyMethod
Com classes não-polimórficas a coisa parece não ter muita utilidade. No entanto, essa mesma técnica pode ser aplicada em classes derivadas, uma vez que o operador typeid pode trabalhar em tempo de execução:
Apenas se lembre de ter de fato uma classe polimórfica (eu consegui isso tornando MyMethod uma função virtual). Do contrário você pode ter problemas.
</description>
</item>

     
        <item>
  <title>Primeiros passos na documentação de código-fonte usando Doxygen</title>
  <link>http://www.caloni.com.br/primeiros-passos-na-documentacao-de-codigo-fonte-usando-doxygen/</link>
  <pubDate>2008-06-26</pubDate>
  
  <guid>http://www.caloni.com.br/primeiros-passos-na-documentacao-de-codigo-fonte-usando-doxygen/</guid>
  <description>Comentários são essenciais em um código-fonte bem feito. O código pode até fazer milagres, salvar vidas e multiplicar pães, mas se não tiver um apóstolo eficiente que escreva um evangelho para ele, as pessoas não vão conseguir usar!
OK, a analogia foi horrível.
Bom, já que é pra fazer comentários, porque não fazê-los de uma forma que seja possível extrair todo esse texto diretamente do fonte e transformá-lo em documentação? Dessa forma você evita ter que abrir o Word (arght!) e evita que a documentação fique desatualizada quando o documentador do seu projeto for embora da empresa.
Vocês não têm documentador no projeto? Ah, tá. Bem-vindo ao grupo.
O Doxygen é uma ferramenta que consegue extrair comentários do seu código-fonte, formatados ou não, e transformar em arquivos html, doc, chm, etc. O resultado é muito impressionante, pois ele é capaz de interpretar algumas linguagens (como C&#43;&#43;) e mostrar a hierarquia de classes e funções.
Ele não obriga que o desenvolvedor formate corretamente os comentários, mas ao fazer isso podemos descrever o funcionamento exato de funções de interface, como o que cada parâmetro significa, o valor de retorno, algumas observações quanto ao uso, etc.
Aprender a usar Doxygen é muito fácil. Ele possui uma ajuda com vários exemplos com os quais podemos começar a programar um código auto-documentado.
Por ser uma ferramenta bem flexível, são permitidos inúmeros formatos para se auto-documentar o código. Vou descrever como eu faço, mas pode ser que outro formato lhe agrade mais. Para conhecê-los, dê uma olhada no manual.
A primeira coisa a saber sobre comentários de documentação é que eles devem vir sempre ANTES do elemento que estamos comentando. Por exemplo, uma classe:
Note que o comentário inicia com um duplo asterisco &amp;quot;/&amp;quot;. Isso indica ao Doxygen que vem documentação por aí.
Observe que seria mais simples que o Doxygen pegasse todo e qualquer comentário e transformasse em documentação. No entanto, existem comentários que não devem ser publicados, pois são muito específicos do funcionamento interno da função. Dessa forma o programa-documentador lhe dá a liberdade de fazer comentários documentáveis e não-documentáveis.
Também existe um outro formato bem popular, usado pelo pessoal do Java, que são os comentários que se iniciam com três barras:
Além desse estilo de comentário, existem campos-chave que podemos colocar. Para definir um campo-chave, uma forma válida é usar o arroba seguido do seu nome, e a descrição. Eis um exemplo cheio deles:
Vejamos:
  brief. Serve como descrição inicial e sucinta do que a função faz. Mais explicações podem existir depois dessa primeira linha introdutória.
  param. Descreve o objetivo de um parâmetro, assim como se ele é de entrada ou saída.
  return. Explica os diversos retornos que a função pode ter.
  remark. Observações especiais que podem ajudar quem chama a função.
  Existem diversos outros tipos de marcadores e com certeza você encontrará muita utilidade em outros. No entanto, esse é o basico que todo desenvolvedor do seu time deve saber para já começar a documentar suas funções.
 Usando o Doxygen (Parte 1 e Parte 2) - Daniel Quadros  </description>
</item>

     
        <item>
  <title>Como estou trabalhando com o Bazaar</title>
  <link>http://www.caloni.com.br/como-estou-trabalhando-com-o-bazaar/</link>
  <pubDate>2008-06-24</pubDate>
  
  <guid>http://www.caloni.com.br/como-estou-trabalhando-com-o-bazaar/</guid>
  <description>Depois de alguns ajustes e muitas perguntas do meu amigo-colega desenvolvedor Rafael, conseguimos definir alguns usos e costumes em nosso código controlado pelo Bazaar. Este é um guia para Dummies de como é possível organizar um ou mais projetos de forma a favorecer o refactoring e a liberdade de uso.
Nosso padrão de diretórios utiliza um repositório compartilhado e dentro, na mesma ramificação, os branches. O branch principal tem o mesmo nome do projeto. Isso na máquina de um desenvolvedor ficaria:
No servidor de fontes geralmente teremos apenas o branch principal, apesar de que o desenvolvimento em paralelo seja permitido:
Foi criado um projeto modelo para que todos os projetos herdassem seu histórico. Para que isso? Bom, na eventualidade de partes de um projeto irem parar em outro (isso quase nunca acontece), isso pode ser feito sem perder todo o histórico do início do projeto.
Resumindo: todos os projetos novos são branches do projeto-modelo.
Como podemos ver acima, o projeto modelo segue o mesmo padrão de repositório compartilhado. Os projetos que criarmos serão baseados nesse projeto modelo, mas em outro repositório compartilhado.
A ramificação dos projetos estará sempre no mesmo lugar, independente da pasta raiz.
O controle distribuído de fontes não significa que não existe um servidor. Existe. O detalhe é que todos os desenvolvedores guardam todo o histórico do projeto com eles, igualzinho o servidor, que é apenas mais uma máquina com mais um branch.
O repositório do servidor pode ser criado com a opção que não cria o diretório de trabalho, que é onde os programadores mexem no código-fonte. Sendo um servidor, o código-fonte não é necessário, só a base de dados:
O Bazzar possui um esquema de servidor embutido nele, que fica escutando em uma porta e se comunica em um protocolo otimizado. Nós gostamos desse esquema, pois protege os projetos de acidentes de usuários que podem apagar uma pasta sem querer.
Para manter o Bazaar eternamente rodando, usamos o programa do DriverEntry que transforma qualquer coisa no formato de um serviço de gelo.
Ou não sei usar direito esse programa ou ele não permite uso de aspas no nome do aplicativo junto de argumentos. Por isso tive que editar o registro onde ele fica para colocar aspas duplas em torno do bzr.exe.
Após isso, ainda temos que configurar o serviço para iniciar automaticamente e usar um usuário conhecido. Enquanto o computador estiver ligado, mesmo que sem sessões abertas, nenhuma tela irá aparecer, mas o Bazaar estará rodando e ativo, escutando em sua porta padrão:
Se estiver tudo certo, ao iniciar o serviço o Bazaar passará a ficar escutando e pronto para fazer commits e branches.
Agora qualquer usuário da rede consegue fazer updates e commits. Um desenvolvedor novo faria o seguinte comando:
Note que o usuário do Bazaar não é obrigado a criar um repositório compartilhado. Esse foi um padrão definido aqui e não necessariamente é o melhor.
O Bazaar por ser muito flexível entra naquela categoria de &amp;quot;Difícil de acertar a maneira certa de utilizar&amp;quot;. Bom, mais ou menos. Eu sinceramente não acho que exista uma maneira errada de usar o Bazaar, mas vamos ver as maneiras mais comuns, que não são exclusivas entre si.
É aquele que prefere fazer tudo localmente e só depois, bem depois, mandar seus commits para o servidor. Nesse caso o comando para começar a programar é branch.
Nesse esquema o servidor e a máquina do desenvolvedor não trocam idéia se ele não quiser. Quando quiser, pode usar os comandos push, pull e merge. O push coloca coisas novas no servidor; o pull puxa coisas novas do servidor, e o merge é necessário quando existem conflitos entre as mudanças no fonte. Mais sobre conflitos em um futuro artigo.
É o cara que quer sempre atualizar todas as modificações que ele faz imediatamente colocadas no servidor. Tudo bem. É só trabalhar no modo Source Safe (ou Subversion) com o comando checkout:
Um checkout funciona como o branch, só que faz um bind (ligação) com o servidor. O que quer dizer que qualquer commit feito localmente irá parar imediatamente também no servidor, a não ser que seja usado o parâmetro --local.
O modo checkout permite usar o comando update para ver se existem mudanças entre a máquina local e o servidor, diferente do modo standalone, onde o update apenas compara com o branch local e o diretório de trabalho.
Como eu havia dito, uma coisa não exclui outra. Se você está trabalhando em um branch e deseja se conectar ao servidor para atualizar mudanças, basta usar o comando bind.
O branch começará a trabalhar como um checkout.
O contrário, que é fazer um checkout ficar desconectado é conseguido pelo comando unbind.
Todos os novos commits serão feitos apenas localmente.
Esses esquemas de conectado e desconectado podem ser usados no modo cliente x servidor ou tudo em uma máquina só. Por exemplo, uma série de mudanças em um projeto pode ser feito em um outro branch desconectado:
Os commits de &amp;quot;novo-branch&amp;quot; não serão replicados para o branch &amp;quot;projeto&amp;quot;.
No entanto, se é uma série de mudanças que devem ser colocadas imediatamente no branch principal, pode-se usar checkout.
Existem diversas outras formas de usar o Bazaar, e isso está sob o controle do desenvolvedor. O importante para quem está migrando é saber definir alguns padrões (onde é o servidor principal, ramificação dos projetos) e o resto é só programar, exatamente como antes.
</description>
</item>

     
        <item>
  <title>É possível carregar duas DLLs gêmeas no mesmo processo?</title>
  <link>http://www.caloni.com.br/e-possivel-carregar-duas-dlls-gemeas-no-mesmo-processo/</link>
  <pubDate>2008-06-21</pubDate>
  
  <guid>http://www.caloni.com.br/e-possivel-carregar-duas-dlls-gemeas-no-mesmo-processo/</guid>
  <description>Um dos últimos artigos de Dmitry Vostokov, e tenho que falar assim porque o cara escreve muito em pouco tempo, fala sobre os perigos de termos uma mesma DLL carregada duas vezes em um único processo, muitas vezes em versões diferentes. Para os observadores atentos como Dmitry esse é um perigo que muitas vezes temos que estar preparados. Para os espertinhos de plantão, a resposta padrão seria: &amp;quot;não vou me preocupar, porque o contador de instâncias cuida disso&amp;quot;.
Será mesmo tão simples?
Vamos supor um caso bem simples e plausível, que é exatamente o mesmo do artigo do Crash Dump Analysis: um produto qualquer possui dois pontos em que ele carrega a mesma DLL. Contudo, no primeiro ponto é usado um caminho relativo, dentro da pasta DLL; na segunda chamada é usado o caminho atual. Se existir de fato duas DLLs, mesmo que idênticas, nesses lugares, então teremos duas instâncias da &amp;quot;mesma DLL&amp;quot; carregadas no processo.
O código do aplicativo apenas tenta carregar a DLL em dois lugares distintos e exibe o endereço para onde elas foram mapeadas em nosso processo de teste:
A DLL é uma DLL trivial:
Vamos aos testes.
Nesse caso, ambos os retornos serão nulos, que é o natural e esperado quando a DLL não pode ser encontrada nos lugares especificados pelo sistema e pelo aplicativo.
No segundo caso, a DLL é carregada com sucesso se usado o caminho relativo, pois o caminho atual faz parte da lista de caminhos que o sistema percorre para encontrá-la. A primeira chamada deve falhar.
No caso problemático, a mesma DLL é carregada em dois endereços distintos da memória do mesmo processo, o que pode causar sérios problemas dependendo do código envolvido.
Apesar do mundo parecer injusto, temos uma segunda regra que podemos usar para aqueles casos onde a idiotisse já foi feita:
Vamos supor que estamos no meio de uma mudança bem radical no produto e queremos ter certeza que qualquer chamada à nossa DLL irá invocar unicamente a que estiver dentro do caminho do produto (caminho atual). Para esse caso o Windows permite uma saída muito interessante, que é o uso de um arquivo com o nome do aplicativo mais o sufixo &amp;quot;.local&amp;quot;. Se esse arquivo existir, de acordo com o MSDN.aspx), então qualquer chamada à DLL irá ter sempre a prioridade do caminho atual.
Tente evitar a replicação do mesmo arquivo em diversos lugares. Quando eu digo &amp;quot;mesmo arquivo&amp;quot; me refiro ao mesmo nome de DLL, embora não necessariamente a mesma versão. Isso pode evitar algumas dores de cabeça futuras. E muitas, muitas horas de depuração.
</description>
</item>

     
        <item>
  <title>Alinhamento de memória portável</title>
  <link>http://www.caloni.com.br/alinhamento-de-memoria-portavel/</link>
  <pubDate>2008-06-18</pubDate>
  
  <guid>http://www.caloni.com.br/alinhamento-de-memoria-portavel/</guid>
  <description>Como vimos durante o seminário CCPP, o alinhamento de memória pode ser problemático durante momentos críticos, como migração de plataforma (16 para 32 bits) e de ambiente (compilador novo). A forma como a memória é alinhada influi diretamente em algoritmos de criptografia, por exemplo, fazendo com que o que funcionava antes não funcione mais sem mexer uma única linha de código. Eu já vi isso. E isso não é bom.
A raiz do problema é que, dependendo do alinhamento usado pelo compilador, o sizeof de uma variável pode mudar de valor, mesmo que o tamanho útil não mude. Por exemplo, vamos supor que temos uma dada estrutura que iremos encriptar:
Se usarmos a construção &amp;quot;sizeof(EstruturaQueIremosEncriptar)&amp;quot;, podemos obter o valor 35 caso o alinhamento seja feito em 1 byte, ou podemos obter o valor 40 se o alinhamento estiver configurado em 8 bytes. E é aí que começa o problema.
Já pensando nesse problema, os projetistas de vários compiladores suportam uma extensão não-padrão que permite definir, para um dado conjunto de estruturas e variáveis, o alinhamento que deve ser seguido. Isso de cara já resolve o problema, SE sua solução usar apenas compiladores que suportem essa idéia. No Visual C&#43;&#43; essa idéia é traduzida por uma diretiva pragma:
A diretiva pragma está definida no padrão C (6.8.6) e C&#43;&#43; (16.6) e seu uso não torna um programa não-padrão. No entanto, o que vai depois da diretiva é dependente da implementação e não é garantido que irá funcionar.
Pronto, nossa estrutura sempre terá 40 bytes ocupados na memória, pois o alinhamento foi forçado em 8 bytes. Resolvido.
Existem aqueles compiladores que não suportam essa idéia da mesma forma, ou não suportam de jeito nenhum. Para esses casos, alguns desvios de comportamento são necessários. A grande pergunta é se isso é possível de ser feito de forma 100% padrão.
Pelo que eu pude constatar, existe, sim.
O código acima usa o conceito de união de estruturas (union) para fazer valer um alinhamento na marra (no caso, 8). Para os que não conhecem unions, é necessário uma breve explicação do conceito.
Uma estrutura, como todos sabem, amontoa os seus membros um após o outro na memória. Dessa forma podemos tratar um bloco de memória com um leiaute que definimos com outros tipos:
Em uma união, os membros não são amontoados um após o outro. Todos eles começam no mesmo ponto da memória. Eles se sobrescrevem. O tamanho da união sempre é o tamanho do seu maior membro, e não a soma de todos. É um tanto difícil de descrever esse leiaute, mas imagine que você tenha apenas uma posição na memória e queira chamá-la de vários nomes e tamanhos diferentes. Essa é a união.
Como deve ser fácil de imaginar, uma união não tem tanto uso quanto uma estrutura, mas ainda assim faz parte da linguagem. Ela possibilita enxergar a mesma região de memória sob vários ângulos. Podemos descobrir a organização de um inteiro na memória, por exemplo, byte a byte:
Dependendo se a plataforma onde o programa acima é compilado, a exibição do último printf pode mudar. Eis o motivo.
Agora que sabemos o que são uniões fica fácil entender o esquema da solução portável. Eu simplesmente uso a segunda estrutura como uma auxiliar de alinhamento. Com ela do tamanho múltiplo do alinhamento desejado forçamos a união inteira a ter esse alinhamento, independente do tamanho da estrutura útil, a que iremos usar para armazenar dados.
Tudo que temos que saber para fazer o alinhamento é o tamanho normal de nosso tipo útil (o Teste). A partir desse valor deduzimos o próximo número que seja múltiplo de 8, através da seguinte construção:
Ou seja, se já for múltiplo de 8, é o próprio valor. Se não for, então dividimos por 8 e multiplicamos pelo mesmo valor adicionado de um, o que nos retorna o próximo múltiplo.
É lógico que, como se trata de uma construção onde temos completo domínio dos tipos e valores envolvidos, transformar isso em um template é &amp;quot;pedaço de torta&amp;quot;.
E essa é a melhor parte de descobrir um padrão em um tipo: o template nasce quase que naturalmente. A beleza da linguagem floresce.
</description>
</item>

     
        <item>
  <title>Como fazer merge de projetos distintos no Bazaar</title>
  <link>http://www.caloni.com.br/como-fazer-merge-de-projetos-distintos-no-bazaar/</link>
  <pubDate>2008-06-16</pubDate>
  
  <guid>http://www.caloni.com.br/como-fazer-merge-de-projetos-distintos-no-bazaar/</guid>
  <description>O problema foi o seguinte: Nós iniciamos o controle de fonte pelo Bazaar na parte Linux do projeto, já que ela não iria funcionar pelo Source Safe, mesmo. Dessa forma apenas um braço do projeto estava no controle de fonte e o resto não.
No segundo momento da evolução decidimos começar a migrar os projetos para o Bazaar, inclusive a parte daquele projeto que compila no Windows. Maravilha. Ambos sendo controlados é uma beleza, não é mesmo?
Até que veio o dia de juntar.
O processo de merge de um controle de fonte supõe que os branches começaram em algum ponto em comum; do contrário não há como o controlador saber as coisas que mudaram em paralelo. Pois é achando a modificação ancestral, pai de ambos os branches, que ele irá medir a dificuldade de juntar as versões novamente. Se não existe ancestral, não existe análise. Como exemplificado na figura:
Acontece que existe um plugin esperto que consegue migrar revisões (commits) entre branches sem qualquer parentesco. Não me pergunte como ele faz isso. Mas ele faz. E foi assim que resolvemos o problema dos branches órfãos.
Para instalar o plugin do rebase, basta baixá-lo e copiar sua pasta extraída com um nome válido no Python (rebase, por exemplo). A partir daí os comandos do plugin estão disponíveis no prompt do Bazaar, assim como a instalação de qualquer plugin que cria novos comandos.
O comando que usamos foi o replay, que não é comando principal do plugin, mas que resolve esse problema de maneira quase satisfatória. Como era tudo o que tínhamos, valeu a pena.
O processo que usei foi de usar esse comando n vezes para buscar revisões de um branch e colocar no outro. Um grande problema com ele é que ao encontrar merges no branch origem ele se perde e o usuário tem que fazer as modificações &amp;quot;na mão&amp;quot;. Deu um pouco de trabalho, mas conseguimos migrar nossos commits mais importantes e deixar o projeto inteiro, Linux&#43;Windows, em um branch só.
</description>
</item>

     
        <item>
  <title>Guia básico de repositórios no Bazaar</title>
  <link>http://www.caloni.com.br/guia-basico-de-repositorios-no-bazaar/</link>
  <pubDate>2008-06-10</pubDate>
  
  <guid>http://www.caloni.com.br/guia-basico-de-repositorios-no-bazaar/</guid>
  <description>Alguns conceitos-chave antes de trabalhar com o Bazaar são:
 Revision (Revisão). Um snapshot dos arquivos que você está trabalhando. Working Tree (Árvore de Trabalho). Um diretório contendo seus arquivos controlados por versão e subdiretórios. Branch (Ramificação). Um grupo ordenado de revisões que descreve o histórico de um grupo de arquivos. Repository (Repositório). Um depósito de revisões.  Agora vamos brincar um pouco com os conceitos.
O uso mais simples que existe no Bazaar é o controle de uma pasta sozinha, conhecida como uma Standalone Tree. Como toda Working Tree, ela possui um repositório relacionado, que no caso está dentro dela mesmo, na pasta oculta &amp;quot;.bzr&amp;quot;.
Pra criar uma Standalone Tree, tudo que precisamos é usar o comando init de dentro da pasta a ser controlada, quando é criado um repositório local. Adicionamos arquivos para o repositório com o comando add, e finalizamos nossa primeira versão com o comando commit.
Feito. A partir daí temos um repositório onde podemos realizar o comando commit sempre que quisermos marcar um snapshot em nosso código-fonte.
Se quisermos fazer uma alteração muito grande em nosso pequeno projeto seria melhor termos outro diretório onde trabalhar antes de realizar o commit na versão estável. Para isso podemos usar o comando branch, que cria uma nova pasta com todo o histórico da pasta inicial até esse ponto. Os históricos em um branch estão duplicados em ambas as pastas, e portanto são independentes. Você pode apagar a pasta original ou a secundária que terá o backup inteiro no novo branch.
Criar um novo branch totalmente duplicado pode se tornar um desperdício enorme de espaço em disco (e tempo). Para isso foi criado o conceito de Shared Repository, que basicamente é um diretório acima dos branchs que trata de organizar as revisões em apenas um só lugar, com a vantagem de otimizar o espaço. Nesse caso, antes de criar o projeto, poderíamos usar o comando init-repo na pasta mãe de nosso projeto, e depois continuar com o processo de init dentro da pasta do projeto.
Se compararmos o tamanho, veremos que o repositório compartilhado é que detém a maior parte dos arquivos, enquanto agora o &amp;quot;.bzr&amp;quot; que está na pasta do projeto possui apenas dados de controle. A mesma coisa irá acontecer com qualquer branch criado dentro da pasta de repositório compartilhado.
Mas já criamos nossos dois branches cheios de arquivos, certo? Certo. Como já fizemos isso, devemos criar uma nova pasta como repositório compartilhado e criar dois novos branches dentro dessa pasta, cópias dos dois branches gordinhos:
Isso irá recriar esses dois branches como os originais, mas com a metade do espaço em disco, pois seus históricos estarão compartilhados na pasta project1-repo.
O SubVersion é um sistema de controle centralizado. O Bazaar consegue se comportar exatamente como o SubVersion, além de permitir carregar o histórico inteiro consigo. Quem decide como usá-lo é apenas você, pois cada usuário do sistema tem a liberdade de escolher a melhor maneira.
Os comandos para usar o Bazaar à SubVersion são os mesmos do SubVersion: checkout e commit. No entanto, um checkout irá fazer com que seu commit crie a nova revisão primeiro no seu servidor (branch principal) e depois localmente. Se você não deseja criar um histórico inteiro localmente, pode criar um checkout leve (parâmetro --lightweight), que apenas contém arquivos de controle. No entanto, se o servidor de fontes não estiver disponível, você não será capaz de ações que dependam dele, como ver o histórico ou fazer commits.
Na verdade, o Bazaar vai além, e permite que um branch/checkout específico seja conectado e desconectado em qualquer repositório válido. Para isso são usados os comandos bind e unbind. Um branch conectado faz commits remotos e locais, enquanto um branch unbinded faz commits apenas locais. É possível mudar esse comportamento com o parâmetro --local, e atualizar o branch local com o comando update.
  Bazaar User Guide
  Bazaar User Reference
  </description>
</item>

     
        <item>
  <title>Declaração x definição</title>
  <link>http://www.caloni.com.br/declaracao-x-definicao/</link>
  <pubDate>2008-06-06</pubDate>
  
  <guid>http://www.caloni.com.br/declaracao-x-definicao/</guid>
  <description>Uma diferença que eu considero crucial na linguagem C/C&#43;&#43; é a questão da declaração/definição (em inglês, declaration/definition). É a diferença entre esses dois conceitos que permite, por exemplo, que sejam criadas estruturas prontas para serem conectadas a listas ligadas:
Por outro lado, e mais importante ainda, é ela que permite que as funções sejam organizadas em unidades de tradução (cpps) distintas para depois se unirem durante o link, mesmo que entre elas exista uma relação de dependência indissociável:
Existem diversas formas de entender esses dois conceitos. Eu prefiro explicar pela mesma experiência que temos quando descobrimos a divisão hardware/software:
 Hardware é o que você chuta Software é o que você xinga  Exatamente. Hardware é algo paupável, que você pode até chutar se quiser. Por exemplo, a sua memória RAM! No entanto, software é algo mais abstrato, que nós, seres humanos, não temos a capacidade de dar umas boas pauladas. Portanto, nos abstemos a somente xingar o maldito que fez o programa &amp;quot;buggento&amp;quot;.
Da mesma forma, uma declaração em C/C&#43;&#43; nos permite moldar como será alguma coisa na memória, sem no entanto ocupar nem um mísero byte no seu programa:
Por outro lado, a definição, o hardware da história, sempre ocupará alguma coisa na memória RAM, o que, de certa forma, permite que você chute uma variável (embora muitas outras também irão para o saco).
Dessa comparação só existe uma pegadinha: uma definição também é uma declaração. Por exemplo, nos exemplos acima, além de definir func, tst e x, o código também informa ao compilador que existe uma função chamada func, que existe uma variável tst do tipo Teste e uma variável x do tipo int.
Informa ao compilador? Essa é uma outra ótima maneira de pensar a respeito de declarações: elas sempre estão conversando diretamente com o compilador. Por outro lado, nunca conversam diretamente com o hardware, pois ao executar seu código compilado, as declarações não mais existem. Foi apenas um interlúdio para que o compilador conseguisse alocar memória da maneira correta.
Complicado? Talvez seja, mesmo. Mas é algo que vale a pena fixar na mente. Isso, é claro, se você quiser ser um programador C/C&#43;&#43; mais esperto que os outros e resolver pequenos problemas de compilação que muitos perdem horas se perdendo.
Então por que diabos a separação declaração/definição consegue definir coisas como listas ligadas, como no código acima? A resposta é um pouco ambígua, mas representa regra essencial na sintaxe da linguagem: após a definição do nome e do tipo de declaração envolvida podemos referenciá-la como declaração, ou seja, não ferindo a limitação de que não sabemos o tamanho de uma variável do tipo declarado. Dessa forma, é perfeitamente legal definirmos um ponteiro para uma estrutura que ainda não se sabe muita coisa, além de que é uma estrutura:
Dessa forma, o começo de uma definição de estrutura já declara o nome da estrutura antes de terminar a declaração do tipo inteiro. Bizarro, não? De qualquer forma, isso permite a construção clássica de lista ligada:
Se vermos pelo lado prático, de qualquer forma seria impossível definir uma variável dentro dela mesma, pois isso geraria uma recursão infinita de definições, e, como sabemos, os recurso da máquina são finitos.
</description>
</item>

     
        <item>
  <title>Launchpad e a democracia do código-fonte</title>
  <link>http://www.caloni.com.br/launchpad-e-a-democracia-do-codigo-fonte/</link>
  <pubDate>2008-06-04</pubDate>
  
  <guid>http://www.caloni.com.br/launchpad-e-a-democracia-do-codigo-fonte/</guid>
  <description>Após a publicação dos projetos que ando mexendo no próprio saite do Caloni.com.br, recebi uma enxurrada de downloads e quase atingi meu limite de fluxo mensal no provedor.
Devido a esse problema inesperado, irei fazer o inevitável: publicar os projetos em um repositório sério. E aproveitando que já estou usando o Bazaar, nada melhor que usar o Launchpad.net.
O Launchpad nada mais é do que um lugar onde é possível publicar seus projetos de fonte aberto para que pessoas possam ter livre acesso ao seu histórico de mudanças, assim como a liberdade de criar sua própria ramificação (branch). O esquema todo é organizado no formato comunidade, o que permite o compartilhamento não só de código, mas de bugs, traduções e, principalmente, idéias.
A idéia é uma das primeiras que usa a modalidade de controle de fonte distribuído, e permite o uso do Bazaar como o controlador oficial, ou importação de outros controles de fonte, em um processo conhecido como espelhamento. Tudo foi feito de forma a amenizar o processo de migração dos sistemas de controle de código centralizado, como CVS e Subversion.
Para ter acesso aos meus projetos iniciais é simples: basta usar o mesmo comando que é usado para obter um novo branch de um projeto do Bazaar:
 MouseTool - Simulador de clique de mouse Influence Board - Complemento ao Winboard que mostra a influência das peças Conversor Houaiss Babylon - Converte de um dicionário para o outro  Como o Bazaar foi feito integrado com o Launchpad, também é possível usar um comando bem mais fácil:
Assim como é possível usar comandos de repositório, também é possível navegar pelo histórico de mudanças do projeto simplesmente usando os linques acima no navegador de sua preferência. E é nessa hora que começa a ficar interessante publicar seu projeto na web. Por falar nisso, que tal aprender como
Tudo que precisamos é de um login, facilmente obtido na página principal, e de registrar um projeto. Para criar o primeiro branch e fazermos alterações precisaremos também de um par de chaves pública e privada para a conexão SSH criada automaticamente pelo Bazaar. Tudo isso é facilmente possível com o uso das ferramentas do Putty, um cliente SSH para Windows.
Dessa forma os passos são os seguintes:
  Criar um login
  Registrar um projeto
  Criar um par de chaves através do PuTTYgen
  ATENÇÃO Devido a alguns problemas, recomendo que use o texto exibido na tela do gerador de chaves em vez de copiar diretamente do arquivo da chave pública para o cadastro no saite. Guarde bem essas chaves com você, pois você as usará sempre que necessário fazer uma modificação no projeto.
 Atualizar no cadastro do saite (item &amp;quot;Update SSH keys&amp;quot;)
  Usar o Pageant para carregar a chave privada na memória
  Use os comandos do Bazaar passando o usuário e o branch:
  Simples e direto. E funciona!
</description>
</item>

     
        <item>
  <title>Como criar uma LIB no Visual Studio</title>
  <link>http://www.caloni.com.br/como-criar-uma-lib-no-visual-studio/</link>
  <pubDate>2008-05-29</pubDate>
  
  <guid>http://www.caloni.com.br/como-criar-uma-lib-no-visual-studio/</guid>
  <description>Quando se está começando no ramo, alguns detalhes nunca vêm à tona para o programador novato. Ele simplesmente vai codando até se sentir satisfeito com o prazer que é proporcionado pela prática da arte dos deuses de silício.
Isso, em termos práticos, quer dizer que todo o fonte vai ser escrito no mesmo &amp;quot;.c&amp;quot;, que aliás talvez nem se dê ao luxo de possuir seu próprio &amp;quot;.h&amp;quot;: pra quê, se as funções são todas amigas de infância e todas se conhecem?
No começo não existe nenhum problema, mesmo. O fonte vai ser pequeno. A coisa só complica quando não dá mais pra se achar no meio de tantos gotos e ifs aninhados. Talvez nessa hora o programador já-não-tão-novato até tenha descoberto que é possível criar vários arquivos-fonte e reuni-los em um negócio chamado projeto, e que existem IDEs, como o Visual Studio, que organizam esses tais projetos.
A partir daí, para chegar em uma LIB, já é meio caminho andado.
Boa pergunta. Uma LIB, ou biblioteca, nada mais é do que um punhado de &amp;quot;.obj&amp;quot; colocados todos no mesmo arquivo, geralmente um &amp;quot;.lib&amp;quot;. Esses &amp;quot;.obj&amp;quot; são o resultado da compilação de seus respectivos &amp;quot;.c&amp;quot; de origem.
Alguns acreditam ser esse negócio de LIB uma pura perda de tempo, pois existem trocentas configurações diferentes (e incompatíveis) e trocentas compilações diferentes para gerenciar. Outros acham que o problema está no tempo de compilação, enquanto outros defendem o uso dos &amp;quot;.obj&amp;quot; de maneira separada. Esse artigo não presume que nem um nem outro seja melhor. Apenas ensina o que você precisa saber para criar sua primeira LIB usando o Visual Studio Express.
Vamos lá?
Após abrir o VS, tudo que precisamos fazer é ir em New, Project, e escolher a configuração de &amp;quot;Win32 Project&amp;quot;:
A seguir, escolhemos nas opções do assistente criar uma &amp;quot;Static library&amp;quot;, e desmarcamos a opção de &amp;quot;Precompiled header&amp;quot; para evitar má sorte logo no primeiro projeto de LIB (má sorte significa horas procurando erros incríveis que você só irá fazer desaparecer se recompilar tudo com o uso do famigerado &amp;quot;Rebuild All&amp;quot;; espero que isso dê certo para você, para mim não tem funcionado).
E pronto! Temos um projeto de LIB completo, funcional e... um tanto inútil. Mas, calma lá. Ainda não terminamos.
Conforme o programador consegue se livrar das maldições das mil dependências, aos poucos ele vai conseguindo novas funções genéricas e encaixáveis para colocar em sua coleção de objs. Essa com certeza não é uma tarefa fácil, mas ei, quem disse que esse trampo de programador seria fácil?
Vamos imaginar que você é muito do sem imaginação (típico de pessoas que mantêm blogues) e criou duas funções lindíssimas que somam e multiplicam dois números:
Não são aquelas coisas, mas são genéricas e, até certo ponto, &amp;quot;úteis&amp;quot; para o nosso exemplo.
Agora, tudo que temos que fazer é criar dois arquivos: mymath.c e mymath.h. No mymath.c, colocamos as funções acima exatamente como estão. No mymath.h, colocamos apenas as declarações dessas duas funções, apenas para avisar outros &amp;quot;.c&amp;quot; que existem duas funções que fazem coisas incríveis nessa nossa LIB.
Adicionamos esses dois arquivos ao projeto (se já não estão), e voilà!
Para usar uma LIB temos inúmeras maneiras de fazê-lo. A mais simples que eu conheço é criar um novo projeto no mesmo Solution de sua LIB. Um console, por exemplo:
Se você seguiu todos os passos direitinho, e eu estou assumindo que você já sabia como criar um projeto console, sua saída da compilação talvez seja mais ou menos essa:
Dois erros! Ele não achou os símbolos mult e sum. Mas eles estão logo ali! E agora?
Nada a temer: tudo que temos que fazer é falar para o Solution que o projeto myfirstcmd depende do projeto myfirstlib:
Isso resolve o problema de organização e compilação quando temos dezenas de &amp;quot;.c&amp;quot; espalhados pelo projeto. Existem melhores alternativas, mais bem organizadas e estruturadas, inclusive lingüisticamente falando. No entanto, tudo tem sua hora, e só se deve preocupar-se com isso quando sua solução tiver algumas dezenas de &amp;quot;.lib&amp;quot;. Até lá!
</description>
</item>

     
        <item>
  <title>How to run anything as a service</title>
  <link>http://www.caloni.com.br/how-to-run-anything-as-a-service/</link>
  <pubDate>2008-05-27</pubDate>
  
  <guid>http://www.caloni.com.br/how-to-run-anything-as-a-service/</guid>
  <description>The biggest advantage running an application as a service, interactive or not, is to allow its start before a logon be performed. An example that happens to me is the need of debugging a GINA. In order to do this, I need the Visual Studio remote debugger be started before logon. The easiest and fastest solution is to run Msvcmon, the server part of debugging, as a service.
Today I&#39;ve figured out a pretty interesting shortcut to achieve it.
An Alex Ionescu article talks about this command line application used to create, initiate and remove services. Even not being the article focus, I found the information pretty useful, since I didn&#39;t know such app. Soon some ideas starting to born in my mind:
&amp;quot;What if I used this guy to run notepad?&amp;quot;
Well, the Notepad is the default test victim. Soon, the following line would prove possible to run it in the system account:
However, as every service, it is supposed to communicate with the Windows Service Manager. Since Notepad even &amp;quot;knows&amp;quot; it is now a superpowerful service, the service initialization time is expired and SCM kills the process.
As would say my friend Thiago, &amp;quot;not good&amp;quot;.
&amp;quot;Yet however&amp;quot;, SCM doesn&#39;t kill the child processes from the service-process. Bug? Feature? Workaround? Whatever it is, it can be used to initiate our beloved msvcmon:
Now, when we start Msvcmon service, the process cmd.exe will be create, that on the other hand will run the msvcmon.exe target process. Cmd in this case will only wait for its imminent death.
</description>
</item>

     
        <item>
  <title>Aprendendo rapidamente conceitos essenciais do WinDbg</title>
  <link>http://www.caloni.com.br/aprendendo-rapidamente-conceitos-essenciais-do-windbg/</link>
  <pubDate>2008-05-23</pubDate>
  
  <guid>http://www.caloni.com.br/aprendendo-rapidamente-conceitos-essenciais-do-windbg/</guid>
  <description>Todo o poder e flexibilidade do pacote Debugging Tools da Microsoft pode ser ofuscado pela sua complexidade e curva de aprendizagem. Afinal de contas, usar o depurador do Visual Studio é muito fácil, quando se começa a usar, mas mesmo assim conheço muitos programadores que relutam em depurar passo-a-passo, preferindo a depuração por meio de &amp;quot;MessageBoxes&amp;quot; ou saídas na tela. Imagine, então, a dificuldade que não é para quem conseguiu às duras penas aprender a tornar um hábito a primeira passada do código novo em folha através do F10 começar a fazer coisas como configurar símbolos e digitar comandos exdrúxulos em uma tela em modo texto. Para piorar a questão, existem aqueles que defendem o uso unificado de uma ferramenta que faça tudo, como um telefone celular. Eu discordo. Quando a vantagem competitiva de uma ferramenta sobre outra é notável, nada pior que ficar preso em um ambiente legalzinho que faz o mínimo para você, mas não resolve o seu problema de deadlock.
Foi pensando nessa dificuldade que foi escrita uma apresentação nota dez por Robert Kuster que explica todas as minúcias importantes para todo programador iniciante e experiente na arte de &amp;quot;WinDbgear&amp;quot;. &amp;quot;WinDbg. From A to Z!&amp;quot; é uma ferramenta tão útil quanto o próprio WinDbg, pois explica desde coisas simples que deve-se saber desde o início, como configurar símbolos, quanto assuntos mais avançados, como depuração remota. Até para quem já está no nível avançado vale a pena recapitular algumas coisas que já foram ditas no AWD.
Mesmo tentando ser sucinto, o assunto ocupou um conjunto de 111 transparências que demoram de uma a duas horas de leitura cuidadosa, se você não fizer testes durante o trajeto. Entre as coisas que eu li e reli, segue uma lista importante para nunca ser esquecida (entre parênteses o número das transparências que considero mais importantes):
  O que é são as bibliotecas de depuração do Windows e como elas podem te ajudar (6 e 9)
  O que são símbolos de depuração (11, 12, 14)
  Como funciona a manipulação de exceções e como depurar (18, 19, 85)
  Como configurar seu depurador para funcionar globalmente (20)
  Tipos de comandos no WinDbg (22)
  Configurando símbolos e fontes no WinDbg (24, 25)
  Interagindo com as janelas do WinDbg (33)
  Informações sobre processos, pilhas e memória (29, 41, 43, 45, 66)
  Informações sobre threads e locks (31, 55)
  Comandos úteis com _strings _e memórias (66)
  Avaliando expressões no WinDb: MASM e C&#43;&#43; (70, 71)
  Usando _breakpoints _no WinDbg (básico) (81)
  Usando _breakpoints _no WinDbg (complicado) (83, 84)
  Depuração remota (muito útil!) (87)
  Escolhendo a melhor ferramenta para o problema (fantástico!) (108)
  Além da enchurrada de informações, o autor ainda explica a teoria com comandos digitados no próprio WinDbg, dando um senso bem mais prático à ferramenta. Ou seja, é útil tanto para os que aprendem por definições abstratas e lista de comandos quanto os que preferem já colocar a mão na massa e massacrar o bom e velho notepad.exe.
No final, duas dicas importantíssimas do autor para quem deseja se aventurar nesse mundo: leia a documentação do WinDbg (que também é ótima, apesar de bem mais extensa) e aprenda assembly (simplesmente essencial para resolver muitos problemas).
Se você ainda não teve tempo de se dedicar à depuração avançada em Windows e pensa que nunca terá, dedique duas horinhas divididas em períodos de 15 minutos por dia para explorar esse fantástico tutorial, que com certeza, se bem aplicado, reduzirá exponencialmente seu tempo de resolução de problemas.
Eu recomendo.
Existe uma tradução para inglês desse texto no saite do próprio Robert Kuster, que usou-o como uma espécie de introdução.
</description>
</item>

     
        <item>
  <title>MouseTool: clique automático do seu rato</title>
  <link>http://www.caloni.com.br/mousetool-clique-automatico-do-seu-rato/</link>
  <pubDate>2008-05-21</pubDate>
  
  <guid>http://www.caloni.com.br/mousetool-clique-automatico-do-seu-rato/</guid>
  <description>Bem, como a maioria de você já sabe, eu realmente não gosto de mouses. Apesar disso respeito os usuário que usam-no e até gostam dele. Essa é a razão por que estou escrevendo mais uma vez sobre isso. Dessa vez, irei mostrar um programa que eu uso todos os dias: MouseTool, para os usuários que não usam o mouse, mas gostam dele [1].
O principal objetivo do programa é evitar de clicar no mouse, simulando um clique toda vez que o usuário pára de mover o ponteiro. E é só isso: simples, eficiente e mouseless =).
Existem algumas outras opções como arrastar-e-soltar e clique-duplo, ambas disponíveis pelo próprio programa através de atalhos do teclado ou mudança de estado, situação onde o usuário antes pousa o ponteiro sobre a ação desejada e depois pousa o ponteiro sobre o alvo, dessa forma alternando entre os três modos.
O MouseTool originalmente foi uma ferramente de fonte aberto. Isso significa que a última versão do código-fonte está disponível, certo? Errado. Na verdade, eu não consegui, por mais que tentasse achar, a versão para baixar do código.
Felizmente meu amigo Marcio Andrey já havia baixado o fonte algum tempo atrás e, assim como eu, ele gostaria de torná-lo disponível para todos que gostassem de usá-lo e alterá-lo. Por isso que estou publicando-o aqui. Ele é gratuito e aberto. Façam o que quiserem com ele =).
Vamos aproveitar o código-fonte e mostrar como explorar um código não escrito por nós. Normalmente as primeiras coisas a fazer são: baixar o arquivo compactado e descompactá-lo dentro de uma nova pasta. Dessa forma encontramos o arquivo de projeto (nesse caso, MouseTool.dsw) e tentamos abri-lo. Falhando de início miseravelmente porque acredito que ninguém mais utilize a versão do Visual Studio que abre isso.
Normalmente programadores de projetos de fonte aberto estão acostumados a obter os arquivos-fonte, modificá-los, publicá-los e assim por diante. Porém isso não é quase nunca verdade para programadores Windows de aplicativos estritamente comerciais. É necessário se reajustar à nova cultura para aproveitar os benefícios da política de fonte aberto.
Por exemplo, dados os arquivos-fonte, nós podemos explorar algumas partes interessantes de coisas que gostaríamos de fazer em nossos próprios programas. São trechos pequenos de código que fazem coisas úteis que gastaríamos algumas horas/dias para pesquisar na internet e achar a resposta procurada. Através de um projeto de fonte aberto, conseguimos usar um programa e ao mesmo tempo aprender seu funcionamento. E a principal parte é: nós temos o fonte, mas não os direitos autorais.
Subi um repo no GitHub para baixar o programa; faça bom uso dele.
PS: MouseTool agora tem uma versão Linux em um projeto no Source Forge! Seu nome é GMouseTool, projeto criado por Márcio de Oliveira.
</description>
</item>

     
        <item>
  <title>Busca do Google com atalhos</title>
  <link>http://www.caloni.com.br/busca-do-google-com-atalhos/</link>
  <pubDate>2008-05-19</pubDate>
  
  <guid>http://www.caloni.com.br/busca-do-google-com-atalhos/</guid>
  <description>Eu adoro atalhos de teclado. Desde meus primeiros anos usando computadores, atalhos têm se tornado minha obsessão. Sempre faço minha pesquisa pessoal de tempos em tempos, colecionando e usando novos atalhos descobertos. Por um bom tempo eu evitei ter que usar o mouse, treinando-me para lembrar de todas as seqüências de teclas que conhecia.
Eu não tenho nada contra o uso do mouse nem as pessoas que o usam. Eu apenas não sou tão entusiástico em usar o mouse. Por algum tempo, eu até acreditei que o ponteiro do cursor estava me atrapalhando, então eu desenvolvi um programa para tirá-lo da tela (usando um atalho de teclado, claro). Porém, mais uma vez, não sou contra seu uso. Eu mesmo uso-o de vez em quando (quando eu preciso).
Até algum tempo atrás a web não era muito convidativa para usuários de atalhos. Então surgiu o Google e as suas aplicações que suportavam essa característica, o que me deu uma razão a mais para passar a usar seu cliente de e-mail e leitor de notícias sem pressionar constantemente a tecla tab. No entanto, ainda faltava a mesma funcionalidade para seu buscador. Felizmente, isso não é mais verdade.
Ainda em teste, eu comecei a usar os novos atalhos de teclado na busca do Google disponíveis no saite Google Experimental Search. Até agora existem atalhos para próximo resultado (J), resultado anterior (K), abertura da busca (O ou enter) e colocação do cursor na caixa de busca (/). Eles funcionam exatamente como o Gmail e o Google Reader. Eu fiquei tão empolgado com a idéia que mudei o complemento de busca do Google de dentro do meu Firefox. E agora vou contar como isso pode ser feito facilmente (nota: minhas dicas servem para usuário de Windows apenas).
Provavelmente seu complemento de busca estará em uma das duas pastas abaixo:
O arquivo do complemento tem o nome google.xml e você pode editá-lo usando o Bloco de Notas ou qualquer outro editor de texto simples (sem formatação). Abaixo está o ponto onde você deve inserir a nova linha que irá ativar os atalhos dentro da página de buscas do Google.
É isso aí. Agora você pode ter o melhor dos dois mundos: o melhor buscador da internete com atalhos. Existirá maneira de se tornar ainda mais produtivo?
</description>
</item>

     
        <item>
  <title>Aquele do-while engraçado</title>
  <link>http://www.caloni.com.br/aquele-do-while-engracado/</link>
  <pubDate>2008-05-15</pubDate>
  
  <guid>http://www.caloni.com.br/aquele-do-while-engracado/</guid>
  <description>Nesses últimos dias andei conversando com um amigo que está estudando sistemas operacionais na faculdade. Melhor ainda, vendo o código real de um sistema operacional em funcionamento. A conseqüência é que, além de aprender um bocado de como as coisas funcionam de verdade debaixo dos panos, acaba-se aprendendo alguns truquezinhos básicos e tradicionais da linguagem C.
Por exemplo, é um hábito conhecido o uso de construções do-while quando existe a necessidade de definir uma macro que possui mais de um comando em vez de usar a igualmente conhecida { construção de múltiplos comandos entre chaves }.
O que talvez não seja tão conhecido é o porquê das coisas serem assim.
Vamos imaginar uma macro de logue que é habilitada em compilações debug, mas é mantida em silêncio em compilações release:
Nada de mais, e parece até funcionar. Porém, como veremos nas próximas linhas, esse é realmente um exemplo de código &amp;quot;buguento&amp;quot;, já que uma chamada dentro de uma construção if-else simplesmente não funciona.
Por que isso? Para responder a essa questão nós precisamos olhar um pouco mais de perto no resultado do preprocessador da linguagem, que apenas troca nossa macro pelo pedaço de código que ela representa:
Dessa forma, podemos ver o porquê. Quando chamamos a macro, geralmente usamos a sintaxe de chamada de função, colocando um sinal de ponto-e-vírgula logo após a chamada. Essa é a maneira correta de se chamar uma função, mas no caso de uma macro, dessa macro, é um desastre, porque ela cria dois comandos em vez de um só (um ponto-e-vírgula vazio, apesar de não fazer nada, é um comando válido). Então, isso é o que o compilador faz:
; /* uma instrução nova! ok, sem else desa vez */
Pense sobre o comando vazio como se ele fosse um comando real, o que é a maneira mais fácil de entender o erro de compilação que recebemos ao compilar o código abaixo:
printf(&amp;quot;here we go&amp;quot;);
Por essa razão, a maneira tradicional de escapar desse erro comum é usar uma construção válida que peça de fato um ponto-e-vírgula no final. Felizmente nós, programadores C/C&#43;&#43;, temos essa construção, e ela é... muito bem, o do-while!
;
Assim nós podemos reescrever nossa macro de logue da maneira certa (e todas as 549.797 macros já escritas em nossa vida de programador). E, apesar de ser uma construção um tanto bizarra, ela funciona melhor do que nossa tentativa inicial:
Ao usar um do-while (com uma expressão que retorna falso dentro do teste, de maneira que o código seja executado apenas uma vez) a construção if-else consegue funcionar perfeitamente:
</description>
</item>

     
        <item>
  <title>Kernel Mode &gt;&gt; User Mode</title>
  <link>http://www.caloni.com.br/kernel-mode-user-mode/</link>
  <pubDate>2008-05-13</pubDate>
  
  <guid>http://www.caloni.com.br/kernel-mode-user-mode/</guid>
  <description>Existem algumas situações onde um depurador WYSIWYG é artigo de luxo.
Imagine o seguinte: temos um serviço que inicia automagicamente antes do login do Windows, e possivelmente antes mesmo do ambiente gráfico. Esse serviço tem algum problema que impede que ele funcione sob as circunstâncias de inicialização do sistema. O que fazer? Atachar o WinDbg no processo?
Mas que mané WinDbg? Que mané atachar? Nessa hora nós temos bem menos do que nossos sentidos são capazes de enxergar.
Nessas horas o único que pode nos ajudar é o kernel debugger.
Os depuradores do pacote Debugging Tools (especialmente o ntsd e o cdb) suportam o funcionamento em modo proxy, ou seja, eles apenas redirecionam a saída e os comandos entre as duas pontas da depuração (o depurador e o depurado). Isso é comumente usado em depuração remota e depuração de kernel, quando o sistema inteiro está congelado. O objetivo aqui é conseguir os dois: depurar remotamente um processo em um sistema que está travado.
Para isso podemos nos utilizar do parâmetro -d, que manda o depurador redirecionar toda saída e controle para o depurador de kernel. Para que isso funcione o depurador já deve estar atachado no sistema-alvo. A coisa funciona mais ou menos assim:
Com essa configuração temos a vantagem de ter o sistema congelado só pra nós, ao mesmo tempo que conseguimos depurar nosso processo fujão, passo-a-passo.
A única desvantagem é não ter uma GUI tão poderosa quando o &amp;quot;WinDbg fonte colorido, tooltips, etc&amp;quot;. Pra quem não liga pra essas frescuras, é possível depurar processos de maneira produtiva utilizando esse cenário.
Para ativar qualquer programa que irá rodar nesse modo, basta usar o aplicativo gflags:
É preciso dar uma lida bem profunda na ajuda do Debugging Tools para entender como as coisas estão funcionando nessa configuração milagrosa que estamos usando. Procure por &amp;quot;Controlling the User-Mode Debugger from the Kernel Debugger&amp;quot;. Também é possível ouvir falar parcamente sobre isso no livro Advanced Windows Debugging na parte &amp;quot;Redirecting a User Mode Debugger Through a Kernel&amp;quot;. A vantagem é que vem de brinde uma bela figura para pendurar em um quadro no escritório (embora eu possa jurar que já vi essa figura na ajuda do WinDbg):
Como podemos notar, o controlador de tudo é o kernel debugger. Assim que o depurador de processo entra em ação, ele se comunica com o depurador de kernel que entra no modo user mode prompt, pedindo entrada para ser redirecionada ao depurador de processo. Existem alguns caminhos para sair de um estado e entrar em outro, como o comando .breakin e o .sleep.
É necessário recomentar: estamos nos comunicando com um depurador e o seu processo depurado em um sistema totalmente travado. Isso quer dizer que o acesso a coisas como código-fonte e símbolos é extremamente limitado, porém não impossível. Apenas mantenha-os localmente na máquina-vítima, pois uma comunicação pela rede não irá funcionar.
A depuração com a linha atual no código-fonte demarcando onde estamos também não é possível, uma vez que o WinDbg da ponta de cá apenas faz o papel de garoto de recados para o &amp;quot;depurador de verdade&amp;quot; do outro lado (no nosso exemplo, o ntsd). Isso quer dizer que a forma mais &amp;quot;fácil&amp;quot; de ir passo-a-passo é usar o comando p (step) ou t (trace), além de habilitar o uso de fonte em 100%.
Um tipo de problema que só pode ser depurado dessa maneira enfatiza a importância do uso de unit tests, além de um controle de qualidade mais aguçado antes de liberar uma versão para o cliente.
</description>
</item>

     
        <item>
  <title>Como tratar um merge no Bazaar</title>
  <link>http://www.caloni.com.br/como-tratar-um-merge-no-bazaar/</link>
  <pubDate>2008-05-09</pubDate>
  
  <guid>http://www.caloni.com.br/como-tratar-um-merge-no-bazaar/</guid>
  <description>Hoje fizemos um merge de duas versões que entraram em conflito em nosso projeto-piloto usando bzr. Isso geralmente ocorre quando alguma coisa mudou no mesmo arquivo em lugares muito próximos um do outro. Veremos um exemplo de código para ter uma idéia de quão fácil é o processo:
A execução do programa contém uma saída parecida com as linhas abaixo:
Parece que está faltando algumas quebras de linha. Além de que sabemos que nossos arquivos de entrada poderão conter até 200 caracteres por linha, o que pode gerar um desastre em nosso buffer de 100 bytes. Buffer overflow!
Para corrigir ambos os problemas foram criados dois branches, seguindo as melhores práticas de uso de um controle de fonte distribuído:
Feitas as correções devidas, o branch linebreak fica com a seguinte cara:
Em vermelho podemos notar as linhas alteradas. Uma mudança diferente foi feita para o bug do buffer overflow, em seu branch correspondente:
Agora só temos que juntar ambas as mudanças no branch principal.
Com toda razão, pensa o programador que está corrigindo o bug da quebra de linha, olhando sorrateiramente a função do meio, intocada, DoAnotherJob.
Então ele resolve fazer um pequeno fix &amp;quot;de brinde&amp;quot;, desconhecendo que mais alguém andou alterando essas linhas:
Pronto. Um fonte politicamente correto! E que vai causar um conflito ao juntar essa galera. Vamos ver na seqüência:
Ops. Algo deu errado no segundo pull. O Bazaar nos diz que os branches estão diferentes, e que termos que usar o comando merge no lugar.
Usamos merge no lugar do pull e ganhamos agora um conflito no arquivo bzppilot.cpp, nosso único arquivo. Vamos ver a bagunça que fizemos?
A última coisa que um controle de fonte quer fazer é confundir ou chatear o usuário. Por isso mesmo, a maioria dos conflitos que o Bazaar encontrar nos fontes serão resolvidos usando o algoritmo &amp;quot;se só um mexeu, então coloca a mudança&amp;quot;. A tabela do guia do usuário ilustra esse algoritmo em possibilidades:
conflito!!!
O ancestral é a última modificação em comum dos dois branches que estamos fazendo merge. Do ancestral pra frente cada um seguiu seu caminho, podendo existir quantas modificações quisermos.
Como podemos ver, o conflito só ocorre se ambos os usuário mexerem na mesma parte do código ao mesmo tempo. Eu disse na mesma parte do código, e não apenas no mesmo arquivo. Isso porque se a mudança for feita no mesmo arquivo, porém em locais diferentes, o conflito é resolvido automaticamente.
Em todos os conflitos de texto desse tipo, o Bazaar cria três arquivos de suporte e modifica o arquivo em conflito. Isso para cada conflito.
Podemos fazer o merge da maneira que quisermos. Se vamos usar nossa versão de qualquer jeito é só sobrescrever o arquivo.cpp pelo arquivo.cpp.THIS. Se vamos fazer troca-troca de alterações, abrimos os arquivos .THIS e .OTHER e igualamos suas diferenças, copiando-as para arquivo.cpp.
Recomendo primeiramente olhar o que o Bazaar já fez. Se houver dúvidas sobre a integridade das mudanças, comparar diretamente os arquivos THIS e OTHER.
Vamos dar uma olhada na versão criada pelo Bazaar:
Ora, vemos que ele já fez boa parte do trabalho para nós: as quebras de linha já foram colocadas e o novo define já está lá. Tudo que temos que fazer é trocar o define por 200 e tirar os marcadores, que é a junção das duas mudanças feitas no mesmo local, e que só um ser humano (AFAIK) consegue juntar:
Resolvido o problema, simplesmente esquecemos das versões .BASE, .THIS e .OTHER e falamos pro Bazaar que está tudo certo.
O controle de fonte apaga automaticamente os arquivos THIS, BASE e OTHER, mantendo o original como a mudança aceita.
Após as correções dos conflitos, temos que fazer um commit que irá ser o filho dos dois branches que estamos juntando.
A versão do branch alternativo é 1.1.1, indicando que ele saiu da revisão número 1, é o primeiro alternativo e foi o único commit. Se houvessem mais modificações neste branch, elas seriam 1.1.2, 1.1.3 e assim por diante. Se mais alguém quisesse juntar alguma modificação da revisão 1 ela seria 1.2.1, 1.3.1, 1.4.1 e assim por diante.
Um erro comum que pode acontecer é supor que o arquivo original está do jeito que deixamos e já usar o comando resolve diretamente. É preciso tomar cuidado, pois se algum conflito é detectado quer dizer que o Bazaar deixou para você alguns marcadores no fonte original, o que quer dizer que ele simplesmente não vai compilar enquanto você não resolver seus problemas.
Enfim, tudo que temos que lembrar durante um merge do Bazaar é ver os conflitos ainda não resolvidos direto no fonte e alterá-los de acordo com o problema. O resto é codificar.
</description>
</item>

     
        <item>
  <title>Acessando memória física no WinDbg</title>
  <link>http://www.caloni.com.br/acessando-memoria-fisica-no-windbg/</link>
  <pubDate>2008-05-01</pubDate>
  
  <guid>http://www.caloni.com.br/acessando-memoria-fisica-no-windbg/</guid>
  <description>Como muitos devem saber, acessar memória virtual no WinDbg é coisa de criança, assim como em todo depurador decente. Se estamos falando de kernel mode então, nem se fala! A memória virtual é parte integrante do sistema operacional. Podemos saber mais sobre isso lendo o artigo do Strauss sobre gerenciamento de memória no Windows.
Porém, existem situações, como a que passei essa semana, onde é preciso saber e alterar o conteúdo da memória de verdade, mesmo. Quando eu falo &amp;quot;de verdade mesmo&amp;quot; estou falando em acessar a memória através do seu endereçamento real, que conta do zero até o final da sua memória RAM, sem divisão de processos e sem proteções de acesso.
Para isso é que serve um depurador de verdade, mesmo.
No modo real, onde vivem sistemas como o MS-DOS e programas como o Turbo C, a memória é acessada através do par de coordenadas conhecido como segmento e offset. Entre outros motivos, isso acontece porque em um determinado momento da história o 8086 possuía 16 bits em seus registradores, mas conseguia endereçar até seiscentos e quarenta quilobytes, o que resulta em seiscentos e quarenta vezes mil e vinte e quatro, ou seja, seiscentos e cinquenta e cinco mil, trezentos e sessenta bytes, um número dez vezes maior do que sessenta e cinco mil, quinhentos e trinta e seis, ou dois elevado a dezesseis, o maior número representado por dezesseis bits.
Dessa forma, foi necessário o uso de mais 4 bits para fazer a coisa funcionar, pois como podemos notar logo abaixo, a representação do último byte de 640 KB exige isso:
Para conseguir esses 4 bits adicionais foram usados dois registradores em conjunto, o segmento e o offset. Funciona assim: o segmento é multiplicado por 16 (ou deslocado 4 bits à esquerda) e logo depois é somado com o offset, resultando no endereçamento desejado:
Ou seja, para acessar o byte de número 595764, ou 0x91734, podemos usar o segmento 0x9022 com o offset 0x1514. A soma desses dois com o segmento deslocado irá resultado no endereço flag, ou seja, aquele que obtemos se contarmos a memória do zero até o final da RAM.
Na época, a RAM não costumava ser de valores como 2GB ou até 4GB, mas em KB mesmo. Isso explica a limitação do 8086 em endereçar até 640 KB.
Se nós repararmos bem, veremos que esse método implica em conseguirmos acessar o mesmo byte com um conjunto de segmentos e offsets diferentes, já que a soma pode ser resultado de operandos diversos. Esse é o chamado efeito de overlapping da memória segmentada, onde os programadores em assembly daquela época tinham que tomar alguns cuidados básicos para não atravessar a memória dos outros. No nosso exemplo acima, por exemplo, seria bem mais fácil chamar nosso bytezinho de segmento 0x9000, offset 0x1734.
É verdade! Então, o WinDbg possui alguns comandos extendidos e formas de representar essa memória real, atualmente limitada não mais em 640 KB, mas até onde seus pentes de RAM agüentarem. Os mais comuns são os que imitam os nossos conhecidos dumps de memória: db, dc, dd... Temos daí as extensões !db, !dc, !dd... (note a exclamação do início).
Simples, assim.
Infelizmente, o WinDbg não nos permite ler certas regiões da memória por conta do cacheamento feito pelo processador. Para permitir a leitura em todas as condições, existem três flags que podem ser utilizados:
 c lê da memória cacheada uc lê da memória não-cacheada wc lê da memória de escrita combinada  Nesse caso é possível, embora fique por sua conta e risco, ler qualquer memória não-cacheada usando-se a flag uc.
É possível fazer mais brincadeiras usando os comandos comuns do WinDbg e uma notação diferente da memória. No entanto, é preciso tomar alguns cuidados quando mexer com isso. É recomendado o uso de uma máquina-vítima para esses testes, e não depuração local como estou fazendo.
É isso aí. Não espero que você use muitas vezes essa forma de acessar memória. Só que eu usei e... nunca se sabe =)
</description>
</item>

     
        <item>
  <title>Bazaar e Fedora 8: a saga</title>
  <link>http://www.caloni.com.br/bazaar-e-fedora-8-a-saga/</link>
  <pubDate>2008-04-29</pubDate>
  
  <guid>http://www.caloni.com.br/bazaar-e-fedora-8-a-saga/</guid>
  <description>Seria bom se as coisas simples da vida fossem simples, não é mesmo?
Ontem, sexta passada e quinta passada, no meio de outras tarefas &amp;quot;urgentes&amp;quot;, tentava desesperadamente conseguir instalar o Bazaar na minha VM de desenvolvimento, um Fedora 8 todinho configurado.
Para azar da minha pessoa, o guia simples e rápido de instalação do Bazaar não funcionava para minha distribuição Linux. Na verdade, funciona. Porém, é instalada uma versão tão antiga (0.91!) que o formato do banco de dados já se tornou incompatível.
O pior, no entanto, foi tentar encontrar uma solução para o problema. Fiz mil e uma pesquisas com palavras-chave que nem imaginava que seria capaz de formular. E nada. A princípio minha idéia era apenas atualizar a lista de pacotes do repositório gerenciado pelo yum, o gerenciador de pacotes oficial do Fedora. Entre minhas buscas, encontrei os seguintes itens:
  Um FAQ do Fedora (que não conseguiu responder à minha pergunta)
  O sítio do projeto do yum, gerenciador de pacotes (cujo FAQ não conseguiu responder o mínimo)
  Uma lista enorme de sítios explicando como criar seu próprio repositório (sem comentários)
  Enfim, a coisa não estava saindo do lugar. E o cronograma apertando até o dia final. Até que decidi usar o caminho mais rápido e pentelho: perguntar para quem entende do assunto. A resposta foi simples e direta:
 Por que você não instala direto dos fontes?  Uia! E não é que é mais simples, mesmo?
E foi isso! É a segunda vez que tento fazer algo simples no Linux e me dou mal. Com certeza os dias futuros serão melhores. Mas me bate aquela sensação que as coisas poderiam já estar em um nível mais fácil de se mexer. Opinião pessoal.
</description>
</item>

     
        <item>
  <title>Ode ao C&#43;&#43;</title>
  <link>http://www.caloni.com.br/ode-ao-c/</link>
  <pubDate>2008-04-21</pubDate>
  
  <guid>http://www.caloni.com.br/ode-ao-c/</guid>
  <description>Strauss: lembra quando nós conversávamos sobre o assunto &amp;quot;Por que C&#43;&#43;?&amp;quot;, há muitas décadas atrás, e seu blogue era um dos primeiros no Brasil que não ficava relatando o que o autor comia no café da manhã, além de falar sobre programação? Pois é, eu estava reorganizando meus g-mails e reencontrei nossa conversa e, pior, seu artigo &amp;quot;derivado&amp;quot; dela, que irei republicar aqui pois, assim como antes, acredito em tudo que escrevi naquela época.
Cristiano -- Olá! Sou programador em basic (Vbasic/Qbasic), fico indignado, com pessoas que sabem entender a linguagem C&#43;&#43;, assembler... Como podem? Eu acho isto coisa de outro mundo! Será que eu tenho chances de aprender a linguagem?
Strauss -- A resposta é simples: estudando. Eu tb comecei com QBasic e VB. Arrume um livro de C&#43;&#43; e estude. Treine bastante. E hoje em dia é mais fácil do que quando eu comecei, pq eu não tinha acesso à Internet. É simples assim... :-)
Caloni -- Você pode ir tão longe quanto queira, mas pra isso a primeira coisa que vc tem que fazer é querer =).
Strauss -- Acho que vou fazer um post sobre isso. &amp;quot;Por que C&#43;&#43;&amp;quot; :-) Vc podia me ajudar...
Caloni -- Escrevi um textículo sobre o assunto da escolha, mas não visando o mercado:
Strauss -- Legal. Vou colocar minha água mercadológica no feijão e colocar no site.
Não quis alterar o texto original, mas colocaria, além de rapidez, o título economia de recursos. É incrível o quanto progredimos no quesito hardware todos esses anos, e mesmo assim, existem linguagens e ambientes que parecem ter fome suficiente para consumir tudo e deixar um computador de última geração parecer um micro &amp;quot;meio lerdinho&amp;quot;. Felizmente não preciso dar nome aos bois, pois todos sabem ou conhecem pelo menos uma linguagem com essa característica.
Também não quis generalizar. C e C&#43;&#43; não são as duas únicas opções quando se fala em bom desempenho. Existe também assembly e linguagens de script, que chegam inclusive a ser mais flexíveis e rápidas (além de mais produtivas).
Ainda acredito em tudo isso que C&#43;&#43; proporciona e irá continuar proporcionando por muto tempo. Para os que não seguiram o linque do artigo do Strauss, existe uma modesta lista de programas escritos nessa linguagem ao redor do planeta. Muitos são conhecidíssimos e usados nos quatro cantos do mundo, muitas vezes em mais de um sistema operacional. C&#43;&#43; está morto? Longe disso... talvez pareça assim em território nacional, mas esse é o motivo de meus votos de sucesso no início de nosso grupo C&#43;&#43;.
</description>
</item>

     
        <item>
  <title>Crash Dump Analysis</title>
  <link>http://www.caloni.com.br/crash-dump-analysis-o-livro/</link>
  <pubDate>2008-04-17</pubDate>
  
  <guid>http://www.caloni.com.br/crash-dump-analysis-o-livro/</guid>
  <description>Para quem acabou de terminar o Advanced Windows Debugging (como eu) e não consegue ler no computador os complicados artigos de Dmitry Vostokov (como eu), &amp;quot;seus problemas acabaram-se&amp;quot;: acabou de ser lançado o Memory Dump Analysis Volume 1 em hardware! Em modelos portáveis (paperback) e desktop (hardcover).
Se você perder um pouco de tempo lendo o índice online, perceberá que boa parte do conteúdo (se não todo) está em seu sítio, disponível gratuitamente. Porém, não há nada como ter um livro organizado para ler no conforto do ônibus para o serviço (ou do metrô para casa). Ainda mais depois de ter aguçado os sentidos com o livro de Mario Hewardt e Daniel Pravat.
Selecionei alguns tópicos que acredito que por si só já valeria a pena a aquisição do livro:
  Crashes and Hangs Differentiated
  Minidump Analysis
  Raw Stack Data Analysis
  Symbols and Images
  X64 Interrupts
  Trap Commands (on x86 and x64)
  Bugchecks Depicted
  Manual Stack Trace Reconstruction
  WinDbg Tips and Tricks
  WinDbg Scripts
  Crash Dump Analysis Patterns
  The Origin of Crash Dumps
  UML and Device Drivers
  Enfim, estou coçando os dedos para comprar logo um exemplar. Já sei pelo menos que com certeza serã a versão em brochura, pois não agüento mais fazer exercício muscular com o mais novo integrante da minha maleta.
</description>
</item>

     
        <item>
  <title>Guia básico de controle de código (Mercurial)</title>
  <link>http://www.caloni.com.br/guia-basico-de-controle-de-codigo-mercurial/</link>
  <pubDate>2008-04-15</pubDate>
  
  <guid>http://www.caloni.com.br/guia-basico-de-controle-de-codigo-mercurial/</guid>
  <description>Houve um bom motivo para que, semana passada, eu estivesse caçando inúmeras versões de um projeto desenvolvido fora da empresa: falta de controle de código. Esse tipo de lapso pode consumir de horas a dias de tempo perdido, dependendo de em quantas cópias de máquinas virtuais ficou espalhado o código.
Já escrevi a respeito da importância de controlar e gerenciar o código-fonte para que a falta de um histórico exato das alterações não seja motivo de recorreções de problemas, binários no cliente sem contraparte para ajustes, além de uma série de dores de cabeça que costumam começar a ocorrer assim que nos damos conta que nosso software está uma bagunça que dói.
Na época, discursei brevemente sobre alguns exemplos de gerenciadores de fonte que utilizam modelo centralizado, e nos exemplos práticos usamos o famigerado Source Safe, velho amigo de quem já programa ou programou Windows por alguns anos. Além dele, temos os conhecidíssimos CVS e Subversion, ambos largamente utilizados no mundo todo.
No entanto, uma nova forma de controlar fontes está nascendo já há algum tempo, com relativo sucesso e crescentes esperanças: o modelo distribuído. Nesse tipo de gerenciamento, a liberdade aumenta exponencialmente, permitindo coisas que no modelo antigo seriam muito difíceis de serem implementadas. Não vou me delongar explicando a teoria por trás da idéia, sabendo que, além de existir um ótimo texto explicando as vantagens em cima do modelo centralizado disponível na web, o próprio sítio das implementações atuais explica a idéia de maneira muito convincente. E são elas:
 Git. Conhecido como o controlador de fontes do kernel do Linux. Escrita a versão inicial por Linux Torvalds em C e módulos de Perl pendurados, hoje em dia tem como principal desvantagem a falta de suporte nos ambientes Windows, impactando negativamente em projetos portáveis. Sua principal vantagem, no entanto, é a rapidez: é o controle de fonte mais rápido do oeste. Mercurial (ou hg). Sem dúvida o mais fácil de usar. Bem documentado e com comandos intuitivos para o usuário, vem ganhando mais adeptos a cada dia. Seu desempenho é comparável ao do Git, e seu sistema de arquivos é bem eficiente. Bazaar (ou bzr). O irmão mais próximo do Mercurial, com comandos bem parecidos. Um costuma lembrar os comandos do outro, com pequenas diferenças. Seu desempenho não chega a ser comparável aos dois acima, mas sua robustez compensa, pois é o único, de acordo com testes e estudos, que suporta o controle total de operações de renomeação de arquivos e pastas. Recentemente seu projeto tem evoluído muito.  Nos sistemas centralizados o repositório de fontes fica em um lugar definido, de onde as pessoas pegam a última versão e sobem modificações, ou não, caso não tenham direito para isso.
Nos sistemas distribuídos, o histórico e ramificações ficam todos locais. Como assim locais? Bom, locais do jeito que eu estou falando quer dizer: na própria pasta onde se está desenvolvendo.
É lógico que pode existir uma versão de ramificações no servidor, que no caso do controle distribuído é mais um membro da rede peer-to-peer de ramificações, já que cada colaborador possui seu próprio repositório local, capaz de trocar revisões entre colaboradores e subir revisões os servidores que interessarem.
Além disso, o conceito de ramificações (branches) e consolidação de versões (merging) é muito mais presente do que em sistemas como o Subversion, onde o commit (ato de enviar as revisões de um código para o repositório central) ocorre de forma controlada. Da maneira distribuída, é comum criar um branch para cada problema ou feature sendo desenvolvida, e ir juntando tudo isso imediatamente após terminado, gerando um histórico bem mais detalhado e livre de gargalos com modificações temporárias.
Porém, a maior vantagem em termos de desenvolvimento acaba sendo a liberdade dos usuários, que podem trocar modificações de código entre si, sem existir a figura centralizadora do branch oficial. Ela pode existir, mas não é mais uma condição sine qua non para modificações no fonte.
Comecei a usar em meus projetos pessoais o Mercurial por ter ouvido falar dele primeiro. Achei a idéia fantástica, pois já estava à procura de um substituto para meu velho Source Safe, meio baleado das tantas inovações de controle de fonte que surgiram nos projetos de fonte aberto. Outro motivo para desistir do Source Safe foi o fato de ser uma solução comercial que custa dinheiro e não chega a ser absurdamente mais fácil de usar a ponto de valer a pena usá-lo.
O princípio de uso de uma ferramenta distribuída é muito simples: se você tiver um diretório de projeto já criado, basta, dentro dessa pasta, iniciar o repositório de fontes.
Após isso, será criada uma pasta com o nome .hg. Dentro dela é armazenado todo o histórico dos fontes. Podemos inicialmente adicionar os arquivos do projeto existente e fazer o primeiro commit, que irá começar a controlar os arquivos adicionados dentro dessa pasta e subpastas:
Se o programa não disse nada ao efetuar o commit, é porque está tudo certo. Agora podemos controlar as mudanças de nosso código usando o comando status. Para vermos o histórico usamos o comando log.
Como vimos, ao alterar um arquivo controlado este é mostrado pelo comando status como alterado (o M na frente do Main.cpp). Também existem controles para cópia e exclusão de arquivos.
Esse é o básico que se precisa saber para usar o Mercurial. Simples, não? O resto também é simples: fazer branches e juntá-los é uma questão de costume, e está entre as boas práticas de uso. Eu recomendo fortemente a leitura do tutorial &amp;quot;Entendendo o Mercurial&amp;quot;, disponível no sítio do projeto, até para entender o que existe por trás da idéia do controle descentralizado de fontes. Existe uma tradução muito boa feita pelo meu amigo Márcio.
Como usuário de Windows, posso dizer que a versão funciona muito bem, e é possível fazer coisas como, por exemplo, usar o WinMerge para juntar branches ou comparar versões automaticamente, o que por si só já mata toda a necessidade que eu tinha do Source Safe.
Testei o Mercurial por cerca de três meses desde que o conheci. Esse fim-de-semana conheci mais a fundo o Bazaar, e pretendo começar a testá-lo também para ter uma visão dos dois mundos e optar por um deles. Ambos são projetos relativamente novos que prometem muito. De uma forma ou de outra, os programadores solitários agora possuem um sistema de controle de fontes sem frescura e que funciona para todos.
  Leia o tutorial passo-a-passo do Mercurial
  Leia o tutorial passo-a-passo do Bazaar
  Comece a usá-los em projetos simples e pequenos
  Comece a comparar seu uso ao do Subversion; identifique prós e contras
  Trace um roteiro de migração e mão à massa
  </description>
</item>

     
        <item>
  <title>Aprendendo assembly com o depurador</title>
  <link>http://www.caloni.com.br/aprendendo-assembly-com-o-depurador/</link>
  <pubDate>2008-04-11</pubDate>
  
  <guid>http://www.caloni.com.br/aprendendo-assembly-com-o-depurador/</guid>
  <description>Além de servir para corrigir alguns bugs escabrosos, o nosso bom e fiel amigo depurador também possui uma utilidade inusitada: ensinar assembly! A pessoa interessada em aprender alguns conceitos básicos da arquitetura do 8086 pode se exercitar na frente de um depurador 16 ou 32 bits sem ter medo de ser feliz.
Vamos ver alguns exemplos?
Para quem está começando, recomendo usar um depurador simples, 16 bits e que existe em todo e qualquer Windows: o debug. Já usado para depurar a MBR no Caloni.com.br, poderá agora ser usado para ensinar alguns princípios da plataforma de uma maneira indolor. Basta iniciá-lo na linha de comando:
Os comandos mais úteis são o r (ver ou alterar registradores), o t/p (executar passo-a-passo), o d (exibir memória), o u (desmontar assembly) e o a (montar assembly). Ah, não se esquecendo do ? (ajuda).
Outro ensinamento bem interessante diz respeito à pilha. Aprendemos sempre que a pilha cresce de cima pra baixo, ou seja, de endereços superiores para valores mais baixos. Também vimos que os registradores responsáveis por controlar a memória da pilha são o sp (stack pointer) e o ss (stack segment). Pois bem. Vamos fazer alguns testes para ver isso acontecer.
Como vemos, ao empilhar coisas na pilha, o valor do registrador sp diminui. E ao fazermos um dump do valor de sp conseguimos ver os valores empilhados anteriormente. Isso é muito útil na hora de depurarmos chamadas de funções. Por exemplo, no velho teste do Windbg x Bloco de notas:
Aposto que você sabe em qual dos três botões eu cliquei =)
Depurar é um processo que exige dedicação (experiência) tanto ou mais do que o próprio desenvolvimento. Por isso, fazer um esforço para descobrir algum problema em algum software pode ser vantajoso no futuro, pois você terá mais capacidade de entender o que está acontecendo à sua volta.
Básico a intermediário:
  Guia básico para programadores de primeiro breakpoint
  Brincando com o WinDbg
  Encontrando as respostas do Flash Pops
  Intermediário a avançado:
  Hook de API no WinDbg
  Hook de COM no WinDbg
  Detectando hooks globais no WinDbg
  Analisando dumps com WinDbg e IDA
  Blogues que eu acho superinteressantes sobre debugging (do mais essencial para o mais avançado):
  Debugging Toolbox
  Mark&#39;s Blog
  Advanced Windows Debugging
  Crash Dump Analysis
  </description>
</item>

     
        <item>
  <title>Linux e o DHCP</title>
  <link>http://www.caloni.com.br/linux-e-o-dhcp/</link>
  <pubDate>2008-04-09</pubDate>
  
  <guid>http://www.caloni.com.br/linux-e-o-dhcp/</guid>
  <description>Quando procuramos no google por &amp;quot;linux dhcp&amp;quot;, o que vem em resposta são diversas dicas, tutoriais, documentos oficiais e palpites sobre como configurar um servidor Linux.
Muito bem. E a outra ponta da história?
[Testes feitos em um Fedora 8, não me pergunte mais detalhes]
O primeiro linque útil encontrado foi a documentação da Red Hat. Além disso seguem alguns macetes que eu descobri no decorrer do percurso. A primeira coisa a ser configurada é o arquivo /etc/sysconfig/network. Nele devemos, em uma configuração simplista, colocar uma única linha:
Tive alguns problemas com a entrada NETWORKINGIPV6, ou algo do gênero. A comunicação com o servidor DHCP da rede simplesmente não funcionava com essa linha, deixando o computador sem IP durante o boot. Má configuração do servidor? Pode até ser. Porém, não quis entrar nesses meandros.
Por isso, se houver a linha sobre IPV6 e você tiver problemas, comente-a temporariamente.
O passo seguinte é configurar a interface de rede, que é no fim das contas a representação da sua placa. Para isso temos alguns arquivos em /etc/sysconfig/network-scripts no formato ifcfg-nome-da-interface. Se você digitar ifconfig na linha de comando terá os nomes de interface disponíveis. No meu caso, eth0.
Note que o valor BOOTPROTO é realmente BOOTPROTO, com um O no final. Tive alguns problemas de soletrar também nesse caso, o que me gerou mais alguns reboots mal-sucedidos.
Bem, o que isso faz? Basicamente, manda o Linux utilizar o protocolo DHCP, procurando na rede algum servidor que lhe dê algum IP válido. Só isso. O resto ele faz dinamicamente.
Inclusive alterar automaticamente o arquivo /etc/resolv.conf. Nele estão definidas algumas coisas como o domínio de nomes que estamos e os IPs de onde buscar a resolução de nomes.
Feito isso, como se costuma dizer, voilà! Temos um cliente DHCP funcionando contente e feliz. Eu reiniciei a máquina para tudo dar certo, mas provavelmente devem existir maneiras mais saudáveis de reiniciar a rede (talvez um ifdown seguido de ifup resolvesse). E agora eu posso finalmente ter acesso aos pacotes de instalação que precisava.
Notas de um Linux padawan =)
</description>
</item>

     
        <item>
  <title>Conversor de Houaiss para Babylon - parte 2</title>
  <link>http://www.caloni.com.br/conversor-de-houaiss-para-babylon-parte-2/</link>
  <pubDate>2008-04-08</pubDate>
  
  <guid>http://www.caloni.com.br/conversor-de-houaiss-para-babylon-parte-2/</guid>
  <description>Após algumas semanas de suspense, chegamos finalmente à nossa segunda e última parte da saga do dicionário Houaiss.
Como devem estar lembrados, a primeira parte se dispôs a desmontar a ofuscação usada nos arquivos do dicionário para permitir nossa posterior análise, com o simples e justo objetivo de importá-lo para o Babylon, cujas funcionalidades de busca são bem superiores.
Feito isso, agora nos resta entender a estrutura interna do Houaiss para montar um conversor que irá ajudar o Babylon Builder a construir nosso Houaiss-Babylon. Simples, não?
A primeira parte de toda análise é a busca por padrões com um pouco de bom senso. O Houaiss armazena suas definições em um conjunto de arquivos de nome deahNNN.dhx (provavelmente deah de Dicionario Eletrônico Antônio Houaiss). Os NNN variam de 001 - o maior arquivo - até 065, com algumas poucas lacunas, em um total de 53 arquivos originais.
O nosso rústico importador fez o trabalho de desofuscar todos os 53 arquivos usando a mesma lógica encontrada pelo WinDbg: somar o valor 0x0B para cada byte do arquivo. Dessa forma foram gerados 53 arquivos novos no mesmo diretório, porém com a extensão TXT.
Partindo do bom senso, abriremos o arquivo maior, deah001.txt, e abriremos o próprio dicionário Houaiss, em busca de um padrão que faça sentido. Como poderemos ver na figura abaixo, o padrão inicial não é nem um pouco complicado.
As duas primeiras observações do formato do arquivo nos dizem que (1) o primeiro caractere de cada linha indica o conteúdo dessa linha, e que (2) a formatação dos caracteres é feita dentro de um par de chaves {}.
Dessa forma, podemos começar a construir nosso interpretador de arquivos do Houaiss em seu formato básico.
Simples e funcional. Com esse código já é possível extrair o básico que precisamos de um dicionário: os vocábulos e suas definições.
Para conseguir mais, é necessário mais trabalho.
A formatação segue o estilo já identificado, de forma que podemos aos poucos montar um interpretador de formatação para HTML, que é o formato reconhecido pelo Babylon Builder. Podemos seguir o seguinte molde, chamado no exemplo de código anterior:
Algumas partes ainda estão feias, eu sei. Mas, ei, isso é um código de ráquer, não é mesmo? Além do mais, se isso não é desculpa suficiente, estamos trabalhando em uma versão beta.
A partir dessas duas funções é possível dissecar o primeiro arquivo do dicionário, e assim, construirmos a primeira versão interessante do Houaiss no Babylon.
Como é normal a qualquer dicionário do Babylon, podemos instalá-lo simplesmente clicando duas vezes no arquivo (em uma máquina com Babylon previamente instalado).
O projeto atual está um tanto capenga, mas já desencripta os arquivos do Houaiss e gera o projeto do Babylon Builder sozinho. Em anexo já está um projeto do Babylon Builder. Basta copiar o arquivo Houaiss.txt para a pasta do projeto e gerar o projeto do Babylon.
</description>
</item>

     
        <item>
  <title>Try-catch flutuante</title>
  <link>http://www.caloni.com.br/try-catch-flutuante/</link>
  <pubDate>2008-04-03</pubDate>
  
  <guid>http://www.caloni.com.br/try-catch-flutuante/</guid>
  <description>Esse detalhe da linguagem quem me fez descobrir foi o Yorick, que costuma comentar no blogue (na época que o blogue tinha comentários) e tive o prazer de conhecer no 4o. EPA-CCPP.
É possível, apesar de bizarro, colocar um bloco try-catch em torno da lista de inicialização de variáveis de um construtor. Essa característica da linguagem permite que possamos capturar alguma exceção lançada por algum construtor de algum membro da classe. A construção em código ficaria no estilo abaixo:
Apesar dessa capacidade, não conseguimos parar o lançamento da exceção. Após seu lançamento, caímos no bloco catch abaixo do corpo do construtor e a exceção é lançada novamente, como se houvesse uma intrução throw no final do catch.
O exemplo abaixo demonstra um código de uma classe que captura a exceção durante a inicialização dos membros. Na seguida o catch da função main é executada, provando que a exceção de fato não é &amp;quot;salva&amp;quot; no primeiro bloco.
Testei esse código nos seguintes compiladores:
  Visual Studio 6. Falhou, demonstrando desconhecer a sintaxe.
  Borland C&#43;&#43; Builder 5. Falhou, demonstrando desconhecer a sintaxe.
  Borland Developer Studio 4. Falhou, com o mesmo erro.
  Visual Studio 2003. Comportamento esperado.
  Visual Studio 2005. Comportamento esperado.
  Visual Studio 2008. Comportamento esperado.
  G&#43;&#43; (no Cygwin). Comportamento esperado.
  A saída esperada é a seguinte:
</description>
</item>

     
        <item>
  <title>Backup de pobre</title>
  <link>http://www.caloni.com.br/backup-de-pobre/</link>
  <pubDate>2008-03-28</pubDate>
  
  <guid>http://www.caloni.com.br/backup-de-pobre/</guid>
  <description>O backup - ato de fazer cópia(s) de segurança de dados considerados importantes -, como tudo na vida, para se tornar efetivo e transformador deve antes se tornar um hábito.
Hábitos, por definição, ao serem realizados repetidamente muitas vezes, podem se tornar poderosos catalisadores de tarefas, sejam elas cozinhar um bolo, compilar um programa ou fazer backups. Por isso é muito importante que o backup, antes de ser 100% seguro, seja 100% previsível e habitual.
Minhas restrições para que algo vire um hábito em minha vida, quando tarefas, são que a tarefa seja, antes de tudo,:
  Simples de fazer. Quero conseguir efetuar a tafefa sem ter que toda vez preparar um ritual em noite de lua cheia, sacrificar uma virgem para os deuses pagãos e lembrar de todas as palavras proparoxítonas que terminam com x e rimam com fênix.
  Fácil de executar. É um complemento do primeiro item. Com isso eu quero dizer que, além de simples, eu não precise despender grande força e energia diariamente para efetuar a tarefa. Limpar uma pasta de arquivos temporários pode ser simples; mas é fácil?
  Fácil de lembrar. Se eu tenho que fazer um esforço mental diário tão grande para lembrar do que fazer então muito provavelmente será difícil transformá-lo em um hábito.
  Passado por esse checklist, podemos montar um esquema tão simples que qualquer bobo que tem um blogue (por exemplo, eu) conseguirá executar diariamente, ou pelo menos quando tiver vontade. A freqüência dependerá se isso irá se transformar em um hábito ou não.
Ele pode não parecer, mas é beeem mais antigo do que parece. Nós, veteranos, que possuímos mais anos de vida em frente ao monitor que gostaríamos de admitir (copyright =&amp;gt; DQ), usávamos o xcopy para copiar pastas e disquetes inteiros no MS-DOS, um sistema operacional predecessor do Windows Vista que vinha em preto e branco e sem User Account Control.
No entanto, esse pequeno grande aplicativo sobreviveu todos esses anos, atingiu a maioridade, e hoje permite a nós, programadores de mouse, fazer nossos backups com um simples arquivo de batch e um pouco de imaginação.
Aos mocinho e mocinhas presentes: os arquivos de batch, de extensão .bat ou .cmd, são, assim como o MS-DOS, coisas de veteranos do velho oeste. São arquivos de script que contém um conjunto de comandos que pode-se digitar manualmente na tela preta. Seu objetivo principal é otimizar e facilitar a digitação de tarefas complexas e torná-las mais simples, fáceis de executar e de lembrar.
O uso do programa pode ser aprendido dando-se uma olhada em sua ajuda (xcopy /?)
Algumas opções bem úteis para efetuar cópias de segurança de arquivos modificados:
/M - copia somente arquivos com atributo de arquivamento; após a cópia, desmarca atributo. Ao escrever novamente em um arquivo copiado com esse método, o arquivo volta a ter o atributo de arquivamento, e irá ser copiado novamente se especificada essa opção. Se nunca mais for mexido, não será mais copiado.
/D - copia arquivos mais novos na origem. Não costumo usar pelos problemas que podem ocorrer em sistemas com horas diferentes, mas, dependendo da ocasião, pode ser útil. Também é possível especificar uma data de início da comparação.
/EXCLUDE - permite excluir arquivo(s) de uma cópia coletiva. Isso pode ser muito útil se você não deseja gastar tempo copiando arquivo que são inúteis dentro de pastas que contém arquivos importantes. É possível especificar um arquivo que irá conter uma lista de nomes-curinga, um por linha, que irá servir como filtro da cópia. Teremos um exemplo logo abaixo.
/E - copia pastas e subpastas, mesmo que vazias. Essa opção é básica, e ao mesmo tempo essencial. Não se esqueça dela quando for criar seu script de backup!
/C - continua copiando, mesmo com erros. Se é mais importante copiar o máximo que puder do que parar no primeiro errinho de acesso negado, essa opção deve ser usada. É possível redirecionar a saída para um arquivo de log, que poderá ser usado para procurar por erros que ocorreram durante a operação.
/Q - não exibe nome de arquivos ao copiar. Às vezes imprimir o nome de cada arquivo na saída do prompt de comando acaba sendo mais custoso que copiar o próprio arquivo. Quando a cópia envolve muitos arquivos pequenos, é recomendável usar esta opção.
/Y - suprime perguntas para o usuário. Muito útil em arquivos batch, já que o usuário geralmente não estará lá para apertar enter quando o programa pedir.
/Z - copia arquivos da rede em modo reiniciável. Muito importante quando estiver fazendo backup pela rede. Às vezes ela pode falhar, e essa opção permite continuar após pequenas quedas de desempenho.
Para a cópia do patrimônio mais valioso de um programador, os fontes, podemos usar um conjunto bem bolado das 0pções acima, além de generalizar um script para ser usado em outras situações. Inicialmente vamos definir que queremos um backup que altere o atributo de arquivamento, sobrescreva cópias antigas e que possa ser copiado pela rede sem maiores problemas. Além disso, não iremos copiar as pastas Debug e Release existentes geradas pela saída de algum compilador (ex: saída do Visual Studio), nem arquivos temporários muito grandes (ex: arquivos de navegação de símbolos).
O resultado é o que vemos abaixo:
O conteúdo de sources.flt (extensão escolhida arbitrariamente) pode ser o seguinte:
Só isso já basta para um backup simples, pequeno e fácil de executar. Só precisamos copiar a chamada ao xcopy em um arquivo de extensão .bat ou .cmd e executarmos sempre que acharmos interessante termos um backup quentinho em folha. Por exemplo, podemos manter os fontes do projeto atual em um pen drive e, ao acessarmos uma máquina confiável, rodar um backup que copia os arquvos-fonte para um ambiente mais seguro e estável.
Note que esse procedimento não anula a necessidade de termos um sistema de versionamento e controle de fontes. O backup é para aquelas projetos que demoram um tempinho para efetuar commit, projetos temporários ou então sistemas de controle de fonte distribuído, em que podemos ter inúmeras pastas com diversos branchs locais.
</description>
</item>

     
        <item>
  <title>WinDbg a distância</title>
  <link>http://www.caloni.com.br/windbg-a-distancia/</link>
  <pubDate>2008-03-26</pubDate>
  
  <guid>http://www.caloni.com.br/windbg-a-distancia/</guid>
  <description>Acho que o que mais me impressionou até hoje a respeito do WinDbg é a sua capacidade de depuração remota. Não há nada como depurar problemas sentado confortavelmente na sua cadeira de programador em frente à sua mesa de programador.
Já é fato consumado que os maiores problemas da humanidade ocorrem sempre no cliente, com uma relação de dificuldade diretamente proporcional ao cargo ocupado pelo usuário da máquina que está dando problemas. Se esse cliente por acaso mora em um lugar tão tão distante, nada mais justo do que conhecermos algumas técnicas de depuração remota para continuar a mantê-lo tão tão distante.
O ambiente de desenvolvimento (em teoria) não se deve confundir com o ambiente de testes, um lugar onde o desenvolvedor deveria colocar o pé somente quando fosse chamado e quando existisse um problema na versão Release. Por isso e portanto, a única coisa permitida em um ambiente de testes é (deveria ser) um servidor de depuração.
O servidor de depuração nada mais é do que um processo que deixa alguma porta aberta na máquina de testes para que o desenvolvedor consiga facilmente depurar problemas que ocorreram durantes os testes de produção. Ele pode ser facilmente configurado através da instalação do pacote Debugging Tools for Windows.
Existem alguns cenários muito comuns de depuração remota que serão abordados aqui. O resto dos cenários se baseia nos exemplos abaixo, e pode ser montado com uma simples releitura dos tópicos de ajuda do WinDbg sobre o assunto (procure por dbgsrv.exe).
Nesse caso podemos supor que a máquina tem total acesso e controle do desenvolvedor. Tudo o que temos que fazer é iniciar um WinDbg na máquina-vítima e outro WinDbg na máquina-programador. O WinDbg da máquina-vítima deve ser iniciado no modo-servidor, enquanto o da máquina-programador no modo-cliente.
A vantagem dessa técnica é que tanto o WinDbg da máquina-vítima quanto o da máquina-programador podem emitir comandos, e todos vêem os resultados. Uma possível desvantagem é que os símbolos devem estar disponíveis a partir da máquina-vítima.
Se for necessário, é possível convidar mais gente pra festa, pois o WinDbg permite se transformar em uma instância servidora pelo comando .server, que possui a mesma sintaxe da linha de comando. Para a comunicação entre todos esses depuradores ambulantes um comando muito útil é o .echo.
Nesse ambiente muito mais hostil, é salutar e recomendável utilizar um servidor genérico que não imprima coisa alguma na tela &amp;quot;do outro lado&amp;quot;. Após iniciar o depurador na máquina que está dando o problema, o programador tem virtualmente uma série de comandos úteis que podem ser executados remotamente, como iniciar novos processos, se anexar a processos já existentes, copiar novas versões de executáveis, etc.
O nome do processo do lado servidor para modo usuário é dbgsrv.exe. Para o modo kernel é kdsrv.exe. Os parâmetros de execução, felizmente, são os mesmos que os do WinDbg (e CDB, NTSD e KD), o que evita ter que decorar uma nova série de comandos.
Para iniciar o servidor de depuração e deixar as portas abertas para o depurador temos apenas que iniciar o processo dbgsrv.exe:
Para iniciar o processo depurador, a sintaxe é quase a mesma, só que no lugar de remote especificamos premote:
Caso não se saiba a porta usada para iniciar o servidor, ou queira-se listar todos os servidores disponíveis em uma determinada máquina, usa-se o comando -QR.
É importante notar que o dbgsrv.exe não é um depurador esperto, no sentido que ele não vai carregar os símbolos para você. Isso é importante na hora de definir qual estratégia utilizar, pois nem sempre os símbolos estarão disponíveis na máquina com problemas, e nem sempre estarão com o desenvolvedor.
Uma organização mais esperta dos ambientes de teste e desenvolvimento tomaria conta de outros problemas como símbolos e fontes com o uso de outras features poderosas do Debugging Tools como servidor de símbolos e servidor de fontes. Porém, a complicação envolvida na configuração desses dois me leva a crer que eles merecem um outro artigo. E é por isso que paramos por aqui.
</description>
</item>

     
        <item>
  <title>Depuração da MBR</title>
  <link>http://www.caloni.com.br/depuracao-da-mbr/</link>
  <pubDate>2008-03-24</pubDate>
  
  <guid>http://www.caloni.com.br/depuracao-da-mbr/</guid>
  <description>Dando continuidade a um artigo beeeem antigo sobre depuração da BIOS usando SoftIce, como já vimos, podemos igualmente depurar a MBR após a chamada da INT13. Porém, devo atentar para o fato que, em algumas VMs, e sob determinadas condições do tempo e quantidade de ectoplasma na atmosfera, é possível que a máquina trave após o hot boot iniciado pelo depurador. Isso provavelmente tem cura usando o espaço de endereçamento alto da memória com a ajuda de aplicativos como LH e UMB.
Porém, estou aqui para contar uma nova forma de depurar essa partezinha do código que pode se tornar um tormento se você só se basear em tracing na tela (ou na COM1): usando o aplicativo debug do DOS.
O debug é um programa extremamente antigo, criado antes mesmo do MS-DOS pertencer à Microsoft e do Windows Vista ter sido criado. Como todo sistema operacional, é essencial que exista um programa para verificar problemas em outros programas. Essa foi a &amp;quot;motivação&amp;quot; para a criação do Debug.
Com o passar do tempo e com a evolução dos depuradores modernos, o uso do debug foi diminuindo até a chegada dos 32 bits, quando daí ele parou de vez de ser usado. Com um conjunto limitado de instruções, a versão MS é incapaz de decodificar o assembly de 32 bits, mostrar os registradores extendidos e de depurar em modo protegido.
O FreeDOS é um projeto de fonte aberto que procura criar uma réplica do sistema MS-DOS, com todos seus aplicativos (e um pouco mais). Entre eles, podemos encontrar o Debug refeito e melhorado. A versão com código-fonte possui suporte às instruções &amp;quot;novas&amp;quot; dos processadores 32 e suporta acesso à memória extendida, modo protegido e melhorias na &amp;quot;interface com o usuário&amp;quot; (como repetição de comandos automática, mudança no valor dos registradores em uma linha, etc). Enfim, nada mau.
É por isso que comecei a utilizá-lo e é nele que me baseio o tutorial logo abaixo.
Para conseguirmos essa proeza é necessário reiniciarmos a máquina com algum sistema 16 bits, de preferência que caiba em um disquete. Junto com ele basta uma cópia do debug.com. Após reiniciarmos e aparecer o prompt de comando, podemos chamar o depurador e começar a diversão:
A MBR fica localizada no primeiro setor do HD ativo (master). A BIOS automaticamente procura esse HD e faz a leitura usando a INT13, função da própria BIOS para leitura de disquetes e derivados.
Lembre-se que nem sempre existirá um MS-DOS para usarmos a INT21, tradicionalmente reservada para este sistema operacional. Portanto, se acostume com as &amp;quot;limitações&amp;quot; das funções básicas da BIOS.
O debug.com inicialmente começa a execução em um espaço de memória baixa. Podemos escrever um assembly qualquer nessa memória e começar a executar. Isso é exatamente o que iremos fazer, e a instrução escolhida será a INT13, pois iremos ler o primeiro setor do HD para a memória e começar a executá-lo. Isso é a depuração da MBR.
Para fazer isso, algumas informações são necessárias, e tudo está disponível no sítio muito simpático e agradável de Ralf Brown, o cara que enumerou todas as interrupções conhecidas, além de diversas outras coisas.
Como queremos ler um setor do disco, a função da interrupção que devemos chamar é a AH=02:
Muito bem. Tudo que temos a fazer é preencher os registradores com os valores corretos:
Essa é a maneira em que as coisas são. Você certamente poderia usar outro endereço, mas estamos tentando deixar a emulação de um boot o mais próximo possível de um boot de verdade. E, tradicionalmente, o endereço de execução da MBR é em 0000:7E00. Para recordar disso, basta lembrar que o tamanho de um setor é de 0x200 bytes, e que dessa forma a MBR vai parar bem no final do endereçamento baixo (apenas offset).
Essa organização é diferente do endereço inicial da BIOS, que é por padrão 0xFFFF0.
Após definir corretamente os registradores, tudo que temos que fazer é escrever uma chamada à INT13 no endereço atual e executar. O conteúdo inicial do disco será escrito no endereço de memória 0000:7E00. Após isso trocamos o IP atual para esse endereço e começamos a depurar a MBR, como se estivéssemos logo após o boot da máquina.
Além da MBR, muitas vezes é preciso depurar a própria BIOS para descobrir o que está acontecendo. Nesse caso, tudo que precisamos fazer é colocar o ponteiro de próxima instrução para a região de memória 0xFFFF0, que traduzido para segmento/offset fica f000:fff0 (mais explicações sobre isso talvez em um futuro artigo).
</description>
</item>

     
        <item>
  <title>Como rodar qualquer coisa como serviço</title>
  <link>http://www.caloni.com.br/como-rodar-qualquer-coisa-como-servico/</link>
  <pubDate>2008-03-20</pubDate>
  
  <guid>http://www.caloni.com.br/como-rodar-qualquer-coisa-como-servico/</guid>
  <description>A maior vantagem de se rodar um aplicativo como serviço, interativo ou não, é permitir que ele seja iniciado antes que seja feito um logon na máquina. Um exemplo que acontece comigo é a necessidade de depurar a GINA. Para isso, preciso que o depurador remoto do Visual Studio seja iniciado antes do logon. A solução mais fácil e rápida é rodar o Msvcmon, a parte servidora da depuração, como um serviço.
Hoje eu descobri um atalho bem interessante para isso.
Um artigo do Alex Ionescu falava sobre esse aplicativo linha de comando usado para criar, iniciar e apagar serviços. Mesmo não sendo o foco do artigo, achei muito útil a informação, pois não conhecia esse utilitário. Logo começaram a borbulhar idéias na minha mente:
&amp;quot;E se eu usasse esse carinha para iniciar o notepad?&amp;quot;
Bem, o Bloco de Notas é a vítima padrão de testes. Logo, a linha a seguir provaria que é possível rodá-lo na conta de sistema:
Porém, como todo serviço, é esperado que ele se comunique com o Gerenciador de Serviços do Windows. Como o Bloco de Notas mal imagina que agora ele é um motta-fucka service, expira o timeout de inicialização e o SCM mata o processo.
Como diria meu amigo Thiago, &amp;quot;não bom&amp;quot;.
Porém porém, o SCM não mata os processos filhos do processo-serviço. Bug? Feature? Gambi? Seja o que for, pode ser usado para iniciar o nosso querido msvcmon:
Agora, quando iniciarmos o serviço Msvcmon, o processo cmd.exe será criado, que por sua vez irá rodar o msvcmon.exe que queríamos, e ficará esperando inocentemente pela sua &amp;quot;funesta morte&amp;quot; pelo SCM.
</description>
</item>

     
        <item>
  <title>Influence Board</title>
  <link>http://www.caloni.com.br/influence-board/</link>
  <pubDate>2008-03-14</pubDate>
  
  <guid>http://www.caloni.com.br/influence-board/</guid>
  <description>Há muito tempo sou enxadrista não-praticante. Acho que os anos de programação me deixaram mais viciado em codar do que pensar no xeque-mate. No entanto, sempre que posso, dou uma escapulida do Visual Studio e jogo uma partida ou duas na rede, quase sempre, é claro, tomando um piau psicológico.
A falta de prática e estudos pesa muito para um enxadrista amador, já que facilmente esquecemos das combinações mortíferas que podemos aplicar e levar. É muito difícil ter em mente aquelas três dúzias de aberturas que já são batidas (e suas variantes), ou então as regrinhas de praxe de como detonar nas finais com um cavalo e um bispo.
Por isso mesmo aprendi em um livro uma técnica universal e independente de decoreba que levei pra vida toda, e tem me trazido algumas partidas no mínimo interessantes. Se trata de analisar o esquema de influências em cima do tabuleiro. Influências, nesse caso, se refere ao poder de fogo das peças amigas e inimigas. O interessante é que deixa-se de lado a análise das próprias peças! Se estuda tão somente o tabuleiro, e apesar de parecer um método difícil, ele melhora sua percepção gradativamente, e é responsável por muitas das partidas simultâneas jogadas às cegas por alguns ilustres GMIs.
Atenção: esse artigo trata sobre xadrez admitindo que o leitor saiba as regras básicas do jogo, assim como um pouco de estratégia. Se você chegou até aqui e está viajando, sugiro que pare de ler e vá jogar uma partida.
Vamos supor que a posição no tabuleiro em um dado momento seja a seguinte:
Ora, é um mate inevitável, não é? Agora imagine por um momento que você não tenha percebido isso, e precise de uma ajudinha para saber onde cada peça pode ir ou atacar no próximo lance.
Agora ficou muito mais fácil de perceber que a única saída do rei não possui nenhuma proteção, já que tanto o peão quanto o próprio rei não podem fazer muita coisa se a dama atacar a diagonal vulnerável. E ela pode fazer isso.
Essa maneira de mostrar as influências em um tabuleiro de xadrez eu apelidei de Influence Board, e criei um projeto em linha de comando para fazer as devidas considerações a respeito de uma posição determinada. Mas como ninguém hoje em dia gosta de usar o WinDbg pra jogar xadrez, transformei meu projeto em pseudo-plugin para o WinBoard, um famoso frontend de xadrez que costumo usar em minhas esporádicas partidas.
Após compilado, basta copiar na pasta de instalação do programa, rodá-lo e habilitar a opção &amp;quot;Show Influence&amp;quot; do menu General. Voilà! É possível até jogar às cegas com esse brinquedinho (opção Blindfold).
Bom divertimento!
</description>
</item>

     
        <item>
  <title>O mistério das pilhas diferentes</title>
  <link>http://www.caloni.com.br/o-misterio-das-pilhas-diferentes/</link>
  <pubDate>2008-03-12</pubDate>
  
  <guid>http://www.caloni.com.br/o-misterio-das-pilhas-diferentes/</guid>
  <description>Mal comecei a leitura do meu mais novo &amp;quot;mother-fucker&amp;quot; livro e já encontrei a solução para nunca mais viver o terror que vivi quando tive que testar minha engenharia reversa do artigo sobre o Houaiss. Se trata de uma simples questão que não sei por que não sigo todas as vezes religiosamente: configure seus símbolos corretamente.
Esse é o primeiro ponto abordado pelo autor, por se tratar de algo que, caso não seja bem feito, pode dar dores de cabeça piores do que o próprio problema que originou a sessão de debugging. Por isso eu repito:
Vamos acompanhar alguns momentos de tortura alheia?
Tudo aconteceu quando inesperadamente perdi metade do artigo que estava escrevendo para explicar o processo de engenharia reversa no dicionário Houaiss. Tive que refazer todos os meus testes que havia feito no laptop. Como a preguiça é a mãe de todas as descobertas, não estava com ele ligado no momento do &amp;quot;reteste&amp;quot; e por isso acabei usando a máquina desktop, mesmo.
A análise inicial consistia simplesmente em verificar as entradas e saídas da função ReadFile, na esperança de entender a formatação interna do dicionário. Repetindo a seqüência:
Se notarmos no artigo anterior, veremos que o conteúdo do arquivo lido não é em texto claro, sendo necessário passar por mais algumas instruções assembly para descobrir a função responsável por embaralhar o conteúdo na memória. Contudo, ao rodar esses comandos novamente, eis que a saída do ReadFile já vem toda legível, como se o dicionário não estivesse mais encriptado.
A leitura foi feita e o texto direto do arquivo veio em claro? O que está acontecendo? Quando abro pelo comando type ele aparece todo obscuro...
Sim, alguma coisa não-trivial acaba de acontecer. Testei esse procedimento no laptop e no desktop, sendo que esse problema aconteceu apenas no desktop. Dessa vez a curiosidade falou mais alto que a preguiça, e tive que abrir as duas máquinas e comparar os resultados.
Depois de um pouco de cabeçadas rastreando o assembly executado, descobri que o ponto onde o breakpoint havia parado não era o retorno da chamada a ReadFile. Isso eu não vou demonstrar aqui pois se trata de raciocínio de passo-a-passo no assembly até descobrir a diferença. É enfadonho e sujeito a erros. Sugiro que tente um dia desses. Para mim, o resultado lógico de tudo isso é a saída que segue:
Como podemos ver pelos comandos acima, o pseudo-registrador $ra não está mostrando o valor corretamente!
A primeira coisa que se faz numa hora dessas é comparar as versões dos componentes do depurador de ambos os ambientes. Para isso usamos o comando version.
OK. A versão instalada no desktop é bem antiga. Pode ser um indício. Fiz então a atualização e comparei novamente a saída de version.
Tudo igual.
Decidi então usar aquela lógica cética que é desenvolvida por quem costuma depurar coisas sinistras e esotéricas por anos e anos e não duvida de mais nada, mas também acredita piamente que tudo tem um motivo. Se não está aparente, basta descobri-lo. E foi o que eu fiz. Gerei dois dumps distintos, um no laptop e outro no desktop. Ambos estavam com os ponteiros de instrução apontados exatamente para a entrada da função ReadFile, início de todo esse problema. Copiei o dump do desktop para o laptop e vice-versa.
Abri o dump do desktop no laptop: tudo funcionando. Abri o dump do laptop no desktop: mesmo erro.
Conclusão óbvia: é algo relacionado com o WinDbg no desktop, uma vez que o estado da pilha que era mostrado corretamente no laptop em ambos os dumps falhava duplamente na máquina desktop.
Isso com certeza não cheira bem. Ainda mais porque do outro lado do hemisfério, meu laptop estava configurado com toda a rigidez que um laptop de WinDbgeiro deve ter:
E aí estava uma diferença plausível. Consertados os diretórios de símbolos, tudo voltou ao normal.
Procure primeiro verificar as coisas mais simples. Depois você tenta consertar o universo. Mas, primeiro, antes de tudo, veja se o cabo de rede está conectado. Ou no nosso cado de debugueiro: Configure Seus Símbolos Corretamente.
</description>
</item>

     
        <item>
  <title>Sed, Grep e afins</title>
  <link>http://www.caloni.com.br/sed-grep-e-afins/</link>
  <pubDate>2008-03-10</pubDate>
  
  <guid>http://www.caloni.com.br/sed-grep-e-afins/</guid>
  <description>Esse artigo é resultado de eu ter me matado para conseguir encontrar a forma correta de usar o aplicativo sed para fazer uma filtragem simples nos resultados de uma listagem de arquivos.
Primeiramente, eu gostaria de expressar minha total surpresa ao não conseguir encontrar um guia simples e confiável de uso dessas ferramentas na web. Existem três teorias: ou eu não sei usar as palavras mágicas certas no Google, ou a indexação das páginas realmente importantes sobre o assunto não funcionam com o Google, ou de fato não existe documentação fácil sobre o tema.
Como esta é uma exceção em anos de &amp;quot;googadas&amp;quot;, eu fico com a terceira opção.
Existem algumas ferramentas que já salvaram minha vida uma dúzia de vezes e devo admitir que são tão poderosas e flexíveis quanto difíceis de usar:
 Grep. Use esta se quiser fazer uma busca, qualquer busca, em um arquivo, um conjunto de arquivos ou uma enxurrada de caracteres do prompt de comando. Sed. Use esta se quiser processar a entrada de um arquivo, um conjunto de arquivos ou uma enxurrada de caracteres do prompt de comando. Sort. Use esta se quiser ordenar qualquer coisa da entrada padrão (inclusive arquivos, conjunto de arquivos...).  Essas ferramentas são nativas do ambiente Linux, mas podem ser instaladas no Windows através do Cygwin, do Mingw ou nativamente através das ferramentas GnuWin32.
O que eu queria era processar a saída de um programa de forma que eu tivesse a lista de todas as extensões dos arquivos. Por exemplo, para a seguinte entrada:
Eu gostaria de uma saída no seguinte formato:
Basicamente é isso.
Sabendo que processamento de entrada estaria envolvido, logo pensei em utilizar o sed para a tarefa. Justiça seja feita, depois de eu perder uma hora e meia em pesquisa eu encontrei um tutorial muito bom para quem está começando a entender melhor o funcionamento do sed, e é nele que me baseei para resolver meu problema e escrever este artigo.
Obs.: sim, eu conheço os tutoriais do Aurélio, e aprendi regex através do livro dele. Contudo, seu guia do sed não é tão bom quanto parece, e apesar de lê-lo de cabo a rabo, acabei precisando de ajuda extra.
Para filtrar o path do arquivo, e ao mesmo tempo retirar seu nome, podemos usar o seguinte comando (fora outras trilhões de variantes):
Após esse processamento, a saída é um monte de extensões vindas de um monte de arquivos:
Como podemos ver e é óbvio de imaginar, muitas extensões irão se repetir. Para eliminar as repetições e ordenar a saída da saída corretamente, usamos o comando sort:
 Os caracteres .*[]^$\ dão problemas se usados sem escape no sed, pois fazem parte dos comandos para procurar expressões regulares. Use-os com o caractere de escape . Para concatenar comandos no sed, use sempre -e &amp;quot;comando&amp;quot;. A ordem de execução dos comandos é a ordem em que eles são inseridos na linha de comando, ou seja, podemos confiar que no segundo comando o primeiro já terá sido executado e assim por diante. Para fazer o escape das barras do caminho de um arquivo temos que usar o conjunto / (obs.: caminhos em formato Unix). Para evitar esse uso enfadonho podemos substituir o caractere de divisão do comando s colocando-o na frente: s#/path#/outropath# Para agrupar expressõe, use sempre &amp;quot;(&amp;quot; e &amp;quot;)&amp;quot;. É o contrário do uso dos caracteres especiais. Coisas de Unix.  </description>
</item>

     
        <item>
  <title>Iteradores não são constantes</title>
  <link>http://www.caloni.com.br/iteradores-nao-sao-constantes/</link>
  <pubDate>2008-03-04</pubDate>
  
  <guid>http://www.caloni.com.br/iteradores-nao-sao-constantes/</guid>
  <description>Um bug que já encontrei uma dúzia de vezes entre os novatos da STL é a utilização de iteradores como se eles não fossem mudar nunca. Porém, a verdade é bem diferente: iteradores se tornam inválidos sim, e com muito mais freqüência do que normalmente se imagina. Entre as situações em que iteradores podem mudar estão as seguintes:
  Inserção de novo elemento no contêiner
  Remoção de novo elemento no contêiner
  Redimensionamento no tamanho do contêiner
  Por exemplo, o tradicional código do exemplo abaixo contém o tradicional erro de iterador inválido:
Para operações como essa, o retorno geralmente nos dá uma dica de para onde vamos na varredura do contêiner. No caso do método erase, o retorno é o próximo iterador válido, ou o final (retornado pelo método end). Um código mais esperto gera um erro mais sutil:
Algo de errado irá acontecer apenas se o elemento removido for o último localizado no contêiner.
Esse é um erro comum para os acostumados com outros tipos de iteração (ex: ponteiros) e que não estudaram os princípios básicos da STL, entre eles o da reutilização de algoritmos. Se fosse usado este princípio, nada disso teria acontecido:
Quando precisamos fazer algo nos elementos de um contêiner STL, é quase certo que existirá um algoritmo genérico para essa tarefa, seja no próprio contêiner ou na forma de função (header algorithm). Nunca se esqueça disso na hora de desenvolver seus próprios algoritmos e não precisará reinventar a roda todos os dias.
</description>
</item>

     
        <item>
  <title>Quando o ponteiro nulo não é inválido</title>
  <link>http://www.caloni.com.br/quando-o-ponteiro-nulo-nao-e-invalido/</link>
  <pubDate>2008-02-29</pubDate>
  
  <guid>http://www.caloni.com.br/quando-o-ponteiro-nulo-nao-e-invalido/</guid>
  <description>Pois bem. O mesmo amigo que me recomendou que escrevesse sobre o assunto do ponteiro nulo achou um livro sobre armadilhas em C com um exemplo que demonstra exatamente o contrário: dependendo da plataforma, ponteiros nulos são sim válidos.
Nesse caso, se tratava de um programa que iria rodar em um microprocessador, daqueles que o DQ costuma programar. Pois bem. Quando o dito cujo ligava era necessário chamar uma rotina que estava localizada exatamente no endereço 0. Para fazer isso, o código era o seguinte:
Nada mais simples: um cast do endereço 0 (apesar de normalmente inválido, 0 pode ser convertido para endereço) para ponteiro de função que não recebe parâmetros e não retorna nada, seguido de deferência (&amp;quot;o apontado de&amp;quot;) e chamada (a dupla final de parênteses).
É bem o que o autor diz depois de jogar esta expressão: &amp;quot;expressions like these strike terror into the hearts of C programmers&amp;quot;. É lógico que isso não é bem verdade para as pessoas que acompanham este blogue =)
</description>
</item>

     
        <item>
  <title>Conversor de Houaiss para Babylon - parte 1</title>
  <link>http://www.caloni.com.br/conversor-de-houaiss-para-babylon-parte-1/</link>
  <pubDate>2008-02-27</pubDate>
  
  <guid>http://www.caloni.com.br/conversor-de-houaiss-para-babylon-parte-1/</guid>
  <description>Este artigo é sobre desmontar e montar novamente. Iremos descobrir como as entradas do dicionário Houaiss eletrônico estão gravadas em um primeiro momento, para depois remontarmos essa informação de maneira que ela possa ser usada em outro dicionário de uso mais flexível, o Babylon. Ou seja, este não é um guia de vandalismo. Estava apenas querendo usar um dicionário de qualidade excelente em outro dicionário cuja interface é muito boa.
Considero o Houaiss o melhor dicionário da atualidade, uso todo santo dia e tenho todo o respeito por ele. Possuo uma cópia legalizada exatamente por isso. Além, é óbvio, pelo escandaloso cinismo que seria se eu, desenvolvedor de software, pirateasse os que utilizo. Porém, acredito que tudo tenha um limite: respeito os direitos de quem desenvolve o programa se o programa se dá ao respeito de ser pago. Quer dizer, eu realmente uso muito esse dicionário, e ele é útil para mim. Logo, nada mais justo do que adquiri-lo como manda a lei.
Assim como adquiri o Houaiss, também comprei o Babylon, um programa-dicionário, cuja interface permite buscar o significado das palavras lidas no computador simplesmente clicando nelas. A qualidade de seu dicionário português embutido é medíocre, mas o que ele ganha mesmo é em sua interface fácil para acessar palavras. Exatamente por faltar um dicionário em português de peso no Babylon, e eu ter adquirido outro muito melhor, quis que ambos funcionassem juntos, ou seja, acesso o Babylon e tenho o resultado adicional desse meu dicionário tupiniquim.
O Babylon possui um mecanismo para criação de dicionários chamado Babylon Builder. É muito simples e fácil de usar (além de ser gratuito). Sabendo que possuo ambas as licenças desses dois programas me sinto mais aliviado em tentar desencriptar a base de dados do primeiro para construir um dicionário para o segundo, e assim realizar meu sonho de consumo: um Babylon com um dicionário de peso!
É necessário que, na hora da instalação, seja escolhida a opção de copiar os arquivos para o disco. Estarei utilizando o path padrão de um Windows em português, que é &amp;quot;C:\Arquivos de Programas\Houaiss&amp;quot;.
A estrutura de diretórios interna da instalação é bem simples:
 Raiz. Arquivos de ajuda, desinstalador, executável principal, etc. Quadros. Figuras com conhecimentos gerais, como calendários, signos, línguas mais faladas, etc. Dicionário. Provavelmente onde está todo o dicionário, cerca de 120 MB.  Se analisarmos o conteúdo dos arquivos dentro da pasta Dicionario vamos descobrir que ele se parece com &amp;quot;garbage nonsense&amp;quot;, apesar de existir um certo padrão. O padrão revela que pode se tratar de uma criptografia muito simples, talvez até um simples XOR.
Sabendo que o conteúdo do dicionário está em arquivos localizados no disco, e que teoricamente o programa não deve copiar todo o conteúdo para a memória, iremos depurar o processo do dicionário de olho nas chamadas da função ReadFile.aspx) quando clicarmos em uma definição de palavra.
Ao clicar na definição de &amp;quot;programa-fonte&amp;quot;, o breakpoint é ativado:
Depois da leitura, não temos muitas alternativas a não ser fazer o tracking de chamadas até que o mesmo buffer esteja desencriptado. Esse é o caminho natural das coisas, mas poderia haver complicações secundárias, como uma cópia de buffer antes de seu uso. Estou usando passos simples porque realmente foi muito simples descobrir o segredo da ofuscação.
Pois bem. Logo depois de chamar a função Houaiss2&#43;0xb8a6c magicamente o buffer incompreensível se transformou no início da definição da palavra &amp;quot;programa-fonte&amp;quot;. Como não temos o programa-fonte do Houaiss, teremos que descer mais um nível no &amp;quot;assemblão&amp;quot;, mesmo.
(Note que reexecutei os passos anteriores para cair na mesma condição)
Estamos diante de um loop, que, ao analisar o valor de ecx, sabemos que se repete 0x200 vezes, que é exatamente o número de bytes lidos pela função ReadFile. Coincidência? Seria, se não estivesse bem no meio do loop a referência ao próprio buffer usado na leitura (08bbf1d0).
Acredito que para todo profissional de engenharia reversa a parte mais emocionante é a descoberta do grande segredo por trás do desafio, o porquê das coisas estarem como estão e o que fazer para desfazer a mágica da segurança: a chave!
Note que essa operação é realizada para cada byte lido do buffer usado na leitura do arquivo. Conseqüentemente, não é difício de imaginar que o valor 0x0B é a chave usada para ofuscar o dicionário em arquivo, subtraindo esse valor de cada byte. Para desfazer a ofuscação, portanto, basta adicionar novamente o mesmo valor, que é exatamente o que faz a instrução assembly acima, e o meu singelo código de desofuscação do dicionário Houaiss abaixo:
Parte da mágica já foi feita, talvez a mais importante e divertida. Daqui pra lá deixaremos o WinDbg de lado e analisaremos o formato em que o texto do dicionário é armazenado, ignorando sua ofuscação básica, que não é mais um problema. Como o artigo já está extenso o suficiente, vou deixar a continuação dessa empreitada para uma futura publicação.
</description>
</item>

     
        <item>
  <title>Códigos de entrevista - o ponteiro nulo</title>
  <link>http://www.caloni.com.br/codigos-de-entrevista-o-ponteiro-nulo/</link>
  <pubDate>2008-02-25</pubDate>
  
  <guid>http://www.caloni.com.br/codigos-de-entrevista-o-ponteiro-nulo/</guid>
  <description>Bom, parece que o &amp;quot;mother-fucker&amp;quot; wordpress ferrou com meu artigo sobre o Houaiss. Enquanto eu choro as pitangas aqui vai um outro artigo um pouco mais simples, mas igualmente interessante.
&amp;quot;Wanderley, tenho umas sugestões para teu blog. A primeira: Que tal analisar o código abaixo e dizer se compila ou não. Se não compilar, explicar porquê não compila. Se compilar, o que acontecerá e por quê.&amp;quot;
O código é o que veremos abaixo:
Bem, para testar a compilação basta compilar. Porém, se estivermos em uma entrevista, geralmente não existe nenhum compilador em um raio de uma sala de reunião senão seu próprio cérebro.
E é nessas horas que os entrevistadores testam se você tem um bom cérebro ou um bom currículo.
Por isso, vamos analisar passo a passo cada bloco de código e entender o que pode estar errado. Se não encontrarmos, iremos supor que está tudo certo.
Dois includes padrões, ultranormal, nada de errado aqui.
Duas ressalvas aqui: a primeira quanto ao retorno da função é void, porém a função retorna um inteiro. Na linguagem C, isso funciona, no máximo um warning do compilador. Em C&#43;&#43;, isso é erro brabo de tipagem.
A segunda ressalva diz respeito à linha obscura, sintaticamente correta, mas cuja semântica iremos guardar para o final, já que ainda falta o main para analisar.
A clássica função inicial, nada de mais aqui. Retorna um int, e de fato retorn. Chama a função func, definida acima.
A linha que guardamos para analisar contém uma operação de casting, atribuição e deferência, sendo o casting executado primeiro, operador unário que é, seguido pelo segundo operador unário, a deferência. Como sempre, a atribuição é uma das últimas. Descomprimida a expressão dessa linha, ficamos com algo parecido com as duas linhas abaixo:
Não tem nada de errado em atribuir o valor 0 a um ponteiro, que é equivalente ao define NULL da biblioteca C (e C&#43;&#43;). De acordo com a referência GNU, é recomendado o uso do define, mas nada impede utilizar o o &amp;quot;hardcoded&amp;quot;.
Porém, estamos escrevendo em um ponteiro nulo, o que com certeza é um comportamento não-definido de conseqüências provavelmente funestas. O ponteiro nulo é um ponteiro inválido que serve apenas para marcar um ponteiro como inválido. Se escrevermos em um endereço inválido, bem, não é preciso ler o padrão para saber o que vai acontecer =)
Alguns amigos me avisaram sobre algo muito pertinente: dizer que acessar um ponteiro nulo, portanto inválido, é errado e nunca deve ser feito. Como um ponteiro nulo aponta para um endereço de memória inválido, acessá-lo irá gerar uma exceção no seu sistema operacional e fazer seu programa capotar. Um ponteiro nulo é uma maneira padrão e confiável de marcar o ponteiro como inválido, e testar isso facilmente através de um if. Mais uma vez: ponteiros nulos apontando para um endereço de memória inválido (o endereço 0) nunca devem ser acessados, apenas atribuído a ponteiros.
Em código. Isso pode:
Isso não pode:
Dito isso, me sinto melhor =)
</description>
</item>

     
        <item>
  <title>Configurando seus projetos no Visual Studio</title>
  <link>http://www.caloni.com.br/configurando-seus-projetos-no-visual-studio/</link>
  <pubDate>2008-02-21</pubDate>
  
  <guid>http://www.caloni.com.br/configurando-seus-projetos-no-visual-studio/</guid>
  <description>Ao iniciar na arte da programação em C no Visual Studio, eventualmente o programador irá querer testar seus programas rodando em outra máquina que não seja a de desenvolvimento, mandar uma versão beta para amigos, pra namorada e pro seu cachorro. Geralmente, por padrão, existem algumas dependências do programa compilado com uma DLL de runtime da versão do ambiente em que foi compilado o dito cujo, dificultando um pouco a distribuição do seu motherfucker-program.
Porém, seus &amp;quot;poroberemas se acabaram-se&amp;quot;. Com o inovador configurador de projetos do Visual Studio, tudo o que você queria é possível, e ainda mais!
Nota do autor: isso não foi uma propaganda gratuita, apenas uma piada. Se fosse um verdadeiro anúncio das maravilhas do Visual Studio, eu agora estaria falando daquele tal código gerenciado e o tal do C&#43;&#43; CLI.
Inicialmente, se compilarmos um programa em Debug no Visual Studio 2005 teremos as seguintes dependências:
A DLL kernel32 é nativa e sempre estará presente no Windows. Porém, a msvcr80d não. Ela veio junto com o pacote do Visual Studio, e se não for distribuída em outras máquinas, você não conseguirá rodar seu programa, pois isso gerará o seguinte erro:
Bem, para resolver isso, a partir da IDE, temos que ir em Project, Properties, Configuration Properties, C/C&#43;&#43;, Code Generation, Runtime Library.
Existem atualmente quatro tipos de runtime que você pode escolher:
 Multi-threaded (/MT). Versão Release que não depende de DLL. Multi-threaded Debug (/MTd). Versão Debug que não depende de DLL. Multi-threaded DLL (/MD). Versão Release que depende de DLL. Multi-threaded Debug DLL (/MDd). Versão Debug que depende de DLL.  Essas runtimes são chamada de multi-threaded porque antigamente existiam versões single-threaded dessas mesmas runtimes. Contudo, versões mais novas do Visual Studio só vêm com esse sabor mesmo.
Note que, por padrão, existem dois tipos de configuração em seu projeto: Debug (para testes) e Release (para distribuição). Convém não misturar configurações Debug com DLLs Release e vice-versa, a não ser que você tenha certeza do que está fazendo.
Pois bem. Para tirar a dependência da maldita DLL, tudo que temos que fazer é alterar a configuração, nesse caso Debug, de /MDd para /MTd. E recompilar.
E testar.
Além da dependência de DLLs, alguns casos especiais vão chiar por causa dos dados do manifesto embutidos no programa compilado. Por algum motivo que eu desconheço, o programa necessita que as DLLs estejam instaladas mesmo que no Dependency Walker não mostre nada. Nesses casos, uma arrancada do manifesto na versão Debug não fará mal algum.
Acho que esses são os únicos empecilhos iniciais para testar seu programa em outras máquinas. Sempre que ver o erro exibido no começo desse artigo, desconfie de alguma dependência que não está presente na máquina. Nessas horas, ter um Dependency Walker na mão vale ouro.
</description>
</item>

     
        <item>
  <title>Os diferentes erros na linguagem C</title>
  <link>http://www.caloni.com.br/os-diferentes-erros-na-linguagem-c/</link>
  <pubDate>2008-02-15</pubDate>
  
  <guid>http://www.caloni.com.br/os-diferentes-erros-na-linguagem-c/</guid>
  <description>Uma coisa que me espanta de vez em quando é o total desconhecimento por programadores mais ou menos experientes dos níveis de erros que podem ocorrer em um fonte escrito em C ou C&#43;&#43;. Desconheço o motivo, mas desconfio que o fato de outras linguagens não terem essa divisão de processos pode causar alguma nivelação entre as linguagens e fazer pensar que o processo de compilação em C é como em qualquer outra linguagem.
Porém, para começar, só de falarmos em compilação já estamos pegando apenas um pedaço do todo, que é a geração de um programa executável em C. Tradicionalmente, dividimos esse processo em três passos:
  Preprocessamento
  Compilação
  Linkedição
  Vamos dar uma olhada mais de perto em cada um deles e descobrir erros típicos de cada processo.
O preprocessamento é especificado pelos padrões C e C&#43;&#43;, mas, tecnicamente, não faz parte da linguagem. Ou seja, antes que qualquer regra de sintaxe seja verificada no código-fonte, o preprocessamento já terá terminado.
Essa parte do processo lida com substituição de texto e diretivas baseadas em arquivos e símbolos. Por exemplo, a diretiva de preprocessamento mais conhecida
faz com que todo o conteúdo do arquivo especificado seja incluído exatamente no ponto onde for colocada essa diretiva. Isso quer dizer que, antes sequer do código-fonte ser compilado, todo o conteúdo desse header padrão estará no corpo do arquivo C.
Para evitar que o mesmo header seja incluído inúmeras vezes dentro da mesma unidade em C, causando assim erros de redefinição, existe outra diretiva muito usada para cercar esses arquivos públicos:
Esse conjunto de duas diretivas, por si só, é capaz de gerar os mais criativos e bizarros erros de compilação em C. E estamos falando de erros que ocorrem antes que sequer seja iniciado o processo de compilação propriamente dito. Obviamente que os erros serão capturados durante a compilação, mas o motivo deles terem ocorrido foi um erro decorrente do processo de preprocessamento. Por exemplo, vamos supor que um determinado fonte necessita de uma declaração de função contida em meuheader.h:
Porém, num daqueles acasos da natureza, o header-do-mal.h define justamente o que não poderia definir jamais (obs.: e isso pode muito bem acontecer na vida real, se usamos definições muito comuns):
Na hora do preprocessamento, o preprocessador não irá mais incluir o conteúdo dentro de header.h:
Conseqüentemente, durante a compilação do código-fonte já preprocessado, sem a declaração da função meuheaderFunc, irá ocorrer o seguinte erro:
Isso em fontes pequenos é facilmente identificável. Em fontes maiores, é preciso ter um pouco mais de cuidado.
Após o processo de preprocessamento, de todos os arquivos indicados terem sido incluídos, de todas as macros terem sido substituídas, todas as constantes colocadas literalmente no código-fonte, temos o que é chamado unidade de compilação, que será entregue ao compilador, que, por sua vez, irá começar a análise sintática de fato, descobrindo novos erros que podem ou não (como vimos) ter a ver com a fase anterior. A figura abaixo ilustra esse processo, com algumas trocas conhecidas:
Dica: quando o bicho estiver pegando, e tudo o que você sabe sobre linguagem C não estiver te ajudando a resolver um problema, tente gerar uma unidade de compilação em C e analisar sua saída. Às vezes o que é claro no código pode se tornar obscuro após o preprocessamento. Para fazer isso no VC&#43;&#43; em linha de comando, use o parâmetro /E.
Se você conseguir passar ileso para a fase de compilação, pode se considerar um mestre do preprocessamento. Por experiência própria, posso afirmar que a maior parte do tempo gasto corrigindo erros de compilação, por ironia do destino, não terá origem na compilação em si, mas no preprocessamento e linkedição. Isso porque o preprocessamento confunde muito o que vimos no nosso editor preferido, e a linkedição ocorre em uma fase onde não importa mais o que está dentro das funções, mas sim o escopo de nomes, um assunto um pouco mais vago do que a linguagem C.
Aqui você irá encontrar geralmente erros bem comportados, como conversão entre tipos, else sem if e esquecimento de pontuação ou parênteses.
Um outro erro que já encontrei algumas vezes é quando a definição de uma classe tem um sizeof diferente do compilado em sua LIB, pela exclusão ou adição de novos membros. Isso pode (vai) fazer com que, durante a execução, a pilha seja corrompida, membros diferentes sejam acessados, entre outras traquinagens. Esses erros costumam acusar a falta de sincronismo entre os headers usados e suas reais implementações.
Enfim, na vida real, é impossível catalogar todos os erros que podem ocorrer em um fonte em C. Se isso fosse possível, ou não existiriam bugs, ou pelo menos existiria uma ferramenta para automaticamente procurar por esses erros e corrigi-los.
Criei uma solução no Visual Studio com alguns erros básicos, alguns demonstrados aqui, outros não, mas enfim, completamente configuráveis e divididos nessas três fases. É possível habilitar e desabilitar erros através do header cpperrors.h. Espero que gostem.
</description>
</item>

     
        <item>
  <title>Funky do-while</title>
  <link>http://www.caloni.com.br/funky-do-while/</link>
  <pubDate>2008-02-13</pubDate>
  
  <guid>http://www.caloni.com.br/funky-do-while/</guid>
  <description>It&#39;s a known habit to use do-while constructions when there&#39;s a need to define a macro that has more than one command instead of using the { simple multicommand brackets }. What was never clear is why this is so.
Let&#39;s imagine a trace macro that&#39;s enabled in debug mode, whilst kept in silence in release builds:
Nothing much, but it seems to work. But, as we going to see in the following lines, it is really a buggy piece of code, since a call inside an if-else construction simply doesn&#39;t work.
Why&#39;s that? In order to answer this question, we need to look closer into the result code from the preprocessor, just replacing the macro for its piece of code:
So, that&#39;s why. When we call a macro, generally we use the funcion-call syntax, putting a semicolon in the end. This is the right way to call a function, but in the macro case, it&#39;s a disaster, because it creates two commands instead of one (an empty semicolon, despite doing nothing, it&#39;s a valid command). So that&#39;s what the compiler does:
Think about the empty command as if it was a real command, what is the easier way to realize the compiler error:
printf(&amp;quot;here we go&amp;quot;);
For this reason, the tradicional way to skip this common error is to use a valid construction who asks for a semicolon in the end. Fortunately, language C has such construction, and it is... right, the do-while!
;
So we can rewrite our trace macro the right way, even being a funcky one:
Using a do-while (with a false expression inside the test to execute the block just once) the if-else construction is allowed and working properly:
</description>
</item>

     
        <item>
  <title>Desconstruindo IOCCC</title>
  <link>http://www.caloni.com.br/desconstruindo-ioccc/</link>
  <pubDate>2008-02-11</pubDate>
  
  <guid>http://www.caloni.com.br/desconstruindo-ioccc/</guid>
  <description>Como alguns devem saber, e outros não (ou não deveriam), existe uma competição internacional para escolher quem escreve o código em C mais ofuscado. Isso mesmo. O evento se chama The International Obfuscated C Code Contest (IOCCC resumidamente) e costuma premiar anualmente os melhores &amp;quot;do ramo&amp;quot; com a chamada &amp;quot;menção desonrosa&amp;quot;.
Acredito que a real valia de um campeonato desse porte é fazer as pessoas pensarem mais a fundo sobre as regras da linguagem. Isso faz com que erros mais obscuros que encontramos no dia-a-dia se tornem mais fáceis. Claro que ninguém deveria programar como os caras desse torneio, mas a título de aprendizagem, é uma grande aula sobre C.
Publico aqui a interpretação do primeiro programa a ganhar a tal menção desonrosa, em 1984. Se trata do batidíssimo &amp;quot;Hello World&amp;quot;, só que um pouco compactado e confuso. Vejamos o fonte original:
Aparentemente o fonte é bem confuso, apesar de podermos já ver a famosa string escondida no meio do código. Depois de aplicar uma formatação mais adequada para nossa tarefa de desfazer o feito, o resultado é bem mais legível:
Algumas construções são óbvias. Vamos então partir para as não-tão-óbvias.
Como toda variável global inteira, é inicializada com zero. Logo, a linha acima é equivalente a &amp;quot;int i =0&amp;quot;.
Aos programadores C&#43;&#43; desavisados de plantão, em C o valor de retorno padrão é int, e, caso não seja retornado nada, isso não constitui um erro, porém o comportamento é não-definido. Nada de mal, porém, pode ocorrer, a não ser o retorno de lixo da pilha.
Outra coisa óbvia, mas não tanto, é um laço for sem corpo. Ele possui apenas um ponto-e-vírgula, que identifica uma instrução nula. Não faz nada no corpo, mas pode fazer coisas interessantes no cabeçalho, ou seja, na inicialização, no teste e no incremento. Como podemos ver, a inicialização também está vazia, contendo esse laço apenas o teste e o incremento. No teste temos a seguinte comparação:
Ora, sabendo que a variável &amp;quot;i&amp;quot; inicialmente tem o valor zero, o que estamos vendo aqui é a mesma coisa que
E uma vez que aprendemos algumas peculiaridades sobre o operador de subscrito em C, sabemos que a linha acima é equivalente a essa linha abaixo:
Agora ficou mais fácil de entender. Se trocarmos a nossa string literal por uma variável (forma mais usual), temos um acesso típico a um dos caracteres de uma string:
Só precisamos lembrar que a variável i é que define a posição, e por ser uma variável, pode mudar durante a execução:
Pois bem. Agora sabemos que o laço irá ser testado pelo menos uma vez, o que quer dizer que a parte do incremento vai executar pelo menos uma vez. E essa parte é a seguinte:
Uma chamada de função. Nada mais simples. Podemos anular algumas coisas por aqui. Por exemplo, se subtraímos um número dele mesmo encontramos zero, e se dividirmos um número por ele mesmo o resultado é um:
Lembre-se de que um caractere em C é um tipo inteiro, e portanto, pode fazer parte de cálculos matemáticos. Depois dessa simplificação, temos
Agora você deveria estar se perguntando (se ainda não encontrou a resposta) do porquê de eu ter dividido os três sinais de &#43; dessa forma. Existem duas opções para a divisão:
A primeira forma é a resposta correta devido à regra de precedência (deferida pela gramática). Antes os operadores unários, depois os binários. Dessa forma, um &amp;quot;i&#43;&amp;quot; não quer dizer nada, mas &amp;quot;i&#43;&#43;&amp;quot; é um operando com um operador unário.
Voltando à expressão, imagino que a essa altura você já deva ter decifrado que i&#43;&#43; &#43; &amp;quot;hello, world!\n&amp;quot; é o mesmo que:
Ou seja, obtemos o endereço do primeiro caractere da string e incrementamos nossa variável &amp;quot;i&amp;quot; que, como sabemos, é usada no teste do laço for. Na primeira vez, testamos se o primeiro caractere de &amp;quot;] &amp;lt; i; &#43;&#43;i ){--i;}&amp;quot; é diferente de zero. Na segunda iteração, portanto, iremos testar se o segundo caractere será zero. Sabendo disso, podemos deduzir que o laço irá correr por todos os caracteres da string de teste, até encontrar o zero finalizador de string. Ao mesmo tempo, iremos enviar para a função read sempre o endereço do i&#39;ésimo caractere da string &amp;quot;hello, world!\n&amp;quot;, pois essa string também é indexada pela variável &amp;quot;i&amp;quot;.
Isso quer dizer que nosso laço irá terminar exatamente no final de ambas as strings! (Note, que para comparar as strings, usamos as strings originais do programa, sem melhorar a formatação).
Também devemos lembrar que o caractere de controle &#39;\n&#39; é representado apenas por um byte, apesar de no fonte parecer dois.
Em um passado bem longínquo, o padrão ANSI C não existia, e outras funções dominavam o ambiente UNIX. Muitas dessas funções foram adaptadas, e outras completamente copiadas para a formação do padrão. No entanto, ainda que o padrão não tenha colocado algumas funções clássicas, elas continuaram sendo usadas e suportadas. Um bom exemplo disso são as funções read e write, que, apesar de não estarem no padrão, estão no livro de K&amp;amp;R, no capítulo sobre fluxos (streams) em UNIX, provando que são bem populares.
Dentro desse mundo paralelo, existem identificadores de fluxos padrões para a entrada e a saída padrão. Melhor ainda, esses identificadores são inteiros que estão especificados da seguinte maneira (tirado da referência GNU da linguagem C, meu grifo):
&amp;quot;There are also symbolic constants defined in unistd.h for the file descriptors belonging to the standard streams stdin, stdout, and stderr; see Standard Streams.
 STDINFILENO This macro has value 0, which is the file descriptor for standard input. STDOUTFILENO This macro has value 1, which is the file descriptor for standard output. STDERRFILENO This macro has value 2, which is the file descriptor for standard error output.&amp;quot;  Agora podemos voltar ao fonte. Vejamos como é implementada a função read, chamada dentro do laço for. Como todos sabem, se uma função já é definida em sua própria unidade, não haverá uma busca por referências externas, o que quer dizer que a implementação padrão de read não atrapalha a implementação local.
Ótimo. A função read chama a função (essa sim, padrão) write. Sabemos que tanto o primeiro quanto o último parâmetro da função será sempre constante no laço for:
O que quer dizer que o primeiro argumento passado para write será sempre o mesmo:
Além da constante óbvia passada no último argumento:
Isso quer dizer que a chamada para write pode ser resumida para:
O decremento da variável &amp;quot;i&amp;quot; (dentro de read) nunca é usado, uma vez que é uma variável local. E subtrair &amp;quot;j&amp;quot; é inócuo, uma vez que o valor de &amp;quot;j&amp;quot; será sempre zero. Logo, o argumento do meio é sempre o parâmetro do meio, por mais idiota que isso possa parecer =)
Pronto, já temos condições de interpretar o significado dessa chamada à write. Como já vimos, o número 1 identifica a saída padrão, o que quer dizer que estamos escrevendo algo na saída padrão. Esse algo é o parâmetro &amp;quot;i&amp;quot; que, como vimos, é o endereço do i&#39;ésimo caractere da string &amp;quot;hello, word!\n&amp;quot;. O último argumento é o número de bytes a serem escritos, que será sempre um. O que quer dizer que o laço em for chamada a função read strlen(&amp;quot;hello, world!\n&amp;quot;) vezes passando o endereço do próximo caractere de cada vez. A função read, por sua vez, escreve este caractere na saída padrão. O resultado, como todos que compilarem o fonte e rodarem poderão comprovar, é a impressão da mensagem mais famosa do mundo da computação:
E voilà =)
Abaixo um código-fonte equivalente, devidamente desencriptado:
</description>
</item>

     
        <item>
  <title>Silly regex trick: finding the project who failed inside a big VS solution</title>
  <link>http://www.caloni.com.br/silly-regex-trick-finding-the-project-who-failed-inside-a-vs-big-solution/</link>
  <pubDate>2008-02-07</pubDate>
  
  <guid>http://www.caloni.com.br/silly-regex-trick-finding-the-project-who-failed-inside-a-vs-big-solution/</guid>
  <description>I know what you going to think about this one: &amp;quot;silly trick&amp;quot;. That&#39;s why I just put it in the title. Anyway, that is something I use everyday, so I thought it might be useful to who cares about productivity.
Let&#39;s say you have to manage a big solution in Visual Studio made of more than 30 projects, and needs to rebuild all them. Suddenly, something goes wrong. The question is: how to discover, in a heartbeat, what project has failed?
Note that you need to enable &amp;quot;Regular Expressions&amp;quot; option in the Find Dialog (not shown here).
What I&#39;m saying inside this regex is &amp;quot;find the first number different from zero followed by a space and the letters err&amp;quot;. This lead us to the first project who has at least one error:
If you think &amp;quot;what about when a project generates more than 9 errors? the regex wouldn&#39;t be able to catch this case&amp;quot;, well, you&#39;re right. Anyway, that&#39;s the quicker form to search for the unsuccessful project inside a big solution. A more complex yet complete regex would be:
For me, the first version is enough. It is faster to type, simpler to catch and solves my problem. I hope it can solve yours =)
</description>
</item>

     
        <item>
  <title>Process Monitor e o monopólio malcriado</title>
  <link>http://www.caloni.com.br/process-monitor-e-o-monopolio-malcriado/</link>
  <pubDate>2008-02-05</pubDate>
  
  <guid>http://www.caloni.com.br/process-monitor-e-o-monopolio-malcriado/</guid>
  <description>Essa é uma regra básica, mas não é fácil de cumpri-la. Só quem já tentou fazer isso sabe do que estou falando. Inúmeros programas mal-escritos vão tentar, de uma hora pra outra, acessar áreas do sistema de arquivos e registro que não possuem acesso, pois agora estão rodando em uma conta mais restrita. E não são programas de administração ou manutenção do sistema. Estou falando de programas de escritório e jogos. Aqui vai um singelo exemplo que tive que lidar esse fim-de-semana.
Primeiramente, quero deixar bem claro que jogamos Monopoly por mais ou menos dois meses sem ter qualquer tipo de problema, em três computadores diferentes. Até que resolvemos usar uma conta mais restrita. Foi o bastante para o programinha inocente começar a chiar.
Mau garoto. Bons tempos em que quando um jogo travava o máximo que tínhamos que fazer era apertar um botão.
Para encontrar problemas desse tipo, sempre uso o Process Monitor, que tem virado minha ferramenta básica para muitas coisas. Para os que não conhecem, o Process Monitor é uma ferramenta de auditoria de operações no sistema operacional, ou seja, tudo que alguém ler e escrever em arquivos e no registro será logado.
Sua função é mostrar tudo, absolutamente tudo que o sistema está fazendo em um determinado espaço no tempo. Isso pode ser ruim por um lado, já que será bem difícil encontrar alguma informação útil no meio de tanto lixo que pode ser gerado em um log de poucos momentos. Para ter uma idéia do que eu estou falando, tente abrir o Procmon sem qualquer filtro e deixá-lo rodando por 30 segundos sem fazer nada. No meu sistema, isso deu aproximadamente 20 000 linhas de eventos de log. Nada mau para um sistema ocioso.
É por isso que ele vem &amp;quot;de fábrica&amp;quot; já com uma série de filtros, que evitam lotar o log de eventos com informação sempre gerada pelo sistema, mas quase sempre inútil. Além dos filtros-padrão, podemos inserir nossos próprios filtros. É isso que faremos aqui para pegar o monopólio malcriado (sem trocadilhos).
Como podemos ver, iremos mostrar em nosso log todos os eventos cujo nome do processo seja monopolyclassic.exe (o nosso amigo faltoso) e iremos excluir do log qualquer evento cujo resultado tenha sido sucesso (se deu certo, provavelmente não é um erro).
Executamos novamente o jogo, dessa vez com o Process Monitor capturando todos seus movimentos.
Agora, uma pequena ressalva: eu estou cansado de ver isso, mas para quem nunca viu, pode não ser tão óbvio. Como eu disse no início do artigo, programas mal-escritos costumam tentar acessar áreas do sistema que não são acessíveis para usuários comuns. Isso quer dizer que, se o problema que está acontecendo com o jogo tem a ver com essa peculiaridade, a primeira coisa a procurar é por erros de acesso negado.
A primeira busca retorna uma chave no registro referente às propriedades de joystick. Como não estou usando joysticks, podemos ignorar este erro por enquanto e passar adiante.
O próximo erro diz respeito a uma tentativa de acesso ao arquivo Monopoly.log localizado no diretório de instalação do jogo, o que já é mais sugestivo. Podemos fazer um pequeno teste alterando o acesso desse arquivo.
Como podemos ver, o que é muito natural, um arquivo dentro da pasta de instalação de programas permite acesso de somente leitura para usuários comuns a seus arquivos, inclusive o Monopoly.log. Para fazer o teste, podemos simplesmente adicionar controle total a apenas esse arquivo, e rodar novamente o jogo.
Ora essa, estou conseguindo rodar o jogo! Isso quer dizer que nosso único problema, o acesso a esse arquivo, foi resolvido. Sabendo que um arquivo de log provavelmente não será executado por nenhuma conta privilegiada, podemos deixá-lo com acesso irrestrito para todos.
Para ter certeza que isso resolveu o problema, uma segunda auditoria de execução executada pelo Process Monitor pode nos revelar mais detalhes.
Moral da história: se algum dia você vier a escrever um programa inocente, deixe que pessoas inocentes consigam utilizá-lo.
</description>
</item>

     
        <item>
  <title>Compartilhando variáveis com o mundo v2</title>
  <link>http://www.caloni.com.br/compartilhando-variaveis-com-o-mundo-v2/</link>
  <pubDate>2008-02-01</pubDate>
  
  <guid>http://www.caloni.com.br/compartilhando-variaveis-com-o-mundo-v2/</guid>
  <description>Nota de desempenho: esse artigo finaliza (finalmente) a republicação de todos os artigos do antigo blogue. Isso quer dizer que a partir de agora eu sou obrigado a trabalhar, e, se quiser manter meu ritmo atual, vou ter que fazer mais do que cinco cliques do mouse.
Como todas as coisas que fazemos e pensamos depois, descobrimos que sempre existe uma outra maneira de fazer a mesma coisa. Se é melhor ou não, pode ser uma questão de gosto, estética, objetivos de vida, etc. Com a implementação das variáveis mapeadas globais não foi diferente. Bem, é isso que se espera fazer com código experimental: experimentos. E deu no que deu: SharedVar versão 2.0 alpha Enterprise Edition.
Quando comentei no final do artigo anterior que existem pessoas que só conseguem gerar código dentro de uma classe, não estava brincando. Existem linguagens, inclusive, que suportam apenas o paradigma de orientação a objetos, e levam isso muito a sério. C&#43;&#43; com certeza não é uma dessas linguagens, o que quer dizer que você tem a liberdade e a responsabilidade de tomar o melhor caminho para determinado problema.
Nessa segunda solução do nosso programa alocador de variáveis globais, pra variar, vamos utilizar uma classe. E pra entrar de vez no mundo POO vamos utilizar de quebra tratamento de erro orientado a exceções. Como vamos notar, aplicadas adequadamente, essas duas características da linguagem conseguirão um código mais simples de entender, embora não se possa dizer o mesmo da implementação &amp;quot;under the hood&amp;quot;.
Como podemos notar, em programação &amp;quot;nada se cria, tudo se reutiliza&amp;quot;. Reutilização é boa quando podemos acrescentar características adicionais ao código sem deturpar seu objetivo original. E isso é bom.
Note que nossa classe tenta fazer as coisas logo no construtor, já que seu único objetivo é representar uma variável da memória cachê. Se ela não for bem-sucedida em sua missão, ela explode, porque não há nada que ela possa fazer para garantir a integridade do objeto sendo criado e ela não tem como saber qual o melhor tratamento de erro para o usuário da classe. Geralmente o melhor - ou pelo menos o mais adequado - é o tratamento que o usuário dá ao seu código, porque o usuário da classe é que deve saber o contexto de execução do seu código.
Bem, como o código agora está em uma classe e o erro é baseado em exceção, o código cliente muda um pouco:
Existem duas mudanças significativas: 1. a variável sozinha já representa a memória compartilhada; 2. o tratamento de erro agora é centralizado em apenas um ponto. Se pra melhor ou pior, eu não sei. Tratamento de exceções e classes são duas &amp;quot;modernisses&amp;quot; que podem ou não se encaixar em um projeto de desenvolvimento. Tudo vai depender de tudo. Por isso a melhor saída depende de como será a entrada.
</description>
</item>

     
        <item>
  <title>Compartilhando variáveis com o mundo</title>
  <link>http://www.caloni.com.br/compartilhando-variaveis-com-o-mundo/</link>
  <pubDate>2008-01-30</pubDate>
  
  <guid>http://www.caloni.com.br/compartilhando-variaveis-com-o-mundo/</guid>
  <description>Desde que comecei a programar, para compartilhar variáveis entre processo é meio que consenso usar-se a milenar técnica do crie uma seção compartilhada no seu executável/DLL. Isso funciona desde a época em que o Windows era em preto e branco. Mas, como tudo em programação, existem mil maneiras de assar o pato. Esse artigo explica uma delas, a não-tão-milenar técnica do use memória mapeada nomeada misturada com templates.
Era comum (talvez ainda seja) fazer um código assim:
Aquele pragma do começo garante que qualquer instância do mesmo executável, mas processos distintos, irão compartilhar qualquer variável definida dentro da seção &amp;quot;shared&amp;quot;. O nome na verdade não importa muito - é apenas usado para clareza - , mas o atributo do final, sim.
Algumas desvantagens dessa técnica são:
  Não permite compartilhamento entre executáveis diferentes, salvo se tratar-se de uma DLL carregada por ambos.
  É um compartilhamento estático, que permanece do início do primeiro processo ao fim do último.
  Não possui proteção, ou seja, se for uma DLL, qualquer executável que a carregar tem acesso à área de memória.
  Muitas vezes essa abordagem é suficiente, como em hooks globais, que precisam apenas de uma ou duas variáveis compartilhadas. Também pode ser útil como contador de instâncias, do mesmo jeito que usamos as variáveis estáticas de uma classe em C&#43;&#43; (vide sharedptr do boost, ou a CString do ATL, que usa o mesmo princípio).
Houve uma vez em que tive que fazer hooks direcionados a threads específicas no sistema, onde eu não sabia nem qual o processo host nem quantos hooks seriam feitos. Essa é uma situação onde fica muito difícil usar a técnica milenar.
Foi daí que eu fiz um conjunto de funções alfa-beta de compartilhamento de variáveis baseado em template e memória mapeada:
Como pode-se ver, o seu funcionamento é muito simples: uma função-template que recebe uma referência para um ponteiro de ponteiro do tipo da variável desejada, o seu nome global e retorna uma variável alocada na memória de cachê do sistema. Como contraparte existe uma função que abre essa memória baseada em seu nome e faz o cast (coversão de tipo) necessário. Ambas as chamadas devem chamar uma terceira função para liberar o recurso.
O segredo para entender mais detalhes dessa técnica é pesquisar as funções envolvidas: CreateFileMapping, OpenFileMapping, MapViewOfFile e UnmapViewOfFile. Bem, o CloseHandle também ;)
Ah, é mesmo! Fiz especialmente para o artigo:
Preciso lembrar que essa é uma versão inicial ainda, mas que pode muito bem ser melhorada. Duas idéias interessantes são: parametrizar a proteção da variável (através do SECURITYATTRIBUTES) e transformá-la em classe. Uma classe parece ser uma idéia bem popular. Afinal, tem tanta gente que só se consegue programar se o código estiver dentro de uma.
  MSDN Library - by Microsoft
  Code Project - by Developers
  Google - by Google
  </description>
</item>

     
        <item>
  <title>RmThread: rode código em processo vizinho</title>
  <link>http://www.caloni.com.br/rmthread-rode-codigo-em-processo-vizinho/</link>
  <pubDate>2008-01-28</pubDate>
  
  <guid>http://www.caloni.com.br/rmthread-rode-codigo-em-processo-vizinho/</guid>
  <description>Aproveitando que utilizei a mesma técnica semana passada para desenvolver um vírus para Ethical Hacking, republico aqui este artigo que já está mofando no Code Projet, mas que espero que sirva de ajuda pra muita gente que gosta de fuçar nos internals do sistema. Boa leitura!
RmThread é um projeto que fiz baseado em uma das três idéias do artigo de Robert Kuster , &amp;quot;Three Ways to Inject Your Code into Another Process&amp;quot;. No entanto, não utilizei código algum. Queria aprender sobre isso, pesquisei pela internet, e me influenciei pela técnica CreateRemoteThread &amp;amp; LoadLibrary. O resto foi uma mistura de &amp;quot;chamada de funções certas&amp;quot; e MSDN.
O projeto que fiz é útil para quem precisa rodar algum código em um processo vizinho, mas não quer se preocupar em desenvolver a técnica para fazer isso. Quer apenas escrever o código que vai ser executado remotamente. O projeto de demonstração, RmThread.exe, funciona exatamente como a técnica citada anteriormente. Você diz qual o processo a ser executado e a DLL a ser carregada, e ele inicia o processo e carrega a DLL em seu contexto. O resto fica por conta do código que está na DLL.
Para fazer a DLL, existe um projeto de demonstração que se utiliza de uma técnica que descobri para fazer rodar algum código a partir da execução de DllMain sem ficar escravo de suas limitações (você só pode chamar com segurança funções localizadas na kernel32.dll).
Existem três funções que poderão ser utilizadas pelo seu programa:
Eis a rotina principal simplificada demonstrando como é simples a utilização das funções:
A parte mais complicada talvez seja o que fazer quando a sua DLL é carregada. Considerando que ao ser chamada em seu ponto de entrada, o código da DLL possui algumas limitações (uma já citada; para mais, vide a ajuda de DllMain no MSDN), fiz uma &amp;quot;execução alternativa&amp;quot;, criando uma thread na função DllMain:
A função da thread, por sua vez, é esperar pela finalização da thread DllMain (temos o handle dessa thread armazenado em ghThrDllMain), fazer o que tem que fazer, e retornar, liberando ao mesmo tempo o handle da DLL criado para si:
A marca TODO é aonde seu código deve ser colocado (você pode tirar o MessageBox, se quiser). Como DllMain já foi previamente executada, essa parte do código está livre para fazer o que quiser no contexto do processo vizinho.
Um detalhe interessante é que é necessária a chamada de FreeLibraryAndExitThread. Do contrário, após chamar FreeLibrary, o código a ser executado depois (um simples return) estaria em um endereço de memória inválido, já que a DLL não está mais carregada. O resultado não seria muito agradável.
Um problema chato (que você poderá encontrar) é que, se a DLL não for carregada com sucesso, não há uma maneira trivial de obter o código de erro da chamada de LoadLibrary. Uma vez que a thread inicia e termina nessa função API, o LastError se perde. Alguma idéia?
 Endereço do artigo (e fontes) no Code Project  </description>
</item>

     
        <item>
  <title>Keychanger de criança</title>
  <link>http://www.caloni.com.br/keychanger-de-crianca/</link>
  <pubDate>2008-01-24</pubDate>
  
  <guid>http://www.caloni.com.br/keychanger-de-crianca/</guid>
  <description>Às vezes na vida a vontade de fazer alguma coisa besta acaba sendo mais forte do que o senso de ridículo. Então, resolvi ressuscitar o quase apodrecido RusKey, um programa que fiz para trocar letras digitadas no teclado. A idéia é muito simples: o sujeito digita &#39;i&#39; e sai um &#39;c&#39;, digita um &#39;f&#39; e sai um &#39;u&#39;, e assim por diante. Se estiver programando e for criar um if, por exemplo, no lugar da palavra if vai aparecer... bom, não é exatamente um if que vai aparecer na tela =).
Mas se analisarmos dessa maneira pode parecer até coisa de &amp;quot;ráquer&amp;quot;, o que certamente não é. Na verdade, se trata de um programa didático que visa ensinar a digitação em leiautes de teclados diferentes do normal em idiomas latinos. Pelo menos essa foi a intenção original.
Na época eu estava às voltas com o leiaute do famoso teclado russo (percebeu a origem do nome do programa?). Eu havia estudado cirílico e estava na hora de pôr em prática no computador. Mas, como quase nunca treinava, quando tentava procurar uma palavra no Babylon ou arriscar uma expressão nas conversas com minha amiga de Moscou me perdia completamente para encontrar as letras. A necessidade é a mãe da invenção e foi aí que começou o desenvolvimento.
Um alfabeto é uma das muitas maneiras de representar as palavras de uma língua por escrito. Uma palavra escrita é um conjunto de letras que representa os sons que usamos para falar essa palavra. Cada som usado é chamado de fonema.
Assim sendo, embora o alfabeto russo seja diferente do alfabeto latino muitos fonemas são compartilhados. Isso quer dizer que podemos pegar algumas letras do cirílico e traduzir diretamente para algumas letras do nosso alfabeto, e outras letras não. Exemplos de letras que podemos fazer isso:
Porém, após a tradução de uma letra no teclado, a posição dela geralmente não é a mesma posição do nosso teclado. Daí temos uma letra de nosso alfabeto em outro lugar. Se for feita uma tradução aproximada entre os dois alfabetos, nossas letras em um teclado russo ficariam dispostas assim:
Bem diferente do QWERT ASDFG que estamos acostumados, não?
Ao digitar usando esse pseudo-leiaute o treino do leiaute do teclado russo estaria sendo feito mesmo escrevendo com o alfabeto latino. Legal, não? Poderia programar com as letras todas trocadas, porque a saída final é a mesma. Basta treinar os dedos para acertarem as mesmas letras nos novos lugares. Assim, quando precisasse escrever no alfabeto cirílico saberia melhor onde cada letra fica.
A idéia é simples, e o código também não é nada complexo. Só preciso de um EXE e uma DLL. No EXE chamo uma função exportada pela DLL que por sua vez instala um hook de mensagens:
Nas chamadas da função de callback da DLL, manipulo a mensagem WMCHAR, que corresponde à digitação de caracteres, para trocar os caracteres originais do teclado pelos caracteres que deveriam existir no recém-inventado formato latino-russo, totalmente fora dos padrões e normas de segurança existentes:
Simples assim. E temos um keylogger que troca caracteres! É impressionante como as coisas mais simples podem se transformar nos momentos mais divertidos de um programador em um feriado.
 Endereço do artigo (e fontes) no Code Project  </description>
</item>

     
        <item>
  <title>Otimização em funções recursivas</title>
  <link>http://www.caloni.com.br/otimizacao-em-funcoes-recursivas/</link>
  <pubDate>2008-01-18</pubDate>
  
  <guid>http://www.caloni.com.br/otimizacao-em-funcoes-recursivas/</guid>
  <description>O livro que estou lendo fala sobre algoritmos em C. Os primeiros capítulos são praticamente uma revisão para quem já programou em C, pois tratam de coisas que programadores com mais de cinco anos de casa devem ter na memória cachê (listas, pilhas, recursão, etc). Porém, tive uma agradável surpresa de achar um truque muito sabido que não conhecia, chamado de tail recursion. Fiz questão de testar nos dois compiladores mais conhecidos e eis o resultado.
Imagine uma função recursiva que calcula o fatorial de um número. Apenas para lembrar, o fatorial de um número n é igual a n * n-1 * n-2 * n-3 até o número 1. Existem implementações iterativas (com um laço for, por exeplo) e recursivas, que no caso chamam a mesma função n vezes.
Para ver o overhead de uma função dessas, compilamos com a opção de debug e depuramos no CDB.
Ou seja, conforme chamamos a função recursivamente, a pilha tende a crescer. Agora imagine todo o overhead da execução, que precisa, a cada chamada, gerar um stack frame.
A mesma coisa podemos notar se compilarmos o mesmo fonte no GCC e depurarmos pelo GDB. Aliás, a primeira participação especial do GDB nesse blogue =)
Isso acontece porque o compilador é obrigado a montar um novo stack frame para cada chamada da mesma função, já que os valores locais precisam manter-se intactos até o retorno recursivo da função. Porém, existe uma otimização chamada de tail recursion, que ocorre se, e somente se (de acordo com meu livro):
  A chamada recursiva é a última instrução que será executada no corpo da função.
  O valor de retorno da chamada não é parte de uma expressão.
  Note que ser a última instrução não implica em ser a última linha da função, o importante é que seja a última linha executada. No nosso exemplo, isso já é fato, só que usamos o retorno em uma expressão.
Por isso é necessário desenvolver uma segunda versão do código, que utiliza dois parâmetros para que aconteça a situação de tail recursion.
Nessa segunda versão, a chamada da função recursiva não mais é parte de uma expressão, e continua sendo a última instrução executada. Agora só temos que compilar com a opção de otimização certa em ambos os compiladores e testar.
Para o Visual Studio, podemos usar a flag /Og (otimização global).
Como podemos ver, após n chamadas, a pilha continua apenas com uma chamada a factorial.
Para o GCC, a opção é mais explítica, e funciona da mesma forma.
Voilà!
PS: De brinde uma versão que permite passar o número via linha de comando para facilitar os testes (e você vai reparar que há um problema em calcular o fatorial de 1000: ele é estupidamente grande! Resolver isso fica como exercício =).
</description>
</item>

     
        <item>
  <title>Encontrando as respostas do Flash Pops</title>
  <link>http://www.caloni.com.br/encontrando-as-respostas-do-flash-pops/</link>
  <pubDate>2008-01-16</pubDate>
  
  <guid>http://www.caloni.com.br/encontrando-as-respostas-do-flash-pops/</guid>
  <description>Existe uma série de jogos no sítio da UOL onde você deve acertar o nome de filmes, programas de televisão, entre outros, que vão da década de 40 até a atualidade. É divertido e viciante fazer pesquisa na internet para encontrar os resultados, ainda mais quando já se é viciado em cinema. Ficamos jogando, eu e minha namorada, por semanas a fio. Quase chegamos a preencher tudo, e por um bom tempo ficamos travados para terminar. Então começamos a apelar para o Google e o IMDB até os limites do razoável. Nesse fim de semana, por exemplo, chegamos a assistir um filme de madrugada onde tocou rapidamente um trecho de uma das músicas que faltava no jogo sobre televisão. No dia seguinte procuramos a trilha sonora do filme, ouvimos faixa a faixa e procuramos o nome da música no Google, para finalmente encontrar o resultado.
Essa foi a última resposta &amp;quot;honesta&amp;quot;. Depois resolvi apelar para o WinDbg =)
A primeira coisa que pensei a respeito desse jogo foi que ele não seria tão ingênuo a ponto de colocar as respostas em texto aberto, do contrário, qual seria a graça, certo? Errado! Bom, no final das contas, um passo-a-passo bem simples me levou a encontrar a lista de respostas.
A primeira coisa a fazer é carregar o jogo na memória do navegador. Em seguida, seguindo meu raciocínio inicial, digitei a primeira resposta do jogo.
A partir daí, podemos &amp;quot;atachar&amp;quot; o WinDbg no processo do navegador e rastrear a memória do processo.
[](/images/win-pan.mp3)Então, como eu dizia, não faça isso em casa enquanto estiver digitando um artigo de seu blogue dentro do navegador. Ele vai travar!
OK. A primeira coisa é procurar pela string digitada, na esperança de achar a estrutura que escreve as respostas de acordo com a digitação. Isso pode ser feito facilmente graças ao WinDbg e ao artigo de Volker von Einem que ensina como procurar strings por toda a memória de um processo (mais tarde iremos também usar o comando-bônus do comentário de Roberto Farah).
Interessante. Dois resultados. Olhando o primeiro deles, vemos que encontramos o que queríamos sem nem mesmo tentar quebrar alguma chave de criptografia.
O segundo, porém, não parece uma lista de respostas, mas sim a resposta que acabamos de digitar no navegador.
Para se certificar, rodamos novamente o navegador, apagamos a resposta e refazemos a busca.
De fato, a lista de respostas é tudo que encontramos.
Assim como no artigo sobre carregamento de DLLs arbitrárias, vamos usar o muito útil comando .foreach, que caminha em uma lista de resultados de um comando para executar uma lista secundária de comandos. Apenas para relembrar, a sintaxe do foreach é a seguinte:
  Variable. Um nome que usamos no OutCommands. Representa cada token do resultado de InCommands.
  InCommands. Um ou mais comandos que executamos para gerar uma saída na tela. Essa saída será usada em OutCommands, onde Variable é substituído por cada token da saída.
  OutCommands. Um ou mais comandos executados usando a saída na tela de InCommands.
  Para o .foreach, um token é uma string separada por espaço(s). A saída dos comandos do WinDbg nem sempre vai gerar algo que podemos usar diretamente, como no caso da busca que fizemos inicialmente. Apenas para demonstração, vamos imprimir todos os tokens da saída de nosso comando.
Isso acontece porque ele utilizada cada palavra separada por espaços da saída da busca.
Por isso usamos a flag [1], que faz com que o comando imprima apenas o endereço onde ele encontrou a string.
Enfim, vamos ao que interessa. Para imprimir todas as strings que representam as respostas, podemos simplesmente, no OutCommands, fazer uma nova busca por string, só que dessa vez genérica, dentro de uma faixa razoável (digamos, 4KB).
Bom, vou parar o dump por aqui, já que, entre os leitores, pode haver quem queria se divertir primeiro do jeito certo =)
Vimos que o jogo é facilmente quebrável porque armazena as respostas em texto claro. Uma solução alternativa seria utilizar um hash com colisão próxima de zero. Com isso bastaria trocar as respostas possíveis por hashs possíveis e armazená-los no lugar. Quando o usuário digitasse, tudo que o programa precisaria mudar era gerar um hash a partir da resposta do usuário e comparar com o hashs das respostas válidas.
Por uma incrível coincidência, esse truquezinho eu aprendi com meu amigo Thiago há poucos dias, que está lendo Reversing. Simples, porém funcional.
</description>
</item>

     
        <item>
  <title>Temas no WinDbg</title>
  <link>http://www.caloni.com.br/temas-no-windbg/</link>
  <pubDate>2008-01-14</pubDate>
  
  <guid>http://www.caloni.com.br/temas-no-windbg/</guid>
  <description>Desde a versão 6.4.7.2 que o WinDbg fornece uma subpasta chamada Themes, onde lá estão diversos workspaces configurados. Existe até um passo-a-passo de como organizar esses temas e escolher o seu favorito. Segue algumas dicas de como transformar corretamente sua área de trabalho para depuração (e mantê-la).
O WinDbg salva suas configurações no registro. Para apagar os valores previamente gravados, rode o seguinte comando:
Você pode gravar um tema, rodar o WinDbg (sem parâmetros), ver se gosta do que viu, e tentar novamente. Quando estiver satisfeito com a aparência, fique com ela e comece o próximo passo.
Nas depurações do dia-a-dia algumas configurações devem estar sempre muito bem configuradas, para que torne seus momentos de desespero porque nada está funcionando mais agradáveis. Por isso, assim que escolher seu tema preferido trate de configurar os seguintes itens:
  Diretórios de símbolos. Você pode começar com .symfix, que vai montar uma string padrão, e adicionar mais diretórios com .sympath&#43;.
  Diretórios de código-fonte. Coloque a raiz dos seus projetos principais. Com o tempo, se você mexe muito nos seus diretórios, é necessário fazer uma manutenção desse valor.
  Diretórios de executáveis. Basicamente é o mesmo do diretório de símbolos.
  Depois de configurar tudo isso, ajuste as janelas na melhor maneira e proporção que achar mais agradável. Esse será o último passo, pois depois você irá fechar o WinDbg e salvar o workspace, que a partir daí será o padrão sempre que abrir o depurador.
Como esses passos deram algum trabalho, trate de salvar as configurações, caso tenha que usá-las em outras máquinas ou restaurá-las caso algo de ruim aconteça com seu SO (como quando você depura seus drivers na mesma máquina em que desenvolve, por exemplo).
Leia a documentação do WinDbg sobre temas (dentro de Themes, Themes.doc). Foi de lá que eu fiz a tradução e adaptação dos passos mais importantes. E esqueça do Visual Studio =)
</description>
</item>

     
        <item>
  <title>Analisando dumps com WinDbg e IDA</title>
  <link>http://www.caloni.com.br/analisando-dumps-com-windbg-e-ida/</link>
  <pubDate>2008-01-10</pubDate>
  
  <guid>http://www.caloni.com.br/analisando-dumps-com-windbg-e-ida/</guid>
  <description>Apesar de ser recomendado que 100% dos componentes de um software esteja configurado corretamente para gerar símbolos na versão release, possibilitando assim a visualização do nome das funções internas através de um arquivo de dump (despejo) gerado na ocorrência de um crash, essa verdade só ocorre em 80% das vezes. Quis Murphy que dessa vez a única parte não &amp;quot;simbolizada&amp;quot; fosse a que gerou a tela azul em um Intel Quad Core que estou analisando esses dias.
Para incluir um programa novo em nosso leque de opções, vamos usar dessa vez uma ferramenta chamada IDA, um disassembler estático cujo nome é uma clara homenagem à nossa primeira programadora da história. E, é lógico, o WinDbg não poderá ficar de fora, já que ele será nosso analisador de dumps.
Tecnicamente falando, um dump nada mais é do que o conjunto de informações relevantes de um sistema em um determinado momento da execução, geralmente logo após um crash, onde tudo pára e morre. No caso do Windows, o crash é chamado de BSOD, Blue Screen Of Death, ou Tela Azul da Morte (bem macabro, não?). Do ponto de vista do usuário, é aquela simpática tela azul que aparece logo após o travamento da máquina.
Em algumas máquinas, essa tela nem mais é vista, pois o Windows XP é configurado automaticamente para exibir um simpático reboot que joga todos os seus dados não-salvos naquele momento para o limbo (ou, como diria o Thiago, para o &amp;quot;céu dos dados não-salvos antes de uma tela azul&amp;quot;).
Dumps podem ser abertos por um depurador que entenda o tipo de dump gerado (Visual Studio, WinDbg, OllyDbg, IDA, sd, etc). Se estamos falando de aplicativos que travaram, o Visual Studio pode dar conta do recado. Se é realmente uma tela azul, o WinDbg é o mais indicado.
Para abrir um dump no WinDbg, tudo que temos que fazer é usar o item do menu &amp;quot;File, Open Crash Dump&amp;quot; ou digitar direto da linha de comando:
Após alguns segundos, o WinDbg irá imprimir uma saída parecida com as linhas abaixo.
Mini Kernel Dump File: Only registers and stack trace are available
Geralmente a melhor idéia agora é seguir o conselho do WinDbg e usar o comando !analyze.
Esse é o resultado de um dos minidumps recebidos.
Um minidump contém apenas a pilha de chamada que causou a tela azul, o estados dos registradores e algumas informações sobre módulos carregados no kernel.
A partir daí podemos extrair algumas informações úteis, que eu sublinhei na saída do WinDbg. Na ordem de chegada:
  O código do Bug Check. Esse é talvez o mais importante, pois pode resolver rapidamente o nosso problema. Procurando na ajuda do WinDbg pelo código do erro (obs: execute o link pelo explorer) conseguimos ter algumas dicas de como evitar esse erro: &amp;quot;The MAXIMUMWAITOBJECTSEXCEEDED bug check has a value of 0x0000000C. This indicates that the current thread exceeded the permitted number of wait objects.&amp;quot; Mais sobre isso pra depois.
  Os dados da pilha. Pela pilha de chamadas, podemos não apenas saber se nosso driver está no meio com cara de culpado, como, através dos offsets, descobrir em que função ele se enfiou para dar no que deu.
  A última chamada do kernel antes do nosso driver pode indicar-nos que evento foi o responsável por iniciar todo o processo de cabum. Nesse caso, IopLoadDriver nos dá uma ótima dica: foi na hora de carregar o nosso driver.
  Com isso em mãos, mesmo sem símbolos e nomes de funções no código, conseguiríamos achar o código responsável pelo BSOD. Porém, vamos imaginar por um momento que não foi tão fácil assim e fazer entrar em cena outra ferramenta indispensável nessas horas: o Interactive Disassembler.
No sítio do IDA podemos encontrar o download para uma versão gratuita do IDA, isso se usado com objetivos não-comerciais. Ou seja, para você que está lendo esse blogue por aprendizado, não terá nenhum problema você baixar essa versão e fazer alguns testes com seu driver favorito.
O funcionamento básico do IDA é bem básico, mesmo. Simplesmente escolhemos um executável para ele destrinchar e nos mostrar um assembly bem amigável, com todos os nomes de funções que ele puder deduzir. Como não temos os símbolos do próprio executável, as funções internas ganham &amp;quot;apelidos&amp;quot;, como sub6669, loc13F35 e por aí vai. Isso não importa, já que temos nomes amigáveis de APIs para pesquisar no código-fonte e tentar encontrar as funções originais em C.
Pois bem. Como manda o figurino, o primeiro ponto do assembly que temos que procurar é o ponto em que uma função interna é chamada logo após IopLoadDriver, mydriver&#43;0x4058. Por coincidência (ou não, já que essa é a função do IopLoadDriver), se trata da função inicial do executável, ou seja, provavelmente a função DriverEntry no código-fonte (obs: estamos analisando um driver feito para plataforma NT).
Como podemos ver pela imagem acima, o ponto de retorno é logo após uma chamada à função sub113F0, que não sabemos qual é. No entanto, sabemos que logo no início é chamada a função IoIsWdmVersionAvailable, o que já nos permite fazer uma correlação com o código-fonte original. Após a chamada à IoIsWdmVersionAvailable, a próxima e última chamada de uma função é o que procuramos. Dessa forma, podemos ir caminhando até o ponto onde o driver chama o sistema operacional:
Voilà! O caminho não foi tão longo. Chegamos rapidamente no ponto onde é chamada a função KeWaitForMultipleObject que, de acordo com o WinDbg e com a OSR, pode gerar uma tela azul se esperarmos por mais de três objetos e não especificarmos um buffer no parâmetro WaitBlockArray. Agora podemos olhar no fonte e ver por quantos objetos esperamos e tirar nossa própria conclusão do que está acontecendo:
Ora, ora. O número de processadores influencia no número de objetos que estaremos esperando na função de espera. Esse seria um bom motivo para gerar um MAXIMUMWAITOBJECTSEXCEEDED em máquinas onde existe mais de 3 processadores ativos, não? Talvez seja uma boa hora para atualizar esse código e torná-lo compatível com os novos Quad Core.
É importante, durantes os testes de desenvolvimento, sempre manter em dia uma versão debug (para o mundo kernel mode, versões checked) para que os primeiros problemas, geralmente os mais bestinhas, sejam pêgos de forma rápida e eficiente. No entanto, um bom desenvolvedor não se limita a depurar com código-fonte. Ele deve estar sempre preparado para enfrentar problemas de falta da versão certa, informação pela metade, situação não-reproduzível. Para isso que servem as ferramentas maravilhosas que podemos usar no dia-a-dia. O IDA é mais uma das que deve estar sempre no cinto de utilidades do bom &amp;quot;debugador&amp;quot;.
</description>
</item>

     
        <item>
  <title>Como ser um melhor desenvolvedor em 2008</title>
  <link>http://www.caloni.com.br/como-ser-um-melhor-desenvolvedor-em-2008/</link>
  <pubDate>2008-01-02</pubDate>
  
  <guid>http://www.caloni.com.br/como-ser-um-melhor-desenvolvedor-em-2008/</guid>
  <description>Aproveitando que está se aproximando meu prazo final para minhas resoluções de seis meses atrás, e o DQ já fez o checklist dele, vou dar uma espiada na minha lista de desejos atual e fazer uma nova lista para 2008.
Comecei, fiz vários exercícios, mas ainda não acabei todas as aulas. Descobri que a memória pode ser muito mais bem treinada do que realmente é, e existem técnicas bem pensadas que fazem isso sem muito mais esforço do que apenas tempo despendido. De fato todos nós já temos uma memória incrível, só precisamos treiná-la adequadamente.
Como comecei e ainda não parei considero esta tarefa realizada (começar e ganhar ritmo é o mais difícil) e estendido para 2008 inteiro.
Comecei, fiz quase todos os exercícios e terminei. De fato melhorou em muito minha capacidade de concentração na hora de ler um texto rápido, embora eu ainda fique com muito sono quando faço isso. O importante agora é nunca deixar de treinar, e melhorar cada vez mais o poder dos movimentos oculares.
Não existe milagre, mas existem coisas que podemos fazer para ajudá-lo a acontecer. Foi isso que aprendi durante minhas inúmeras tentativas de dominar o tempo e o espaço no desenvolvimento de software. Aprendi muita coisa, inclusive que escritórios não foram criados para serem lugares produtivos, e quase sempre é necessário se defender dos riscos que a internet faz para a saúde.
Enfim, essa tarefa também terminou. Agora é só manutenção constante e disciplinada.
 Conclusão  Por fim, considero se achar melhor depois de ter melhorado um ou dois itens da vida profissional uma &amp;quot;escrutinisse&amp;quot;, tão inútil quanto achar-se já um desenvolvedor muito bom. Porque a qualquer hora podemos cometer novamente aquelas besteiras que fazíamos há cinco anos, e a qualquer hora podemos ter idéias brilhantes. O importante, na minha opinião, é aprender exatamente por que erramos e por que acertamos. Aprender exatamente, e lembrar-se disso, pode ser um enorme catalisador de anos de depuração aleatória.
Sem estar na lista previamente concebida, comecei a fazer outras coisas de maneira mais eficiente, seja relacionado ao trabalho ou não:
  Aprender o leiaute do teclado Dvorak. Treino todo dia cinco minutos há três meses a digitação usando esse leiaute, porque é mais simples, mais rápido e dói menos os dedos.
  Anotar todas as coisas importantes. Seja uma idéia nova, uma idéia sobre uma idéia, ou até mesmo melhoramentos em algum software que dou manutenção, é importante manter tudo anotado, porque sabe-se lá quando isso vai ser usado. Mas, quando for, quem vai se lembrar?
  Bloguear constantemente. Apesar dos sacrifícios que isso às vezes causa, é edificante nunca &amp;quot;deixar a bola cair&amp;quot;. Minha regra é sempre publicar um artigo dia sim, dia não durante a semana. Em uma semana começo na segunda, em outra na terça, e assim sucessivamente. Tem funcionado desde que reiniciei o blogue há seis meses, e espero que continue assim.
  Usar novo controle de versão em casa. Há um mês mais ou menos conheci o Mercurial, que é um sistema de controle de versão muito leve e não-centralizado, duas coisas que fazem uns sininhos soarem em minha cabeça. Ele é baseado conjunto de modificações e merge, duas coisas a que não estou acostumado e me forcei a aprender.
  Não é muito difícil definir essa lista, pois ela na verdade são as mesmas duas listas que citei anteriormente. Comecei a fazer essas coisas seis meses atrás. Para um fumante de fato parar, uns cinco anos de abstinência é um bom indicador. Acredito que, para um hábito se enraizar, um ano e meio pode ser de bom tamanho.
</description>
</item>

     
        <item>
  <title>Gambi do dia: swap com apenas duas variáveis</title>
  <link>http://www.caloni.com.br/gambi-do-dia-swap-com-apenas-duas-variaveis/</link>
  <pubDate>2007-12-31</pubDate>
  
  <guid>http://www.caloni.com.br/gambi-do-dia-swap-com-apenas-duas-variaveis/</guid>
  <description>Este artigo é uma reedição de meu blogue antigo, guardado para ser republicado durante minhas miniférias. Esteja à vontade para sugerir outros temas obscuros sobre a linguagem C ou C&#43;&#43; de sua preferência. Boa leitura!
Essa interessantíssima questão veio do meu amigo Kabloc: como trocar o valor entre duas variáveis do tipo int sem utilizar uma variável intermediária? O algoritmo ordinário para um swap entre tipos inteiros é:
Uma das soluções que eu conheço é utilizar o operador de ou exclusivo, o conhecido XOR. Esse operador binário tem a não pouco bizarra habilidade de armazenar dois padrões de bits dentro de um mesmo espaço de armazenamento. Se você tiver um dos dois padrões, conseguirá o segundo. Relembremos sua tabela verdade:
Ou seja, imagine que temos o valor 1 e o valor 0. Armazenando os dois juntos com XOR obtemos 1, já que:
Mais tarde, se quisermos obter o primeiro padrão, usamos o segundo:
Para obter o segundo padrão é só utilizar o primeiro obtido:
Calcule a mesma operação com as quatro combinações possíveis e verá que podemos sempre reaver os dados partindo de um dos padrões. Como o cálculo independe do número de bits, já que operadores bit a bit operam um bit de cada vez, podemos usar a mesma técnica para juntar dois inteiros, duas strings, dois &amp;quot;qualquer coisa armazenada numa seqüência de zeros e uns&amp;quot;:
Essa técnica é uma das mais básicas - se não for a mais - de criptografia simétrica. O primeiro padrão faz o papel de texto aberto, o segundo banca a senha e o terceiro será o texto encriptado. Para &amp;quot;desencriptar&amp;quot; o texto é necessária a senha (e se você souber qual o texto original, saberá a senha).
Mas, voltando ao nosso problema original, podemos trocar duas variáveis inteiras usando a técnica do XOR. Em claro:
Bom, preciso dizer que isso é uma gambi das grossas? Preciso dizer que NÃO uso isso no meu dia a dia, até porque swap é uma função já consagrada da STL? Não? Então sem Postscript dessa vez. E sem bois-cornetas =).
</description>
</item>

     
        <item>
  <title>Curiosidades inúteis: o operador de subscrito em C&#43;&#43;</title>
  <link>http://www.caloni.com.br/curiosidades-inuteis-o-operador-de-subscrito-em-c/</link>
  <pubDate>2007-12-27</pubDate>
  
  <guid>http://www.caloni.com.br/curiosidades-inuteis-o-operador-de-subscrito-em-c/</guid>
  <description>Este artigo é uma reedição de meu blogue antigo, guardado para ser republicado durante minhas miniférias. Esteja à vontade para sugerir outros temas obscuros sobre a linguagem C ou C&#43;&#43; de sua preferência. Boa leitura!
Em C e C&#43;&#43; as regras de sintaxe são extremamente flexíveis. Essa liberdade toda se manteve no decorrer dos tempos porque se trata de uma das idéias fundamentais da linguagem C, motivo de sua criação. Me lembro certa vez que, bitolado em C Standard 89, usei uma sintaxe não lá muito usual para acessar um elemento de um array. Foi apenas um experimento de estudante, coisa que nunca vi em código algum e queria comprovar.
As regras de acesso a elementos de um array (subscrito) são definidas não em termos do array, mas em termos de um ponteiro e de um índice. &amp;quot;Me dê um ponteiro para T e um inteiro e te retorno um lvalue do tipo T&amp;quot;. Essa é a idéia geral. A mesma idéia, com pequenas alterações, se manteve em C&#43;&#43;. Eis parte do parágrafo que fala sobre isso:
 A postfix expression followed by an expression in square brackets is a postfix expression. One of the expressions shall have the type &amp;quot;pointer to T&amp;quot; and the other shall have enumeration or integral type. The result is an lvalue of type &amp;quot;T&amp;quot;. (...) The expression E1 [ E2 ] is identical (by definition) to *( (E1) &#43; (E2) ). - C&#43;&#43;: International Standard ISO/IEC 14882 First Edition 1998-09-01
 Isso traduzido em miúdos quer dizer que com duas expressões formando a construção E1 [ E2 ], sendo uma delas do tipo ponteiro para um tipo e a outra do tipo integral, o resultado é equivalente a *( (E1) &#43; (E2) ). Como no código abaixo:
A teoria comprovada na prática: temos duas expressões no formato E1 [ E2 ] sendo uma do tipo ponteiro para char e a outra do tipo int, exatamente como a regra define. O detalhe obscuro que permaneceu durante a evolução dessas duas linguagens é que a regra de acesso a elementos não define a ordem das expressões. Assim sendo, me aproveito dessa flexibilidade e inverto os elementos do subscrito:
Isso também compila e tem o mesmo resultado, pois também é equivalente a *( (E1) &#43; (E2) ). No final dá na mesma. E do jeito que está a inversão nem dá tanto susto assim, pois estamos lidando com duas variáveis. A coisa começa a ficar mais IOCCC se colocarmos em vez de uma delas uma constante:
Isso ainda é válido, certo? Os tipos das expressões estão de acordo com a regra. Fica simples de visualizar se sempre pensarmos no &amp;quot;equivalente universal&amp;quot; *( (E1) &#43; (E2) ). Até coisas bizarras como essa acabam ficando simples:
Nota do autor: esse tipo de &amp;quot;recurso obscuro&amp;quot; dificilmente passará por uma revisão de código, e com razão, dado que não é um método útil e muito menos conhecido. Sábio é saber evitar. Não acredito, porém, que o conhecimento de certos detalhes da linguagem em que se programa sejam completamente inúteis. Conhecimento nunca é demais, pois quanto mais se conhece maior é o número de ferramentas conceituais que se dispõe para resolver um certo problema. Em muitas vezes o &amp;quot;conhecimento inútil&amp;quot; de hoje se torna um guia sábio quando se precisa de bons conceitos sobre a coisa toda. No entanto, que não venha um boi-corneta me dizer que esse código fere as boas práticas de programação. Tenho dito.
</description>
</item>

     
        <item>
  <title>O que acontece quando o contador estoura</title>
  <link>http://www.caloni.com.br/o-que-acontece-quando-o-contador-estoura/</link>
  <pubDate>2007-12-25</pubDate>
  
  <guid>http://www.caloni.com.br/o-que-acontece-quando-o-contador-estoura/</guid>
  <description>Dois conceitos de programação relacionados a limites computacionais são bem conhecidos do programador: o famigerado overflow e o não-tão-famoso underflow (embora seja fácil imaginar que ele é o oposto do primeiro). O primeiro ocorre quando somamos a uma variável inteira não-nula um valor cujo resultado não consegue ser representado pelo tamanho de memória usado para armazenar esse tipo inteiro (que pode ser um caractere, um inteiro curto, inteiro longo e por aí vai). O underflow, por outro lado (outro lado mesmo), é o resultado de uma subtração que não pode ser representado pelo número de bits do seu tipo inteiro.
Nada melhor que um código para ilustrar melhor esses dois ilustres acontecimentos:
O indicador de que algo está errado é simples: como diabos foi um número positivo virar negativo, já que eu somei ao invés de subtrair? No entanto, computacionalmente parece extremamente correto: o próximo número após o maior valor positivo possível é o menor número negativo possível.
Nos computadores atuais tudo no final acaba sendo representado por zeros e uns, até o sinal de negativo dos números menores que zero. Por isso mesmo, para que consigamos usar números menores que zero, precisamos gastar um bit para indicar que este número é negativo. Existem muitas representações interessantes, dentre as quais a mais popular acabou sendo a de complemento de dois. A regra é simples:
Toda representação binária que tiver o bit mais significativo ligado (o bit mais à esquerda) significa um número negativo cujo valor absoluto se obtém invertendo-se o resto dos bits e adicionando um.
Quando o bit mais à esquerda não está ligado o valor absoluto é ele mesmo; ou seja, é um número positivo, incluindo o zero. Como vamos ver, isso facilita em muito os cálculos para o computador. Para nós, a coisa não fica lá muito difícil. Só precisamos lembrar que, em hexadecimal, todos os valores que tiverem o byte mais significativo igual ou maior que 8 (que é 1000 em binário) é negativo e temos que aplicar o método de complemento de dois para obter seu valor absoluto. Vejamos o valor -8, por exemplo:
 Primeiro temos a representação real (em um byte): 1111 1000. O bit mais significativo está ligado: é um número negativo. Descartamos o sinal, fica 111 1000. Devemos agora inverter todos os bits: 111 1000 se torna 000 0111. Por fim, somamos um: 000 0111 &#43; 1 = 000 1000. Como vimos no parágrafo anterior, 000 1000, ou simplesmente 1000, é 8. Na verdade, -8!  Se alterarmos o código acima para imprimir na saída os números hexadecimais, obteremos a seguinte saída:
E o mais legal é que agora sabemos que o primeiro número é o maior valor positivo possível nesse tamanho de int, pois possui todos os bits ligados exceto o bit de sinal. Já o segundo número, o primeiro incrementado de 1, possui todos os bits desligados exceto o bit de sinal: é o menor número negativo possível!
</description>
</item>

     
        <item>
  <title>Banco de dados no C&#43;&#43; Builder</title>
  <link>http://www.caloni.com.br/banco-de-dados-no-c-builder/</link>
  <pubDate>2007-12-21</pubDate>
  
  <guid>http://www.caloni.com.br/banco-de-dados-no-c-builder/</guid>
  <description>Um banco de dados é qualquer lugar onde podemos ler e escrever informação geralmente persistente. Pode ser um arquivo INI, uma estrutura binária ou uma plantação de servidores para fazer busca na internet.
O uso de banco de dados em programação é mais que essencial, pois permite que armazenemos os resultados de um processamento e utilizemos esses mesmos resultados em futuras execuções.
Visando preencher algumas lacunas na internet sobre esse tema, iremos agora nos aventurar na configuração e uso de um banco de dados no C&#43;&#43; Builder.
Obs. de camarada: banco de dados pode ser uma coisa bem chata. Contudo, a vida não é completa sem as partes chatas. O conhecimento dessa área é vital para a sobrevivência de muito desenvolvedores de software. Além do mais, pode se tornar bem mais interessante em algumas situações, como o estudo sobre normalização.
Quase como um prêmio de consolação por participarmos de um sorteio que sabemos que não iremos ganhar nunca, a Caixa generosamente oferece a opção de baixarmos todos os resultados da Mega Sena desde seu início. Iremos utilizar esse banco de dados para criar uma interface de visualização de resultados no C&#43;&#43; Builder.
Um problema inicial está no fato que o arquivo está no formato HTML, um formato mais difícil de usarmos no C&#43;&#43; Builder. Portanto, irei converter este formato em algo mais maleável, como um arquivo do Microsoft Access (manipulável pelo Open Office), o famoso MDB.
Para a conversão, nada mais que algumas expressões regulares e macros de edição não resolvam em 5 minutos, sem contar a opção de importação do próprio Access.
Neste tutorial vamos usar aquilo que é o configurador oficial de banco de dados no C&#43;&#43; Builder: o BDE. Se você ainda não observou, após a instalação do C&#43;&#43; Builder um novo item surgiu no Painel de Controle, o BDE Administrator. Vamos usá-lo para configurar uma base de dados baseada no nosso arquivo MDB recém-gerado .
Criado o MDB, podemos clicar no BDE Administrator do Painel de Controle. A única coisa que precisamos fazer é criar uma nova base de dados, e especificar seus poucos parâmetros, como o tipo de base (MSACCESS) e o path de onde está o arquivo MDB.
Ah, sim, claro, também é importante colocar um nome apropriado para a base de dados: MegaSena.
A partir daí, clicando no botão Apply !BDE Apply, tudo deve fluir. Como em informática tudo quer dizer nada, eu deixo por conta do leitor a resolução de quaisquer problemas que acontecerem durante a configuração.
Criado o banco e testado (experimente conectar pelo próprio BDE) podemos agora criar um novo projeto VCL e colocar alguns componentes interessantes feitos especialmente para banco de dados. São eles:
  TDatabase: representa a própria base da dados, onde especificamos o nome da base de dados que vamos utilizar.
  TTable: representa uma tabela de uma base de dados.
  TDataSource: a origem dos dados que serão usados para popular seja lá o que quisermos popular.
  Abaixo segue a configuração de cada um deles, ou seja, as propriedades que você deve mudar para que tudo funcione.
Após todos esses componentes não-visuais terem sido inseridos no form, nada como colocar alguma coisa que o usuário veja: um TDBGrid.
Com isso, nossa janela já exibe o conteúdo da tabela em tempo de design:
E é isso! Se chegamos até aqui, já sabemos o arroz com feijão de usar banco de dados com o C&#43;&#43; Builder. Mais para a frente podemos nos aventurar em tópicos um pouco mais avançados, como fazer buscas, navegar item a item e essas coisas que as pessoas costumam fazer com um MDB.
 Borland Developer Studio: baixe a versão gratuita para desenvolver programas Win32 nativos em RAD OpenOffice: uma suíte de escritório gratuita (para ler e escrever MDBs)  </description>
</item>

     
        <item>
  <title>Drag and drop no C&#43;&#43; Builder</title>
  <link>http://www.caloni.com.br/drag-and-drop-no-c-builder/</link>
  <pubDate>2007-12-19</pubDate>
  
  <guid>http://www.caloni.com.br/drag-and-drop-no-c-builder/</guid>
  <description>O sistema de drag and drop do C&#43;&#43; Builder é muito fácil de usar, integrado que está com o sistema de classes e objetos do framework. Tanto para o objeto de drag quanto para o objeto de drop tudo que temos que fazer é definirmos a propriedade DragMode para dmAutomatic como mostra a figura. Isso fará com que toda a troca de mensagens seja manipulada automaticamente pela VCL.
A parte (ridídula) do código fica por conta da manipulação do evento de drop. Para aceitar um objeto, devemos tratar o evento OnDragOver. Basta isso para que a variável Accept tenha seu valor default definido para true. Podemos, entretanto, escolher se iremos ou não tratar um possível drop de um objeto. Verificando seu tipo, por exemplo:
A parte mais interessante do código fica por conta da hora que o objeto é &amp;quot;jogado&amp;quot;, no evento OnDragDrop. Nela recebemos o ponteiro para o Sender (como sempre), que é o target object, e um Source. Geralmente para manipular o source object é necessário antes realizar um cast para um tipo mais conhecido.
E mais uma vez voilà! Pouquíssimas linhas de código e um movimentador e empilhador de controles. Dois detalhes merecem ser destacados:
  O uso de dynamic_cast em cima dos ponteiros da VCL é uma maneira saudável de checar a integridade dos tipos recebidos - particularmente do Sender. O uso do primeiro parâmetro dos tratadores de eventos também torna o código menos preso à componentes específicos do formulário;
  O método FindChildControl é deveras útil quando não temos certeza da existência de um controle. Geralmente é uma boa idéia confiar no sistema de gerenciamento de componentes da VCL. Não é à toa que existe um framework por baixo do ambiente RAD.
  </description>
</item>

     
        <item>
  <title>Sizeof (de novo)</title>
  <link>http://www.caloni.com.br/sizeof-de-novo/</link>
  <pubDate>2007-12-17</pubDate>
  
  <guid>http://www.caloni.com.br/sizeof-de-novo/</guid>
  <description>Algumas coisas em C parecem tão simples na programação do dia-a-dia que em alguns momentos podem existir situações confusas e misteriosas. O uso obscuro do operador sizeof, por exemplo, pode dar margens a interpretações erradas a respeito do que está acontecendo por baixo dos panos. Apesar do padrão ter sido elaborado para tentar tornar a linguagem uma coisa intuitiva e de fácil dedução, isso não acontece todas as vezes.
Vamos tomar, por exemplo, o seguinte minicódigo:
A pergunta ingênua: quantos bytes são copiados para buf?
A resposta ingênua: er... o tamanho de &amp;quot;A simple string&amp;quot;?
Agora vamos supor que você é um pouco mais esperto e começa a pensar: &amp;quot;mas, peraí, estou passando na realidade um ponteiro para sizeof, o que quer dizer que, se meus cálculos estiverem corretos, e estivermos em uma plataforma de 32 bits, sizeof deve retornar 4, o que quer dizer que acabei de achar um bug escabroso, uhuu!&amp;quot;.
Muito bem, o raciocínio é perfeito. Afinal de contas, &amp;quot;A simple string&amp;quot; é um ponteiro para um array de caracteres terminados em zero, certo?
Estou quase certo disso. Porém, isso quer dizer que já deixei vários bugs escabrosos há uns 4 anos atrás em trechos de código parecidos com esse. Será que eu estava errado e não me dei conta, ou sabia de algo que esqueci faz muito tempo?
Eu e meu amigo demos uma olhada no padrão da linguagem C de 89 (revisão de 90), que diz duas coisas muito importantes nesse momento: o que é um sizeof e o que é uma string constante (chamada no padrão de string literal):
A character string literal is a sequence of zero or more multibyte characters enclosed in double-quotes, as in &amp;quot;xyz&amp;quot;. A wide string literal is the same, except prefixed by the letter L. (...) The multibyte character sequence is then used to initialize an array of static storage duration and lenght just sufficient to contain the sequence.
Em C&#43;&#43; (padrão ISO de 98) o texto é muito parecido, apenas abragendo também o conceito de type-id (desnecessário explicar para o contexto deste artigo):
A string literal is a sequence of characters (as defined in 2.13.2) surrounded by double quotes, optionally beginning with the letter L, as in &amp;quot;...&amp;quot; or L&amp;quot;...&amp;quot;. (...) An ordinary string literal has type &amp;quot;array of n const char&amp;quot; and static storage duration (...).
Os grifos são meus, para demonstrar que o operador sizeof irá retornar o número de bytes baseado no tipo do operando, e que o tipo de uma string literal é de array de caracteres com o tamanho justo para caber a string.
Bem, todos sabemos o resultado das linhas abaixo:
Nesse caso é simples de observar que o operador sizeof irá retornar 100, que é o número em bytes para abrigar o tipo do operando, que é de &amp;quot;array de 100 caracteres&amp;quot;. Podemos, então, imaginar que a nossa idiomática expressão do início é no fundo um resumo das linhas que se seguem.
Ou seja, o tipo de nossa string é na verdade de array estático de caracteres, como se uma variável tivesse sido definida anteriormente com o conteúdo da string, que deve estar em algum lugar da memória do programa. Visto dessa forma fica bem mais simples de entender o que acontece na versão resumida.
O mais encorajador desse problema do sizeof é que a resposta ingênua estava certa, ou seja, pelo menos dessa vez, o padrão conseguiu através de suas regras seguir a intuição do programador.
</description>
</item>

     
        <item>
  <title>Debug remoto no C&#43;&#43; Builder</title>
  <link>http://www.caloni.com.br/debug-remoto-no-c-builder/</link>
  <pubDate>2007-12-13</pubDate>
  
  <guid>http://www.caloni.com.br/debug-remoto-no-c-builder/</guid>
  <description>Esse é um detalhe que pode passar despercebido da maioria da população Borland, mas o Builder, assim como o Visual Studio, possui sua suíte para depuração remota. E tudo o que você precisa fazer é instalar um pacote no cliente.
  No CD de instalação, existe uma pasta chamada RDEBUG.
  Na máquina cliente, execute o arquivo setup.exe contido nesta pasta. De preferência, não instale como um serviço (a menos que tenha um motivo).
  Crie uma aplicação tosca de teste (ou use uma aplicação tosca existente).
  Lembre-se que as DLLs do Builder não estarão disponíveis na máquina remota. Para não depender delas, utilize as opções &amp;quot;Use dynamic RTL&amp;quot; (aba Link) e &amp;quot;Build with runtime packages&amp;quot; (aba Packages) do seu projeto.
  Copie a aplicação para a máquina remota ou torne-a acessível através de mapeamento.
  Em Run, Parameters, habilite na aba Remote a opção &amp;quot;Debug project on remote machine&amp;quot;
  Em Remote Path especifique o path de sua aplicação visto da máquina remota.
  Em Remote Host especifique o nome ou o IP da máquina remota.
  Execute o aplicativo através do Builder (certifique-se que o cliente do Builder está rodando na máquina remota).
  Bom proveito!
  Infelizmente essa opção não está disponível nas versões Standard do produto, assim como não está o debugging remoto no Visual Studio Express. Porém, a nova versão do Builder, renomeada para Borland Turbo C&#43;&#43;, é gratuita a possui essa feature embutida. O único porém é que a instalação não é automatizada, e os arquivos devem ser copiados &amp;quot;na mão&amp;quot;, seguindo um dos tópicos da ajuda. Melhor que nada.
Para os que utilizam o Visual Studio Express, realmente ainda não achei solução a não ser usar o bom, velho e fiel companheiro WinDbg. Não saia de casa sem ele.
</description>
</item>

     
        <item>
  <title>Gerenciamento de janelas em C&#43;&#43; Builder</title>
  <link>http://www.caloni.com.br/gerenciamento-de-janelas-em-c-builder/</link>
  <pubDate>2007-12-11</pubDate>
  
  <guid>http://www.caloni.com.br/gerenciamento-de-janelas-em-c-builder/</guid>
  <description>As janelas criadas no C&#43;&#43; Builder são equivalentes às janelas criadas pela API, com o detalhe que a VCL gerencia tudo automaticamente. Isso não quer dizer que não podemos tomar controle de tudo. Quer dizer que não precisamos.
Abra o Builder. Um projeto padrão é criado. Agora no menu File, vá em New, Form. Isso adicionará um novo formulário ao projeto padrão. Pronto! Temos dois formulários. Agora se formos dar uma passeada no WinMain, vemos que o código para iniciar a VCL se alterou conforme a música:
Porém, se rodarmos a aplicação nesse momento, podemos notar que o programa exibe apenas a janela correspondente ao primeiro formulário. De fato, ao chamar o método Application-&amp;gt;Run(), apenas o primeiro form criado é exibido. Isso não significa, é claro, que o segundo form não tenha sido criado. Para demonstrar como ele está lá, coloque o seguinte evento no clique de um botão do Form1:
Agora ao clicar do botão a janela correspondente ao formulário número 2 também aparece. Podemos fechá-la e abri-la quantas vezes quisermos que o aplicativo continua rodando. Apenas ao fechar a janela no. 1 o aplicativo realmente encerra. Esse comportamento segue o mesmo padrão da função main() na forma clássica das linguagens C/C&#43;&#43;:
Podemos, também como em C/C&#43;&#43; padrão, finalizar explicitamente a aplicação chamando o método Application-&amp;gt;Terminate. O MainForm em tempo de execução é uma propriedade de somente leitura de Application. Em tempo de design, ele pode ser alterado pela ordem de criação dos formulários no código ou pela IDE em Project, Options, Forms. Lá você também escolhe quais forms serão criados automaticamente.
Esse funcionamento e automação na criação de janelas da VCL foi feita para facilitar a vida do programador. Contudo, nunca estamos presos a somente isso. As maneiras das coisas funcionarem apenas refletem o uso mais comum no ambiente e não tem como função limitar a criatividade do desenvolvedor.
Para exemplificar, vamos inverter as coisas. Coloque um botão no segundo formulário que finalize o programa de maneira explítica:
Agora, no evento de OnClose (acho que você conhece o Object Inspector, não? Bom, se não conhece, talvez isso mereça um artigo à parte) do TForm1 insira o seguinte código:
Pronto! Agora você decide onde termina e onde acaba sua aplicação.
Se dermos uma olhada bem de perto no que acontece por dentro de um aplicativo que usa a VCL descobriremos que o método Run de Application nada mais é que o loop de mensagens que já conhecemos.
Para analisarmos melhor o que ocorre nos internals da coisa, criei um projeto simplista que possui dois forms, ambos com quatro botões: 1) mostrar o outro form, 2) esconder a si mesmo, 3) fechar a si mesmo e 4) terminar aplicação. Os dois formulários são tão parecidos que desconfio que sejam gêmeos.
Além disso, iremos precisar do nosso velho e fiel amigo WinDbg, o que o trás de volta à cena do crime depois de alguns artigos de jejum.
 Não fique de fora!  Para saber mais sobre o WinDbg e dar suas &amp;quot;WinDbgzadas&amp;quot;, dê uma olhada em alguns artigos interessantes sobre depuração usando WinDbg.
A primeira coisa que um loop de mensagens deveria fazer seria chamar a função GetMessage, que obtém a primeira mensagem em espera na fila de mensagens da thread chamadora. Portanto, vamos dar uma olhada nas chamadas dessa função:
E o resultado é... nada! Mesmo mexendo com a janela e apertando seus botões não há uma única ocorrência do GetMessage. Bruxaria? Programação oculta?
Nem tanto. Uma alternativa ao GetMessage, que captura a primeira mensagem da fila de mensagens e a retira, é o PeekMessage, que captura a primeira mensagem da fila, mas mantém a mensagem na fila. Por algum motivo, os programadores da Borland fizeram seu loop de mensagens usando PeekMessage.
Agora, sim!
Analisando os parâmetros da função PeekMessage podemos obter algumas informações interessantes sobre uma mensagem, como seu código e a janela destino:
Podemos bater essas informações com as do aplicativo Spy&#43;&#43;, que captura janelas e suas mensagens:
Normalmente esses dois rodando juntos podem causar alguns conflitos internos. Por isso, quando for usar o Spy&#43;&#43;, procure desabilitar seus breakpoints. Após mexer no Spy&#43;&#43;, feche-o antes de continuar depurando.
Como podemos ver, nesse caso a janela encontrada foi justamente a que não aparece: TApplication! Sim, a classe principal da VCL é representada em runtime por uma janela escondida, que controla algumas mensagens específicas da aplicação.
Tem tudo a ver! Mais do que simplesmente programar interfaces, esses conhecimentos permitem fazer a análise de qualquer aplicativo que possua um loop de mensagens. O importante descoberto aqui é que o C&#43;&#43; Builder, assim como o .NET, o Java e o &amp;quot;próximo framework gerenciado&amp;quot;, não pode escapar da fatal realidade de que, para exibir janelas, o aplicativo deverá dançar a música da API Win32.
</description>
</item>

     
        <item>
  <title>Interação entre controles no C&#43;&#43; Builder</title>
  <link>http://www.caloni.com.br/interacao-entre-controles-no-c-builder/</link>
  <pubDate>2007-12-05</pubDate>
  
  <guid>http://www.caloni.com.br/interacao-entre-controles-no-c-builder/</guid>
  <description>Para essa proeza precisaremos de:
Bom, sabemos já como colocar esses caras no form principal. Apenas espalhe-os de maneira que eles não fiquem uns em cima dos outros (essa técnica de espalhamento chama-se design).
Agora no evento default do Button1 (duplo-clique nele) colocaremos o seguinte código:
Percebeu? Não? Então rode e note o que acontece quando você aperta o botão.
Agora iremos fazer algo mais interessante ainda com o segundo botão. Coloque no evento default o seguinte código:
Mais simples, impossível. E com um pouco de imaginação, o mais besta dos aplicativos pode se tornar uma utilidade do dia a dia. Até sua mãe vai adorar.
</description>
</item>

     
        <item>
  <title>Conceitos básicos na programação com C&#43;&#43; Builder</title>
  <link>http://www.caloni.com.br/conceitos-basicos-na-programacao-com-c-builder/</link>
  <pubDate>2007-12-03</pubDate>
  
  <guid>http://www.caloni.com.br/conceitos-basicos-na-programacao-com-c-builder/</guid>
  <description>No projeto que é criado quando iniciamos a IDE três arquivos-fonte são gerados: Project1.cpp, Unit1.cpp e Unit1.h. Desses três, vamos analisar o primeiro:
Sim, existe um WinMain e ele não está escondido! Nele você pode fazer o que quiser. A IDE apenas auxilia você a gerenciar seus forms. Note que também existe a inclusão de um cabeçalho chamado vcl.h (obrigatório), o que nos leva diretamente para a base de toda a programação Delphi/Builder.
A VCL é o framework usado tanto no Builder quanto no Delphi para a programação RAD nesses ambientes. Considere como a MFC geração C&#43;&#43; da Borland (antes era o OWL). Todos os controles que você vê na paleta da IDE - Button, Label, CheckBox, Timer - são criados e gerenciados através da VCL. Com os mesmos nomes acrescidos do prefixo T (TButton, TCheckBox...) você tem as classes que representam em código o que você vê no ambiente RAD. Através da VCL pode-se criar novos componentes extendidos dos originais, e eles serão gerenciados pela IDE, que aliás é feita usando VCL.
Voltando ao código: o Application é um objeto visível em todo os módulos do processo e representa a aplicação em execução. Através dele você cria e destrói forms e inicia a execução da VCL. Ah, sim, é bom lembrar que todos os objetos VCL devem ser criados no heap (usando o operador new ou algum método de um objeto VCL já criado, como o CreateForm do Application). Essa e mais algumas restrições foram impostas na criação de classes VCL para que seu comportamento fosse similar/compatível com tecnologias como COM e CORBA (além das vantagens do polimorfismo e gerenciamento automático de objetos).
Olhando para o outro fonte, Unit1.h, podemos ver a definição da classe que representa o form principal:
A classe deriva de TForm, que é uma classe da VCL que representa uma janela padrão do Windows. Como se nota, um objeto da classe é criado automaticamente, exatamente o utilizado no WinMain para a criação da janela principal.
Na classe existe um escopo extendido chamado published. Nele são colocados os membros da classe que podem ser gerenciados pela IDE. Considere como um public dinâmico. Coloque um TButton no form e note que um novo membro é criado na classe, dentro do escopo gerenciado pela IDE:
Esses membros são iniciados automaticamente pela VCL. Contudo, você ainda pode criar objetos em tempo de execução e entregar o gerenciamento de seu tempo de vida para a VCL (o que significa chamar new e nunca um delete). Para essa proeza, todos os construtores de componentes devem receber um ponteiro para o seu Owner, que será o responsável por destruir o objeto. Veja como é ridículo criar um controle novo e definir algumas propriedades:
O Parent é o component que abriga a representação visual do objeto dentro de si. Parent e Owner são dois conceitos distintos. Pra frente veremos como as janelas são gerenciadas pela VCL e pela IDE.
É claro! O Borlando C&#43;&#43; Builder é coisa do passado, assim como Delphi e VB como os conhecemos. A versão nova do C&#43;&#43; Buider chama-se Turbo C&#43;&#43; (até semana passada, pelo menos). Nele as coisas são iguais mas diferentes. Ou seja, os conceitos aqui apresentados ainda valem. Só estão com uma cara diferente.
</description>
</item>

     
        <item>
  <title>Desenhando em C&#43;&#43; Builder</title>
  <link>http://www.caloni.com.br/desenhando-em-c-builder/</link>
  <pubDate>2007-11-29</pubDate>
  
  <guid>http://www.caloni.com.br/desenhando-em-c-builder/</guid>
  <description>Uma das partes mais fáceis e divertidas de se mexer no C&#43;&#43; Builder é a que lida com gráficos. A abstração da VCL toma conta da alocação e liberação dos objetos gráficos da GDI e nos fornece uma interface para desenhar linhas e figuras geométricas, mexer com bitmaps, usar fontes etc. Concomitantemente, temos acesso ao handles &amp;quot;crus&amp;quot; da Win32 API para que possamos chamar alguma função esotérica necessária para o seu programa, o que nos garante flexibilidade suficiente.
Vamos fazer da área da janela principal uma tela onde possamos desenhar. Para isso, só precisamos fazer duas coisas em nosso programa: saber quando o mouse está com algum botão pressionado e desenhar quando ele estiver sendo &amp;quot;arrastado&amp;quot;.
Saber o estado dos botões é trivial, podemos capturar isso nos eventos OnMouseDown e OnMouseUp e guardar em alguma variável.
Saber quando o mouse está sendo arrastado também é um passo trivial, uma vez que temos esse evento (OnMove) para tratar no controle da janela.
Para desenhar, todo formulário e mais alguns controles gráficos possuem um objeto chamado Canvas, do tipo TCanvas (duh). Essa classe representa uma superfície de desenho que você pode acessar a partir de seus métodos. Isso é a abstração do conhecido device context da GDI, tornando a programação mais fácil. O desenho de uma linha, por exemplo, é feito literalmente em uma linha de código.
O método LineTo() desenha uma linha do ponto onde está atualmente a caneta de desenho até a coordenada especificada. Esse é o motivo pelo qual no evento OnMouseDown alteramos a propriedade PenPos do Canvas para o ponto onde o usuário pressiona o botão do mouse.
Voila! Temos o nosso Personal PaintBrush, com toda a tosquisse que menos de 10 linhas de código podem fazer. OK, ele não é perfeito, admito, mas pode ser melhorado. Temos o código-fonte =).
Um dos problemas nele reflete o comportamento de gráficos em janelas no Windows. Seja o que for que tenhamos desenhado sobre uma janela, seu conteúdo é perdido ao ser sobrescrito por outra janela. Isso porque a memória de vídeo da área de trabalho é compartilhada entre todas as janelas do sistema (isso muda com o advento do &amp;quot;Avalon&amp;quot;). Precisamos, então, sempre repintar o que é feito durante a execução do programa.
Se precisamos repintar, logo precisamos saber tudo o que o usuário fez até então. Uma das técnicas mais baratas no quesito memória para salvar o estado gráfico de uma janela é guardar um histórico das operações realizadas sobre sua superfície e executá-las novamente ao repintar a janela. A GDI é rápida o bastante para que o custo de processamento não seja sentido na maioria dos casos. Para o nosso Paint, apenas um array de coordenadas origem-destino já dá conta do recado:
</description>
</item>

     
        <item>
  <title>Carregando DLLs arbitrárias pelo WinDbg - parte 2</title>
  <link>http://www.caloni.com.br/carregando-dlls-arbitrarias-pelo-windbg-parte-2/</link>
  <pubDate>2007-11-27</pubDate>
  
  <guid>http://www.caloni.com.br/carregando-dlls-arbitrarias-pelo-windbg-parte-2/</guid>
  <description>Como pudemos ver no artigo anterior, o processo para carregar uma DLL pelo WinDbg é muito extenso, enfadonho e sujeito a erros. Por esse motivo, e para tornar as coisas mais divertidas, resolvi transformar tudo aquilo em um simples script que pode ser executado digitando apenas uma linha.
Se trata do meu primeiro script grande para o WinDbg, por isso, peço que tenham dó de mim =).
Um script no WinDbg nada mais é que uma execução em batch: um arquivo texto cheio de comandos que poderíamos digitar manualmente, mas que preferimos guardar para poupar nossos dedos.
Existem quatro maneiras diferentes de chamar um script no WinDbg, todas muito parecidas, variando apenas se são permitidos espaços antes do nome do arquivo e se os comandos são condensados, isto é, as quebras de linhas substituídas por ponto-e-vírgula para executar tudo em uma linha só.
 $&amp;lt;nome-do-arquivo - não permite espaços e condensa comandos. $&amp;gt;&amp;lt;nome-do-arquivo - não permite espaços e não condensa comandos. $$&amp;lt;nome-do-arquivo - permite espaços e condensa comandos. $$&amp;gt;&amp;lt;nome-do-arquivo - permite espaços e não condensa comandos. $$&amp;gt;a&amp;lt;nome-do-arquivo - igual ao anterior, e ainda permite passar argumentos.  OBS: a ajuda do WinDbg descreve as diferenças dos comandos acima de forma adversa, afirmando que os comandos &#39;&amp;lt;&#39; não condensam as linhas e os &#39;&amp;gt;&amp;lt;&#39; o fazem, quando na realidade é o contrário. Não se deixe enganar por esse detalhe.
No caso do script desse artigo, utilizaremos a última forma, pois precisamos de um argumento para funcionar: o nome da DLL. Caso você não digite esse argumento, a ajuda do script será impressa:
Não há qualquer dificuldade. Tudo que você tem que fazer é baixar o script que carrega DLLs e salvá-lo em um lugar de sua preferência. Depois é só digitar o comando que carrega scripts, o path de nosso script e o nome da DLL a ser carregada em uma das três formas exibidas. Eu costumo criar uma pasta chamada &amp;quot;scripts&amp;quot; dentro do diretório de instalação do Debugging Tools, o que quer dizer que posso simplesmente chamar todos meus scripts (ou seja, 1) dessa maneira:
Abaixo um pequeno teste que fiz carregando a DLL do Direct Draw (ddraw.dll) na nossa vítima de plantão:
Simples e indolor.
Vamos agora dar uma olhada no script completo e dissecar as linhas pausadamente. Dessa forma entenderemos como a função inteira funciona e como usar os comandos isoladamente para criar novos scripts.
Como podemos ver, ele é um pouco grandinho. Por isso mesmo que ele é um script, já que não precisamos, sempre que formos usar este comando, ficar olhando para o fonte.
Por falar em olhar, uma primeira olhada revela a seguinte estrutura:
Qualquer semelhança com as instruções em C não é mera coincidência. Essa estrutura de fato verifica se o resultado dentro do .if é verdadeiro. No caso o script verifica se o primeiro parâmetro foi passado, já que os argumentos são acessíveis através dos alias (apelidos) $arg1 - $argn. Essa maneira de usar os argumentos passados no WinDbg ainda não foi documentada, mas encontrei essa dica em um artigo do Roberto Farah, um grande escritor de scripts para o WinDbg.
Da mesma forma, o que não deve ser nenhuma surpresa, o WinDbg suporta comentários. Todas as linhas que contêm &#39;$$&#39; isoladamente são comentários, e seu conteúdo da direita é ignorado, salvo se for encontrado um ponto-e-vírgula.
A primeira coisa que fazemos para carregar a DLL é salvar o estado do registrador IP, que indica onde está a próxima instrução:
Feito isso, usamos um comando não tão comum, mas que pode ser muito útil nos casos em que precisamos capturar algum dado da saída de um comando do WinDbg e usá-lo em outro comando.
A estrutura do .foreach deixa o usuário especificar dois grupos de comandos: o primeiro grupo irá gerar uma saída que pode ser aproveitada no segundo grupo.
A opção &amp;quot;/pS 5&amp;quot; diz ao comando para pular 5 posições antes de capturar o token que será usado no próximo comando. Os tokens são divididos por espaço. Sendo a saída de &amp;quot;.dvalloc 0x1000&amp;quot;
Pulando 5 posições iremos capturar o endereço onde a memória foi alocada. E é isso mesmo que queremos!
O sinônimo do endereço (alias) se torna &amp;quot;addr&amp;quot;, apelido que usamos ao executar o segundo comando, que armazena o endereço no registrador temporário $t0:
Após alocada a memória, gravamos o parâmetro de LoadLibrary, o path da DLL a ser carregada, em seu início.
O código assembly que irá chamar fica um ponto à frente, mas na mesma memória alocada.
Conforme as técnicas vão cada vez ficando mais &amp;quot;não-usuais&amp;quot;, mais difícil fica achar um nome para a coisa. Essa técnica de escrever o assembly de um código através de escritas em hexadecimal dentro de um script do WinDbg eu chamei de &amp;quot;script assembly&amp;quot;. Se tiver um nome melhor, não se acanhe em usá-lo. E me deixe saber =).
Cada comentário de uma instrução em assembly é seguido pela escrita dessa instrução usando o comando e. Se trata de um código bem trivial, fora alguns detalhes que merecem mais atenção.
Os comandos acima servem para salvar e restaurar o estado dos registradores e das flags de execução. Isso permite que possamos executar o código virtualmente em qualquer posição que pararmos no código depurado, já que retornamos tudo como estava ao final da execução do LoadLibrary. É claro que isso não garante que o código estará 100% estável em todas as condições, mas já ajuda um bocado.
Uma chamada através do opcode call (código em hexa 0xe80c) é bem comum e se trata de uma chamada relativa, baseada no estado do Instruction Pointer atual mais o valor especificado. Por isso mesmo que fazemos o cálculo usando o endereço de onde será escrita a próxima instrução, que é o valor que teremos em IP quando este call for executado:
Quando o código estiver completamente escrito na memória alocada, um disassembly dele retornará algo parecido com o código abaixo:
Você pode ver com seus próprio olhos se editar o script comentando o último comando (g), executando o script e executando o disassembly do IP.
Somos um script bem comportado (na medida do possível) e por isso colocamos um breakpoint temporário no final para, quando retornarmos para o código atual, desalocarmos a memória usada para a escrita e execução das instruções.
Eu não me responsabilizo por qualquer (mau) uso do script aqui disponibilizado, assim como as eventuais perdas de código-fonte, trilhas de HD e placas de memória RAM pela sua execução. Assim sendo, bom divertimento.
O criador do DriverEntry me questionou se não seria mais fácil, em vez de escrever todos os opcodes em hexa, usar o comando a, que permite entrar o código assembly diretamente a partir de um endereço especificado. Essa realmente é uma ótima idéia, e de fato eu tentei isso no começo de meus testes. Porém, infelizmente para scripts isso não funciona bem. A partir do comando a o prompt fica esperando uma entrada do usuário, não lendo o assembly que estaria no próprio script. Pior ainda, a escrita do assembly não permite usar os registradores temporários, como $t0 ou $t1, o que nos força a escrever um código dependende de valores constantes. Por esses motivos, tive que apelar para o comando e, que é a forma mais confusa de escrever e entender assembly. Nesse tipo de edição é vital comentar bem cada linha que se escreve.
</description>
</item>

     
        <item>
  <title>Carregando DLLs arbitrárias pelo WinDbg</title>
  <link>http://www.caloni.com.br/carregando-dlls-arbitrarias-pelo-windbg/</link>
  <pubDate>2007-11-23</pubDate>
  
  <guid>http://www.caloni.com.br/carregando-dlls-arbitrarias-pelo-windbg/</guid>
  <description>Durante meus testes para a correção de um bug me deparei com a necessidade de carregar uma DLL desenvolvida por mim no processo depurado. O detalhe é que o processo depurado é de terceiros e não possuo o fonte. Portanto, as opções para mim mais simples são:
 Usar o projeto RmThread para injetar a DLL (nesse caso iniciando o processo através dele). Fazer um módulo wrapper para uma DLL qualquer e ser carregado de brinde. Usar o WinDbg e brincar um pouco.  Por um motivo desconhecido a terceira opção me pareceu mais interessante =).
A seqüência mais simples para carregar uma DLL através do WinDbg é chamar kernel32!LoadLibrary através de um código digitado na hora, o que podemos chamar de live assembly (algo como &amp;quot;assembly ao vivo&amp;quot;). Porém, essa simples seqüência contém um pouco mais que uma dúzia de passos.
Primeiro devemos parar a execução, voltar para um ponto seguro do código e armazenar o local seguro em um registrador temporário (o WinDbg tem 20 deles, $t0 até $t19).
Parada a execução em um local seguro e armazenado o IP, em seguida podemos alocar memória para entrar o código em assembly da chamada, além do seu parâmetro, no caso o path da DLL a ser carregada.
Note que estamos usando a versão ANSI do LoadLibrary, aquela que termina com A. Sendo assim, escrevemos uma string ANSI como parâmetro usando o comando eza.
O último passo é chamar a função previamente &amp;quot;editada&amp;quot;. Para isso basta mudarmos o endereço da próxima instrução para o começo de nosso código e mandar executar, pois ele irá parar automaticamente no breakpoint que definimos &amp;quot;na mão&amp;quot;, o int 3 digitado. Após a execução devemos voltar o ponteiro usando nosso backup no registrador $t0.
Como pudemos ver pela saída, a DLL foi carregada e agora temos a possibilidade de chamar qualquer código que lá esteja. Como fazer isso? Provavelmente usando o mesmo método aqui aplicado. Live-assembly é o que manda 8).
</description>
</item>

     
        <item>
  <title>Usando a LIBC nativa do Windows</title>
  <link>http://www.caloni.com.br/usando-a-libc-nativa-do-windows/</link>
  <pubDate>2007-11-21</pubDate>
  
  <guid>http://www.caloni.com.br/usando-a-libc-nativa-do-windows/</guid>
  <description>Por padrão, todo projeto no Visual Studio depende da LIBC. Isso quer dizer que, mesmo que você não use nem um mísero printf em todos os projetos criados, está atrelado a essa dependência. Em tempos onde fazer um &amp;quot;Hello World&amp;quot; pode custar 56 KB em Release - Visual Studio 2005, configuração padrão sem &amp;quot;buffer security check&amp;quot; - vale a pena economizar alguns KBytes que não se vão usar. Principalmente se essa possibilidade existe desde o cavernoso Windows 95.
  Crie um novo projeto console Win32 vazio (File, New, Project, blá blá blá)
  Crie um arquivo CPP no projeto (Project, Add New Item, etc)
  Crie um código parecido com o código abaixo (parecido == usando apenas LIBC básica)
  Troque a configuração para Release, pois Debug não tem graça (Build, Configuration Manager, Release)
  Mude a runtime para estática (Project, Properties, C/C&#43;&#43;, Code Generation, Multi-threaded)
  Compile e link (Build, Build Solution)
  Pronto, após esses passos temos um projeto ordinário que compila um executável console ordinário que não depende de runtimes novas com exatos (pelo menos aqui) 57.344 bytes.
Agora a parte divertida =).
Desde o Windows 95, existe uma DLL com a maioria das funções da LIBC disponíveis para link dinâmico. Só que, com o uso padrão do Visual C&#43;&#43;, é usada sempre a biblioteca que vem junto com o ambiente, com suas trocentas funções (e conseqüentes bytes enche-lingüiça). Porém, é possível utilizar diretamente a msvcrt.dll distribuída no diretório do sistema se criarmos uma LIB de importação para ela.
  Copie a msvcrt.dll diretamente de um Windows 95 (diretório System) para evitar funções que não existam desde a primeira distribuição
  Utilizando essa versão da DLL e o prompt de comando do Visual Studio, execute:
  Utilizando o editor do seu coração, retire as linhas desnecessárias (aquelas do início do comando)
  Retire as colunas desnecessárias (todas menos a com o nome das funções)
  Retire os nomes bizarros que você não vai usar (todos os primeiros e que começam com &#39;?&#39;)
  Ainda no ambiente console do VC execute o seguinte comando:
  Ótimo. Geramos a LIB que precisávamos e agora só falta integrar com o projeto. Para isso, mais alguns passos:
  Copie o msvcrt.lib para o diretório do projeto.
  No projeto, coloque o arquivo na lista de LIBs a serem incluídas (Properties, Linker, Input, Additional Dependencies).
  Ignore o resto das LIBs colocadas por padrão no projeto (Linker, Input, Ignore All Default Libraries).
  Ignore as firulas de checagem (C/C&#43;&#43;, Code Generation, Buffer Security Check, e Basic Runtime Checks em Debug).
  Explicite o entry-point para a função main (Linker, Advanced, Entry Point).
  Compile e linke!
  E agora o tamanho final de nosso executável passou para espantosos 2KB! Isso a princípio parece ótimo e dá vontade de usar em todos os projetos, mas existe um porém ainda não resolvido: as limitações da falta de um runtime. Para isso que existe a próxima seção.
Essa é uma solução bem bobinha que não tem nada a ver com uma solução profissional 100% garantida e com suporte técnico 24 horas. Algumas coisas não vão funcionar, como inicialização de variáveis estáticas, exceções, redirecionamento de entrada/saída, etc. Contudo, para projetos simples e pequenos, isso não deverá ser um problema. No entanto, eu não garanto qualquer coisa que advier de compilações inspiradas neste artigo.
  Reduce EXE and DLL Size with LIBCTINY.LIB - Matt Pietrek
  Creating the smallest possible PE executable
  </description>
</item>

     
        <item>
  <title>SDelete</title>
  <link>http://www.caloni.com.br/sdelete/</link>
  <pubDate>2007-11-15</pubDate>
  
  <guid>http://www.caloni.com.br/sdelete/</guid>
  <description>Minha vida tem que ser portátil. Existem pelo menos três lugares diferentes onde costumo ficar com um computador (não o mesmo). Por causa disso, os dados mais relevantes e que precisam fazer parte do meu sistema biológico eu carrego comigo pra cima e pra baixo em meu PenDrive/MP3Player.
Até aí tudo bem. Quer dizer, mais ou menos. Dados relevantes costumam ser sensíveis, e busco sempre manter todos os arquivos sensíveis encriptados ou com uma senha específica do programa que o abre. O grande problema mesmo é que eu sei que operações no sistema de arquivos costumam deixar lastros do que já foi escrito um dia, e que é possível reaver esses dados com um pouco de persistência e sorte. É nessa hora que entra a praticidade do SDelete.
Desde a versão NT, o Windows segue as diretivas de segurança do C2, o que entre outras coisas quer dizer que o a reutilização de um objeto no sistema operacional será protegida. Um objeto aqui está para representar recursos da máquina em geral, como páginas de memória e setores do disco. Quando um programa pede um setor de disco livre (ou uma página de memória) para uso próprio, o Windows apaga qualquer conteúdo remanescente naquele espaço de memória, evitando assim que exista uma maneira do atacante obter dados de terceiros (e.g. arquivos protegidos ou memória do sistema) sem autorização.
Ou seja, desde que o Windows esteja no comando, os dados escritos por um programa não estarão disponíveis ao usuário por meio do reaproveitamento dos setores. Ficou claro?
Se ficou claro, deve ter notado o &amp;quot;desde que o Windows esteja no comando&amp;quot;. Essa é uma condição sine qua non, mas que nem sempre é verdadeira. Um atacante que tenha acesso físico ao dispositivo de armazenamento (e.g. meu PenDrive) pode certamente usar outro sistema operacional (ou até mesmo o Windows em condições especiais) e vasculhar os dados que eu já apaguei, pois estes, como mostra a figura, não são apagados de fato até que um programa peça o espaço ocupado por eles.
Para esse tipo de problema eu costumo usar um programinha esperto chamado SDelete (de Secure Delete). O que ele faz é zerar os setores não usados, da mesma forma com que o Windows faz quando um programa pede um setor não usado. Para isso, basta especificar um ou mais arquivos:
Uma outra coisa que ele faz, muito útil quando comecei a usá-lo, é apagar todos os setores não usados que existem no disco inteiro (ou uma pasta inteira). Com isso podemos começar uma vida nova. Apenas tome muito cuidado nessa hora para especificar o comando, pois um errinho no comando pode realmente fazer você começar uma vida nova.
O SDelete segue o padrão DOD 5220.22-M, o que quer dizer que ele está dentro das especificações da indústria que garantem a confidencialidade dos dados apagados. Além do mais, você pode especificar quantas &amp;quot;passadas&amp;quot; nos setores você deseja, para evitar aqueles ataques mais rebuscados em que é analisada a impedância das trilhas físicas de um disco magnético para obter os dados que uma vez estavam lá. É claro que isso não deve valer muito a pena se você está usando um PenDrive com memória flash =).
</description>
</item>

     
        <item>
  <title>MouseTool</title>
  <link>http://www.caloni.com.br/mousetool/</link>
  <pubDate>2007-11-13</pubDate>
  
  <guid>http://www.caloni.com.br/mousetool/</guid>
  <description>Well, as most of you already know, I really don&#39;t like mice. Nevertheless I respect the users who use it and like it. That is the reason why I am writing a little more about it. This time, I going to show a program I use every day: MouseTool, for the users who does not use the mouse and like it.
The program main purpose is to avoid clicking the mouse, simulating a click every time the user stops to move the cursor. Just this: simple, efficient and mouseless =).
There are some options like drag-and-drop and double-click, both available through the program. You can choose to use a keyboard shortcut or the mode state, where you can switch the program default among simple-click, double-click and drag-and-drop.
MouseTool was originally a open source tool. That means the lastest open source code is available, right? Wrong. Actually, I was unable to find it in every place I looked for.
Fortunately, my friend Marcio Andrey has got the source, and just like me, he wanted to make it available to everyone who would like to use it and change it. That&#39;s why I&#39;m publishing it in GitHub. It&#39;s free, and it&#39;s 4all =).
Let&#39;s make use of this source and show how to explore a code not written by us. Normally the first things to do are: download the compacted file and extract the files into a new folder. So we find the project file (in this case, MouseTool.dsw) and try to open it. The result is a total failure, because I believe no one use the Visual Studio version that opens this kind of file (it will convert it to another one).
Normally open source projects programmers are used to get the source code files, modify them, use them, publish them and all. But this is not always true about strict Windows commercial programmers.
Given the source files, we can explore some interesting parts we&#39;d like to do someday in our own programs. And the main part is: we have the source, but not the copyright.
Click in the link in the end of the post and make good use of it.
Update: MouseTool now has a home page and a Source Forge project! Its new name is GMouseTool.
</description>
</item>

     
        <item>
  <title>Detectando hooks globais no WinDbg</title>
  <link>http://www.caloni.com.br/detectando-hooks-globais-no-windbg/</link>
  <pubDate>2007-11-09</pubDate>
  
  <guid>http://www.caloni.com.br/detectando-hooks-globais-no-windbg/</guid>
  <description>Nada como um comando prático para aprender rapidamente uma técnica. Nesse caso, tive que usar o comando abaixo para localizar o momento em que um executável instala um hook global:
Vamos analisar cada um dos subcomandos novos um a um.
No WinDbg é possível definir um ou mais comandos que são executados quando um breakpoint é acionado. Esses comandos ficam entre aspas duplas e podem conter as mesmas coisas que digitamos na linha de comando. Alguns comandos, porém, são mais úteis que outros nesse contexto. Por exemplo, o comando &amp;quot;.echo&amp;quot;. Podemos digitar .echo na linha de comando do WinDbg. O que acontece?
Exatamente o que o comando se dispõe a fazer: imprimir seus argumentos na tela. E qual a vantagem nisso? Nenhuma, se estamos na linha de comando. Mas muita se estivermos colocando um breakpoint onde queremos contar o número de vezes que passamos por lá, o comando tem serventia:
Se essa mensagem fosse exibida mais de uma vez, poderíamos supor que é possível existir algum tipo de infecção na execução do aplicativo, como quando o código inicial carrega o original e volta a executar o mesmo ponto.
O objetivo aqui é &amp;quot;preparar o terreno&amp;quot; (ficar residente) antes que o código original seja executado. Com um simples breakpoint e um simples .echo conseguimos visualizar esse tipo de ataque. Outra possibilidade é que se trata daqueles executáveis &amp;quot;empacotados&amp;quot; por meio de algum encriptador de códigos como UPX, que desempacota o código e reexecuta o ponto de entrada do executável.
Claro, esse é apenas um uso que podemos fazer desses comandos.
Aprendi o comando j antes do .if, por isso acabo usando mais o primeiro, mas ambos possuem similaridades. O formato desse comando é exatamente como um &amp;quot;if-else&amp;quot;:
Se Expression for verdadeiro, Command1 será executado; do contrário, Command2 será. Se você não precisa do else basta usar um comando vazio &#39; &#39;. A escolha é sua em usar aspas simples ou nada. Se usar aspas simples, é possível colocar mais de um comando, que foi o que eu fiz no else:
Tudo depende do uso que você fizer desde comando. Algumas peculiaridades existem com relação ao uso de aspas duplas, simples, sem aspas, com ponto-e-vírgula, etc, mas são coisas que, como diz o Thiago, &amp;quot;só se aprende na dor&amp;quot;.
Lembram-se de nossa peregrinação pela pilha de chamadas quando fizemos um hook na função MessageBox pelo WinDbg? Aqui é a mesma coisa, pois estou analisando um parâmetro passado na pilha (esp): o ID da thread para onde vai o hook:
Relembrando nosso passeio pela pilha, ao entrar em uma função stdcall, os primeiros 4 bytes são o endereço de retorno, os próximos o primeiro parâmetro e assim por diante. O que quer dizer que:
É o apontado do quarto parâmetro (44) que está sendo verificado. Concluindo, se o parâmetro dwThreadId for igual a zero, estamos diante de um hook global, e é o momento em que meu .echo vai exibir na tela &amp;quot;** GLOBAL HOOK ***&amp;quot;. Do contrário, a execução vai continuar silenciosamente.
</description>
</item>

     
        <item>
  <title>Ponteiro de método: qual this é usado?</title>
  <link>http://www.caloni.com.br/ponteiro-de-metodo-qual-this-e-usado/</link>
  <pubDate>2007-11-07</pubDate>
  
  <guid>http://www.caloni.com.br/ponteiro-de-metodo-qual-this-e-usado/</guid>
  <description>Depois de publicado o artigo anterior sobre ponteiros de métodos surgiu uma dúvida muito pertinente do autor do blogue CodeBehind, um escovador de bits disfarçado de programador .NET: qual objeto que vale na hora de chamar um método pelo ponteiro?
Isso me estimulou a desdobrar um pouco mais os mistérios por trás dos ponteiro de métodos e de membros, e descobrir os detalhes mais ocultos desse lado esotérico da linguagem.
Para entender por inteiro o que acontece quando uma chamada ou acesso utilizando ponteiros dependentes de escopo, algumas pequenas mudanças foram feitas no nosso pequeno FuzzyCall.
O novo código chama através do mesmo ponteiro o mesmo método (duh), mas através de três objetos diferentes. Se observarmos a saída veremos que cada instância da classe guardou uma pedra diferente do saco de bingo para si (até porque, no jogo do bingo, não é possível existir mais de uma pedra com o mesmo número):
Cada compilador e plataforma tem a liberdade de implementar o padrão C&#43;&#43; da maneira que quiser, mas o conceito no final acaba ficando quase a mesma coisa. No caso de ponteiros de métodos, o ponteiro guarda realmente o endereço da função que pertence à classe. Porém, como todo método não-estático em C&#43;&#43;, para chamá-lo é necessário possuir um this, ou seja, o ponteiro para a instância:
Em assembly (comando &amp;quot;cl /Fafuzzycall3.asm fuzzycall3.cpp&amp;quot; para gerar a listagem), teremos algo assim:
Além do ponteiro de métodos, também é possível no C&#43;&#43; apontar para membros de um dado objeto. Para tanto, como vimos no código, basta declarar um tipo de ponteiro de membro de acordo com o tipo desejado:
Nesse caso, a técnica de usar o próprio enderenço não funciona, já que cada objeto possui um membro próprio em um lugar de memória próprio. Porém, assim como os ponteiros de métodos, os ponteiros de membros exigem um objeto para serem acessados, o que já nos dá a dica de onde o objeto começa. Sabendo onde ele começa, fica fácil saber onde fica o membro através do seu offset, ou seja, a distância dele a partir do início da memória do objeto. Só que para isso precisamos do offset armazenado em algum lugar. E adivinha onde que ele fica armazenado?
Podemos acompanhar este código no WinDbg (ou alguma outra IDE mais pomposa, se preferir) e veremos que o conteúdo do eax irá refletir o offset do membro dentro da classe FuzzyCall.
Como podemos ver, não é nenhuma magia negra a responsável por fazer os ponteiros de métodos e de membros funcionarem em C&#43;&#43;. Porém, eles não são ponteiros ordinário que costumamos misturar a torto e a direito. Essa distinção na linguagem é importante para manter o código &amp;quot;minimamente sadio&amp;quot;.
</description>
</item>

     
        <item>
  <title>Ponteiros de método: conceito fundamental</title>
  <link>http://www.caloni.com.br/ponteiros-de-metodo-conceito-fundamental/</link>
  <pubDate>2007-11-05</pubDate>
  
  <guid>http://www.caloni.com.br/ponteiros-de-metodo-conceito-fundamental/</guid>
  <description>Diferente de ponteiros de função (funções globais ou estáticas) - que são a grosso modo ponteiros como qualquer um - os ponteiros de método possuem uma semântica toda especial que costuma intimidar até quem está acostumado com a aritmética de ponteiros avançada. Não é pra menos: é praticamente uma definição à parte, com algumas limitações e que deixa a desejar os quase sempre criativos programadores da linguagem, que vira e mexe estão pedindo mudanças no C&#43;&#43;0x.
Três regras iniciais que devem ser consideradas para usarmos ponteiros para métodos são:
  A semântica para lidar com ponteiros de método é totalmente diferente de ponteiros de função.
  Ponteiros de método de classes distintas nunca se misturam.
  Para chamarmos um ponteiro de método precisamos sempre de um objeto da classe para a qual ele aponta.
  Visto isso, passemos a um exemplo simples, um chamador de métodos aleatórios, que ilustra o princípio básico de utilização:
Como podemos ver, para o typedef de ponteiros de método é necessário especificar o escopo da classe. Com isso o compilador já sabe que só poderá aceitar endereços de métodos pertencentes à mesma classe com o mesmo protótipo.
Na hora de atribuir, usamos o operador de endereço e o nome do método (com escopo, se estivermos fora da classe). É importante notar que, diferente de ponteiros de função, o operador de endereço é obrigatório. Do contrário:
E, por fim, a chamada. Como é a chamada de um método, é quase intuitiva a necessidade de um objeto para chamá-la. Do contrário não teríamos um this para alterar o objeto em qualquer método não-estático, certo? Daí a necessidade do padrão C&#43;&#43; especificar dois operadores especialistas para esse fim, construídos a partir da combinação de operadores já existentes em C:
Esses operadores obrigam o programador a sempre ter um objeto e um ponteiro. Daí não tem como errar. Infelizmente, devido à ordem de precedência, temos que colocar os parênteses em torno da expressão para chamar o método. Pelo menos fica equivalente ao que precisávamos fazer antes da padronização da linguagem C.
</description>
</item>

     
        <item>
  <title>Desenvolvendo em linha de comando</title>
  <link>http://www.caloni.com.br/desenvolvendo-em-linha-de-comando/</link>
  <pubDate>2007-11-01</pubDate>
  
  <guid>http://www.caloni.com.br/desenvolvendo-em-linha-de-comando/</guid>
  <description>Desde uns tempos para cá o Visual Studio tem se tornado uma das ferramentas mais pesadas de desenvolvimento já criadas. Como se não bastasse, a compilação de pequenos trechos de código é algo desnecessariamente complicado no ambiente. Por esse motivo estou ganhando o costume de usar a linha de comando para esse tipo de tarefa. Afinal de contas, na maioria das vezes a única coisa que eu preciso fazer é abrir o atalho &amp;quot;Visual Studio Command Prompt&amp;quot; e digitar uma linha:
O problema é ter que &amp;quot;andar&amp;quot; do diretório padrão de início até a pasta onde está o código-fonte que desejo compilar. Porém, isso é facilmente resolvido com uma linha (no registro):
A partir daí, o comando &amp;quot;Console&amp;quot; existe no menu de contexto de qualquer pasta que clicarmos no Windows Explorer.
Note que é possível criar outros comandos, como é o meu caso, onde preciso de vez em quando compilar utilizando o Visual Studio 2005 (o comando Console) e o Visual Studio 2003 (o comando VS2003). Ao escolher a opção, um prompt de comando é aberto com o ambiente de compilação montado e (adivinhe) com a pasta padrão sendo a que foi clicada no explorer.
Nossos projetos aqui na empresa costumam ser divididos em inúmeras soluções do Visual Studio para evitar a bagunça que seria (foi) ter que abrir uma solução de 10^24324 projetos. O problema é que, se abrir um Visual Studio já pesa, imagine abrir cinco de uma vez.
Por isso mesmo que, aproveitando que agora tenho uma linha de comando personalizada com o ambiente de compilação, faço uso da compilação de soluções em modo console que o devenv (a IDE do Visual Studio) oferece:
 Dica para programadores profissionais  Além de ser rápido, pode ser usado em builds automatizados, coisa que já fazemos. O que quer dizer que podemos matar os itens 2 e 3 do teste do Joel, nos deixando um passo mais próximo do purgatório.
Tudo bem, mas eu preciso depurar o código! Você não quer que eu use o NTSD, ou quer?
Sabe que não é uma má idéia?
Porém, se você prefere algo mais amigável, mais ainda que o WinDbg, você pode iniciar o depurador do Visual Studio por linha de comando:
Daí não tem jeito: você economiza no start, mas o Visual Studio vai acabar subindo. Ou um ou outro.
Por isso eu recomendo aprender a usar o WinDbg ou até o NTSD. Quer dizer, é muito melhor do que esperar por uma versão mais light do Visual Studio no próximo ano.
</description>
</item>

     
        <item>
  <title>Brincando com o WinDbg</title>
  <link>http://www.caloni.com.br/brincando-com-o-windbg/</link>
  <pubDate>2007-10-30</pubDate>
  
  <guid>http://www.caloni.com.br/brincando-com-o-windbg/</guid>
  <description>No primeiro artigo sobre o WinDbg usamos o aplicativo Logger para verificar as funções APIs que são chamadas por um determinado programa. Agora iremos dar um passo adiante e depurar de fato um aplicativo qualquer, com o detalhe que não teremos o código-fonte.
Existem duas maneiras de depurar um programa localmente usando o WinDbg: iniciá-lo pelo próprio WinDbg ou conectar o depurador (attach) em um programa já em execução. Podemos especificar o que faremos direto na linha de comando ou pela sua interface.
Pela linha de comando:
Pela interface:
Para variar, iremos depurar o Bloco de Notas, o maravilhoso editor de textos da Microsoft e plataforma de testes para serviços, GINAs e drivers. Para começar, poderemos usar quaisquer das opções anteriores, o que nos levará para uma saída parecida com a seguinte:
Não se preocupe, nada aconteceu de errado. Essa é apenas a maneira do WinDbg de dizer &amp;quot;oi, estou aqui, positivo e operando&amp;quot;.
Vamos destrinchar as informações iniciais para evitar confusão:
Muito bem. Agora vamos explicar resumidamente o que cada parte significa:
  Version: versão que está sendo executada do WinDbg (duh).
  CommandLine: linha de comando que foi usada ao executar o depurador.
  ModLoad: sempre que um módulo é carregado no processo (DLLs ou o próprio executável) o WinDbg informa os endereços inicial e final de carregamente e o nome do módulo. Para rever a lista de módulos carregados usa-se o comando lm.
  pid.tid: Break instruction exception - code 8000003 (first chance)_. Qualquer informação específica de uma thread é informada dessa maneira no WinDbg. No caso, foi a exceção de breakpoint (parada na execução) acionada no começo da depuração (e é por isso que o notepad ainda não está aparecendo).
  Explicado o começo, o resto é fácil. Para continuar a execução do bloco de notas basta usarmos o comando g (Go), ou pressionar F5, ou ir no menu &amp;quot;Debug, Go&amp;quot;, ou ainda apertar este botão:
Na maioria dos comandos mais comums você terá todas essas opções ao seu dispor. Na maioria dos comandos mais incomuns tudo o que você terá será o prompt de comando do WinDbg e a ajuda, acionada por F1 ou pelo comando .hh tópico. Geralmente os comandos do WinDbg possuem milhares de parâmetros, e é considerada atitude sábia olhar de vez em quando o que alguns desses parâmetros significam para que, aos poucos, aprenda-se alguns truques até a chegada da iluminação completa, onde seu espírito irá fluir livremente pela memória de todos os processos do sistema.
Por enquanto, basta apertar g e .
 A tempo: após executar g e mais um monte daquelas mensagens cheias de caracteres irão aparecer. Não se preocupe. Elas realmente não são importantes no momento, mas é importante saber o básico, que é &amp;quot;o WinDbg está avisando você de tudo o que ocorre&amp;quot;. No momento certo, saberemos usar as informações na tela quando houver necessidade.
 Vamos fazer algo não tão esperto para ver como o bloco de notas reage. Tente abrir um arquivo com um nome inexistente:
Como podemos ver, o Bloco de Notas exibe uma mensagem de erro indicando que o arquivo cujo nome você digitou não existe, pede para você verificar a &amp;quot;orografia&amp;quot; e tudo o mais. O importante aqui não é que você não sabe digitar nomes de arquivos, mas sim que a função que o notepad usa para exibir sua mensagem de erro é a conhecida API MessageBox, cujo protótipo é o seguinte:
Algumas coisas a serem notadas nessa API:
 Como (quase) toda API no Windows, a convenção de chamada é WINAPI, o que significa que quem chama empilha todos os parâmetros na pilha. Eu estou falando apenas de Windows 32 bits. A função recebe 4 parâmetros e, de acordo com a convenção de chamada, podemos supor que esses parâmetros são empilhados na seguinte ordem (invertida): uType, lpCaption, lpText, hWnd, endereço-de-retorno. As strings para as quais os dois parâmetros do meio apontam são do tipo LPCTSTR, o que significa que, além de constantes, podem ser ANSI ou UNICODE, dependendo da versão que estamos utilizando.   ANSI x UNICODE  O sistema operacional utiliza internamente a codificação UNICODE. Contudo, para manter compatibilidade com versões anteriores de outros SOs, como Windows 95, 98 e ME, as APIs são desenvolvidas em duplas, com versões UNICODE (final W), que repassam a chamada diretamente para o sistema operacional, e ANSI (final A), que fazem a conversão de strings para daí (normalmente) chamar sua irmã em UNICODE.
Sabendo que tudo converge para UNICODE, vamos colocar um singelo breakpoint nessa função API. Para parar a execução do notepad, podemos digitar &amp;quot;Ctrl &#43; Break&amp;quot; ou ir no menu &amp;quot;Debug, break&amp;quot; ou ainda... bem, você pegou o espírito da coisa.
 Faça do modo inteligente  Note que utilizei o prefixo user32! para especificar que a função está no módulo user32.dll, mas não seria necessário já que o WinDbg procura por qualquer função digitada na sua lista de funções exportadas e símbolos atuais. Contudo, fazer isso torna as coisas mais rápidas e evita perder tempo à toa.
Agora podemos efetuar a mesma operação de abrir um arquivo inexistente no bloco de notas que a execução irá parar no início da função MessageBoxW da API:
Vamos exibir o estado da pilha atual (no registrador esp) no formato de double words, a palavra padrão em sistemas 32 bits:
A primeira coluna (cujo primeiro valor é 0007cfa0) exibe o endereço da pilha, sendo que o resto das colunas são os valores encontrados a partir do topo da pilha. Sabendo que a pilha cresce &amp;quot;ao contrário&amp;quot;, de valores maiores de endereço para menores, os parâmetros empilhados invertidos aparecem agora na ordem do protótipo da função. Complicado? Nem tanto. Os parâmetros são empilhados na ordem inversa do protótipo em C, como tínhamos observado: uType, lpCaption, lpText, hWnd e por fim endereço-de-retorno, que é empilhado ao ser executada a instrução call.
Ao chegar em user32!MessageBoxW o estado da pilha reflete o protótipo, pois é o inverso do inverso (a pilha cresce &amp;quot;para baixo&amp;quot;, porém os parâmetros são empilhados do último para o primeiro).
Para referenciarmos os parâmetros através do WinDbg, de forma genérica, tudo que precisamos é adicionar 4 bytes para pularmos de parâmetro em parâmetro:
Baseado nesse princípio básico, podemos agora exibir o conteúdo de cada parâmetro passado usando o comando d (Dump) do WinDbg, aliado ao comando poi (pointer), que deferencia um determinado endereço (&amp;quot;o apontado de&amp;quot;).
Note que se estivéssemos tentando exibir uma string Ansi iríamos usar o comando da. O WinDbg possui inúmeros comandos parecidos que começam com d, cuja lista pode ser consultada pelo comando .hh d.
Como último passo em nosso passeio, vamos especificar alguns comandos para serem executados quando o breakpoint do MessageBox for acionado. O que iremos fazer aqui é trocar a mensagem de erro e seguir em frente (um breakpoint que não pára).
Para trocar a mensagem de erro usamos o comando e (Edit), semelhante ao d.
Para continuar a execução, como já vimos, usamos o comando g (Go), e é nessas horas que apenas o comando do prompt pode nos salvar:
O comando bp (BreakPoint) permite que sejam especificados comandos para serem executados automaticamente sempre que o breakpoint for ativado. Por isso, ao passar em user32!MessageBoxW colocamos dois comandos (separados por ponto-e-vírgula): ezu, que Edita uma string Unicode com outra string terminada em Zero, e o comando g, que já estamos carecas de saber. O resultado é óbvio, mas divertido de ver:
Repare que colocamos esse breakpoint diretamente na função API, ou seja, qualquer outro ponto do notepad em que ele tiver vontade de chamar a mesma API irá ativar o mesmo breakpoint e exibir a mesma mensagem, o que pode ser um pouco importuno da parte dele. Um bom exercício pós-leitura seria tratar as condições em que a mensagem será trocada, talvez se baseando na mensagem recebida. Mas isso já é lição de casa, e paramos por aqui.
</description>
</item>

     
        <item>
  <title>Proteção dos membros protected</title>
  <link>http://www.caloni.com.br/protecao-dos-membros-protected/</link>
  <pubDate>2007-10-26</pubDate>
  
  <guid>http://www.caloni.com.br/protecao-dos-membros-protected/</guid>
  <description>Quando queremos que um membro de nossa classe seja visível apenas dentro dos métodos da classe e dentro dos métodos das classes derivadas dessa classe usamos o nível de proteção protected. Isso, é claro, não quer dizer que uma classe derivada vá ter acesso aos membros protegidos de outra:
Esse é o motivo fundamental do porquê não podermos fazer isso:
Ao acessar membros protegidos é importante o tipo da expressão que está do lado esquerdo do &amp;quot;.&amp;quot; ou &amp;quot;-&amp;gt;&amp;quot;. Afinal, o nível de proteção se baseia no escopo, e as classes são um escopo. É por isso que consigo acessar os membros protegidos de um outro objeto de minha classe, mesmo sendo outro objeto:
A definição do escopo é tudo o que o compilador dispõe para saber se acessa ou não acessa um membro. Podemos ter acesso a mprotected enquanto somos do tipo Derived, mas não quando o mesmo objeto é usado como Base:
Essa proteção parece desnecessária - e até mesmo incoerente - quando lidamos com o mesmo objeto que acessa. Afinal, somos nós mesmos! Só que o compilador não sabe disso, e ele deve desconfiar de tudo e de todos para evitar esse tipo de &amp;quot;ataque&amp;quot;:
Agora a proteção do compilador faz sentido. Parece um detalhe frívolo, mas depois que vi alguns programadores de respeito se debatendo pela &amp;quot;burrice&amp;quot; do compilador, imaginei que talvez houvesse mais pessoas com a mesma dúvida de se existe ou não um &amp;quot;bug na linguagem&amp;quot;.
</description>
</item>

     
        <item>
  <title>Typeid e os perigos do não-polimorfismo</title>
  <link>http://www.caloni.com.br/typeid-e-os-perigos-do-nao-polimorfismo/</link>
  <pubDate>2007-10-24</pubDate>
  
  <guid>http://www.caloni.com.br/typeid-e-os-perigos-do-nao-polimorfismo/</guid>
  <description>Quando usamos o operador typeid geralmente desejamos conhecer informações sobre o tipo exato do objeto que temos em mãos, independente da hierarquia de herança a qual seu tipo pertença. Só que por ignorar, assim como o sizeof, que esse operador possui duas caras, às vezes damos com os burros n&#39;água e compramos gato por lebre. Não é pra menos. Uma sutil diferença entre classes polimórficas e estáticas pode dar aquele susto que só C&#43;&#43; pode proporcionar.
Eis um exemplo singelo, sem dramatização (com dramatização == &amp;quot;500 linhas de código de produção além do código abaixo&amp;quot;).
O typeid usado nesse exemplo será o estático, no estilo typeid(type), porque o tipo do objeto para a função é de &amp;quot;ponteiro para objeto de classe não-polimórfica&amp;quot;, ou seja, sem nenhuma função virtual. É importante lembrar que o polimorfismo em C&#43;&#43; só é aplicado se houver razão para tal, pois na linguagem a regra é que &amp;quot;não existe sobrecarga de execução sem que o programador queira&amp;quot;.
Se o esperado pelo programador fosse um class Deriv na última linha da saída, ou seja, que o typeid utilizado fosse a versão dinâmica, então a nossa classe Base tem que ser polimórfica:
Esse é um erro equivalente ao chamar o operador delete usando o ponteiro recebido em func. Se isso fosse feito, seria chamado apenas o destrutor da classe Base. Por falar nisso, temos nesse exemplo um leak de memória (percebeu pela saída que os destrutores não são chamados?). Mas esse é um erro bem menos sutil que o visto pelo nosso amigo typeid amigo-da-onça ;).
</description>
</item>

     
        <item>
  <title>Guia básico para programadores de primeiro breakpoint</title>
  <link>http://www.caloni.com.br/guia-basico-para-programadores-de-primeiro-breakpoint/</link>
  <pubDate>2007-10-22</pubDate>
  
  <guid>http://www.caloni.com.br/guia-basico-para-programadores-de-primeiro-breakpoint/</guid>
  <description>Aproveitando um dos últimos artigos que fala sobre conceitos básicos de programação, lembro que, tão importante quanto, é possuir habilidades básicas de depuração, uma arte por muitos programadores ignorada.
É interessante notar como muitos programadores e instituições de ensino ignoram a utilidade e conveniência das tradicionais e poderosas ferramentas de depuração passo-a-passo. O motivo pode ser puro desdém ou ignorância (no sentido de desconhecimento). Se for pelo segundo, aí vão algumas dicas para dar uma passada geral no seu programa e, quem sabe, encontrar um ou outro bug pelo caminho.
É o comando primário. Simplesmente inicia uma nova execução de seu programa. Geralmente você deve utilizar esse comando quando já tiver definido seus breakpoints (mais abaixo). Do contrário o programa vai iniciar, executar e sair, sem sequer você notar.
Na ordem: Start/Continue, Break, Stop, Restart, Show Next Statement, Step Into, Over e Out.
Esse comando avança uma linha de código-fonte, parando na seguinte, de uma maneira iterativa. É a chamada execução passo-a-passo. Com ele você consegue, com a ajuda das janelas de watch e variáveis locais, analisar passo-a-passo a execução do fluxo de seu programa variando de acordo com as condições do sistema.
Parente bem próximo do Step Over, com a importante diferença de entrar dentro das funções que são chamadas em cada linha de execução. Geralmente é usado quando você pretende revisar todo o fluxo de execução porque escreveu código novo ou porque ainda não chegou na situação que pretende simular ou ainda porque usou o Step Over antes e descobriu que existe algum problema na função X que você passou direto.
É o complemento dos dois comandos acima. Ele vai sair executar todo o resto da função onde você está e parar exatamente uma linha após a chamada dessa função. Em suma: você já viu o que queria ver dentro da função atual e quer continuar a execução um ou mais níveis acima na pilha de chamadas.
Você não precisa passar por todo o seu código e todos os seus loops/laços de 500 iterações até chegar ao ponto que quer analisar. Existe um comando nativo do sistema que é dos mais úteis para o programador, capaz de parar o fluxo de execução em um ponto específico do código. O depurador torna disponível para você esse comando que pode ser engatilhado em qualquer linha, geralmente em uma quantidade razoável. Para controlar todos os breakpoints definidos existe uma janela com essa lista que indica, entre outras coisas, se estão habilitados ou não, se possuem alguma condição de quebra, quantas vezes devem parar, etc. Costuma existir um ótimo controle sobre breakpoints nos depuradores, pois esse é um comando muito usado em programação (e dos mais antigos).
Praticamente qualquer ferramenta de debug possui um mecanismo para que você consiga ver o que está dentro das variáveis de seu programa. Basicamente temos uma janela de watch, ou inspection, onde podemos inserir as variáveis que queremos espiar. Em um nível mais sofisticado, temos as janelas de locals e autos (o nome pode variar), onde podemos ver, respectivamente, as variáveis dentro da função e as variáveis mais próximas do ponto onde o código está parado (as que foram usadas na última linha e as que serão usadas na próxima, por exemplo). Claro que cada ambiente te fornece o que melhor ajudar durante a depuração, assim como o Delphi e o C&#43;&#43; Builder possuem o magnífico Object Inspector, uma janela com todas as propriedades de um objeto qualquer do sistema (uma janela, um botão, uma classe, etc).
Essa é a pilha de chamadas da thread atual. Com ela você consegue ver o nome da função que chamou a função que chamou a função que chamou... até a função inicial (por exemplo, o nosso conhecido main, a primeira função de um programa &amp;quot;normal&amp;quot; em C/C&#43;&#43;).
No caso de seu programa ser multithreading, ou seja, possuir várias linhas de execução, fluxos distintos de código rodando, existirá uma janela onde você pode ver qual a thread atual (a que está sendo depurada e destrinchada nas outras janelas) e quais as outras threads. Muitos ambientes permitem que com essa janela seja feito um switch de threads, que é a troca da thread atual, o que irá alterar a janela de pilha de chamadas, de variáveis locais, e muito provavelmente a janela do código-fonte atualmente em execução.
Depurar esteve sempre ligado à programação desde os primórdios da humanidade. Por isso hoje em dia os depuradores estão muito evoluídos, geralmente integrados em um ambiente de desenvolvimento (exs: Visual Studio, KDE Develop) e possuem comandos e mais comandos e mais comandos. Existem comandos, por exemplo, para pular fluxo sem executar, definir um breakpoint temporário, visualizar registradores da máquina, visualizar páginas de memória, controle de exceções, misturar assembly com código-fonte, etc. Enfim, cada comando deve ser usado conforme a necessidade e conveniência. Não adianta querer usar tudo e entender tudo de uma vez. Os comandos acima já são um ótimo começo para uma depuração poderosa o suficiente para pegar alguns bugs.
</description>
</item>

     
        <item>
  <title>Por que minha DLL travou?</title>
  <link>http://www.caloni.com.br/por-que-minha-dll-travou/</link>
  <pubDate>2007-10-18</pubDate>
  
  <guid>http://www.caloni.com.br/por-que-minha-dll-travou/</guid>
  <description>Saiu um documento da Microsoft alertando sobre os perigos em colocar código no DllMain. É algo mais completo e didático do que as simples observações do help do MSDN. Vale a pena dar uma lida, especialmente por causa das explicações sobre o loader lock e seus efeitos colaterais.
O resumo da ópera é que o código do Windows chamador do DllMain das DLLs carregadas/descarregadas utiliza um objeto de acesso exclusivo (leia &amp;quot;mutex&amp;quot;) para sincronizar as chamadas. O resultado é que, em um processo, apenas um DllMain é chamado em um dado momento. Esse objeto é chamado de &amp;quot;loader lock&amp;quot; na documentação da Microsoft.
O código abaixo é besta, mas representa o que já vi em muito código-fonte, e muitas vezes não consegui perceber o que estava acontecendo (tanto porque desconhecia a existência desse loader lock quanto o código estava obscuro demais pra entender mesmo). Os comentários dizem tudo:
Uma simples vítima disso pode ser um pobre executável usando uma pobremente escrita DLL, assim como no código abaixo:
Para ver o problema de lock em ação, copie os fontes da DLL e do EXEcutável e use os comandos abaixo para gerar os arquivos:
É importante sempre lembrar que a Microsoft acha feio, muito feio você ficar dependendo do DllMain pra fazer alguma coisa, mas admite que em alguns casos o único lugar onde podemos rodar código é no DllMain. Nesses casos - e em alguns outros - utilize uma comunicação paralela com sua thread travadona, por meio de um evento ou algo do gênero, antes que ela realmente saia. Com isso a thread pode ainda não ter saído, mas pode avisar a thread principal que o que ela precisava fazer já foi feito.
 NT Loader (MSJ Sep 99) - Matt Pietrek mgrier&#39;s WebLog - NT Loader team participant  </description>
</item>

     
        <item>
  <title>Guia básico para programadores de primeiro int main</title>
  <link>http://www.caloni.com.br/guia-basico-para-programadores-de-primeiro-int-main/</link>
  <pubDate>2007-10-16</pubDate>
  
  <guid>http://www.caloni.com.br/guia-basico-para-programadores-de-primeiro-int-main/</guid>
  <description> Vou aproveitar que meu amigo DQ publicou um artigo muito bom sobre como fazer programas fáceis de manter (merece ser lido!) e vou republicar um artigo do blogue antigo sobre o básico do básico para quem deseja entender como os programas funcionam. Não é nada sofisticado, apenas alguns conceitos comuns que, se você deseja ser programador, deveria procurar saber.
 A primeira coisa a saber é o que é um programa. Podemos imaginá-lo como um arquivo que vai ser interpretado pelo computador. Essa interpretação chamamos de execução. Quando um programa está sendo executado também é comum dizermos que ele está rodando. Teoricamente ele pode rodar eternamente, mas o que acontece em casos normais é que ele tem um fim previsto, seja quando o usuário fechar a janela principal (evento externo) ou quando ele terminar o que tinha que fazer (lógica interna).
E do que é feito um programa? Basicamente de duas coisas: dados de entrada e instruções (ou código). Os dados podem estar no próprio programa ou serem lidos de algum outro lugar (do teclado, de outro arquivo, da internet, etc). As instruções do seu programa é o que será interpretado pelo computador. E o que ele fará? Basicamente alterar os dados de entrada. O objetivo fundamental de um programa é gerar dados de saída. Esses dados são escritos/exibidos para algum outro lugar (para a tela, para um arquivo, para a internet, etc).
Vamos analisar essas abstrações em exemplos da vida real:
   Exemplo Dados de entrada Processamento Dados de saída     Bloco de Notas Digitação do usuário Leitura do teclado Texto exibido na tela   MSN Envio de mensagem Conexão com a internet Seu amigo recebe a mensagem   PaintBrush Movimento do mouse Interpretação de movimento Retângulo desenhado   Firefox Clique do mouse em uma URL Conexão com o site Exibição da nova página   Counter Strike Clique no botão de tiro Cálculo do projétil Inimigo acertado   Compilador Código do programador Interpretação das instruções Código de máquina (seu programa!)    Como podemos ver, podemos abstrair esse lance de &amp;quot;dados de entrada &#43; processamento = dados de saída&amp;quot; com qualquer tipo de programa que usarmos. Basta relacionar o que fazemos (digitar algo, arrastar o mouse, apertar um botão, etc) para obtermos a saída desejada (texto/gráfico na tela, no arquivo, na impressora, etc). O programa é o elemento que fica no meio fazendo essa &amp;quot;mágica&amp;quot;.
Existem informações intermediárias que precisamos guardar em um programa em execução para que no final consigamos apresentar a saída desejada ao usuário. Essas informações intermediárias também são dados, só que o usuário não os enxerga. A elas chamamos de variáveis. Entenda uma variável como &amp;quot;um lugar na memória onde o programa armazena alguma informação durante o processamento&amp;quot;.
Toda variável é apenas memória interpretada de uma maneira peculiar. Essa maneira de interpretar a memória é chamada de tipo. Cada variável possui o tipo que lhe convém. Basicamente, existem dois tipos de variáveis: número (ou inteiro) e texto (ou string).
Imagine um programa sendo executado do começo ao fim. A ordem em que um programa é executado é chamado de fluxo de execução. A tendência natural de um programa é ser executado pelo computador da sua primeira instrução até a última, sempre nessa ordem. Ou seja, linha 1, linha 2, linha 3, ...., linha n. Pronto. Acabou.
Porém, se fosse sempre assim, isso quer dizer que o programa seria executado sempre do mesmo jeito, e os dados de saída seriam sempre os mesmos, independente dos dados de entrada. Mas isso não acontece, certo? Quer dizer, se você não mirar direito e apertar o botão certo, o inimigo não vai cair no chão. Isso faz um certo sentido, não?
Seguindo esse raciocínio, podemos deduzir que um programa deve tomar decisões para saber o que fazer. E para tomar essas decisões ele usa o que recebeu como entrada, que são exatamente os dados de entrada. Nesse contexto, tomar decisão significa alterar o fluxo de execução. Ou seja, a ordem não necessariamente será sempre linha 1, linha 2, linha 3, etc, mas poderá ser, por exemplo, linha 1, linha 52, linha 237643, linha 52 de novo, linha 890, e assim por diante.
Note que existem várias perguntas que o programa precisa responder para seguir em frente. Para respondê-las, o programa pede a ajuda do computador para fazer comparações entre variáveis. E aí está o uso desses dados internos.
Bem, até aqui você já aprendeu um montão de coisas:
  Programas podem ser armazenados em arquivos.
  Quando executados, o computador interpreta suas instruções.
  Um programa usa dados de entrada para gerar dados de saída.
  Para tomar decisões, ele utiliza variáveis internas.
  A ordem das instruções é chamado fluxo de execução.
  A tomada de decisões altera o fluxo de execução de um programa.
  Para concluir, vamos dar uma espiada nas estruturas de comparação de um programa em C e suas conseqüentes mudanças de fluxo. Note também que as comparações são feitas com variáveis internas.
If significa &amp;quot;se&amp;quot;, ou seja, faz uma comparação, e retorna se a comparação é verdadeira (sim!) ou não (não!). Porém, o if apenas faz alguma coisa se o resultado for sim.
Else significa &amp;quot;senão&amp;quot;, ou seja, é o complemento do if. Lembra-se que o if só faz alguma coisa se o resultado da comparação for sim? Pois bem, o else permite fazer outra coisa se o resultado for não.
While significa &amp;quot;enquanto&amp;quot;, e é o nosso primeiro exemplo de laço, ou loop. Um loop faz constantemente a mesma coisa enquanto o resultado da comparação for sim. Uma vez que for não (pode ser a primeira, inclusive), ele não faz mais nada e o programa continua seu fluxo natural.
For significa &amp;quot;por&amp;quot;, com o mesmo sentido que em &amp;quot;ele me chutou por 5 vezes seguidas&amp;quot;. Ele pode ter muitos usos, mas o tradicional é fazer n vezes alguma coisa, sabendo que n é um número de vezes já conhecido. Nesse caso, o loop serve apenas para repetir um determinado número de vezes uma ação, sem nunca variar esse número de vezes.
Programar não tem segredo. É tudo uma questão de gostar, aprender, executar, aprender, gostar mais, aprender mais, executar mais, etc. Não exatamente nessa ordem. Tudo vai depender dos seus dados de entrada. Mas o fluxo já começou sua execução...
 A inteligência do if - parte 1 A inteligência do if - parte 2 Arquitetura de von Neumann Máquina de Turing  </description>
</item>

     
        <item>
  <title>A Linguagem de Programação C</title>
  <link>http://www.caloni.com.br/the-c-programming-language/</link>
  <pubDate>2007-10-12</pubDate>
  
  <guid>http://www.caloni.com.br/the-c-programming-language/</guid>
  <description>O clássico de Ritchie e Kernighan, criadores da linguagem C, não foi meu primeiro livro de programação. E nem deveria ser. Não o recomendo para iniciantes, pois é necessário possuir algun conhecimento e prática para realmente aproveitar os conceitos desse livro.
Então, o que ler antes disso? Existem tantos livros bons para iniciantes (e tantos livros péssimos). Eu comecei com C Completo e Total, de Herbert Schildt. Não me arrependi. O autor vai descrevendo C para quem já tentou fazer algumas coisas, já programou outras e está afim de tirar as principais dúvidas sobre essa linguagem que tantos abominam por ser difícil, e tantos idolatram por ser poderosa. As práticas do livro já são um bom início para quem quer pensar, entender e programar.
Depois de Schildt, passei a ler os livros da Viviane, os famosíssimos módulos do Treinamento em Linguagem C. São ótimos para a prática e para reafirmar os conceitos lidos no primeiro livro. Para uma linguagem tão importante, uma segunda opinião é sempre bem-vinda.
Então chegou a hora. Passei algumas das minhas melhores horas na biblioteca lendo como os próprios criadores da linguagem a ensinam, e como o padrão ANSI é definido (em termos bem simplificados, condição perfeita para entender a lógica do compilador). Com o livro é possível perceber claramente que a linguagem é tão simples quanto poderosa, lembrando (quem diria!) o mais abominado ainda assembly.
Vamos aos capítulos.
O começo é quase sempre o mesmo. Os autores explicam um programa simples na linguagem, fazem alguns testes e explicam linha a linha o que cada coisa significa. O importante aqui é esquecer que existe um sistema operacional rodando por baixo de nosso programa e entender que a linguagem foi desenhada para independer disso. É tão genérica a ponto de independer dela mesma. Explico: enquanto a maioria das linguagens considera sua biblioteca parte integrante da mesma, a linguagem C faz questão de separar as coisas, reafirmando sempre que uma coisa é o preprocessamento, outra é a compilação, outra é a linkedição e nenhuma delas precisa de uma biblioteca, apesar de uma ter sido definida no padrão (baseada no uso comum da linguagem em diversos ambientes).
Se você nunca teve contato com C ou deseja ter uma aproximação mais simplificada e quer entender como as coisas mais simples funcionam na linguagem, este capítulo é imperdível.
Essa é a hora ideal para separar dois conceitos que muitas vezes ficam grudados na mente dos precoces programadores para o resto de suas vidas: uma coisa é um tipo e outra coisa é uma expressão. Uma expressão possui um tipo, que define seu comportamento de acordo com o operador usado. Tudo é explicado muito bem com exemplos bem escritos e que são realmente úteis, como strlen, atoi, strcat (presentes na biblioteca padrão) e até um contador de bits.
Se quiser entender o que cada fragmento de lógica na linguagem significa por completo (e não apenas uma expressão jogada na correria da programação do dia-a-dia) esse capítulo irá explicar. Depois de entendê-lo, nunca mais vai achar bizarro aqueles problemas de precedência que permeiam código pouco sensato.
Apenas após ter explicado os conceitos que regem qualquer linha de código operacional em C os autores se dedicam a explanar as diversas formas de controlar o fluxo do seu programa. Nessa hora a linguagem se desdobra, se torna mágica, simples, flexível e poderosa.
Não basta apenas possuir lógica de programação. Para escrever bons programas é necessário saber como construir os blocos funcionais que irão traduzir seus comandos para o computador. É nesse ponto que é fundamental o domínio de qualquer construção em C, seja um simples if ou uma combinação maluca de switches, whiles e breaks.
Entendidos os princípios básicos de criação e execução de qualquer programa em C, chegou a hora de explicar como a linguagem suporta a organização de seu código através de funções, módulos e diretivas de preprocessamento. Note que os autores partem do princípio minimalista da linguagem e imagina o que acontece conforme seus programas vão se tornando cada vez maiores. Para isso explicam o mesmo princípio que foi utilizado ao desenhar a linguagem, que até hoje é usada para escrever dezenas de milhares de código em um único projeto, ou até milhões (como em sistemas operacionais).
No desenvolvimento de software a organização é um dos pilares que irá transformar o programador em um mestre da arquitetura de seu próprio código. Não negligencie a lógica das partes maiores do seu código, só se importando com os pequenos pedaços de blocos dentro de uma função. Antes de ser cientista, seja um desenvolvedor nato.
A dificuldade com que muitos programadores C têm com essas duas características da linguagem fizeram com que fosse dedicado um capítulo inteiro para explicar e reexplicar como os arrays (vetores) e ponteiros funcionam e qual a relação intrínseca entre eles. É também explicada a relação strings x arrays, já que em C uma string é uma cadeia de caracteres.
Se você programa em C e até hoje tem dificuldades para entender completamente esse assunto, sugiro que largue o que você está fazendo agora e leia esse capítulo até o final. Será bem mais proveitoso que ficar zanzando no meio de um monte de blogues (como este aqui).
A estrutura é uma composição complexa em C, mas permite um organização melhor dos dados, da mesma maneira com que as funções organizam melhor o código.
Aparentemente o tema estrutura é mais simples que ponteiros, e deveria ser tratado antes. Porém, fazer isso impediria abordar o tema de listas ligadas e outras estruturas que dependem do uso de ponteiros para que estruturas referenciem elas mesmas, algo extremamente recorrente no mundo da programação.
É sempre bom lembrar que o uso de estruturas foi o nascimento do C&#43;&#43;, que prima pela elegância na organização e harmonia entre seu código e dados. A linguagem C também não fica para trás, mas é importante saber usar.
Para finalizar é abordado o tema da interface com o mundo exterior da linguagem. Desde sempre suportando a maneira mais básica, genérica e portátil de qualquer sistema operacional, o console, talvez hoje essa característica seja um tanto menosprezada pelos usuários de ambientes gráficos. Contudo, não deixa de ter seu valor ainda hoje, nem que seja para escrever programas de teste.
Os adendos são incrivelmente úteis e os utilizo ainda hoje como referência. Cá entre nós, o padrão formal da linguagem é algo chato de se ler, e muitos detalhes são perfeitamente ignoráveis para quem não está desenvolvendo um compilador. Contudo, acredito que a maioria dos bons programadores deveria se preocupar em entender como os compiladores entendem seu código, pois muitos dos erros podem ser facilmente resolvidos através do desenvolvimento de uma certa empatia com a linguagem. É por isso que considero o Apêndice A o mais útil de todos.
Por outro lado, sempre fui contra a reinvenção da roda. O que quer dizer que sempre fui a favor do pleno conhecimento da biblioteca padrão, pois ela fornece funções das mais usadas no dia-a-dia, e algumas outras que poderão ter sua serventia um dia desses. Mas para isso elas devem ser conhecidas. Isso quer dizer que uma passada de olhos no Apêndice B não faz mal a ninguém.
O Apêndice C hoje é um pequeno guia dos curiosos para as mudanças que foram infligidas na linguagem quando esta foi padronizada. Como fã incondicional de C, não pude deixar de ler e reler essa parte, já que me dedico também a conhecer os primórdios dessa linguagem. Contudo, é parte opcional para as pessoas práticas (a não ser que você esteja com problemas com código legado do século passado).
Livros vêm, livros vão, mas apenas os clássicos permanecerão. A Linguagem de Programação C é um clássico, sem sombra de dúvida, e nunca irá perder seu valor para a linguagem. A maioria dos livros usa-o como referência, assim como os livros tão amados da comunidade C&#43;&#43; sempre usam Stroustrup como referência. Portanto, se puder, reserve um tempo para o passado.
</description>
</item>

     
        <item>
  <title>Engenharia reversa para principiantes</title>
  <link>http://www.caloni.com.br/engenharia-reversa-para-principiantes/</link>
  <pubDate>2007-10-10</pubDate>
  
  <guid>http://www.caloni.com.br/engenharia-reversa-para-principiantes/</guid>
  <description>Dei uma reformada em minha última palestra sobre engenharia reversa. O tema escolhido foi tentar abranger os níveis de conhecimento que uma pessoa disposta a se dedicar à engenharia reversa de programas deveria ter, desde programação, passando pelo sistema operacional e terminando no uso de ferramentas. Achei interessante abordar esse tipo de conteúdo pelo fato de existirem pessoas que gostariam de começar ou já começaram e não sabem para onde ir.
Outra coisa que fiquei receoso de colocar (mas coloquei) foi a lista de tarefas para usar o conhecimento aprendido. Pode ser frustrante tentar procurar emprego nessa área aqui no Brasil e não adianta nada aprender e não usar. A engenharia reversa, assim como a área de segurança da informação, para ser efetiva, deve levar em conta como as coisas são feitas, o que quer dizer que fazer vírus e quebrar proteção de software faz parte do aprendizado.
Se houverem interessados o suficiente poderei ministrar uma palestra online, para ilustrar os slides e tirar dúvidas. Lembrando que isso não inclui as perguntas &amp;quot;como eu quebro o programa X&amp;quot; ou &amp;quot;faz um vírus pra mim&amp;quot;.
</description>
</item>

     
        <item>
  <title>Debug da BIOS com o SoftIce 16 bits</title>
  <link>http://www.caloni.com.br/debug-da-bios-com-o-softice-16-bits/</link>
  <pubDate>2007-10-02</pubDate>
  
  <guid>http://www.caloni.com.br/debug-da-bios-com-o-softice-16-bits/</guid>
  <description>Para quem ainda acha que não desceu demais o nível, existe um ótimo artigo de ShalomZ, do Code Project, sobre como construir seu próprio sistema operacional. É simples, direta e empolgante a maneira com que ele explica e trata os detalhes básicos, desde quando o computador é ligado até quando o boot loader carrega e entrega o controle de execução. Eu mesmo fiz o teste com a imagem que foi disponibilizada para download e funcionou direitinho. Agora esse meu artigo se dispõe a explicar como você pode fazer para depurar o processo de load do seu primeiro sistema operacional.
Primeiro, precisamos de uma ferramenta fundamental para esse tipo de depuração: o SoftIce versão 16 bits. Desconheço algum outro depurador de sistema em 16 bits, mas se você souber de algum, pode usá-lo com esse tutorial com as devidas adaptações.
Passado o desafio inicial de encontrar essa versão do SoftIce e saber usá-la, o resto é fácil:
 Crie uma nova VMWare, Virtual PC, VMSbrubles configurada para bootar pelo disquete. Formate dois disquetes de MS-DOS, FreeDos, Sbrubles-DOS. Copie o setor de boot disponível no artigo do CP para o disquete usando o programa disponível em um dos disquetes. Copie o SoftIce no outro disquete. Efetue o boot com o disquete do SoftIce. Execute o SoftIce (é só rodar, ele permanece residente e é ativado com Ctrl &#43; D). Coloque um breakpoint na int 0x13 (disco) na função 2 (leitura) (faz-se assim: bpint 13 ah=2). Troque o disquete do Softice pelo disquete com o setor de boot do artigo do CP. Efetue novamente o boot na máquina em modo &amp;quot;quente&amp;quot; (usando o próprio SoftIce, comando boot). A execução deve ser paralisada exatamente no ponto onde o código da BIOS lê o setor de boot do seu disquete. Digite p ret e em seguida F10 ou T e seja feliz.  Pelo softice 16 bits conseguimos parar a execução nas interrupções da BIOS e ainda especificar qual das funções será executada, definida no registrador AH (mais detalhes sobre layout de memória do 8086 no artigo do DQ).
Quando o código da BIOS é executado, ele precisa, entre outras coisas, fazer três:
 Encontrar o dispositivo padrão de boot. Ler o primeiro setor desse dispositivo para o endereço 0x7C00. Entregar a execução para o código em 0x7C00.  O item 2 é justamente o que utiliza essa interrupção para ler do disco. Eu prefiri colocar o breakpoint no item 2, mas nada impediria de você colocá-lo no item 3 e já iniciar a depuração no código do boot loader. Mas, como eu já passei por problemas encontrados no código da BIOS que impediam o sistema de entregar a execução para o setor de boot, já dei a dica de lambuja caso você também tenha a oportunidade de se divertir em um cliente depurando a BIOS de algum laptop desajustado.
Pela imagem acima sabemos que após o boot foi executada a interrupção 0x13, função 2 e que se trata de leitura em disquete, pois o conteúdo do registrador DL está em 0 (veja a referência das interrupções da BIOS em Ralf Brown&#39;s Interrupt List).
É mais ou menos o step out do SoftIce 32. Ou seja, ele avança a execução até a função retornar. No caso do SoftIce 16, ele irá avançar até o próximo ret/iret. Por isso que também precisamos executar a próxima instrução (o próprio ret) para cair onde queremos. É nesse ponto que o &amp;quot;nosso&amp;quot; código começa a executar e onde conseguimos colocar breakpoints &amp;quot;de verdade&amp;quot; (lembre-se que o código da BIOS está em uma memória de somente leitura, pelo menos durante a execução).
 Building your own operating system - ShalomZ Ralf Brown&#39;s Interrupt List Gerenciamento de memória 386 - Daniel Quadros  </description>
</item>

     
        <item>
  <title>Introdução ao C&#43;&#43; Builder...Turbo C&#43;&#43;</title>
  <link>http://www.caloni.com.br/introducao-ao-c-builderturbo-c/</link>
  <pubDate>2007-09-26</pubDate>
  
  <guid>http://www.caloni.com.br/introducao-ao-c-builderturbo-c/</guid>
  <description>Após mais de um ano de tentativas, finalmente consegui instalar e iniciar com sucesso o Borland Developer Studio. Esse foi o nome pomposo dado pela Borland para a &amp;quot;continuação&amp;quot; do velho C&#43;&#43; Builder e seus parentes, o Delphi e o C# Builder.
Existem muitas coisas novas ainda para ver, mas não é a usabilidade. Assim como a IDE antiga, é fácil de sair mexendo e fazendo janelas, no bom estilo WYSIWYG dos produtos da Borland.
Para quem começa a desenvolver aplicativos com interface para Windows, deve saber que uma das coisas mais produtivas que já inventaram foi o Visual Basic. De fato, o VB permite que virtualmente qualquer pessoa com conhecimentos mínimos de informática torne-se um gabaritado programador de telinhas.
Porém, com o tempo você percebe que cada ferramenta tem suas vantagens e desvantagens. Uma desvantagem do VB era a falta de flexibilidade. Outra era que a linguagem usada não favorecia muito aqueles que se aventuravam chamando a Win32 API diretamente dos seus programas. Era possível, sim, mas enfadonho e nem sempre as coisas funcionavam como o esperado.
Para as pessoas que chegam nesse nível de necessidade, existem basicamente duas escolhas:
  Permanecer no mundo Microsoft e usar MFC &#43; Win32 API, passando a programar na linguagem em que foi feito o Windows (C/C&#43;&#43;).
  Tentar usar o Delphi, a evolução do Turbo Pascal para Windows, da Borland, que pode ser considerado mais flexível que o VB, mas ainda assim usa uma linguagem alienígena (no sentido de que ainda não é a linguagem nativa do SO).
  Mudar de sistema operacional e esquecer esse negócio de loop de mensagens (eu disse duas escolhas, certo?)
  Bom, eis que surge o C&#43;&#43; Builder: uma ferramenta idêntica ao Delphi, contudo que oferece a linguagem C&#43;&#43; para que todas aquelas pessoas recém-saídas da faculdade e ansiosas por entrar no mercado de trabalho esqueçam aquele papo de Pascal e passem a usar a linguagem da indústria. Pelo jeito, era mais ou menos essa a visão da Borland quando lançaram o produto.
Desde o princípio, o C&#43;&#43; Builder foi lançado em revistas de informática em versões para estudantes, o que estimulava as pessoas financeiramente menos capacitadas (estudantes, como eu) a cada vez mais utilizar essa ferramenta de programação para desenvolver aplicativos Windows, já que, além de não ser pago como o Visual Basic e o Visual C&#43;&#43;, não era nem tão limitado quando o primeiro nem tão complicado quanto o segundo. E estava sempre entre os programas completos para serem testados na revista que acabou de chegar na banca. Nossa, como era divertido programar por prazer!
O mais impressionante no Builder era que desde o começo, na versão 1, já tínhamos aquela palheta maravilhosa cheio de todos os controles que já faziam parte do Windows 95. Tudo isso por causa de uma estratégia simples e eficaz: os componentes são os mesmos do Delphi. O que o C&#43;&#43; Builder adicionou foi uma camada de interface para que C&#43;&#43; e Object Pascal conversassem. O resultado disso é espantoso: é possível programar em C&#43;&#43; puro, chamar APIs diretamente, e ainda usar os componentes em Delphi, além de também poder desenvolver em Delphi e mesclar ambas as linguagens em um projeto. É possível até usar herança entre componentes escritos em Delphi e C&#43;&#43; Builder.
 Quando entrei na Scua comecei a trabalhar profissionalmente com o C&#43;&#43; Builder, ao desenvolver o aplicativo de administração do software de controle de acesso. Na época não tínhamos muito tempo para perder desenvolvendo tudo em Win32 API ou usar algo mais rústico como a MFC, que é mais parecido com a finada biblioteca OWL do que com a VCL (a biblioteca visual de componentes usada pela Borland para Delphi e Builder). E não, usar Visual Basic não era uma alternativa. Como a produtividade estava em jogo, hoje tenho certeza que fizemos uma boa escolha.
 Eu gostava do C&#43;&#43; Builder antigo: sem frescura de registrar componentes e sem necessidade de instalação. Até hoje uso a versão 1.0 para brincar de vez em quando, pois é relativamente pequena; apenas copio para uma pasta e ainda funciona muito bem.
Mas desde que o mundo gerenciado veio à tona, para instalar esse singelo produto da Borland você vai precisar de alguns pré-requisitos da Microsoft:
  Microsoft .NET Framework SDK 1.1
  Visual J# .NET Redistributable Package 1.1
  Microsoft XML 4.0 SP2 Parser and SDK
  Se for necessária mais alguma instalação, não se preocupe: o Borland Turbo C&#43;&#43; Instalation Wizard irá te avisar no momento da instalação, que deverá ser a última a ser realizada.
Após tudo isso instalado, finalmente conseguiremos rodar nossa ferramenta RAD. Aliás, antes que eu me esqueça, RAD é uma abreviação para Rapid Application Development.
Se você nunca usou essa ferramenta, ao abrir o ambiente, irá se deparar com vários elementos que precisam ser nomeados e explicados para fazer algum sentido. Mesmo que muitas coisas sejam novas, algumas devem estar sempre gravadas em sua memória:
Sempre que você clicar em algum componente gráfico para ser editado - como uma janela, um botão, uma lista - o Object Inspector será o lugar para editá-lo. Ele está dividido em propriedades e eventos. Propriedades são as características gráficas e comportamentais do componente que está sendo editado. Eventos especificam métodos para tratar as ações recebidas de algum componente (ex: clique de um botão).
A palheta é onde estão todos os componentes que podem ser usados no momento para a edição do programa. Existe uma infinidade deles, tais como: botões, menus, caixas de seleção, listas de itens, barras de rolagem, listas de ações, imagens, rótulos, grupos de botões, e assim vai a valsa. Para usá-los, basta arrastar para uma janela e editar suas propriedades.
Onde estão todos os meus arquivos? O Gerenciador de Projetos está aí para ajudá-lo. Todas as units (unidades de código) e forms (janelas) que você criar no projeto estará visível para fácil acesso. É muito importante saber organizar um projeto, pois conforme se avança, ele tende a se tornar maior e mais complexo. Junto do Gerenciador de Projetos existe o seu ajudante, o Structure. Na visão de design, o Structure irá mostrar os controles inseridos nas janelas; na visão de unit, o Structure irá mostrar os includes, macros, classes e funções do código-fonte exibido no momento.
Considerando que o Bloco de Notas é minha vítima preferida para testes (e a vítima preferida de outros, também), nada melhor que nosso projeto seja um Bloco de Notas simplificado, que leia, exiba e salve arquivo-texto. Para esse projeto iremos utilizar apenas 5 componentes e cerca de 10 linhas de código:
  2 botões (abrir e salvar arquivo),
  1 memo (para exibir o arquivo aberto),
  2 caixas de diálogo comum (abrir e salvar arquivo).
  </description>
</item>

     
        <item>
  <title>Why is my DLL locked?</title>
  <link>http://www.caloni.com.br/why-is-my-dll-locked/</link>
  <pubDate>2007-09-24</pubDate>
  
  <guid>http://www.caloni.com.br/why-is-my-dll-locked/</guid>
  <description>There is a document from Microsoft alerting about the hazards in putting your code inside a DllMain function. what is more comprehensive and easier to read than the MSDN observations. It is worth reading, even because the explanations about the loader lock and its side effects can do very good for your code health.
In short, the Windows code responsible to call DllMain for each loaded/unloaded DLLs uses an exclusive access object (the so-called &amp;quot;mutex&amp;quot;) to synchronize its calls. The result is that inside a process just one DllMain can be called at a given moment. This object-mutex is called &amp;quot;loader lock&amp;quot; into the Microsoft documentation.
The code below is silly, but represents quite well what I&#39;ve seen in lots of production code. For many times I was unable to realize what was going on (whether because I didn&#39;t know about the loader lock or the code readability was too bad). The comments say by themselves:
A simple victim of all this can be an executable using a poorly written DLL, just like the code above:
In order to the see the locking code in action, copy the DLL and EXE source files and use the following commands to generate the executable files:
It is important to remember that a DllMain dependant code is a very, very bad thing. Nevertheless, there are some particular cases the only place to run our code is inside DllMain. In these cases, when detected, try to run a side by side communication with your locked thread using an event object (or equivalent) before it really returns. Using this craft the thread can warn the waiting thread that the important thing to be done is done, and the waiting thread can go to sleep and stop waiting forever locked threads.
 NT Loader (MSJ Sep 99) - Matt Pietrek mgrier&#39;s WebLog - NT Loader team participant  </description>
</item>

     
        <item>
  <title>A mobilidade das variáveis no printf</title>
  <link>http://www.caloni.com.br/a-mobilidade-das-variaveis-no-printf/</link>
  <pubDate>2007-09-20</pubDate>
  
  <guid>http://www.caloni.com.br/a-mobilidade-das-variaveis-no-printf/</guid>
  <description>O printf (e derivados) tem sérios problemas por conta de sua falta de tipagem. Não vou aqui dizer que cout é a alternativa óbvia e melhorada porque não é. Mas isso é uma discussão que eu não deveria começar aqui. E não começarei. Portanto, ignorem essa linha =).
O mais comum de todos é a passagem de tipo na string de formatação diferente da variável passada:
Isso costuma ser mais comum quando existem centenas de milhares de parâmetros na chamada, o que confunde o programador (e o leitor de certos blogues especializados em confundir):
O segundo que me lembro que costuma dar muitos problemas é a passagem de tipo inteiro de tamanho diferente:
É mais sutil, também costuma confundir no meio de vários parâmetros, e pode ser detectado utilizando a técnica de transformar tudo em assembly, pois com isso temos dica de tipagem ao empilhar os argumentos na saída do arquivo asm.
É claro que hoje em dia existem compiladores muito espertos, que detectam na hora o que você está digitando e a cagada que isso vai dar depois de compilado. Mas, assumindo que você não tem toda essa tecnologia ao seu dispor, ou está mesmo interessado em entender como as coisas funcionam, e não apenas seguir o manual do seu ambiente de desenvolvimento preferido, essa é uma maneira interessante de analisar o que ocorre com o seu código. Agora, a pergunta que não quer calar: por que isso acontece?
Conforme o printf interpreta a string de formatação, ele vai &amp;quot;comendo&amp;quot; (no bom sentido) os argumentos passados na pilha. Se a string informa que existe um int de 32 bits, mas na verdade existe um de 64, ele vai comer apenas 32 bits da pilha, deixando os próximos 32 para o desastre iminente. Como os próximos 32 bits de nosso int64 estão zerados, faz sentido o printf imprimir (null) no lugar da string, pois este é o comportamento padrão da função quando o ponteiro é nulo. Agora, se tivéssemos um int realmente grande - vulgo &amp;quot;intão&amp;quot; - daí as coisas seriam diferentes:
</description>
</item>

     
        <item>
  <title>Hook de COM no WinDbg</title>
  <link>http://www.caloni.com.br/hook-de-com-no-windbg/</link>
  <pubDate>2007-09-18</pubDate>
  
  <guid>http://www.caloni.com.br/hook-de-com-no-windbg/</guid>
  <description>Continuando com o tema hooks no WinDbg, vamos aqui &amp;quot;hookear&amp;quot; e analisar as chamadas de métodos de um objeto COM. O que será feito aqui é o mesmo experimento feito para uma palestra de engenharia reversa que apresentei há um tempo atrás [1], mas com as opções de pause, rewind, replay e câmera lenta habilitadas.
Antes de começar, se você não sabe nada sobre COM, não deveria estar aqui, mas aqui, aqui e aqui.
Pra começar, vamos dar uma olhada na representação da interface IUnknown em UML e em memória:
Como podemos ver, para implementar o polimorfismo, os endereços das funções virtuais de uma classe são colocados em uma tabela, a chamada vtable, famosa tanto no COM quanto no C&#43;&#43;. Existe uma tabela para cada classe-base polimórfica, e não para cada objeto. Se fosse para cada objeto não faria sentido deixar esses endereços &amp;quot;do lado de fora&amp;quot; do leiaute. E não seria nada simples e elegante fazer uma cópia desse objeto.
Assim, quando você chama uma função virtual de um objeto, o código em assembly irá chamar o endereço que estiver na posição correspondente ao método chamado dentro da vtable. Se você chama AddRef, por exemplo, que é o segundo método na tabela, será chamado o endereço da posição número dois. Com isso, mesmo desconhecendo de que tipo é o objeto a função certa será chamada, porque existe um ponteiro para essa tabela no início da interface.
Sabendo de tudo isso, agora sabemos como teoricamente proceder para colocar uns breakpoints nessas chamadas:
Note que o breakpoint não é colocado dentro da tabela, o que seria absurdo. Uma tabela são dados e dados geralmente não são executados (eu disse geralmente). Porém, usamos a tabela para saber onde está o começo da função para daí colocar a parada nesse endereço, que por fazer parte do código da função é (quem diria!) executado.
Agora vamos sair da teoria e tentar fazer as coisas mais ou menos parecidas na prática.
O nosso sorteado desse artigo foi o IMalloc, a interface de alocação de memória do COM, que existe desde a época em que não se sabia direito pra que esse tal de COM iria servir. O IMalloc é definido como se segue:
Nesse experimento, como iremos interceptar quando alguém aloca ou desaloca memória, nossos alvos são os métodos Alloc e Free. Para saber onde eles estão na tabela, é só contar, começando pelos métodos do IUnknown, que é de quem o IMalloc deriva. Se houvessem mais derivações teríamos que contar da primeira interface até a última. Portanto: QueryInterface um, AddRef dois, Release três, Alloc quatro, Realloc cinco, Free seis. OK. Contar foi a parte mais fácil.
Agora iremos precisar interceptar primeiro a função que irá retornar essa interface, pois do contrário não saberemos onde fica a vtable. Nesse caso, a função é a ole32!CoGetMalloc. Muitas vezes você irá usar a ole32!CoCreateInstance(Ex) ou a CoGetClassObject diretamente na DLL que pretende interceptar. Outras vezes, você receberá o ponteiro em alguma ocasião diversa. O importante é conseguir o ponteiro de alguma forma.
Nesse exemplo iremos obter o ponteiro através de um aplicativo de teste trivial, ignorando todas aquelas proteções antidebugging que podem estar presentes no momento da reversa, feitos por alguém que lê meu blog (quanta pretensão!):
Vamos fazer de conta que é desnecessário dizer como se compila o fonte acima.
WinDbg. Na opção &amp;quot;File, Open Executable&amp;quot; selecionamos a nossa vítima, cujo nome você escolhe na hora de compilar o fonte acima. Aqui, ele irá chamar imalloc-hook.exe. A seguir, colocamos um breakpoint na função da ole32, mandamos rodar, e esperamos a parada do código:
Maravilha. Alguém chamou a função que queríamos (quem será?). Agora podemos dar uma olhada na pilha e no protótipo da CoGetMalloc:
Como podemos ver nos parâmetros da pilha, o nosso chamador passou certinho o valor 1 no campo reservado e um ponteiro no segundo parâmetro para uma área onde, se der tudo certo, será escrito o endereço de um IMalloc, que podemos chamar carinhosamente de this. De início vemos que a variável está zerada. Agora vamos executar a função até a saída e examinar os resultados.
E não é que tudo deu certo? A variável foi preenchida, e partir dela demos uma espiadela nos endereços das funções da vtable. Nós pegamos o valor da variável que foi preenchida (o endereço da interface) e obtemos os seus primeiros 4 bytes (o endereço da vtable) e listamos o seu conteúdo (a própria vtable!). Agora basta usarmos o resultados de nossas contagens lá em cima e colocarmos os breakpoints nas funções corretas. E mandar rodar. E analisar os resultados.
Note que a função pode eventualmente ser chamada internamente (pelo próprio objeto) ou até por outro objeto que não estamos interessados em interceptar (lembre-se que os métodos de uma classe são compartilhados por todos os objetos). Por isso é importante sempre dar uma olhada no primeiro parâmetro, que é o this que obtemos primeiramente.
Com isso termina o nosso pequeno experimento de como é possível interceptar chamadas COM simplesmente contando e usando o WinDbg. OK, talvez um pouquinho a mais, mas nada de quebrar a cabeça.
Para saber mais: Engenharia Reversa para Principiantes.
</description>
</item>

     
        <item>
  <title>Aquisição de recurso é inicialização</title>
  <link>http://www.caloni.com.br/aquisicao-de-recurso-e-inicializacao/</link>
  <pubDate>2007-09-14</pubDate>
  
  <guid>http://www.caloni.com.br/aquisicao-de-recurso-e-inicializacao/</guid>
  <description>O título desse artigo é uma técnica presente no paradigma da programação em C&#43;&#43;, razão pela qual não temos o operador finally. A idéia por trás dessa técnica é conseguirmos usar recursos representados por objetos locais de maneira que ao final da função esses objetos sejam destruídos e, junto com eles, os recursos que foram alocados. Podemos chamar de recursos aquele arquivo que necessita ser aberto para escrita, o bitmap que é exibido na tela, o ponteiro de uma interface COM, etc. O nosso exemplo é sobre arquivos:
Ignorei tratamento de erros e a dor de cabeça que é a discussão sobre inicializações dentro do construtor, matéria para um outro artigo. Fora os detalhes, o que temos é: 1. uma classe que se preocupa em alocar os recursos que necessita e no seu fim desalocá-los, 2. uma função que usa um objeto dessa classe, alegremente apenas preocupada em usar e abusar do objeto. A demonstração da técnica reside no fato que a função não se preocupa em desalocar os recursos alocados pelo objeto config. Algo óbvio, desejável e esperado.
Para vislumbrarmos melhor a utilidade dessa técnica convém lidarmos com as famigeradas exceções. A possibilidade de nossa função ou alguma função chamada por essa lançar uma exceção enquanto nosso objeto está ainda construído - e com o recurso alocado - faz com que seja vital a classe do objeto ter sido bem construída a ponto de prever essa situação e liberar os recursos no destrutor. Daí o uso da técnica se torna necessário.
Por outro lado, ao usarmos objetos, devemos ter plena confiança nas suas capacidades de gerenciar os recursos que foram por eles alocados. Só assim se tem liberdade o suficiente para nos concentrarmos no código da função e solenemente ignorarmos a implementação da classe que estamos utilizando. Afinal, temos que considerar que muitas vezes o código-fonte não está disponível. Veja a mesma função com uma chance de desvio incondicional (o lançamento de uma exceção):
Nesse exemplo tudo funciona, certo? Até se a exceção for lançada, o recurso será desalocado, pois o objeto é destruído. Isso ilustra como várias técnicas de C&#43;&#43; podem conviver harmoniosamente. Mais que isso, se ajudam mutuamente. O que seria das exceções se não existissem os construtores e destrutores? Da mesma forma, os recursos são alocados e desalocados baseado na premissa de construção e destruição de objetos. Por sua vez, essa premissa vale em qualquer situação, existindo ou não exceções.
Agora, e se a exceção de BlowUpFunction é lançada e a classe File não está preparada para fechar o arquivo no destrutor? Esse é o caso da versão 2 de nossa classe File, logo abaixo. Apesar de ser a segunda versão ela foi piorada (acontece nas melhores famílias e classes):
Nesse caso o código de UseFile2 acaba deixando um recurso alocado por conta de uma exceção que ocorreu em uma função secundária chamada lá pelas tantas em um momento delicado demais para ocorrerem exceções. Note que o destrutor de File2 é chamado assim como o de File, só que este não libera os recursos do objeto. Ele não usa a técnica RAII (Resource Acquisition Is Initialization, ou o título do artigo em inglês).
Nesse tipo de classe o convívio com exceções gera um dilema: onde está o erro? Como consertá-lo? Se o problema é encontrado numa hora apertada e temos cinco minutos para revolver isso, capturar a exceção causada por BlowUpFunction é uma boa idéia. Só que nem sempre as soluções de cinco minutos são as mais maduras. Podemos não saber muito bem o que fazer com esse tipo de exceção, por exemplo. Isso geraria um tratamento de erro ou redundante - se tratarmos ali mesmo o Scatadush, já tratado em um escopo mais externo - ou fragmentado - se apenas desalocarmos o recurso de File2 e relançarmos a exceção. Eu nem diria fragmentado, pois estamos tratando um erro inventado, se considerarmos que é função dos objetos desalocarem os recursos que foram por eles mesmos alocados.
A opção que dura mais de cinco minutos pode evitar futuras dores de cabeça: arregaçar as mangas e refazer a classe File2 observando o princípio de RAII. Possivelmente algo na interface deverá ser alterado, o que causará a alteração de mais códigos-fonte que utilizam essa classe. Alterar mais códigos-fonte significa testar novamente mais partes do software, algumas nem de perto relacionadas com o problema em si. Ou seja, não é cômodo, mas é íntegro. Sabendo que futuras funções que usarem essa classe já estarão corretas, mesmo que uma exceção seja lançada e não seja capturada, é um dado significativo: representa produtividade futura.
A decisão sobre qual solução é a melhor está muito além do escopo desse artigo, pois obviamente cada caso é um caso. Mas não custa nada pensar um pouco sobre C&#43;&#43; quando se estiver programando. E &amp;quot;aquisição de recurso é inicialização&amp;quot; faz parte do modo de pensar dessa linguagem.
</description>
</item>

     
        <item>
  <title>Guia básico de controle de código (Source Safe)</title>
  <link>http://www.caloni.com.br/guia-basico-de-controle-de-codigo-source-safe/</link>
  <pubDate>2007-09-12</pubDate>
  
  <guid>http://www.caloni.com.br/guia-basico-de-controle-de-codigo-source-safe/</guid>
  <description>O primeiro passo para se passar no Teste do Joel é possuir algum tipo de controle de código. E ele está mais do que certo. Não existe nada mais frustrante do que não ter exatamente o código-fonte da versão que está rodando no cliente ou não saber o que mudou desde que a versão foi entregue. Esse tipo de coisa pode acabar com uma empresa ou fazer com que ela fique muito mal vista no mercado.
Porém, independente do mercado, existe um bom motivo para o desenvolvedor possuir algum tipo de controle de código: controle. Se você ou sua equipe não conseguem corrigir todos os bugs, pelo menos saberão o que já foi feito. Se você achou um bug que não existia antes da versão 10, o histórico das mudanças entre a versão estável 9 e a versão não-tão-estável 10 vai te dar uma pista muito boa de onde o problema pode ter sido gerado. Visto dessa forma, não importa muito o tamanho da equipe ou da organização. O importante de um bom código é que suas mudanças estejam sempre registradas, visíveis e disponíveis a qualquer um.
Um controle de código para uma pessoa só não precisa ser nada muito sofisticado, sendo que um amontoado de ZIPs pode dar conta do recado. Porém, a partir do momento em que o número de desenvolvedores aumenta para dois ou mais, aí o controle baseado em ZIPs começa a ruir, e é necessário usar uma ferramenta mais apropriada. Existem algumas opções, que vai do gosto e necessidades de cada um:
  Visual Source Safe ou VSS: não é gratuito nem robusto o suficiente para agüentar toneladas de código-fonte, mas vem junto do Visual Studio e pode ser apropriado para empresas de porte pequeno ou médio (e empresas de um programador só).
  Concurrent Version System ou CVS: é um sistema fonte aberto, gratuito e robusto. Suficiente para agüentar toneladas de código-fonte e equipes de vários andares. Atualmente está sendo substituído gradualmente pelo
  Subversion ou SVN: é um substituto moderno do antigo CVS; igualmente gratuito e poderoso, está rapidamente se tornando a opção predominante.
  Vou explicar aqui os principais passos para começar a utilizar um controle de código usando como exemplo o Source Safe versão 2005 que, apesar de não ser gratuito, é muito usado em empresas que programam para Windows e já utilizam o Visual Studio há muito tempo.
Antes de qualquer coisa é necessário criar uma base de dados onde estarão os fontes. Para isso a primeira execução do programa irá exibir um assistente que irá guiá-lo pelos poucos e simples passos para a criação de uma nova base.
O processo é bem simples, baseado em Next, Next, até que você chega em momento de decisão, onde deve escolher qual dos dois métodos de controle de fonte irá utilizar:
  Lock-Modify-Unlock Model. O modelo clássico do Source Safe, permite que apenas um programador altere um fonte de cada vez. Se você é novo nesse negócio de controle de fonte, recomendo essa opção, que é a mais indolor. Em equipes pequenas costuma funcionar. E esse é o modelo que iremos utilizar aqui.
  Copy-Modify-Merge Model. Esse novo modelo segue o princípio do CVS e do Subversion. Nele todos podem alterar ao mesmo tempo qualquer código-fonte. Porém, na hora de subir as modificações de volta para a base é necessário um passo intermediário conhecido como merge. É onde são resolvidos conflitos, caso algum desenvolvedor tenha feito modificações no mesmo local que você. Geralmente é escolhida uma ou mais pessoas para gerenciar essa parte do processo. Esse modelo tem funcionado bastante em projetos de fonte aberto e de empresas grandes.
  Agora que a base está criada, o próximo passo é torná-la disponível a todos. A maneira mais fácil de fazer isso é criando um compartilhamento na rede (de preferência oculto) e divulgando às pessoas interessadas. É claro que você, como bom administrador, irá ter que criar os usuários que irão acessar a base.
Após esse processo de integração, os usuários podem começar a usar o Source Safe através da primeira opção do início do assistente (Database Selection).
Antes de começar a mexer nos fontes, o Source Safe pede que você defina um diretório raiz onde começa a ramificação de pastas dos seus fontes. Isso pode ser feito pela opção File, Set Working Folder (Ctrl &#43; D). A partir daí, cada pasta é chamada de projeto (project) no Source Safe. Para criar novos projetos/pastas, use a opção &amp;quot;File, Create Project&amp;quot;. Para adicionar novos arquivos, &amp;quot;File, Add Files&amp;quot;. Cada usuário pode definir seu próprio diretório de trabalho por máquina, mas geralmente é uma boa idéia mantê-los todos utilizando a mesma pasta.
Após adicionar os arquivos do projeto, é possível fazer modificações usando a opção check-out. O check-out quer dizer que os fontes saem (OUT) da base e são copiados com direito de escrita para seu disco local. Após feitas as modificações, usa-se a opção check-in para subir as modificações para o banco. O check-in quer dizer que as modificações feitas no disco local entram (IN) na base. Cada operação feita com esses dois passos é armazenada no histórico do Source Safe, e podem ser utilizadas para voltar versões antigas, comparar versões antigas novas, etc.
Quando todos os fontes que subirem constituirem uma alteração madura, compilável, testada pelo desenvolvedor e pronta para ser repassada para os testadores, deve-se criar um rótulo, ou label, para que futuramente essa versão possa ser facilmente identificada entre os milhões de modificações de fonte que sua equipe irá fazer ao longo do tempo. Se essa versão se tornar uma &amp;quot;entregável&amp;quot;, pode-se utilizar o rótulo para obter exatamente a versão entregue a qualquer momento, independente de quantas modificações terem sido feitas depois. Essa marcação de fontes pode ser muito útil na ocorrência de incêndios, e todos sabemos que eles ocorrem com mais freqüência do que gostaríamos. Por isso é importante estar preparado.
Se você chegou até aqui, quer dizer que está realmente interessado em controlar seus fontes. Parabéns! O controle de fontes vem com algumas vantagens. Vamos supor que já exista uma versão estável no Source Safe e você precisa fazer alguma correção/teste como prova de conceito. Esse tipo de fonte normalmente seria descartável, mas agora que você possui uma ferramenta de controle de fonte funcionando, isso não é necessário.
Se é necessário desenvolver uma prova de conceito, pode-se optar por criar uma ramificação do fonte, ou branch. Essa opção cria um novo projeto no Source Safe com fontes existentes, mantém o histórico de modificações, mas gera uma nova linha de vida do fonte. Qualquer modificação feita em um branch fica nesse branch, seja o principal ou secundário. É possível também no futuro juntar dois branchs.
Agora, se a modificação é um simples teste durante a depuração, pode ser feito o check-out para modificações temporárias. Se mais tarde for decidido que as modificações não serão efetuadas na base, basta executar a opção undo check-out, que volta o fonte da base para o disco local e mantém a versão intacta. Use essa opção com cuidado, pois quaisquer modificações no disco local serão perdidas.
Agora que os fontes estão vivendo tranqüilamente no controle de fontes, é possível executar builds automatizados de tempos em tempos. Isso garante a estabilidade do seu projeto, pois junto dos builds é possível fazer testes, tanto da compilação em si quanto depois de compilado.
O Source Safe possui uma ferramenta em linha de comando que faz as mesmas operações que a versão gráfica, além de possuir uma série de interfaces COM que podem ser usadas para interagir com o controle de fontes através de scripts. Além de outras ferramentas de automação de builds que podem ser integradas, como o NAnt e o CruiseControl.
O resumo da ópera é: cuide bem dos seus fontes. Muito trabalho, tempo e dinheiro são despendidos com desenvolvimento. Não cuidar do resultado de tudo isso é como botar fogo no estoque de uma fábrica.
</description>
</item>

     
        <item>
  <title>Antidebug: detectando attach</title>
  <link>http://www.caloni.com.br/antidebug-detectando-attach/</link>
  <pubDate>2007-09-10</pubDate>
  
  <guid>http://www.caloni.com.br/antidebug-detectando-attach/</guid>
  <description>Hoje foi um belo dia para engenharia reversa e análise de proteções. Dois ótimos programas vieram ao meu conhecimento: um monitor de chamadas de API e um monitor de chamadas de COM (complementando o primeiro, que não monitora funções depois que CoCreateInstance foi chamado). Além de que no sítio do primeiro programa - de algum entusiasta do bom e velho Assembly Win32, diga-se de passagem - encontrei o código-fonte para mais uma técnica antidebugging, o que nos leva de volta para a já consagrada série de técnicas antidepuração.
O objetivo dessa proteção é detectar se, após o executável ter sido iniciado, algum depurador metido a besta tentou atachar-se no processo criado, ou seja, tentou iniciar o processo de depuração após o aplicativo já ter iniciada a execução. Isso é possível - de certa forma trivial - na maioria dos depuradores (se não todos), como o Visual Studio e o WinDbg. Diferente da técnica de ocupar a DebugPort, que impede a ação de attach, a proteção nesse caso não protege diretamente; apenas permite que o processo saiba do suposto ataque antes de entregar o controle ao processo depurador.
O código que eu encontrei nada mais faz do que se aproveitar de uma peculiaridade do processo de attach: ao disparar o evento, a função ntdll!DbgUiRemoteBreakin é chamada. Ora, se é chamada, é lá que devemos estar, certo? E isso, como vemos abaixo, é relativamente fácil:
Para compilar o código acima, basta chamar o compilador seguido do ligador. Obs.: precisamos da user32.lib para chamar a função API MessageBox:
Após o programa ter sido executado, qualquer tentativa de attach irá exibir nossa mensagem de detecção, seguida pelo capotamento do programa.
Sim, eu sei. Às vezes temos que apelar pra &amp;quot;ignorância&amp;quot; e fazer códigos obscuros como esse:
Existem inúmeras maneiras de fazer a mesma coisa. O exemplo acima é o que é chamado comumente nas rodinhas de crackers de shellcode, que é um nome bonitinho para &amp;quot;array de bytes que na verdade é um assembly de um código que faz coisas interessantes&amp;quot;. Shellcode for short =).
Maneiras alternativas de fazer isso são:
  Declarar uma função naked no Visual Studio, criar uma função vazia logo após e fazer continha de mais e menos para chegar ao tamanho que deve ser copiado.
  Criar uma estrutura cujos membros são opcodes disfarçados. Dessa forma é possível no construtor dessa estrutura preencher os valores corretamente e usá-la como uma &amp;quot;função móvel&amp;quot;.
  Ambas possuem prós e contras. Os contras estão relacionados com a dependência do ambiente. Na primeira alternativa é necessário configurar o projeto para desabilitar o &amp;quot;Edit and Continue&amp;quot;, enquanto no segundo é necessário alinhar a estrutura em 1 byte.
Seja qual for a solução escolhida, ao menos temos a vantagem do impacto no sistema de nosso aplicativo ser praticamente nulo, pois isolamos em duas funções - AntiAttachAbort e InstallAntiAttach - um hook de uma API local (do próprio processo) que supostamente nunca deveria ser chamada em um binário de produção. Além do mais, existem maneiras mais a la C&#43;&#43; de fazer coisas como &amp;quot;live assembly&amp;quot;. Mas isso já é matéria para futuros e excitantes artigos =D.
</description>
</item>

     
        <item>
  <title>Hook de API no WinDbg</title>
  <link>http://www.caloni.com.br/hook-de-api-no-windbg/</link>
  <pubDate>2007-08-29</pubDate>
  
  <guid>http://www.caloni.com.br/hook-de-api-no-windbg/</guid>
  <description>Basicamente existem duas maneiras de um executável obter o endereço de uma função API do Windows: ou ele usa uma lib de interface com a DLL (o chamado &amp;quot;link estático&amp;quot;) ou ele chama a função kernel32!GetProcAddress explicitamente [1].
Para conseguir saber as funções das quais um executável obtém o endereço através da primeira técnica podemos utilizar o mundialmente famoso Dependency Walker. Ele nos mostrará quais DLLs ele utiliza e quais funções por DLL ele quer o endereço. Ele também nos avisa sobre as DLLs que estão utilizando delay load, uma técnica inventada no Visual Studio para que os executáveis não dependam estaticamente de APIs muito novas que podem não existir em versões do Windows mais antigas. Com o Depends também é possível fazer hook de chamadas de API utilizando a opção profiling (F7), mas não costuma funcionar muito bem com trojans, pois eles capotam antes que alguma coisa interessante ocorra.
O importante do Dependency Walker para o WinDbg é que com um editor é possível copiar todas as funções exibidas em sua interface para um editor, usar um pouco de regular expressions e criar uma batelada de breakpoints no WinDbg:
O comando &amp;quot;bp&amp;quot; cria um breakpoint no endereço requisitado. O que está entre aspas são os comandos que você deseja executar quando o breakpoint for disparado. No caso, para todas as funções será impresso o seu nome (comando &amp;quot;.echo&amp;quot;) e a execução irá continuar (comando &amp;quot;g&amp;quot;). Ao rodar o programa, as chamadas das funções são mostradas na saída do depurador:
Lindo, não? Porém ainda podem estar sendo chamadas as funções obtidas pela segunda técnica, a do GetProcAddress. Para esse caso devemos ir um pouquinho mais fundo e rodar o executável duas vezes. Na primeira, coletamos as funções que são obtidas por essa técnica através do seguinte comando:
O comando &amp;quot;da&amp;quot; exibe o conteúdo de uma string em C (caracteres ANSI e terminada em zero) na memória. A memória no caso é o &amp;quot;apontado do valor contido no segundo parâmetro da pilha&amp;quot;. Complicado? Nem tanto: lembre-se que o ESP aponta sempre pro endereço de retorno da função chamadora e os parâmetros são sempre empilhados na ordem inversa da declaração em C. Logo, se o protótipo de GetProcAddress é:
O último parâmetro empilhado (ESP&#43;4) é o hModule, e o penúltimo (ESP&#43;8) é o lpProcName, que é o lugar onde é passado o nome da função.
Devemos lembrar de colocar esse breakpoint bem no início da execução e rodar o executável uma vez. Com isso coletamos o conjunto de nomes de funções usadas para chamar GetProcAddress:
Daí é só organizar a lista obtida em ordem alfabética, acabar com duplicidades e criar o mesmo tipo de breakpoint que foi usado para as funções estáticas (pode ser sem o nome da DLL porque, embora não recomendado, o WinDbg se vira para encontrar os símbolos). Depois de criados os comandos, rodamos novamente o executável e, logo no início, já colocamos todos os breakpoints das funções coletadas.
Essa é uma maneira rústica, porém eficaz e rápida de obter a lista de execução da API utilizada por um programa [2].
[1] Uma variação do método GetProcAddress é a técnica de delay load usado pelo Visual C&#43;&#43;. Porém, como o Dependency Walker nos mostra também as DLLs que estão linkadas usando essa técnica se torna dispensável um tratamento ad hoc.
[2] Essa técnica nem sempre funciona com todas as chamadas API, pois o aplicativo ainda pode utilizar outras maneiras de obter o endereço de uma função e chamá-la. A solução definitiva seria escrever diretamente um assembly esperto no começo da função, o que pode gerar mais problemas que soluções. Do jeito que está, conseguimos resolver 90% dos nossos problemas com análise de chamadas API. O resto nós podemos resolver em futuros artigos.
 http://www.kakeeware.com: sítio com monitor de chamadas de API e outras ferramentas interessantes. Detalhe notável: o cara faz tudo usando apenas assembly, o que torna os programas realmente pequenos e rápidos. ComTrace: outro monitor de chamadas, mas de componentes COM. Intercepta todas as chamadas de métodos de um aplicativo.  </description>
</item>

     
        <item>
  <title>Antidebug: ocupando a DebugPort</title>
  <link>http://www.caloni.com.br/antidebug-ocupando-a-debugport/</link>
  <pubDate>2007-08-23</pubDate>
  
  <guid>http://www.caloni.com.br/antidebug-ocupando-a-debugport/</guid>
  <description>Quando um depurador inicia um processo para ser depurado ou, o caso abordado por este artigo, se conecta em um processo já iniciado, as comunicações entre esses dois processos é feita através de um recurso interno do Windows chamado de LPC (Local Procedure Call). O sistema cria uma &amp;quot;porta mágica&amp;quot; de comunicação específica para a depuração e os eventos trafegam por meio dela.
Entre esses eventos podemos citar os seguintes:
  Breakpoints disparados
  Exceções lançadas
  Criação/saída de threads
  Load/unload de DLLs
  Saída do processo
  No caso de se conectar em um processo já existente, é chamada a função da API DebugActiveProcess. A partir dessa chamada, se retornado sucesso, o processo que depura agora está liberado para ficar chamando continuamente a função API WaitForDebugEvent. E o código se resume a isto:
O detalhe interessante desse processo de comunicação depurador/depurado é que um processo só pode ser depurado por apenas UM depurador. Ou seja, enquanto houver um processo depurando outro, os outros processos só ficam na vontade.
Partindo desse princípio, podemos imaginar uma proteção baseada nessa exclusividade, criando um processo protetor que conecta no processo protegido e o &amp;quot;depura&amp;quot;:
Os passos para testar o código acima são:
  Compilar o código.
  Executar o notepad (ou qualquer outra vítima).
  Obter seu PID (Process ID).
  Executar o protetor passando o PID como parâmetro.
  Tentar &amp;quot;atachar&amp;quot; no processo através do Visual C&#43;&#43;.
  Após o processo de attach, a porta de debug é ocupada, e a comunicação entre depurador e depurado é feita através do LPC. Abaixo uma pequena ilustração de como as coisas ocorrem:
Basicamente o processo fica recebendo eventos de debug (através da fila de mensagens LPC) continuamente até o evento final, o de final de processo. Note que se alguém tentar derrubar o processo que depura o processo depurado cai junto.
O ponto forte desse tipo de proteção é que não afeta a compreensão e a legibilidade do código. De fato o próprio código que &amp;quot;protege&amp;quot; está em outro processo. O fraco, eu diria, é a sua alta visibilidade. Todo mundo que tentar atacar verá dois processos serem criados; e isso já faz pensar...
Por isso é necessário pensar bem na implementação. Particularmente uma coisa a ser bem arquitetada é a união entre depurador e depurado. Quanto melhor essas duas peças forem encaixadas, tão mais difícil será para o atacante separá-las. Uma idéia adicional é utilizar a mesma técnica na direção oposta, ou seja, o processo depurado se atachar no depurador.
Dessa vez não vou afirmar que, uma vez entendido o problema, a solução torna-se óbvia. Isso porque ainda não pensei o suficiente para achar uma solução óbvia. Idéias?
</description>
</item>

     
        <item>
  <title>Erro de compilação: funções muito novas na Win32 API</title>
  <link>http://www.caloni.com.br/erro-de-compilacao-funcoes-muito-novas-na-win32-api/</link>
  <pubDate>2007-08-21</pubDate>
  
  <guid>http://www.caloni.com.br/erro-de-compilacao-funcoes-muito-novas-na-win32-api/</guid>
  <description>Quando fala-se em depuração geralmente o pensamento que vem é de um código que já foi compilado e está rodando em alguma outra máquina e gerando problemas não detectados nos testes de desenvolvedor. Mas nem sempre é assim. Depuração pode envolver problemas durante a própria compilação. Afinal de contas, se não está compilando, ou foi compilado errado, é porque já existem problemas antes mesmo da execução começar.
O fonte abaixo, por exemplo, envolve um detalhe que costuma atormentar alguns programadores, ou por falta de observação ou documentação (ou ambos).
Tirando o fato que o retorno void não é mais um protótipo padrão da função main e que a definição da enumeração COMPUTERNAMEFORMAT dentro da função main é no mínimo suspeita, podemos testar a compilação e verificar que existe exatamente um erro grave neste fonte:
A função GetComputerNameEx parece não ter sido definida, apesar de estarmos incluindo o header windows.h, que é o pedido pela documentação do MSDN. Esse tipo de problema acontece na maioria das vezes por dois motivos:
 o header responsável não foi incluído (não é o caso, como vimos), é necessário especificar a versão mínima do sistema operacional.  De fato, se criarmos coragem e abrirmos o arquivo winbase.h, que é onde a função é definida de fato, e procurarmos pela função GetComputerNameEx encontramos a seguinte condição:
Ou seja, para que essa função seja visível a quem inclui o windows.h, é necessário antes definir que a versão mínima do Windows será a 0x0500, ou seja, Windows 2000 (vulgo Windows 5.0). Aliás, é como aparece na documentação. Um pouco de observação nesse caso seria o suficiente para resolver o caso, já que tanto abrindo o header quanto olhando no exemplo do MSDN nos levaria a crer que é necessário definir essa macro:
Outra observação que poderia ter ajudado na hora de codificar seria dar uma olhada no que os caras escrevem na seção de advertências (remarks) da documentação:
 To compile an application that uses this function, define the WIN32WINNT macro as 0x0500 or later. For more information, see Using the Windows Headers.
 Podemos também notar pela definição do COMPUTERNAMEFORMAT dentro do main que o código estava no meio do caminho de cometer um sacrilégio: declarar funções e estruturas que já estão definidas nos headers da API. Portanto, se você já encontrou algum código parecido com esse, é hora de colocar em prática algumas teorias de refactoring.
</description>
</item>

     
        <item>
  <title>Junctions</title>
  <link>http://www.caloni.com.br/junctions/</link>
  <pubDate>2007-08-17</pubDate>
  
  <guid>http://www.caloni.com.br/junctions/</guid>
  <description>Semana passada baixei uma nova imagem para minha máquina de desenvolvimento. Esse esquema do pessoal da engenharia instalar as coisas para você facilita muito as coisas, mas existe o risco de algo ser instalado no lugar errado, que foram os casos do DDK e do SDK do Windows. Aqui no desenvolvimento, para efeito de padronização, utilizamos a seguinte estrutura de diretórios para esses dois aplicativos:
Porém, por algum motivo desconhecido os instaladores da Microsoft não seguem o nosso padrão: o SDK é instalado em &amp;quot;%programfiles%\Microsoft Platform SDK&amp;quot; e o DDK em &amp;quot;C:\WINDDK\3790.1830&amp;quot;. Para corrigir este pequeno ato relapso eu até poderia reinstalar ambos os aplicativos no local correto, gastanto algumas horas do dia, mas existe uma outra solução mais rápida e simpática chamada de junction.
Um junction é um link simbólico (symbolic link) de diretório. É praticamente um atalho, com a diferença que ele se comporta exatamente como se fosse o próprio objeto para o qual aponta: qualquer arquivo criado ou apagado usando o junction cria ou apaga um arquivo real no diretório real para o qual ele aponta. Essa característica pode ser tão útil quanto perigosa, por isso devem-se utilizar junctions com cuidado.
Para criar um junction pode-se usar uma ferramenta disponível no Windows Resource Kit chamada linkd.exe. Porém, para evitar de ter que baixar todo o pacote para usar um único arquivo, existe uma outra ferramenta desenvolvida à parte por Russinovich chamada junction.exe. O comando para criar junctions é bem fácil e direto:
E é isso aí. A partir de agora tanto as pastas originais quanto os junctions criados para elas respondem como se fossem a mesma coisa, porém com paths diferentes.
 &amp;quot;Neo, sooner or later, you&#39;re going to realize, just as I did, that there&#39;s a different between knowing the path... and walking the path...&amp;quot;
 No Vista os junctions também funcionam para arquivos e possuem seu próprio aplicativo nativo, o mklink.exe. Porém, ele chama os links para diretórios de junctions (em português, junções) e os links para arquivos de links mesmo. Você pode notar uma pequena gamb.. adaptação técnica ao mudarem o nome da pasta &amp;quot;Documents and Settings&amp;quot; para &amp;quot;Users&amp;quot; (ou &amp;quot;Usuários&amp;quot;, na versão em português).
Esse link é extremamente necessário para a compatibilidade daqueles aplicativos feitos às pressas que não se importam em perguntar para o sistema onde está a pasta de documentos do usuário, fixando o path como se ele fosse estar sempre lá.
 Lista dos junctions do Vista e explicações mais detalhadas e técnicas.  </description>
</item>

     
        <item>
  <title>História da linguagem C - parte 2</title>
  <link>http://www.caloni.com.br/historia-da-linguagem-c-parte-2/</link>
  <pubDate>2007-08-15</pubDate>
  
  <guid>http://www.caloni.com.br/historia-da-linguagem-c-parte-2/</guid>
  <description>No princípio... não, não, não. Antes do princípio, quando C era considerada a terceira letra do alfabeto e o que tínhamos eram linguagens experimentais para todos os lados, dois famigerados Srs. dos Laboratórios Bell, K. Thompson e D. Ritchie, criaram uma linguagem chamada B. E B era bom.
O bom de B era sua rica expressividade e sua simples gramática. Tão simples que o manual da linguagem consistia de apenas 30 páginas. Isso é menos do que as 32 palavras reservadas de C. As instruções eram definidas em termos de if&#39;s e goto&#39;s e as variáveis eram definidas em termos de um padrão de bits de tamanho fixo - geralmente a word da plataforma - que utilizada em expressões definiam seu tipo; esse padrão de bits era chamado rvalue. Imagine a linguagem C de hoje em dia com apenas um tipo: int.
Como esse padrão de bits nunca muda de tamanho, todas as rotinas da biblioteca recebiam e retornavam sempre valores do mesmo tamanho na memória. Isso na linguagem C quer dizer que o char da época ocupava tanto quanto o int. Existia inclusive uma função que retornava o caractere de uma string na posição especificada:
Sim! Char era uma função, um conversor de &amp;quot;tipos&amp;quot;. No entanto a própria variável que armazenava um char tinha o tamanho de qualquer objeto da linguagem. Esse é o motivo pelo qual, tradicionalmente, as seguintes funções recebem e retornam ints em C e C&#43;&#43;:
Segue o exemplo de uma função na linguagem B, hoje muito famosa:
Como podemos ver, vários elementos (se não todos) da linguagem C já estão presentes na B.
</description>
</item>

     
        <item>
  <title>GINA x Credential Provider</title>
  <link>http://www.caloni.com.br/gina-x-credential-provider/</link>
  <pubDate>2007-08-13</pubDate>
  
  <guid>http://www.caloni.com.br/gina-x-credential-provider/</guid>
  <description>Não fui convidado a participar do tema, mas como já faz algum tempo que o rascunho deste artigo está no molho, e aproveitando que meu amigo Ferdinando resolveu escrever sobre nossa amiga em comum, darei continuidade à minha empolgação sobre o tagging e largarei aqui este pequeno adendo.
Com a chegada do Windows Vista, uma velha conhecida minha e dos meus colegas deixou de fazer parte do sistema de autenticação do sistema operacional: a velha GINA, Graphical Identification aNd Autentication.
Basicamente se trata de uma DLL que é chamada pelo WinLogon, o componente responsável pelo famoso Secure Attention Sequence (SAS), mais conhecido por Ctrl &#43; Alt &#43; Del. Ele efetua o logon do usuário, mas quem mostra as telas de autenticação, troca de senha, bloqueio da estação é a GINA. Mexi com várias GINAs há um tempo atrás: GINAs invisíveis, GINAs que autenticam smart cards, GINAs que autenticam pela impressão digital, e por aí vai a valsa.
O Windows já vem com uma GINA padrão, a MsGina.dll, que autentica o usuário baseada em usuário e senha e/ou smart card. Teoricamente o intuito original de uma GINA fornecida por terceiros era permitir outros meios de autenticação. Para isso o fornecedor deveria trocar todas as telas de autenticação pela equivalente de acordo com o novo tipo de autenticação (por exemplo, um campo com uma impressão digital para permitir o uso de biometria em vez de senha). Porém, um outro uso pode ser controlar o login dos usuários baseado em outras regras além das que o Windows já fornece.
Apesar de útil, o sistema baseado em GINAs tinha um pequeno problema: permitia somente a troca exclusiva, ou seja, só uma GINA pode ser ativada. Se não for a da Microsoft, que seja a do fornecedor, e apenas a de um fornecedor. Isso começa a ficar limitado diante das novas e conflitantes maneiras que um usuário possui hoje em dia de fazer logon: nome e senha, íris dos olhos, impressão digital, formato do nariz e assim por diante. Todas essas autenticações deveriam estar disponíveis ao mesmo tempo para que o usuário escolha qual deles lhe convém.
Foi por isso que surgiu seu substituto natural no Windows Vista: o Credential Provider.
O sistema de Credential Provider permite que inúmeras DLLs sejam registradas no sistema para receberem eventos de logon, seja para criar uma nova sessão (tela de boas vindas) ou apenas para se autenticar já em uma sessão iniciada, como, por exemplo, nos casos em que o Controle da Conta do Usuário (UAC: User Account Control) entra em ação.
O sistema de coleta foi simplificado e modernizado: agora a interface não se baseia em funções exportadas, como a GINA, mas em interfaces COM disponíveis. O desenvolvedor também consegue escolher os cenários em que ele pretende entrar em ação:
  Efetuar logon
  Desbloquear estação
  Mudar a senha
  Efetuar conexão de rede (antes do logon)
  Baseado no número de CPs registrados no sistema, o LogonUI (processo responsável por exibir a tela de boas vindas) irá exibir as respectivas credenciais para cada um dos CPs envolvidos no logon.
Já que fomos brindados com um exemplo de GINA stub do Ferdinando, também irei disponibilizar um outro exemplo, este um pouco mais perigoso, da época de laboratório da faculdade. Se trata igualmente de uma GINA que se aproveita da implementação da GINA original, porém na hora de autenticar um usuário ela captura os dados do logon (usuário e senha) e grava em uma parte do registro acessível apenas pelo sistema (lembre-se que a GINA, por fazer parte do WinLogon, roda na conta de sistema).
 É claro que para utilizar essa GINA, você deve possuir direitos de administração, ou conhecer alguma brecha de segurança. Eu optei pela segunda opção, já que não tinha a primeira. Podemos dizer apenas que o artigo sobre falhas de segurança relacionadas a usuários avançados do Russinovich pôde resolver meu problema.
  Última referência técnica Documentação das interfaces Guia de migração GINA =&amp;gt; CP  </description>
</item>

     
        <item>
  <title>Antidebug: interpretação baseada em exceção (parte 2)</title>
  <link>http://www.caloni.com.br/antidebug-interpretacao-baseada-em-excecao-parte-2/</link>
  <pubDate>2007-08-09</pubDate>
  
  <guid>http://www.caloni.com.br/antidebug-interpretacao-baseada-em-excecao-parte-2/</guid>
  <description>No primeiro artigo vimos como é possível &amp;quot;enganar&amp;quot; o depurador através de exceções e assim fazer o atacante perder um tempo considerável tentando se desvencilhar dos breakpoints de mentira. Porém, vimos também que essa é uma solução difícil de manter no código-fonte, além de possuir o ponto fraco de ser facilmente contornada se descoberta. Agora é a hora de tornar as coisas mais fáceis de manter e ao mesmo tempo garantir maior dificuldade mesmo que o atacante descubra o que está acontecendo debaixo do seu nariz.
O upgrade apresentado aqui continua utilizando o lançamento de exceções intrinsecamente, mas agora não depende mais da divisão do código em minifunções e chamá-las aos poucos. Em invés disso, temos apenas que pegar traços de código e colocá-los em torno de uma macro milagrosa que fará tudo o que quisermos. Isso, claro, depois de algumas marteladas que serão explicadas aqui.
A solução acima está apresentada em pseudo-código para tornar mais claro o conceito. Note que existe uma espécie de &amp;quot;retorno invisível&amp;quot;, não baseado em retorno de pilha, envolvido. Para implementá-lo, contudo, podemos nos ajeitar com o velho e bom padrão C ANSI, com as rotinas setjmp (passo 1) e longjmp (passo 3). Para entender a implementação dessa funções na plataforma 8086 precisamos ter primeiro uma visão básica da estrutura de chamada de funções baseada em pilha.
Registradores são variáveis reservadas do processador que podem ser utilizadas pelo código assembly da plataforma envolvida. Stack frame (estrutura da pilha) nada mais é que a hierarquia de chamadas das funções, o &amp;quot;quem chamou quem&amp;quot; em uma execução qualquer. Call e ret são instruções em assembly para chamar uma função (call) e sair de uma função (ret), respectivamente. Ambas alteram o stack frame.
Imagine que você tem uma função, CallFunc, e outra função, Func, e que uma chame a outra. Para analisarmos apenas a chamada de função, e apenas isso, vamos considerar que Func não recebe nenhum parâmetro e não retorna nenhum valor. O código em C fica, então, assim:
void Func() { return; }
void CallFunc() { Func(); }
Simples, não? Por esse mesmo motivo o disassembly terá que ser igualmente simples. Em CallFunc ele deverá conter a chamada da função (call) e em Func o retorno da chamada (ret). O resto que eventualmente aparecer está relacionado aos controles da versão Debug.
Func: 00411F73 previnstruction ; ESP = 0012FD38 (four bytes stacked up) 00411F74 ret ; *ESP = 00411FA3 (return address)
CallFunc: 00411F9C previnstruction 00411F9E call Func (411424h) ; ESP = 0012FD3C 00411FA3 nextinstruction
A partir do assembly acima podemos concluir no mínimo duas coisas: 1. a pilha &amp;quot;cresce&amp;quot; para baixo, pois seu valor decrementou de quadro (0012FD3C para 0012FD38 são 4 byte a menos) e 2. o valor de retorno da função chamada é o endereço da próxima instrução após a chamada (call), no caso 00411FA3.
Ora, da mesma forma que conseguimos acompanhar essa simples execução, o atacante também o fará. Por isso que no meio dessa chamada iremos colocar o lançamento de uma exceção e, no retorno, faremos não do modo convencional apresentado, mas por uma outra técnica que, ao invés de utilizar a instrução ret, seta &amp;quot;manualmente&amp;quot; o valor do registrador ESP (estado da pilha) e &amp;quot;pula&amp;quot; para a próxima instrução de CallFunc.
Func: 00411F60 throwexception 00411F61 ... 00411F73 catchexception 00411F74 mov ESP, 0012FD3C ; ESP = 0012FD3C, como em CallFunc 00411F75 jmp 00411FA3 ; &amp;quot;pula&amp;quot; para CallFunc::nextinstruction
Toda essa esculhambada em assembly não precisa ser necessariamente feita em linguagem de baixo nível. Foi apenas uma maneira que encontrei pra ilustrar as diferenças entre retorno baseado em pilha e alteração no fluxo do código. Como já foi dito, para a sorte e o bem-estar de todos, essa mesma técnica pode ser implementada com funções C da biblioteca ANSI:
Essa foi a técnica adicionada à solução do lançamento de exceções. O código final ficou mais claro:
À primeira vista parece um desperdício o if estar diretamente no código (lembre-se que vamos utilizar a mesma estrutura condicional em várias e várias partes do código. Para tornar mais claro seu uso, resumir a chamada protegida e permitir que a proteção seja desabilitada em debug, vamos criar uma macro:
Veja que como agora permitimos a seleção do anti-debug por chamada, fica mais fácil escolher quais os pontos a serem protegidos e quais não devem/podem por conta de perfomance ou outro detalhe obscuro que sempre existe na vida de um programador C&#43;&#43;.
</description>
</item>

     
        <item>
  <title>História da linguagem C - parte 1</title>
  <link>http://www.caloni.com.br/historia-da-linguagem-c-parte-1/</link>
  <pubDate>2007-08-01</pubDate>
  
  <guid>http://www.caloni.com.br/historia-da-linguagem-c-parte-1/</guid>
  <description>Confesso que adoro estudar sobre a história da linguagem C. Essa verdadeira adoração pela linguagem me fez estudar suas precursoras, como as linguagens BCPL e B. Posso dizer que todo esse conhecimento, no final das contas, valeu a pena. Hoje entendo muito melhor as decisões tomadas na criação da linguagem e, principalmente, a origem de algumas idiossincrasias e boas idéias que permaneceram até hoje.
Em 21 de julho de 1967 Martin Richards libera o manual da sua recém-criada linguagem BCLP. Na verdade, ela havia sido criada em 66 e implementada na primavera do ano seguinte no Instituto de Tecnologia de Massachusetts (vulgo MIT). Seus objetivos eram claros, como para todo criador de uma nova linguagem: melhorar uma linguagem anterior. Nesse caso, foi uma melhoria da Combined Programming Language (CPL), retirando, de acordo com Martin, &amp;quot;todas aquelas características da linguagem completa que tornavam a compilação difícil&amp;quot;.
E BCPL era de fato bem simples. Não tinha tipos, era limpa e poderosa. Porém, mais importante que tudo isso, ela era portável. E essa portabilidade, aliada ao fato que escrever compiladores para ela era bem mais simples (alguns compiladores rodavam com apenas 16 KB), a tornaram especialmente popular na época.
Essa portabilidade era obtida com o uso de um artifício mais ou menos conhecido da comunidade C/C&#43;&#43; hoje em dia: a divisão entre código objeto e código final. O compilador era dividido em duas partes: a primeira parte era responsável por criar um código em estado intermediário feito para rodar em uma máquina virtual. Esse código era chamado de O-code (O de object). A segunda parte do compilador era responsável por traduzir esse O-code no código da máquina-alvo (onde iria ser rodado o programa). Essa sacada genial de 40 anos atrás permitiu que fosse mais simples fazer um compilador para uma nova plataforma e portar todo o código que já tinha sido escrito para uma plataforma anterior, driblando o grande problema daquela época: a incompatibilidade entre plataformas.
Perceba que é possível fazer toda a parte do compilador detrás do código-objeto uma única vez e, conforme a necessidade, criar novos interpretadores BCPL para máquinas diferentes.
O código intermediário é gerado para uma máquina virtual. O interpretador, cerca de um quinto do compilador, tem a função de traduzir o código gerado para a máquina-alvo. Qualquer semelhança com Java ou .NET não é mera coincidência. Pois é. As boas idéias têm mais idade que seus criadores.
É inevitável também não fazer a associação entre essa forma de funcionamento do compilador BCPL e a divisão feita em C/C&#43;&#43; entre o pré-processador, o compilador e o ligador (linker, em inglês).
O uso do pré-processador na linguagem C facilitou a portabilidade por um bom tempo, quando não existiam typedefs. Diferente do BCPL, C já tinha tipagem, o que quer dizer que era necessário escolher o espaço de armazenamento que seria utilizado para as variáveis. Com o pré-processamento, essa escolha pode ser feita de maneira seletiva, documentada e generalizada.
Como é natural, o código-fonte de uma aplicação tende a crescer em muitas linhas durante sua evolução, especialmente se estamos falando de sistemas operacionais. A compilação desse código vai tomar cada vez mais tempo no processo de desenvolvimento. Por isso, manter esse código-fonte em um mesmo arquivo eventualmente torna-se inviável, tornando a compilação de módulos separados uma solução pra lá de elegante. Compila-se apenas o módulo que foi modificado e liga-se esse módulo com módulos pré-compilados.
Para saber mais:
 Bell Labs BCPL Reference Manual by Martin Richards Parte 2  </description>
</item>

     
        <item>
  <title>C and C&#43;&#43; Operators Precedence Table</title>
  <link>http://www.caloni.com.br/c-and-c-operators-precedence-table/</link>
  <pubDate>2007-07-30</pubDate>
  
  <guid>http://www.caloni.com.br/c-and-c-operators-precedence-table/</guid>
  <description> Wanderley, your explanation about why a program compiles in C&#43;&#43; and not in C seems to me logic and correct, but gave me some doubts, because I always learned that the C and C&#43;&#43; operator precedence are the same thing. I checked out the Appendix A in the &amp;quot;C &#43;&#43; - How To Program&amp;quot; (sixth edition) and the book table is equal to the C operators precedence table and it is different from the C&#43;&#43; precedence table presented by you in the article. I went to the internet and found out in two websites the table and both are equal to the book table.
From where did you get the presented C&#43;&#43; table?
[]s
Márcio Andrey Oliveira
 Dear Márcio,
You have been my most productive reader ever. Besides having found the portability fail using static variables inside ifs, now you put in check the precedence table comparison between these two languages. In fact, some things were not so clear in that post. Let&#39;s clarify everything now (or at least try) using trustworthy sources, including the Wikipedia link sent to me.
The first doubt it&#39;s about the most basic principle: what is a precedence table? Well, it is who defines, amount a set of concurrent operations in a language, which will be the evaluation order. In other words, who cames first, who cames next, etc. Through this table is possible to know all the language facts, as the fact that the multiplication operators are evaluated before the addition operators.
This way, the table can resolve 99% of the evaluation order issues in a language, but it is not perfect.
Let&#39;s see, by example, the conditional operator, most of the times known by ternary operator. Given its peculiar format, even having the precedence lower than the comma operator, the language doesn&#39;t allow a misinterpretation. If so,
will be interpreted as
and not as
that would be the logic result if we followed the precedence table, since the comma operator has lower precedence than the ternary operator. But that doesn&#39;t make any sense in the language, and that&#39;s why the first form is understood by the compiler, even contradicting the precedence table. This is corroborated by the following quote from Wikipedia:
 A precedence table, while mostly adequate, cannot resolve a few details. In particular, note that the ternary operator allows any arbitrary expression as its middle operand, despite being listed as having higher precedence than the assignment and comma operators.
 That is one of the reasons why the precedence table is just a way to express the grammar rules of a language in a simple and resumed manner. It is not the grammar neither ought to be. Let&#39;s see one more quotation, this time from the Stroustrup himself, just after presented the C&#43;&#43; precedence table (by the way, that was the source used by me to get the table for my post):
 A few grammar rules cannot be expressed in terms of precedence (also known as binding strength) and associativity.
 We can see from my example, the Wikipedia example and the Stroustrup example that the ternary operator is the main victim. Not for less. Talking about the grammar, the C ternary operator definition is different from the C&#43;&#43; ternary operator definition. While in C this operator is defined like this:
In C&#43;&#43; language it is defined like this:
This little difference can give us some (rare) situations where we can get a syntax error in C. As in a Wikipedia example , the following expression:
is interpreted by the C language as:
In the C&#43;&#43; language is interpreted as:
In the C language case, we have a compilation error because the code is trying to assign a value to a lvalue (remember that lvalues can&#39;t be assigned to anything).
But in C&#43;&#43; there&#39;s no invalid assignment, what makes a no error compilation performed.
Now, one last question, that seems to be the most relevant in this precedence issue:
Why is the Stroustrup book precedence table different from the C precedence table? Well, I believe that, after all our analysis, the answer must be somewhat obvious: knowing that, in the ternary operator, the third operand is an assignment-expression, it is most likely the table is agree with the grammar if we put a extra weight for the assignment operators before the ternary operator. This way, if the third operand is an assignment operation (as the case above), the imaginary parentesis will be put first in the assignment operation, making the grammar definition valid (green is in C&#43;&#43;; red is in C):
I hope this second post about the precedence table have cleared a bit more about the subject. Is not easy to understand the C language, but once you start to try, one magic door opens. Some things to remember from this experience:
 The precedence table is not in the Standard; it is deduced from the grammar rules. There are rare expressions where we can&#39;t use the precedence table (e.g. ternary operator). Nobody knows so well a language to the point to understand 100% from it; after all, nobody (and nothing) is perfect.  </description>
</item>

     
        <item>
  <title>Movendo o cursor do mouse com o teclado</title>
  <link>http://www.caloni.com.br/movendo-o-cursor-do-mouse-com-o-teclado/</link>
  <pubDate>2007-07-26</pubDate>
  
  <guid>http://www.caloni.com.br/movendo-o-cursor-do-mouse-com-o-teclado/</guid>
  <description>Bom, vamos deixar de papo furado e &amp;quot;codar&amp;quot;. Para essa primeira tentativa iremos desenvolver um programa que move o cursor do mouse quando pressionada uma tecla de atalho e voltar à sua posição original quando pressionada outra tecla.
Nota de desculpas: eu sei que estou sendo rabugento demais com o mouse. Já é o segundo artigo que escrevo falando como evitar o mouse e isso deve realmente irritar os fãs desse ponteirinho irritante.
Como eu já havia dito anteriormente, uso o mouse quando necessário. Quando ele não é necessário ele fica clicando inconscientemente no Windows Explorer, já que utilizo a configuração de clique único, onde as pastas e arquivos ficam selecionáveis apenas pousando o cursor sobre eles. Eu gosto dessa configuração, exceto pelo comportamento desagradável que ocorre quando mudo para a janela do Windows Explorer e meu mouse ganha vida própria, selecionando alguma pasta ou arquivo e mudando meu foco de seleção.
Portanto, o objetivo desse programa é simples e direto: mover o mouse para um canto enquanto eu uso meu teclado. Nada mais, nada menos. Para isso iremos registrar alguns atalhos globais no Windows. Para registrar atalhos globais no Windows utilizamos a função RegisterHotKey.
O importante aqui é saber que iremos ser avisados do pressionamento das teclas que registrarmos por meio dessa função através do loop de mensagens da thread que chamar a função.
Resumidamente, um loop de mensagens é a maneira definida pelo Windows para avisar as aplicações dos eventos que ocorrerem no sistema que são relevantes para as suas janelas. Teremos chance de observar isso mais vezes, mas por enquanto basta ter uma visão geral do fluxo de mensagens que ocorre quando digitarmos a nossa tecla de atalho:
Como você pode ver o código não tem muitos segredos. Para registrar os atalhos, usamos a função RegisterHotKey. Para manipular os eventos usamos o tal loop de mensagens e manipulamos a mensagem WMHOTKEY de acordo com a tecla pressionada. Para mover o mouse usamos a função SetCursorPos (e para armazenar a posição atual GetCursorPos). Por fim, para ler configurações de um .ini usamos a função GetPrivateProfileInt. Abaixo um exemplo desse arquivo texto:
Nota final: você acha que os atalhos &amp;quot;WinKey &#43; Del&amp;quot;, &amp;quot;WinKey &#43; Insert&amp;quot; e &amp;quot;WinKey &#43; End&amp;quot; foram uma má escolha? Concordo. Fiz de propósito. Que tal customizar o programa para que as teclas sejam lidas do arquivo de configuração HideCursor.ini?
</description>
</item>

     
        <item>
  <title>C&#43;&#43;0x parcial no novo GCC 4.3</title>
  <link>http://www.caloni.com.br/c0x-parcial-no-novo-gcc-43/</link>
  <pubDate>2007-07-24</pubDate>
  
  <guid>http://www.caloni.com.br/c0x-parcial-no-novo-gcc-43/</guid>
  <description>A nova versão do GCC implementa em caráter de teste algumas novas características da nova versão da linguagem C&#43;&#43;, que será lançada ainda nesta década (provavelmente em 2009). As novas funcionalidades são empolgantes e já fazem parte do imaginário dos programadores C&#43;&#43; já há algum tempo.
Atualmente temos duas maneiras de fazer asserções: usando a função assert (assert.h) ou utilizando a diretiva do pré-processador #error. Nenhum desses dois serve para templates. Para eles deverá ser definida a nova palavra-chave staticassert, que irá ser composta de dois parâmetros:
Podemos usá-la tanto no lugar da função assert quanto da diretiva #error. Mas seu uso mais interessante é como limite para a instanciação de templates:
Existem outros lugares onde esse novo comando pode ser usado. Para saber quando usá-lo, lembre-se que a verificação é feita durante a compilação, diferente do assert tradicional, que é chamada em tempo de execução.
Quem diria: depois de todos esse anos o pré-processador sofrerá um upgrade. O objetivo é ser compatível com o novo padrão da linguagem C, o C99. A maior novidade fica por conta do número variável de parâmetros para macros. A linha abaixo resume tudo:
Ou seja, não será mais necessário usar o truque dos &amp;quot;parênteses duplos&amp;quot; em macros de log que formatam parâmetros.
Considero essa mudança a mais interessante. Com ela será possível usar um número variável de parâmetros em templates. Basicamente isso permite que um dado template aceite um número variável de parâmetros e esses parâmetros sejam &amp;quot;expandidos&amp;quot; em inúmeras construções dentro do escopo desse template. Nada melhor para explicar que um exemplo, como o caso da herança múltipla. Imagine um template que precisa herdar de seus parâmetros, mas não quer especificar a quantidade:
Outras pequenas correções também serão feitas para tornar a linguagem mais robusta:
  Referências para lvalue.
  Parâmetros default em funções-template.
  Problema do fecha-templates duplo (&amp;gt;&amp;gt;).
  Podemos esperar por outras grandes mudanças que irão ocorrer nesse novo padrão? Não exatamente. As principais estarão na biblioteca C&#43;&#43;, com a inclusão de diversas classes e funções do projeto Boost. O resto são pequenas correções e melhorias de uma linguagem que, cá entre nós, já está bem poderosa e complexa.
</description>
</item>

     
        <item>
  <title>Antidebug: interpretação baseada em exceção (parte 1)</title>
  <link>http://www.caloni.com.br/antidebug-interpretacao-baseada-em-excecao-parte-1/</link>
  <pubDate>2007-07-20</pubDate>
  
  <guid>http://www.caloni.com.br/antidebug-interpretacao-baseada-em-excecao-parte-1/</guid>
  <description>Um depurador utiliza breakpoints para &amp;quot;paralisar&amp;quot; momentaneamente a execução do programa sendo depurado. Para isso ele se utiliza de uma bem conhecida instrução conhecida como int 3. Essa instrução gera uma exceção - exceção de breakpoint - que é capturada pelo sistema operacional e repassada para o código de tratamento dessa exceção. Em programas sendo depurados esse código está localizado no depurador. Em programas &amp;quot;livres&amp;quot; esse código normalmente não existe e ao acontecer essa exceção o aplicativo simplesmente &amp;quot;capota&amp;quot;.
A idéia principal na proteção baseada em exceção é tomarmos conta dessas exceções durante a execução do aplicativo. Fazendo isso podemos nos aproveitar desse fato e, no código responsável por tratar a exceção, executar o código protegido. A solução discutida aqui é parecido com um interpretador de scripts. Consiste basicamente de duas threads. A primeira thread lê uma seqüência de instruções e manda a segunda thread executá-las passo a passo. Para fazer isso a segunda thread usa um conjunto de pequenas funções com blocos de código bem definidos. Em pseudocódigo isso ficaria assim:
A proteção ainda não está aí. Mas fará parte intrínseca da thread de execução. Tudo que precisamos fazer é adicionar um tratamento de exceções e fazer chover ints 3. As exceções disparadas pela int 3 são capturadas por uma segunda função que antes de retornar o controle executa a próxima instrução enfileirada:
O algoritmo da thread de execução continua o mesmo. Só que o ponto onde cada instrução é executada depende do lançamento de uma exceção. Note que essa exceção tem que ocorrer para que a chamada da próxima instrução ocorra. Isso é fundamental, pois dessa forma ninguém pode simplesmente retirar o int 3 do código para evitar o lançamento da exceção. Se fizer isso, então mais nenhuma instrução será executada.
Na prática, se alguém tentar depurar um programa desse tipo vai ter que enfrentar dezenas ou centenas de lançamento de exceções até descobrir o que está acontecendo. Claro que, como em toda a proteção de software, ela não é definitiva; tem por função dificultar o trabalho de quem tenta entender o software. Isso não vai parar aqueles que são realmente bons no que fazem.
O preço pago por essa proteção fica na visibilidade e compreensão do código-fonte comprometidos pelo uso da técnica. A programação fica baseada em uma máquina de estados e as funções ficam limitadas a algum tipo de padronização no comportamento. Quando mais granular for o pseudoscript, ou seja, quanto menores forem os blocos de código contido nas minifunções, mais difícil de entender o código será.
O exemplo abaixo recebe entrada por um prompt de comandos e mapeia a primeira palavra digitada para o índice de uma função que deve ser chamada. O resto da linha digitada é passado como parâmetro para essa função. A thread de interpretação lê a entrada do usuário e escreve em uma variável-string global, ao mesmo tempo que a thread de execução espera essa string ser preenchida para executar a ação. Foi usado o pool dessa variável para o código ficar mais simples, mas o ideal seria algum tipo de sincronismo, como eventos, por exemplo.
O ponto forte da proteção é que a pessoa precisa entender o que está acontecendo para tomar alguma atitude inteligente para solucionar o &amp;quot;problema&amp;quot;. O ponto fraco é que após entendido o problema a solução torna-se fácil de visualizar. Tão fácil que eu nem pretendo citar aqui.
Futuramente veremos uma maneira de tornar as coisas mais legíveis e usáveis no dia-a-dia de um programador de software de segurança.
</description>
</item>

     
        <item>
  <title>Como ser um melhor desenvolvedor nos próximos seis meses</title>
  <link>http://www.caloni.com.br/como-ser-um-melhor-desenvolvedor-nos-proximos-seis-meses/</link>
  <pubDate>2007-07-18</pubDate>
  
  <guid>http://www.caloni.com.br/como-ser-um-melhor-desenvolvedor-nos-proximos-seis-meses/</guid>
  <description>Graças ao meu amigo Thiago estive acompanhando uma série de posts de gente renomada sobre o tema deste artigo. Eles fazem parte de uma nova modalidade entre os blogueiros (pelo menos para mim) chamada de tagging. Funciona assim: você escreve sobre algo (por exemplo, &amp;quot;como ser um melhor cozinheiro em 6 meses&amp;quot;) e manda uma tag para que outras pessoas também escrevam sobre o mesmo assunto, o que pode ser feito referenciando o sítio dessas pessoas.
Ainda não tive tempo de ler todos os artigos (nem vou ter, pela velocidade com que isso se espalha), mas acho que dá tempo de escrever um pouco sobre isso.
Acredito que nós, programadores/desenvolvedores/depuradores, tentamos aprimorar nossos conhecimentos e nossas técnicas com o objetivo de enxergar os problemas do dia-a-dia de todos os ângulos e de encará-los e resolvê-los da melhor maneira possível. Quer dizer, nós achamos que é a melhor maneira possível. E exatamente por acharmos que tentamos melhorar sempre, em busca da inalcançável perfeição.
O problema existe quando nós, embriagados pela falsa crença de sabermos tudo (ou o suficiente), acreditamos realmente que estamos fazendo o melhor possível e que não há nem haverá maneira de melhorar. É lógico que sempre há. Melhor maneira de ver isso é pegar um código-fonte antigo e observar as mudanças de estilo. E nem precisa ser tão antigo assim. E nem precisa ser código. Pode ser uma idéia antiga de como implementar alguma coisa. A não ser que você seja um teimoso que quer fazer tudo em assembly verá que o que aprendemos ontem influencia nas decisões de amanhã.
Minha lista não é muito diferente da dos outros. Basicamente se resume em: ler livros e blogs, programar mais e pensar mais ainda. O importante é que já estou ciente das coisas que devo melhorar, e é nelas que devo me focar nos próximos 180 dias:
 Fazer um curso de memorização. Confesso que não ligava muito para isso e agora isso faz um diferença e tanto. Eu sei que hoje temos post-its e agendas, mas nada substitui a confiança que temos em nossa própria mente. E é frustrante ler um livro três meses atrás e não se lembrar de capítulos inteiros. Fazer um curso de leitura dinâmica. Minha velocidade na leitura é deplorável e eu sei disso. Minha vontade de ler sempre ultrapassa o ato (isso deve ter acontecido com alguns de vocês). Mas o objetivo não é apenas ler mais rápido. É ter foco. Ler e absorver. Não estou dizendo isso de livros de ficção, que para mim são um entretenimento prazeroso. São os livros técnicos que pertubam, e urgem pela minha atenção quando os estou lendo. Aprender o meu ritmo. Às vezes me impressiono com o meu descaso para comigo mesmo. Por exemplo, eu já sabia que &amp;quot;rendia&amp;quot; bem mais quando lia livros simultaneamente, e não em fila. Mas mesmo assim insistia em querer terminar um livro antes de começar o outro. O resultado? Aproveitamento 60%. Nada mau. Mas poderia ser bem melhor. Bastava seguir o método que melhor se adapte às minhas necessidades. E isso é o que eu chamo de aprender a si mesmo.  Agora que já passei pelo sofrimento de taguear nada como escolher minhas vítimas. Não conheço pessoalmente muitos blogueiros, mas pelo menos essa minha lista é fiel e sincera. Rodrigo Strauss, Fernando Roberto e Thiago Oliveira: o que vocês farão nos próximos seis meses para se tornarem melhores desenvolvedores (ainda)?
</description>
</item>

     
        <item>
  <title>What happens inside the sizeof operator</title>
  <link>http://www.caloni.com.br/what-happens-inside-the-sizeof-operator/</link>
  <pubDate>2007-07-16</pubDate>
  
  <guid>http://www.caloni.com.br/what-happens-inside-the-sizeof-operator/</guid>
  <description>The question: how to get the size of a struct member without declaring it as a variable in memory? In pseudocode:
In this first try (even being a nice one) we can clearly see by instinct that the construction is not supposed to work. The compiler error is not even clear. The member access operator (the point sign) needs to have as its left some variable or constant of the same type of the struct. Since the operand is the type itself, there is no deal.
The second test is more feasible. Even the compiler can alert us. We have accessed the right member in the right struct but in the wrong way. As we&#39;re not using a static member or, in other words, a class variable, we can&#39;t access the member by scope. We need an object. But in order to have an object we are supposed to have to create one, and this is exactly what is not allowed in our solution.
This kind of problem reminds me about a curious feature inside the sizeof operator: it doesn&#39;t evaluate the expressions used as operands. How&#39;s that? Well, as the sizeof main purpose is to provide us the memory size filled by the expression, it simply doesn&#39;t make sense to execute the expression. We just need to note that the language we&#39;re talking about defends eficiency and clarity as main principles. If you want to execute the expression, we do it without using sizeof operator.
So, now we know that everything put inside a sizeof is not going to be executed in fact. It works somewhat like the c&#43;&#43; &amp;quot;dead zone&amp;quot;: is the place where - talking about executable code - nothing runs. That means we can build a object inside sizeof that nothing is going to happen, except for the expression size. Let&#39;s look the resulting assembly:
Another way to do the same thing (for those who can&#39;t bear the use of operator new delete, seeing the code as a memory leak):
Conclusion: the operator new is called and nothing happens. We got what we wanted. That shows us one more time that the little details built inside a language layout are only very important in the exact time we need them.
</description>
</item>

     
        <item>
  <title>Desejo insano de programar no kernel</title>
  <link>http://www.caloni.com.br/desejo-insano-de-programar-no-kernel/</link>
  <pubDate>2007-07-12</pubDate>
  
  <guid>http://www.caloni.com.br/desejo-insano-de-programar-no-kernel/</guid>
  <description>Muitas vezes meus amigos (um em particular) me perguntam por que não me interesso em programar em kernel mode, como se isso fosse um objetivo a ser alcançado por qualquer programador em user mode. Bom, não é.
Claro que sempre me empenho em entender como o sistema funciona, nos menores detalhes e sempre que posso, o que nem sempre me leva para o kernel mode (entender como a CLR funciona, por exemplo). Posso até me considerar um ser privilegiado, já que trabalho com dois experts em kernel mode e .NET, respectivamente. Isso já faz algum tempo, e ambos possuem conhecimento e experiência necessários para sanar minhas dúvidas mais cruéis. Porém, uma coisa é o conhecimento da coisa. Outra coisa é a prática. E a teoria, como já dizia o Sr. Heldai, na prática é outra.
Existem também aqueles programadores que, entorpecidos pela idéia de que seu software deve ser o mais baixo nível possível porque... bem, porque ele faz coisas muito profundas (?), ou é muito avançado (??), ou talvez até porque ele precisa ser otimizado ao máximo. Baseados nessas premissas (???), antes mesmo de conhecer o sistema operacional e pesquisar o que ele tem a oferecer que já está disponível em user mode partem direto para a programação nua e crua, pelo simples motivo de ser legal ou na ilusão de ser a melhor maneira de se fazer as coisas sob qualquer circunstância.
Munidos de bons motivos para fazer drivers, o próximo passo seria então pedir ajuda desesperadamente (e urgentemente) em listas de discussões. Talvez esse seja o lugar menos apropriado para procurar por uma palavra amiga. Acompanhei por um tempo uma lista de kernel do Windows. Apenas para efeitos de descrição, o clima e a impressão com que fiquei de lá foi que os programadores em kernel não se dão muito ao trabalho de ajudar aqueles que estão perdidos no ring0. Então para que existe a lista? Aparentemente para aqueles que já sabem fazer o carro andar, já conhecem o motor e um pouco de mecânica dos fluidos.
Digamos que é uma cultura bem diferente do que estamos acostumados a vivenciar em user mode. Eles estão muito mais ocupados com problemas relacionados especificamente com o desenvolvimento de drivers, e não dúvidas bestas do tipo &amp;quot;como eu faria isso&amp;quot;. Lá não se briga entre linguagens gerenciadas e não-gerenciadas (nem entre linguagens gerenciadas), mas entre linguagens C e C&#43;&#43;. Lá não se ajuda a fazer aquelas &amp;quot;gambis&amp;quot; que tanto ajudam o programador na hora do sufoco, mas sim redirecionam os hereges para o desenvolvimento &amp;quot;politicamente correto&amp;quot; (siga a documentação e seja feliz).
Isso não é uma crítica destrutiva, apenas uma descrição narrativa. Nada que falo aqui é exagero ou blasfêmia. Podem perguntar para o meu amigo de kernel mode. Aliás, use o blog dele para aprender um pouco sobre o kernel.
O fato é que bons programadores são bons onde quer que eles estejam (e os ruins serão ruins em qualquer lugar). E ser um desenvolvedor de qualidade exige tempo, dedicação, paciência e estudo. Pode ser um designer usando Action Script ou um engenheiro da NASA projetando foguetes. Tanto faz. Fazer as coisas com qualidade sempre exigirá mais tempo do que gostaríamos de despender. Não é uma questão de ser mais difícil em kernel mode ou mais fácil em Javascript. É saber qual dos dois será necessário usar para atingir o nível de funcionalidade e qualidade que o projeto exige. O resto é preconceito.
</description>
</item>

     
        <item>
  <title>Precedence difference</title>
  <link>http://www.caloni.com.br/precedence-difference/</link>
  <pubDate>2007-07-10</pubDate>
  
  <guid>http://www.caloni.com.br/precedence-difference/</guid>
  <description>Once upon a time my old friend Kabloc wrote this little and &amp;quot;harmless&amp;quot; function in order to print the multiplication table:
Despite the fact the result is a strong candidate to &amp;quot;The International Obfuscated C Code Contest&amp;quot;, the linux guys told him the code was not successful on GCC, and somewhere inside those four lines there was a non-standard piece of code.
Asked to solve the problem, given my congenital inclination to random subjects involving C&#43;&#43;, I decided to fix the things up in my old-n-good Visual Studio 2003. Nonetheless, it compiles C source code as well. We just need to rename the file from .cpp to .c. It was doing this that I found the following compiler error:
That happens in the line 6, the first for line. In other words, a C source that compiles as C&#43;&#43; but gives us a lack of l-value error since compiled as pure C.
Thinking about the problem rather intuitively than rationally I imagined that could be some little difference in the precedence table. Keeping that in mind, wrested the standard papers for both languages and took a look at the precedence tables.
Besides some now less important details, we can notice at the end of the table a inversion between the ternary operator and the attribution operator and, more importantly, the inversion of the evaluation order. In C, the ternary operator is evaluated from right to left, whilst in C&#43;&#43; from left to right, like the rest. This is going to shows us that, in line 6, the same expression has two different interpretations in each language.
In order to understand bit by bit the problem, let&#39;s disassemble the second part of that for:
We have two ternary operators nestled. In accordance with C&#43;&#43; standard, the ternary operators have less precedence than the attribution operators and are evaluated from left to right. In other words, in first place all the atributions inside the expression are made before any ternary operator. After that, the first ternary operator is executed, followed by the second:
The parts in red are the first ones to run, followed by the green ones and, finally, by the blue ones. This color priority is completely arbitrary. Of course, the colors you see in your text editor doesn&#39;t have anything to do with this explanation.
Now let&#39;t take a look in C. In this language, different from C&#43;&#43;, the ternary operators have more precedence than the attribution operators, and are executed from right to left. That means the first and last ternary operators are executed, ignoring the right attribution, and after that the first ternary operator is executed. Only after these two events the right attribution is evaluated:
All this make us to see the attribution to 12 will be done on the first ternary operator result, which possible values could be from the putchar return or f1. Remember about the comma operator purpose outside function calls: chain expressions, execute them and return the value from the rightmost expression:
Well, the f1 variable is an integer. And putchar return as well. This is not going to break any type rule. However, breaks the attribution gold rule: &amp;quot;put an lvalue in the right side of an attribution&amp;quot;.
This finishes the long explanation about why that little insignificant error at the beginning of this article happened only in the C language. This is a perfect example of the little differences between these two languages. Perhaps do you use parenthesis like a crazy, and are not going to find this kind of problems inside your source code. Perhaps not.
</description>
</item>

     
        <item>
  <title>Google shortcuts</title>
  <link>http://www.caloni.com.br/google-shortcuts/</link>
  <pubDate>2007-07-06</pubDate>
  
  <guid>http://www.caloni.com.br/google-shortcuts/</guid>
  <description>I do love shortcuts. Since my very first years using computers, shortcuts had become my obsession. I research them through the time, collecting them, using them. For a long time I avoid myself from touching the mouse, trainning to remember all keystroke sequences I know.
 I have nothing against using the mouse neither the people that do it. I&#39;m just not very much enthusiastic in using mice. For sometime, I even believed that the cursor pointer was getting me annoyed, so I developed a program to get rid of it from the screen (using a shortcut, of course). But, one more time, I&#39;m not againt its use, and I use it myself sometimes (when I need to).
 Until some time ago the web was not so good for shortcut users. So came out Google, plenty of web applications supporting shortcuts and giving me a true reason to use webmail and web RSS reader without pressing constantly the tab key. But there was a lack for its web search engine. Fortunately, there WAS.
Even being in test, I began to use the new keyboard shortcuts in Google search, available in the Google Experimental Search website. Until now there is shortcuts for next result (J), previous result (K), opening the search (O or Enter) and putting the cursor in the search box (/). It is just like Gmail and Google Reader. I was so excited with the idea that I changed the Google search plugin inside Firefox by myself. And now I&#39;m going to tell how to do it (note: Windows only).
Probably your search plugin will be in one of these two folder bellow. Try one of them:
The search plugin file has the name google.xml and you can edit it using notepad or another simple text editor. Bellow is the point where you must insert the new line that will get the plugin able to show the shortcuts inside Google.
That&#39;s all. Now you can get all the best: the best search engine with shortcuts. How can we be even more productive?
</description>
</item>

     
        <item>
  <title>Introdução ao SoftICE</title>
  <link>http://www.caloni.com.br/introducao-ao-softice/</link>
  <pubDate>2007-07-02</pubDate>
  
  <guid>http://www.caloni.com.br/introducao-ao-softice/</guid>
  <description>O que acontece quando você precisa depurar um programa e não tem o Visual Studio instalado na máquina onde o problema está ocorrendo? Ora, para isso que existe o Remote Debugging.aspx). Eu uso direto. Você só precisa rodar um pequeno programa na máquina que vai ser depurada e abrir uma porta ou duas. O resto o Visual Studio da máquina que vai depurar faz.
Tudo bem, mas e se estamos falando de depuração em kernel mode? Bem, nesse caso o mais indicado é o nosso já conhecido WinDbg. Só precisamos de um cabo serial, firewire ou USB conectando as duas máquinas.
A vida pode ser complicada às vezes. O WinDbg em versões antigas até rodava em plataforma 9x (95/98/ME), mas agora já não roda mais. Felizmente eu mantenho uma versão das antigonas, só para garantir. Só que ele rodava apenas para depurar em user mode, o que de qualquer forma não seria útil nesse caso.
Existe uma ferramenta de depuração no DDK do Windows 98 chamada WDEB386. Sua existência está documentada no próprio DKK. Funciona similarmente ao WinDbg, ou seja, o depurador em parte roda na máquina depurada e em parte na máquina que depura, e ambas são conectadas por um cabo serial. Teoricamente essa ferramenta serviria para depurar o kernel dos sistemas 9x, mas na maioria das vezes tive problemas com ela. Não que nunca tenha funcionado. Até já consegui essa proeza uma vez depois de muito ler a documentação e resolver uma série de problemas que não estavam documentados. Se você leitor quiser tentar a sorte, vá em frente.
Para piorar as coisas, existe mais um último problema: a máquina não está ao alcance de um cabo serial. Para esse último caso talvez fosse a hora de chamar um produto não-Microsoft que dá conta do recado muito bem: o SoftICE.
O SoftICE é um depurador de kernel e user mode que é instalado na própria máquina depurarada. Ou seja, ele não precisa de uma segunda máquina só para rodar o depurador ou parte dele. Funciona no MS-DOS (versão 16 bits), plataforma 9x e NT. Criado pela Numega, mais tarde foi comprado pela Compuware, que passou a vendê-lo como um pacote para desenvolvimento de drivers, o Driver Studio. No seu time de desenvolvimento passaram nomes consagrados como Matt Pietrek e Mark Russinovich.
Essa ferramenta teve seus dias de glória quando a maioria dos crackers a utilizava para quebrar a proteção de programas e do sistema operacional. Tanto foi famosa que foram desenvolvidas diversas técnicas para detectar se o SoftICE estava ativo na máquina, mais ou menos o equivalente das diversas técnicas atuais para detectar se um programa está sendo executado dentro de uma máquina virtual.
O SoftICE deve ser instalado na máquina do desenvolvedor para gerar os símbolos dos programas e na máquina que vai ser depurada para depurar. Isso quer dizer que ele não precisa ser ativado na máquina do desenvolvedor. Só precisamos usar uma ferramenta chamada Symbol Loader, responsável por gerar símbolos e empacotar os fontes para serem usados na máquina depurada.
Na hora de instalar, você tem três opções:
 Full installation: desenvolvimento e depuração; use se for desenvolver e depurar na mesma máquina. Host machine: apenas desenvolvimento; não serve para depuração. Target machine: depuração; instale essa opção na máquina de testes.  Após esse processo e a compilação do seu driver favorito podemos gerar os símbolos.
Obs. importante! Infelizmente, o Driver Studio só traduz os símbolos corretamente até a versão 6 do Visual C&#43;&#43;, ou seja, não inclui nenhuma das versões .NET do Visual Studio (2002/2003/2005&#43;). A Compuware se negou a oferecer suporte para os novos compiladores, talvez até prevendo que o produto iria ser descontinuado em breve.
A geração de símbolos pode ser feita de modo gráfico pelo Symbol Loader ou pela linha de comando. Vamos usar aqui a linha de comando para demonstrar como automatizar esse processo durante o processo de build:
As opções source e package são importantes para traduzir utilizando o código-fonte e empacotar esse código-fonte no arquivo gerado. Note que eu disse empacotar, o que significa que o fonte vai estar dentro do arquivo de símbolos. Portanto, se a licença do seu software é de código fechado, nunca se esqueça de apagar esse arquivo quando estiver na máquina de um cliente.
Se tudo der certo no final teremos dois arquivos a serem copiados para a máquina depurada:
Depois de copiados e o driver instalado, insira pelo Symbol Loader o arquivo NMS na lista de símbolos a serem carregados no reboot. Após configurar o depurador como lhe aprouver basta reiniciar a máquina. Feito o reboot, existe uma tecla mágica que irá nos levar para o mundo da tela preta, o ambiente padrão do SoftICE: Ctrl &#43; D.
A interface é divida em pseudojanelas que ficam organizadas em camadas. Para exibir/esconder as janelas ou especificar o tamanho de uma delas usa-se o comando w. Aliás, basta começar a digitar um comando e o programa irá listar os comandos possíveis.
Com certeza existe um monte de coisas novas para aprender quando se troca de depurador. Mais uma vez, assim como o WinDbg, temos a opção de utilizar o sistema de janelas ou a linha de comando. Aqui vão algumas dicas importantes:
 Para mostrar a tela do SoftICE, Ctrl &#43; D. Digite novamente e ela some e o sistema volta a rodar. Os nomes dos comandos se assemelham aos do WinDbg. Tente usá-los e sinta as diferenças. A ajuda do programa é muito boa e explica direitinho todos os detalhes do ambiente. Caso algo falhe, RTFM!  Essa parece ser uma introdução muito básica ao SoftICE. E na verdade é. Teremos outras oportunidades mais pra frente de usar esse poderoso depurador, principalmente naqueles casos onde um problema só acontece no Windows 95 Release A e sem rede. Isso não é tão incomum quanto parece.
</description>
</item>

     
        <item>
  <title>A Inteligência do if: Parte 2</title>
  <link>http://www.caloni.com.br/a-inteligencia-do-if-parte-2/</link>
  <pubDate>2007-06-29</pubDate>
  
  <guid>http://www.caloni.com.br/a-inteligencia-do-if-parte-2/</guid>
  <description>Vimos na primeira parte desse artigo como o if revolucionou o mundo da computação ao trazer um salto que depende de condições anteriores e, portanto, depende do estado do programa. A ele chamamos de salto condicional. Também vimos como o resto das construções lógicas de uma linguagem são apenas derivações montadas a partir de saltos condicionais e incondicionais. Nesta segunda parte veremos como implementar um saldo condicional baseando-se no fato de que o computador pode apenas realizar operações matemáticas. Afinal de contas, um computador não &amp;quot;pensa&amp;quot;.
Uma condição, item necessário para o funcionamento do salto condicional, nada mais é do que o conjunto de um cálculo matemático e o seu resultado, sendo o salto dependente desse resultado. Geralmente o resultado usado é uma flag, um indicador, definida pela arquitetura, como o armazenador de resultado para comparações de igualdade. Na plataforma 8086, por exemplo, as instruções que comparam memória definem uma flag chamada de Zero Flag (ZF) que é modificada sempre logo após executada uma instrução da categoria de comparações de valores.
É comum nas arquitetura o resultado de uma comparação ser igual a zero se os elementos são iguais e diferente de zero se são diferentes. O resultado, então, denota a diferença entre as memórias comparadas, e se não há diferença o resultado é zero.
set memA, 1set memB, 1cmp memA, memB # ZF=0set memA, 1set memB, 0cmp memA, memB # ZF=1 Mas como de fato comparar? Aí é que reside a mágica das portas lógicas e operações booleanas. A comparação acima pode ser feita com uma porta lógica XOR, o OU-eXclusivo, por exemplo, e o resultado pode ser obtido e armazenado se a saída for conectada a um flip-flop (um flip-flop, ou multivibrador biestável, é um circuito de computador capaz de armazenar o valor de 1 bit, o necessário para o nosso salto). Vamos por partes.
Uma porta lógica é uma série de circuitos que recebe uma ou mais entradas e que resulta em uma saída, sendo as entradas e a saída representadas pelo sinal 1 e 0. As portas lógicas costumam ser nomeadas pela sua função na lógica booleana. Dessa forma, uma porta AND, ou E, é uma porta em que a saída será 1 se todas as suas entradas forem 1, e 0 se pelo menos uma de suas entradas for 0.
Um flip-flop é o circuito que é usado para armazenar os resultados das portas lógicas de forma que após ter sido alimentado o valor não se perde. É o bloco mais fundamental de memória de um computador. Ele não se esquece depois que as entradas foram zeradas e pode ser reiniciado quando novas entradas forem fornecidas. É a maneira de gravar dados temporários na memória RAM da placa-mãe ou na memória cache do processador.
O flip-flop serve para que o valor do ZF permaneça após a instrução XOR entre os registradores que serão comparados. Eis como funciona: é usada uma porta lógica XOR para cada um dos bits dos valores comparados, fazendo com que qualquer bit diferente tenha uma saída 1. Se todos os bits dos valores comparados forem iguais a zero, significa que os valores são idênticos. Para agrupar todas essas saídas é usada uma porta lógica OR, fazendo com que um único bit diferente de zero (ou mais) reflita na saída. A saída da porta OR, por sua vez, é invertida através da porta NOT colocada antes do flip-flop. Ou seja, se os valores forem idênticos (saída zero da porta OR) a saída final será 1, do contrário será zero.
No final das contas, esse valor armazenado por um flip-flop é a flag ZF da arquitetura 8086. Se houver alguma diferença entre os valores, como foi o caso no exemplo acima, o valor final será o um invertido, ou seja, zero. Esse valor armazenado pode ser usado nas próximas instruções para realizar o salto, que dependerá do que estiver nessa flag. Dessa forma temos o nosso resultado realizado automaticamente através de um cálculo matemático.
Um salto incondicional, como vimos na parte um, é um salto para um outro ponto no código que vai ser feito de qualquer forma. Pode ser uma instrução do processador saltar para um endereço definido em algum lugar da memória. O goto possui como destino o endereço X, sendo que X depende do que estiver em seu próprio endereço.
001 set memA, 004002 jump memA003 code # not executed004 code005 ... Agora, para executar o salto condicional, precisamos não apenas de um, mas de dois endereços de destino, cada um deles com um endereço de memória. Podemos definir o primeiro endereço como o armazenador do salto se a condição for falsa, e o segundo endereço se a condição for verdadeira.
001 set memA, 006002 set memB, 005003 cmp memC, memD004 jz memA005 code # ZF=1006 code # ZF=0007 ... Se os valores em memC e memD forem iguais a comparação feita na linha 003 deixará o ZF igual a 0 e portanto o comando jz (jump if zero, saltar se zero) irá realizar o salto para a linha 006, que é o endereço contido em memA. Caso contrário não será feito o salto, ou seja, a próxima instrução será a da linha 005, a mesma contida em memB.
Agora você pode estar se perguntando por que existe o endereço em memB, já que se a condição for falsa o código simplesmente seguirá o fluxo normal. Bom, este memB é meramente figurativo, pois estou tentando demonstrar como não existe, de fato, uma &amp;quot;inteligência&amp;quot; na instrução de comparação que determine a igualdade de dois valores. Tudo se resume a circuitos realizando cálculos matemáticos.
Para isso continue imaginando o memB sendo usado como o endereço a ser usado caso a condição falhe. Esse endereço está localizado logo após o memA na memória. Se memA estiver em 080, memB estará em 081.
080 memA # 006081 memB # 005 Dessa forma, para executar o salto baseado em um resultado de 0 ou 1 (o Zero Flag) só temos que alterar o endereço da próxima instrução para o valor do endereço de comparação mais o valor de ZF, que pode ser 1 ou 0. Se for 0 será o próprio endereço da condição (memA), mas se for 1 será esse endereço mais 1 (ZF), ou seja, memB.
001 set memA, 006002 set memB, 005003 cmp memC, memD # muda ZF004 jump [memA &#43; ZF]005 code # ZF=1006 code # ZF=0007 ... Lembre-se que essa é apenas uma demonstração de como pode funcionar um salto condicional através de cálculos matemáticos. De maneira alguma estou afirmando que é feito dessa forma. Aliás, existem inúmeras formas de realizar esse salto. Uma segunda solução seria adicionar a defasagem (offset) entre o endereço da próxima instrução e o endereço do salto. Meu objetivo foi apenas ilustrar que, dado um problema, pode haver várias soluções. Talvez mais para a frente veremos como é implementado um if em assembly, subindo mais um nível de abstração. Por enquanto estamos apenas trabalhando no nível filosófico. O mais importante de todos.
</description>
</item>

     
        <item>
  <title>Disassembling the array operator</title>
  <link>http://www.caloni.com.br/disassembling-the-array-operator/</link>
  <pubDate>2007-06-22</pubDate>
  
  <guid>http://www.caloni.com.br/disassembling-the-array-operator/</guid>
  <description>Arrays are fascinating in C language because they are so simple and so powerful at the same time. When we start to really understand them and realize all its power we are very close to understand another awesome feature of the language: pointers.
When I was reading the K&amp;amp;R book (again) I was enjoying the language specification details in the Appendix A. It was specially odd the description as an array must be accessed:
A postfix expression followed by an expression in square brackets is a postfix expression. One of the expressions shall have the type &amp;quot;pointer to T&amp;quot; and the other shall have enumeration or integral type. The result is an lvalue of type &amp;quot;T&amp;quot;. (...) The expression E1 [ E2 ] is identical (by definition) to *( (E1) &#43; (E2) ).
Notice that the rules don&#39;t specify the order of expressions to access the array. In other words, it doesn&#39;t matter for the language if we use a pointer before the integer or an integer before the pointer.
The quote[index] bellow shows that we can use both orders and the code will compile successfully.
This code doesn&#39;t show how obscure we can be. If we use a constant integer replacing the index, by example, the code starts to be an IOCCC participant:
Is this a valid code yet, right? The expression types are following the rule. It is easy to see if we always think about using the &amp;quot;universal match&amp;quot; *( (E1) &#43; (E2) ). Even bizarre things like this are easy to realize:
Obs.: this kind of &amp;quot;obscure rule&amp;quot; hardly will pass in a code review since it is a useless feature. Be wise and don&#39;t use it in production code. This is just an amusing detail in the language specification scope. It can help in analysis, never in programming.
</description>
</item>

     
        <item>
  <title>Introdução ao Debugging Tools for Windows</title>
  <link>http://www.caloni.com.br/introducao-ao-debugging-tools-for-windows/</link>
  <pubDate>2007-06-20</pubDate>
  
  <guid>http://www.caloni.com.br/introducao-ao-debugging-tools-for-windows/</guid>
  <description>O WinDbg é uma ferramenta obrigatória em uma das minhas mais divertidas tarefas aqui na Open: engenharia reversa de cavalos de tróia. Não tenho o código-fonte desses programas, não posso executá-los em minha própria máquina e não consigo fazer tudo que preciso usando apenas o depurador integrado do Visual Studio (como remontar o assembly do programa, por exemplo). Tudo isso faz do WinDbg a alternativa perfeita (senão uma das únicas). É um depurador que permite ser usado tanto através de janelas quanto através de comandos, o que permite um aprendizado em doses homeopáticas: comece com as janelas e aos poucos ganhe o controle total. Conseqüentemente cada dia aprendo um comando novo ou um novo uso para um comando que já conheço.
Abaixo um esboço de como o WinDbg se parece, com suas principais janelas. A de comandos é a da direita.
Ele não está limitado apenas para engenharia reversa de código malévolo. Esse é o uso que eu faço dele. Meu amigo Thiago, por exemplo, resolve problemas em servidores que rodam código gerenciado com WinDbg. É a maneira ideal de depurar um problema em uma máquina onde o ambiente de desenvolvimento não está disponível nem pode ser instalado. Outro ponto relevante é que ele não depura apenas um programa em particular, mas pode ser usado para depurar um sistema inteiro. Chamado de kernel debugging, podemos usar esse modo de funcionamento para resolver os problemas que surgem logo depois de espetar algum periférico novo comprado na Santa Ifigênia.
Mas esse artigo não é apenas sobre o WinDbg. Ele não vem sozinho. É uma interface amigável para alguns depuradores linha de comando e outras ferramentas disponíveis no Debugging Tools for Windows, pacote disponível gratuitamente no sítio da Microsoft e atualizado geralmente de seis em seis meses. Nele podemos encontrar:
 CDB: depurador que roda em user mode e é uma &amp;quot;linha de comando agradável&amp;quot; para um programador avançado. NTSD: depurador que roda em user mode, da mesma forma que o CDB, mas também pode ser usado como um redirecionador de comandos para o depurador de kernel (logo abaixo). Existem algumas diferenças sutis entre esses dois depuradores (como o fato do NTSD não criar janelas quando usado como redirecionador), mas são diferenças que se aprendem no dia-a-dia. KD: depurador que roda em kernel mode, pode analisar dados do sistema local ou depurar um sistema remoto conectado através de um cabo serial ou por meio de um pipe criado por uma máquina virtual. Existem outros métodos mais avançados ainda para conseguir depurar uma máquina tão tão distante, por exemplo. Logger: _tracer _de chamadas de funções da API. Pode ser usado para análise de performance ou para fazer o que eu faço com os trojans, que é dar uma olhada nas funções que eles chamam constantemente. Logviewer: visualiza resultados do Logger. É o que abriremos depois de capturar as APIs chamadas por um programa através do logger.  Existem ainda outras ferramentas, mas estas são as principais que costumo utilizar. Para saber como usá-las de acordo com suas necessidades recomendo a leitura de um pequeno tutorial para o WinDbg que vem junto da instalação, o kerneldebuggingtutorial.doc. Ele é apenas a introdução dos principais comandos e técnicas. Depois de ter dominado o básico, pode partir para o arquivo de ajuda, que detalha de forma completa todos os comandos, técnicas e ferramentas de todo o pacote: o debugger.chm. A maioria dos comandos que precisava encontrei usando essa ajuda ou em alguns blogs muito bons. Acredite: no WinDbg, você quase sempre vai encontrar o comando que precisa.
Já baixei e instalei. E agora, o que eu faço? Para exemplificar um uso prático dessas ferramentas vamos usar o Loggerpara descobrir quais funções API estão sendo chamadas constantemente por um cavalo de tróia, uma coisa um tanto comum em ataques a bancos. Para tornar as coisas mais reais ainda vamos utilizar o código-fonte de um suposto cavalo de tróia usado em minhas apresentações:
Para compilar esse programa, você só precisa digitar os seguintes comandos em um console do Visual Studio:
O logger.exe possui uma extensão que pode ser usada pelo WinDbg para usar os mesmos comandos a partir do depurador. Mas para tornar as coisas mais fáceis nesse primeiro contato iremos iniciar o programa através do próprio executável:
Irá aparecer uma janela onde selecionamos o conjunto de APIs que serão capturadas. Podemos manter todas as categorias selecionadas e mandar rodar usando o botão &amp;quot;Go&amp;quot;.
Aguarde o programa executar por um tempo para termos um pouco de dados para analisar. Em minhas análises reais eu geralmente deixo ele atacar, seja no sítio real do banco ou em uma armadilha. Depois do ataque posso confirmar qual a API que ele utilizou. Se quiser fazer isso nesse teste basta criar uma janela que contenha o texto &amp;quot;Fict Bank&amp;quot; em seu título. Após isso, podemos finalizar o processo pelo Gerenciador de Tarefas:
Mesmo após finalizá-lo ele continuará na lista de processos, como se tivesse travado. Na verdade, a parte injetada do Logger mantém o processo no ar, em um estado semi-morto (ou semi-vivo). Depois de finalizar o Logger fechando sua janela principal ambos os processos terminam e podemos ler o resultado da captura em uma pasta chamada LogExts criada por padrão no Desktop ouÁrea de Trabalho. Podemos dar uma olhada nos resultados através do visualizador de logs gerados, o Logviewer.
Algumas colunas do Logviewersão tão úteis que vale a pena mencioná-las:
 Module: determina quem chamou a API, o próprio executável ou alguma DLL. Call Duration: tempo em milissegundos que a chamada da função demorou. API Function: o nome da função API que foi chamada. Return Value: o retorno da chamada da função.  De quebra ele exibe todos os parâmetros das funções de acordo com o tipo, identificando inclusive quando se trata de uma enumeração ou define reservado. Essa &amp;quot;mágica&amp;quot; é feita interpretando os headers que ficam na pasta &amp;quot;Debugging Tools for Windows\winext\manifest&amp;quot;, tarefa executada pelo Logger no início.
É só isso? O Debugging Tools é um pacote extremamente poderoso de ferramentas para programadores avançados. De maneira alguma conseguirei cobrir tudo que é possível fazer com essas ferramentas em apenas um blog. Porém, espero que essa pequena introdução seja o começo de uma série de artigos bem interessantes sobre debugging e uma série de testes realizados pelos meus leitores.
Seguem alguns blogs dedicados inteiramente ao assunto WinDbg e debugging:
 Microsoft Advanced Windows Debugging and Troubleshooting - site mantido pelo time de resolução de problemas críticos da Microsoft. Debugging Toolbox - blog mantido pelo Roberto Farah, contém muitos scripts para ser utilizando no Windbg. Crash Dump Analysis - uma exploração profunda na análise de telas azuis e o motivo delas existirem. WinDbg by Volker von Einem - como o autor mesmo diz, &amp;quot;uma coleção de utilidades para lidar com windbg&amp;quot;. Nynaeve - além de falar sobre debugging no Windows contém análises de engenharia reversa.  </description>
</item>

     
        <item>
  <title>A Inteligência do if: Parte 1</title>
  <link>http://www.caloni.com.br/a-inteligencia-do-if-parte-1/</link>
  <pubDate>2007-06-18</pubDate>
  
  <guid>http://www.caloni.com.br/a-inteligencia-do-if-parte-1/</guid>
  <description>No nível mais baixo, podemos dizer que as instruções de um computador se baseiam simplesmente em cálculos matemáticos e manipulação de memória. E entre os tipos de manipulação existe aquela que muda o endereço da próxima instrução que será executada. A essa manipulação damos o nome de salto.
O salto simples e direto permite a organização do código em subrotinas. Subrotinas permitem o reaproveitamento de código com parâmetros de entrada distintos, o que economiza memória, mas computacionalmente é &amp;quot;inútil&amp;quot;, já que pode ser implementado simplesmente pela repetição das mesmas subrotinas. O que eu quero dizer é que, do ponto de vista da execução, a mesma seqüência de instruções será executada. Pense no fluxo de execução de uma rotina que chama várias vezes a mesma subrotina:
sub:coderetroutine:codecall subcodecall subcodecall sub Ela é, na prática, equivalente à uma rotina que contém várias cópias da subrotina na memória, uma seguida da outra.
routine:codesub:codecodesub:codecodesub:code A grande sacada computacional não são subrotinas. O real motivo pelo qual hoje os computadores são tão úteis para os seres humanos é a invenção de um conceito chamado salto condicional. Ou seja, não é um salto certo, mas um salto que será executado caso a condição sob a qual ele está subordinado for verdadeira:
codeif cond:call subcodeif cond:call subcodeif cond:call subcode Os saltos condicionais, vulgarmente conhecidos como if, permitiram às linguagens de programação possuírem construções de execução mais sofisticadas: laços, iterações e seleção de caso. Claro que no fundo todas essas construções não passam de um conjunto formado por saltos condicionais e incondicionais. Peguemos o while e seu bloco, por exemplo. A construção em uma linguagem de programação possui uma condicional seguido de um bloco de código que se repete enquanto a condicional for verdadeira:
while cond:code Enquanto para o programador dessa fictícia linguagem existe um controle de execução no início que determina quando o código deixará de ser executado repetidamente, para o compilador o while não passa de um salto no final do bloco para o começo de um if.
label:if cond:codejump label O for, por outro lado, possui tradicionalmente em seu início três operações: inicialização, condição e incremento. O código começa executando a inicialização e verifica a condição uma primeira vez. Após executado o bloco de código condicionado ao for, o incremento será executado, e mais uma vez a condição verificada. Caso a condição seja verdadeira novamente o bloco de código volta a executar, para no final executar o incremento e verificar a condição, e assim por diante.
for: i = 0; i &amp;lt; 10; i&#43;&#43;code Do ponto de vista do compilador, que irá transformar esta lógica em código de máquina, o for não passa de um contador que é incrementado a cada iteração com um salto incondiconal no final do bloco de código executado.
i = 0label:if i &amp;lt; 10:codei&#43;&#43;jump label O switch-case, ou seleção, filtra um determinado valor em comparações de igualdade, a condição, em série. Quando é encontrada alguma igualdade verdadeira o código atrelado é executado e o código imediatamente seguinte ao switch é executado. Opcionalmente o bloco inteiro após uma seleção é ignorado.
switch i:case 0:codecase 1:codecase 2:codedefault:code Essa lógica embutida nas linguagens de programação são convertidas pelo compilador em vários ifs seguidos e unidos por um else, o que torna a comparação exclusiva. No final de cada bloco de código existe um salto incondicional para o final da construção.
if i = 0:codejump labelelif i = 1:codejump labelelif i = 2:codejump labelelse:codelabel: Neste artigo vimos como todas as construções de uma linguagem de programação, independente do seu nível, podem ser convertidas em um conjunto de saltos, condicionais e incondicionais. Em um próximo artigo veremos como o salto condicional verdadeiramente funciona, e como pode ser implementado usando apenas operações matemáticas. Afinal, matemática básica é o bloco lógico mais básico que temos em um computador. Qualquer computador.
</description>
</item>

     
    
  </channel>
</rss>
